{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING IN TEXT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.2\n",
      "1.1.3\n",
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322010, 20)\n"
     ]
    }
   ],
   "source": [
    "d_shuffle = pd.read_csv('C:\\\\Users\\\\mqian\\\\Documents\\\\senior schoolwork\\\\syslab\\\\data-3.txt',sep=',', header=0)\n",
    "print(d_shuffle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have balanced datasets, with each set having 171866 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322010, 1) (322010, 19)\n"
     ]
    }
   ],
   "source": [
    "y = d_shuffle[['Survival months']]\n",
    "x = d_shuffle.drop(columns='Survival months')\n",
    "print(y.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_neg_1 = pd.DataFrame(y.to_numpy(), columns=['Survival months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_0 = pd.DataFrame(y.to_numpy(), columns=['Survival months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Survival months\n",
      "0                     1\n",
      "1                     0\n",
      "2                     0\n",
      "3                     0\n",
      "4                     1\n",
      "...                 ...\n",
      "322005                1\n",
      "322006                0\n",
      "322007                0\n",
      "322008                1\n",
      "322009                1\n",
      "\n",
      "[322010 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "yy_0[yy_0['Survival months'] == -1] = 0 #did not survive\n",
    "print(yy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the activation/loss functions are different for the two models...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the X and y numpy arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(x, test_size=0.2, random_state=42)\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival months\n",
      "0                  128839\n",
      "1                  128769\n",
      "dtype: int64\n",
      "Survival months\n",
      "1                  32236\n",
      "0                  32166\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_0 = pd.DataFrame(y_test.to_numpy(), columns=['Survival months'])\n",
    "y_train_0 = pd.DataFrame(y_train.to_numpy(), columns=['Survival months'])\n",
    "\n",
    "y_test_0[y_test_0['Survival months'] == -1] = 0 #did not survive\n",
    "y_train_0[y_train_0['Survival months'] == -1] = 0 #did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1 = pd.DataFrame(y_test.to_numpy(), columns=['Survival months'])\n",
    "y_train_1 = pd.DataFrame(y_train.to_numpy(), columns=['Survival months'])\n",
    "\n",
    "y_test_1[y_test_0['Survival months'] == 0] = -1 #did not survive\n",
    "y_train_1[y_train_0['Survival months'] == 0] = -1 #did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survival months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64397</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64398</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64399</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64400</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64401</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64402 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survival months\n",
       "0                   -1\n",
       "1                   -1\n",
       "2                   -1\n",
       "3                   -1\n",
       "4                   -1\n",
       "...                ...\n",
       "64397               -1\n",
       "64398                1\n",
       "64399                1\n",
       "64400                1\n",
       "64401               -1\n",
       "\n",
       "[64402 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257608, 20)\n",
      "(64402, 20)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data-4-train.txt',sep=',', header=0)\n",
    "print(train.shape)\n",
    "test = pd.read_csv('data-4-test.txt',sep=',', header=0)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257608, 1) (257608, 19)\n",
      "(64402, 1) (64402, 19)\n"
     ]
    }
   ],
   "source": [
    "y_train = train[['19']]\n",
    "X_train = train.drop(columns='19')\n",
    "print(y_train.shape, X_train.shape)\n",
    "\n",
    "y_test = test[['19']]\n",
    "X_test = test.drop(columns='19')\n",
    "print(y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1 = pd.DataFrame(y_test.to_numpy(), columns=['Survival months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1 = pd.DataFrame(y_train.to_numpy(), columns=['Survival months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_0 = pd.DataFrame(y_test.to_numpy(), columns=['Survival months'])\n",
    "y_train_0 = pd.DataFrame(y_train.to_numpy(), columns=['Survival months'])\n",
    "\n",
    "y_test_0[y_test_1['Survival months'] == -1] = 0 #did not survive\n",
    "y_train_0[y_train_1['Survival months'] == -1] = 0 #did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savepickle(path, folder, filename, history):\n",
    "    with open (path+folder+'/'+filename, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "        \n",
    "# def readpickle(fname):\n",
    "#     pickle_file = open(fname)\n",
    "#     metrics_dict = pickle.load(pickle_file)\n",
    "#     return metrics_dict\n",
    "\n",
    "def plotdata(path, folder, filename, H):\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(path+folder+'/'+filename+\".png\")\n",
    "    plt.show()\n",
    "    print('done with plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "path = 'C:\\\\Users\\\\mqian\\\\Documents\\\\senior schoolwork\\\\syslab\\\\model\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Cycle Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 2s 4ms/step - loss: 0.9962 - accuracy: 0.2535\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_test, y_test_0, epochs=1, max_rate = 1, batch_size=128)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max_rate from the plot in find_learning_rate in the above function\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Decay LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```\n",
    "Reduce the learning rate factor of 10 every s steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from geron textbook for exponential \n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "steps = 20 \n",
    "initial_lr = 0.01\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=initial_lr, s=steps)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "#include in callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_5\\\\'\n",
    "num = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[19]),\n",
    "    keras.layers.Dense(200, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(150, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.experimental.RandomFourierFeatures(output_dim=50, kernel_initializer='gaussian'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.kernelized.RandomFourierFeatures"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.experimental.RandomFourierFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 19)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               4000      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "random_fourier_features_3 (R (None, 50)                5051      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 55,752\n",
      "Trainable params: 50,001\n",
      "Non-trainable params: 5,751\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='hinge',\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "NAME = \"Survivability-200-150-100-D-BN-He-newest-{0}-{1}\".format(time.time(), num)\n",
    "tensorboard = TensorBoard(log_dir=\"{0}\\\\logs\\\\{1}\".format(path, NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(path+folder+'best_try_'+num+'_1.h5', monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint, onecycle, tensorboard]\n",
    "#callbacks = [checkpoint, onecycle]\n",
    "#callbacks = [checkpoint, lr_scheduler]\n",
    "\n",
    "\n",
    "#figPath = os.path.sep.join([\"monitor\", plotnum+\"_{}.png\".format(os.getpid())])\n",
    "#jsonPath = os.path.sep.join([\"monitor\", plotnum+\"_{}.json\".format(os.getpid())])\n",
    "#callbacks = [ LearningRateScheduler(lr),checkpoint, TrainingMonitor(figPath, jsonPath=jsonPath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning further\n",
    "#model = keras.models.load_model('/cluster/2021mqian/snr research/recurrence_my_project/trial_2/'+'model_15'+'/best_try_'+'15'+'_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 15:36 - loss: 0.9915 - accuracy: 0.1641WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.9249s). Check your callbacks.\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9685 - accuracy: 0.2759\n",
      "Epoch 00001: val_loss improved from inf to 0.93491, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9685 - accuracy: 0.2760 - val_loss: 0.9349 - val_accuracy: 0.3292\n",
      "Epoch 2/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9426 - accuracy: 0.3008\n",
      "Epoch 00002: val_loss improved from 0.93491 to 0.93075, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9427 - accuracy: 0.3008 - val_loss: 0.9307 - val_accuracy: 0.3163\n",
      "Epoch 3/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9364 - accuracy: 0.2952\n",
      "Epoch 00003: val_loss improved from 0.93075 to 0.93050, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9364 - accuracy: 0.2952 - val_loss: 0.9305 - val_accuracy: 0.2988\n",
      "Epoch 4/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9341 - accuracy: 0.2942\n",
      "Epoch 00004: val_loss improved from 0.93050 to 0.92975, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9340 - accuracy: 0.2942 - val_loss: 0.9298 - val_accuracy: 0.2323\n",
      "Epoch 5/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9320 - accuracy: 0.2910\n",
      "Epoch 00005: val_loss improved from 0.92975 to 0.92685, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9321 - accuracy: 0.2909 - val_loss: 0.9269 - val_accuracy: 0.2886\n",
      "Epoch 6/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9315 - accuracy: 0.2926\n",
      "Epoch 00006: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9313 - accuracy: 0.2927 - val_loss: 0.9286 - val_accuracy: 0.2975\n",
      "Epoch 7/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9319 - accuracy: 0.2920\n",
      "Epoch 00007: val_loss improved from 0.92685 to 0.92591, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9319 - accuracy: 0.2920 - val_loss: 0.9259 - val_accuracy: 0.2934\n",
      "Epoch 8/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9309 - accuracy: 0.2853\n",
      "Epoch 00008: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9309 - accuracy: 0.2853 - val_loss: 0.9264 - val_accuracy: 0.3049\n",
      "Epoch 9/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.2833\n",
      "Epoch 00009: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9302 - accuracy: 0.2832 - val_loss: 0.9278 - val_accuracy: 0.2653\n",
      "Epoch 10/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9304 - accuracy: 0.2831\n",
      "Epoch 00010: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 13s 7ms/step - loss: 0.9303 - accuracy: 0.2832 - val_loss: 0.9275 - val_accuracy: 0.2969\n",
      "Epoch 11/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.2766\n",
      "Epoch 00011: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9300 - accuracy: 0.2766 - val_loss: 0.9288 - val_accuracy: 0.3184\n",
      "Epoch 12/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9301 - accuracy: 0.3003\n",
      "Epoch 00012: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9300 - accuracy: 0.3003 - val_loss: 0.9291 - val_accuracy: 0.2417\n",
      "Epoch 13/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9298 - accuracy: 0.2915\n",
      "Epoch 00013: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9298 - accuracy: 0.2914 - val_loss: 0.9293 - val_accuracy: 0.2348\n",
      "Epoch 14/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9310 - accuracy: 0.2947\n",
      "Epoch 00014: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9311 - accuracy: 0.2947 - val_loss: 0.9291 - val_accuracy: 0.3241\n",
      "Epoch 15/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9314 - accuracy: 0.2869\n",
      "Epoch 00015: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9314 - accuracy: 0.2869 - val_loss: 0.9285 - val_accuracy: 0.2640\n",
      "Epoch 16/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9310 - accuracy: 0.2795\n",
      "Epoch 00016: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9310 - accuracy: 0.2795 - val_loss: 0.9286 - val_accuracy: 0.2374\n",
      "Epoch 17/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9309 - accuracy: 0.3072\n",
      "Epoch 00017: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9309 - accuracy: 0.3072 - val_loss: 0.9274 - val_accuracy: 0.2919\n",
      "Epoch 18/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.2744\n",
      "Epoch 00018: val_loss did not improve from 0.92591\n",
      "2013/2013 [==============================] - 14s 7ms/step - loss: 0.9305 - accuracy: 0.2744 - val_loss: 0.9269 - val_accuracy: 0.2583\n",
      "Epoch 19/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.2920\n",
      "Epoch 00019: val_loss improved from 0.92591 to 0.92502, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9308 - accuracy: 0.2920 - val_loss: 0.9250 - val_accuracy: 0.2462\n",
      "Epoch 20/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.2907\n",
      "Epoch 00020: val_loss did not improve from 0.92502\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9307 - accuracy: 0.2906 - val_loss: 0.9256 - val_accuracy: 0.2418\n",
      "Epoch 21/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.3033\n",
      "Epoch 00021: val_loss did not improve from 0.92502\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9300 - accuracy: 0.3033 - val_loss: 0.9266 - val_accuracy: 0.3088\n",
      "Epoch 22/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9294 - accuracy: 0.2978\n",
      "Epoch 00022: val_loss did not improve from 0.92502\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9295 - accuracy: 0.2978 - val_loss: 0.9252 - val_accuracy: 0.2560\n",
      "Epoch 23/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9286 - accuracy: 0.2747\n",
      "Epoch 00023: val_loss did not improve from 0.92502\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9285 - accuracy: 0.2748 - val_loss: 0.9258 - val_accuracy: 0.2769\n",
      "Epoch 24/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.2844\n",
      "Epoch 00024: val_loss improved from 0.92502 to 0.92369, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9274 - accuracy: 0.2844 - val_loss: 0.9237 - val_accuracy: 0.2977\n",
      "Epoch 25/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9277 - accuracy: 0.2924\n",
      "Epoch 00025: val_loss did not improve from 0.92369\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9278 - accuracy: 0.2924 - val_loss: 0.9249 - val_accuracy: 0.3023\n",
      "Epoch 26/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9269 - accuracy: 0.2862\n",
      "Epoch 00026: val_loss did not improve from 0.92369\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9270 - accuracy: 0.2862 - val_loss: 0.9266 - val_accuracy: 0.2426\n",
      "Epoch 27/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.2820\n",
      "Epoch 00027: val_loss did not improve from 0.92369\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9274 - accuracy: 0.2822 - val_loss: 0.9256 - val_accuracy: 0.3173\n",
      "Epoch 28/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9260 - accuracy: 0.3005\n",
      "Epoch 00028: val_loss did not improve from 0.92369\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9260 - accuracy: 0.3005 - val_loss: 0.9238 - val_accuracy: 0.2925\n",
      "Epoch 29/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9263 - accuracy: 0.2997\n",
      "Epoch 00029: val_loss improved from 0.92369 to 0.92355, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 14s 7ms/step - loss: 0.9263 - accuracy: 0.2996 - val_loss: 0.9235 - val_accuracy: 0.2740\n",
      "Epoch 30/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9258 - accuracy: 0.2871\n",
      "Epoch 00030: val_loss improved from 0.92355 to 0.92185, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_5\\best_try_5_1.h5\n",
      "2013/2013 [==============================] - 14s 7ms/step - loss: 0.9258 - accuracy: 0.2871 - val_loss: 0.9218 - val_accuracy: 0.2650\n",
      "Epoch 31/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.2760 ETA: 0s - loss: 0.9264 - accuracy\n",
      "Epoch 00031: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 15s 7ms/step - loss: 0.9265 - accuracy: 0.2760 - val_loss: 0.9229 - val_accuracy: 0.2620\n",
      "Epoch 32/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9250 - accuracy: 0.2822\n",
      "Epoch 00032: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 17s 9ms/step - loss: 0.9250 - accuracy: 0.2822 - val_loss: 0.9235 - val_accuracy: 0.2951\n",
      "Epoch 33/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9258 - accuracy: 0.2919\n",
      "Epoch 00033: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9258 - accuracy: 0.2919 - val_loss: 0.9235 - val_accuracy: 0.2696\n",
      "Epoch 34/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9241 - accuracy: 0.2873\n",
      "Epoch 00034: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9241 - accuracy: 0.2873 - val_loss: 0.9226 - val_accuracy: 0.2853\n",
      "Epoch 35/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9249 - accuracy: 0.2902\n",
      "Epoch 00035: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9248 - accuracy: 0.2902 - val_loss: 0.9235 - val_accuracy: 0.2730\n",
      "Epoch 36/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9258 - accuracy: 0.2854\n",
      "Epoch 00036: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9256 - accuracy: 0.2854 - val_loss: 0.9229 - val_accuracy: 0.2798\n",
      "Epoch 37/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9250 - accuracy: 0.2941\n",
      "Epoch 00037: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9249 - accuracy: 0.2942 - val_loss: 0.9228 - val_accuracy: 0.2895\n",
      "Epoch 38/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9246 - accuracy: 0.2859\n",
      "Epoch 00038: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9245 - accuracy: 0.2859 - val_loss: 0.9228 - val_accuracy: 0.2721\n",
      "Epoch 39/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.2795\n",
      "Epoch 00039: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9242 - accuracy: 0.2795 - val_loss: 0.9222 - val_accuracy: 0.2676\n",
      "Epoch 40/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9238 - accuracy: 0.2812\n",
      "Epoch 00040: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9238 - accuracy: 0.2812 - val_loss: 0.9221 - val_accuracy: 0.2703\n",
      "Epoch 41/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9232 - accuracy: 0.2840\n",
      "Epoch 00041: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9232 - accuracy: 0.2840 - val_loss: 0.9222 - val_accuracy: 0.2772\n",
      "Epoch 42/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9229 - accuracy: 0.2865\n",
      "Epoch 00042: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 13s 6ms/step - loss: 0.9229 - accuracy: 0.2865 - val_loss: 0.9221 - val_accuracy: 0.2765\n",
      "Epoch 43/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9238 - accuracy: 0.2855\n",
      "Epoch 00043: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9238 - accuracy: 0.2855 - val_loss: 0.9224 - val_accuracy: 0.2807\n",
      "Epoch 44/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9235 - accuracy: 0.2862\n",
      "Epoch 00044: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9237 - accuracy: 0.2861 - val_loss: 0.9223 - val_accuracy: 0.2789\n",
      "Epoch 45/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9233 - accuracy: 0.2865\n",
      "Epoch 00045: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9231 - accuracy: 0.2865 - val_loss: 0.9223 - val_accuracy: 0.2803\n",
      "Epoch 46/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9222 - accuracy: 0.2872\n",
      "Epoch 00046: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9222 - accuracy: 0.2872 - val_loss: 0.9222 - val_accuracy: 0.2790\n",
      "Epoch 47/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.2867\n",
      "Epoch 00047: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 13s 6ms/step - loss: 0.9228 - accuracy: 0.2867 - val_loss: 0.9223 - val_accuracy: 0.2788\n",
      "Epoch 48/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9234 - accuracy: 0.2866\n",
      "Epoch 00048: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9234 - accuracy: 0.2866 - val_loss: 0.9223 - val_accuracy: 0.2767\n",
      "Epoch 49/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9231 - accuracy: 0.2861\n",
      "Epoch 00049: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9232 - accuracy: 0.2861 - val_loss: 0.9223 - val_accuracy: 0.2795\n",
      "Epoch 50/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.2867\n",
      "Epoch 00050: val_loss did not improve from 0.92185\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9230 - accuracy: 0.2866 - val_loss: 0.9222 - val_accuracy: 0.2781\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_0, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test_0), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepickle(path, folder, 'history_'+num+'_1', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n"
     ]
    }
   ],
   "source": [
    "plotdata(path, folder, 'plot_'+num+'_1', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(path+folder+'try_'+num+'_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('C:\\\\Users\\\\mqian\\\\Documents\\\\senior schoolwork\\\\syslab\\\\model\\\\'+folder+'best_try_'+num+'_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: RandomFourierFeatures",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e20e8229da3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\mqian\\\\Documents\\\\senior schoolwork\\\\syslab\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'best_try_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    180\u001b[0m     if (h5py is not None and (\n\u001b[0;32m    181\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 182\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     model = model_config_lib.model_from_config(model_config,\n\u001b[0m\u001b[0;32m    178\u001b[0m                                                custom_objects=custom_objects)\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    169\u001b[0m   \"\"\"\n\u001b[0;32m    170\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[0;32m    172\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'custom_objects'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         return cls.from_config(\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[0mcls_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             custom_objects=dict(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_config\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m       layer = layer_module.deserialize(layer_config,\n\u001b[0m\u001b[0;32m    487\u001b[0m                                        custom_objects=custom_objects)\n\u001b[0;32m    488\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    169\u001b[0m   \"\"\"\n\u001b[0;32m    170\u001b[0m   \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m   return generic_utils.deserialize_keras_object(\n\u001b[0m\u001b[0;32m    172\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;31m# In this case we are dealing with a Keras config dictionary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0m\u001b[0;32m    347\u001b[0m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[1;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    294\u001b[0m   \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown layer: RandomFourierFeatures"
     ]
    }
   ],
   "source": [
    "#For some reason, says Unknown layer: RandomFourierFeatures? But I used the same tensorflow version... \n",
    "#new_model = keras.models.load_model('C:\\\\Users\\\\mqian\\\\Documents\\\\senior schoolwork\\\\syslab\\\\'+folder+'best_try_'+num+'_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013/2013 [==============================] - 2s 854us/step - loss: 0.9206 - accuracy: 0.2843\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#save the model in each training\n",
    "#loop through the grid search parameters or use gridsearch cv\n",
    "#ok i think i will just do grid search without the CV ??? but gridsearch does use cross validation automatically \n",
    "lr = []\n",
    "regularization=[]\n",
    "KerasClassifier(callbacks - )\n",
    "grd=GridSearchCV\n",
    "#STEPS TO DO \n",
    "#1. REDO THE SCALING FOR MINMAX FOR TESTING AND TRAINING SETS *DONE* \n",
    "#1.5 SCALE DOWN THE NUMBER OF DATA THAT YOU ARE USING TO SPEED UP TRAINING (didn't do)\n",
    "#2. USE CROSS VALIDATION FOR THE MODEL SELECTION THAT REQUIRES CHANGES IN THE DATA (aka 2 end nodes) - (doing in next section)\n",
    "#3. USE CROSS VALIDATION ON THE GRID SEARCH (tried to do with dropout - I DID IN THIS SECTION)\n",
    "#4. FINE TUNE FROM THERE OR WRITE A CROSS VALIDATION USING UR OWN CODE CAUSE ITS JUST FOR LOOPS (going to code it later after school lulw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_36_norm\\\\'\n",
    "num = '36'\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "NAME = \"Survivability-200-150-100-D-BN-He-{0}-{1}\".format(time.time(), num)\n",
    "tensorboard = TensorBoard(log_dir=\"{0}\\\\logs\\\\{1}\".format(path, NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(path+folder+'best_try_'+num+'_1.h5', monitor=\"accuracy\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint, onecycle, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def create_model(dropout_rate=0.0): #model 35/29 same thing\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[19]),\n",
    "        keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.4530s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.55202, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.55202 to 0.56479, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.56479 to 0.56959, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.56959 to 0.57247, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.57247 to 0.57482, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.57482 to 0.57570, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.57570\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.57570 to 0.57623, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.57623 to 0.57859, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.57859\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.57859 to 0.57898, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.57898 to 0.58001, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.58001\n",
      "\n",
      "Epoch 00014: accuracy improved from 0.58001 to 0.58029, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00015: accuracy improved from 0.58029 to 0.58178, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00016: accuracy improved from 0.58178 to 0.58271, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.58271\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.58271\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.58271\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.58271\n",
      "\n",
      "Epoch 00021: accuracy improved from 0.58271 to 0.58338, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.58338\n",
      "\n",
      "Epoch 00023: accuracy improved from 0.58338 to 0.58420, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.58420\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.58420\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.58420\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.58420\n",
      "\n",
      "Epoch 00028: accuracy improved from 0.58420 to 0.58501, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00029: accuracy improved from 0.58501 to 0.58592, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.58592\n",
      "\n",
      "Epoch 00031: accuracy improved from 0.58592 to 0.58619, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00032: accuracy improved from 0.58619 to 0.58635, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00033: accuracy improved from 0.58635 to 0.58726, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.58726\n",
      "\n",
      "Epoch 00035: accuracy improved from 0.58726 to 0.58826, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00036: accuracy improved from 0.58826 to 0.58897, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00037: accuracy improved from 0.58897 to 0.59005, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00038: accuracy improved from 0.59005 to 0.59063, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00039: accuracy improved from 0.59063 to 0.59212, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00040: accuracy improved from 0.59212 to 0.59279, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00041: accuracy improved from 0.59279 to 0.59495, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.59495\n",
      "\n",
      "Epoch 00043: accuracy improved from 0.59495 to 0.59618, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00044: accuracy improved from 0.59618 to 0.59747, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00045: accuracy improved from 0.59747 to 0.59796, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00046: accuracy improved from 0.59796 to 0.59962, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00047: accuracy improved from 0.59962 to 0.59998, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00048: accuracy improved from 0.59998 to 0.60178, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00049: accuracy improved from 0.60178 to 0.60351, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_36_norm\\best_try_36_1.h5\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 1.0306s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.4945s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.5182s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.7876s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.5150s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_train_batch_end` time: 0.7910s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0079s vs `on_train_batch_end` time: 0.7888s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.4908s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.7848s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.7939s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.5121s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.5150s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.7854s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.8174s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.5500s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.5954s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0115s vs `on_train_batch_end` time: 0.5011s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0083s vs `on_train_batch_end` time: 0.5019s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.5148s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0119s vs `on_train_batch_end` time: 0.5058s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.5172s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0109s vs `on_train_batch_end` time: 0.5313s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.6130s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.8118s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.5445s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.4897s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.5714s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.4958s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.5142s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.8189s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00002: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00003: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00005: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00006: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00008: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00009: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00010: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00031: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00040: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.60351\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.60351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "call = {'callbacks':callbacks}\n",
    "\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate)\n",
    "grid = GridSearchCV(estimator = model, param_grid=param_grid, n_jobs=1, cv=3, scoring='accuracy')\n",
    "grid_result=grid.fit(X_train, y_train_0, **call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.557281 using {'dropout_rate': 0.0}\n",
      "0.557281 (0.021953) with: {'dropout_rate': 0.0}\n",
      "0.526769 (0.006755) with: {'dropout_rate': 0.1}\n",
      "0.519770 (0.004419) with: {'dropout_rate': 0.2}\n",
      "0.522332 (0.003544) with: {'dropout_rate': 0.3}\n",
      "0.523272 (0.004472) with: {'dropout_rate': 0.4}\n",
      "0.520469 (0.006463) with: {'dropout_rate': 0.5}\n",
      "0.516133 (0.007147) with: {'dropout_rate': 0.6}\n",
      "0.517725 (0.006307) with: {'dropout_rate': 0.7}\n",
      "0.508241 (0.005404) with: {'dropout_rate': 0.8}\n",
      "0.501875 (0.003538) with: {'dropout_rate': 0.9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([220.97976987, 191.79969645, 192.56027269, 191.46967753,\n",
       "        191.15229789, 190.56254896, 195.66119432, 189.91678031,\n",
       "        190.26673905, 189.32322439]),\n",
       " 'std_fit_time': array([19.84288681,  3.79740669,  2.75849298,  1.45684184,  0.92014618,\n",
       "         2.53589331, 10.28885864,  0.9920326 ,  0.66685109,  1.41815925]),\n",
       " 'mean_score_time': array([0.66475813, 0.67857424, 0.51151379, 0.55987461, 0.5749201 ,\n",
       "        0.53557475, 0.50964491, 0.50394424, 0.51097155, 0.52482931]),\n",
       " 'std_score_time': array([0.06561047, 0.11502584, 0.01902492, 0.02637318, 0.07053564,\n",
       "        0.0102225 , 0.00740586, 0.0081498 , 0.02068512, 0.0135767 ]),\n",
       " 'param_dropout_rate': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'dropout_rate': 0.0},\n",
       "  {'dropout_rate': 0.1},\n",
       "  {'dropout_rate': 0.2},\n",
       "  {'dropout_rate': 0.3},\n",
       "  {'dropout_rate': 0.4},\n",
       "  {'dropout_rate': 0.5},\n",
       "  {'dropout_rate': 0.6},\n",
       "  {'dropout_rate': 0.7},\n",
       "  {'dropout_rate': 0.8},\n",
       "  {'dropout_rate': 0.9}],\n",
       " 'split0_test_score': array([0.56769535, 0.52043787, 0.52566671, 0.52664493, 0.51834168,\n",
       "        0.51359031, 0.51425411, 0.52245254, 0.51378828, 0.50251543]),\n",
       " 'split1_test_score': array([0.57740279, 0.53613062, 0.51861557, 0.51796341, 0.52916652,\n",
       "        0.51869709, 0.50847221, 0.52191128, 0.50091418, 0.49725745]),\n",
       " 'split2_test_score': array([0.52674423, 0.52373965, 0.51502871, 0.52238875, 0.52230724,\n",
       "        0.52911994, 0.52567283, 0.50880993, 0.51002108, 0.50585194]),\n",
       " 'mean_test_score': array([0.55728079, 0.52676938, 0.51977033, 0.52233236, 0.52327181,\n",
       "        0.52046911, 0.51613305, 0.51772459, 0.50824118, 0.50187494]),\n",
       " 'std_test_score': array([0.02195328, 0.00675525, 0.00441904, 0.00354444, 0.00447155,\n",
       "        0.00646258, 0.00714671, 0.00630748, 0.00540442, 0.00353779]),\n",
       " 'rank_test_score': array([ 1,  2,  6,  4,  3,  5,  8,  7,  9, 10])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model(0.0)\n",
    "model1.load_weights('C:\\\\Users\\\\mqian\\\\Documents\\\\senior schoolwork\\\\syslab\\\\model\\\\'+folder+'best_try_'+num+'_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013/2013 [==============================] - 2s 873us/step - loss: 0.6992 - accuracy: 0.5639\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model1.evaluate(X_test, y_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savepickle(path, folder, filename, history):\n",
    "    with open (path+folder+'/'+filename, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepickle(path, folder, 'history_'+num+'_1', grid_result.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_10\\\\'\n",
    "num = '10'\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 37:49 - loss: 1.0187 - accuracy: 0.4922WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0109s vs `on_train_batch_end` time: 2.2436s). Check your callbacks.\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9976 - accuracy: 0.5060\n",
      "Epoch 00001: val_loss improved from inf to 0.98519, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9974 - accuracy: 0.5061 - val_loss: 0.9852 - val_accuracy: 0.5410\n",
      "Epoch 2/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9881 - accuracy: 0.5235\n",
      "Epoch 00002: val_loss improved from 0.98519 to 0.95906, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9880 - accuracy: 0.5237 - val_loss: 0.9591 - val_accuracy: 0.5555\n",
      "Epoch 3/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9674 - accuracy: 0.5436\n",
      "Epoch 00003: val_loss improved from 0.95906 to 0.94183, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9673 - accuracy: 0.5436 - val_loss: 0.9418 - val_accuracy: 0.5611\n",
      "Epoch 4/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9539 - accuracy: 0.5510\n",
      "Epoch 00004: val_loss improved from 0.94183 to 0.93766, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9539 - accuracy: 0.5510 - val_loss: 0.9377 - val_accuracy: 0.5635\n",
      "Epoch 5/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9472 - accuracy: 0.5555\n",
      "Epoch 00005: val_loss improved from 0.93766 to 0.93534, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9472 - accuracy: 0.5555 - val_loss: 0.9353 - val_accuracy: 0.5657\n",
      "Epoch 6/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9439 - accuracy: 0.5577\n",
      "Epoch 00006: val_loss improved from 0.93534 to 0.93527, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9440 - accuracy: 0.5577 - val_loss: 0.9353 - val_accuracy: 0.5650\n",
      "Epoch 7/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9399 - accuracy: 0.5609\n",
      "Epoch 00007: val_loss improved from 0.93527 to 0.93228, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9399 - accuracy: 0.5609 - val_loss: 0.9323 - val_accuracy: 0.5687\n",
      "Epoch 8/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9389 - accuracy: 0.5619\n",
      "Epoch 00008: val_loss did not improve from 0.93228\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9386 - accuracy: 0.5620 - val_loss: 0.9340 - val_accuracy: 0.5663\n",
      "Epoch 9/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5636\n",
      "Epoch 00009: val_loss did not improve from 0.93228\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9369 - accuracy: 0.5636 - val_loss: 0.9329 - val_accuracy: 0.5672\n",
      "Epoch 10/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5635\n",
      "Epoch 00010: val_loss improved from 0.93228 to 0.93193, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9367 - accuracy: 0.5635 - val_loss: 0.9319 - val_accuracy: 0.5687\n",
      "Epoch 11/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9352 - accuracy: 0.5654\n",
      "Epoch 00011: val_loss did not improve from 0.93193\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9352 - accuracy: 0.5654 - val_loss: 0.9345 - val_accuracy: 0.5660\n",
      "Epoch 12/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5635\n",
      "Epoch 00012: val_loss improved from 0.93193 to 0.93049, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9366 - accuracy: 0.5635 - val_loss: 0.9305 - val_accuracy: 0.5700\n",
      "Epoch 13/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5667\n",
      "Epoch 00013: val_loss did not improve from 0.93049\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9334 - accuracy: 0.5667 - val_loss: 0.9307 - val_accuracy: 0.5700\n",
      "Epoch 14/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9343 - accuracy: 0.5660\n",
      "Epoch 00014: val_loss did not improve from 0.93049\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9342 - accuracy: 0.5660 - val_loss: 0.9316 - val_accuracy: 0.5684\n",
      "Epoch 15/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9326 - accuracy: 0.5676\n",
      "Epoch 00015: val_loss did not improve from 0.93049\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9326 - accuracy: 0.5677 - val_loss: 0.9327 - val_accuracy: 0.5679\n",
      "Epoch 16/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9335 - accuracy: 0.5669\n",
      "Epoch 00016: val_loss did not improve from 0.93049\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9336 - accuracy: 0.5668 - val_loss: 0.9332 - val_accuracy: 0.5672\n",
      "Epoch 17/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9341 - accuracy: 0.5660\n",
      "Epoch 00017: val_loss did not improve from 0.93049\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9339 - accuracy: 0.5661 - val_loss: 0.9372 - val_accuracy: 0.5635\n",
      "Epoch 18/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9362 - accuracy: 0.5639\n",
      "Epoch 00018: val_loss did not improve from 0.93049\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9362 - accuracy: 0.5639 - val_loss: 0.9314 - val_accuracy: 0.5691\n",
      "Epoch 19/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9359 - accuracy: 0.5642 ETA: 0s - loss: 0.9361 - accu\n",
      "Epoch 00019: val_loss improved from 0.93049 to 0.92952, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9359 - accuracy: 0.5642 - val_loss: 0.9295 - val_accuracy: 0.5710\n",
      "Epoch 20/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.5660\n",
      "Epoch 00020: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9339 - accuracy: 0.5661 - val_loss: 0.9406 - val_accuracy: 0.5597\n",
      "Epoch 21/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9361 - accuracy: 0.5639\n",
      "Epoch 00021: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9361 - accuracy: 0.5639 - val_loss: 0.9345 - val_accuracy: 0.5661\n",
      "Epoch 22/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9350 - accuracy: 0.5651\n",
      "Epoch 00022: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9351 - accuracy: 0.5650 - val_loss: 0.9337 - val_accuracy: 0.5667\n",
      "Epoch 23/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5651\n",
      "Epoch 00023: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9351 - accuracy: 0.5650 - val_loss: 0.9447 - val_accuracy: 0.5556\n",
      "Epoch 24/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.5646\n",
      "Epoch 00024: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9354 - accuracy: 0.5646 - val_loss: 0.9298 - val_accuracy: 0.5702\n",
      "Epoch 25/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5666\n",
      "Epoch 00025: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9333 - accuracy: 0.5666 - val_loss: 0.9304 - val_accuracy: 0.5699\n",
      "Epoch 26/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9337 - accuracy: 0.5661\n",
      "Epoch 00026: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9337 - accuracy: 0.5662 - val_loss: 0.9317 - val_accuracy: 0.5689\n",
      "Epoch 27/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9335 - accuracy: 0.5666\n",
      "Epoch 00027: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9334 - accuracy: 0.5666 - val_loss: 0.9308 - val_accuracy: 0.5695\n",
      "Epoch 28/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9329 - accuracy: 0.5670\n",
      "Epoch 00028: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 13s 6ms/step - loss: 0.9329 - accuracy: 0.5670 - val_loss: 0.9372 - val_accuracy: 0.5632\n",
      "Epoch 29/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9326 - accuracy: 0.5675\n",
      "Epoch 00029: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9326 - accuracy: 0.5675 - val_loss: 0.9336 - val_accuracy: 0.5666\n",
      "Epoch 30/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9322 - accuracy: 0.5678\n",
      "Epoch 00030: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9321 - accuracy: 0.5678 - val_loss: 0.9339 - val_accuracy: 0.5666\n",
      "Epoch 31/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9315 - accuracy: 0.5685\n",
      "Epoch 00031: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9315 - accuracy: 0.5685 - val_loss: 0.9325 - val_accuracy: 0.5680\n",
      "Epoch 32/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9335 - accuracy: 0.5665\n",
      "Epoch 00032: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9335 - accuracy: 0.5665 - val_loss: 0.9312 - val_accuracy: 0.5692\n",
      "Epoch 33/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9314 - accuracy: 0.5685\n",
      "Epoch 00033: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9314 - accuracy: 0.5686 - val_loss: 0.9337 - val_accuracy: 0.5667\n",
      "Epoch 34/50\n",
      "1999/2013 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.5677\n",
      "Epoch 00034: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9324 - accuracy: 0.5676 - val_loss: 0.9314 - val_accuracy: 0.5689\n",
      "Epoch 35/50\n",
      "1999/2013 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.5676\n",
      "Epoch 00035: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 7s 4ms/step - loss: 0.9322 - accuracy: 0.5678 - val_loss: 0.9307 - val_accuracy: 0.5696\n",
      "Epoch 36/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9310 - accuracy: 0.5691\n",
      "Epoch 00036: val_loss did not improve from 0.92952\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9310 - accuracy: 0.5690 - val_loss: 0.9338 - val_accuracy: 0.5666\n",
      "Epoch 37/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9304 - accuracy: 0.5696\n",
      "Epoch 00037: val_loss improved from 0.92952 to 0.92879, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9305 - accuracy: 0.5695 - val_loss: 0.9288 - val_accuracy: 0.5713\n",
      "Epoch 38/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.5701\n",
      "Epoch 00038: val_loss did not improve from 0.92879\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9300 - accuracy: 0.5701 - val_loss: 0.9311 - val_accuracy: 0.5694\n",
      "Epoch 39/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.5712\n",
      "Epoch 00039: val_loss improved from 0.92879 to 0.92827, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9288 - accuracy: 0.5712 - val_loss: 0.9283 - val_accuracy: 0.5721\n",
      "Epoch 40/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9296 - accuracy: 0.5702\n",
      "Epoch 00040: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9296 - accuracy: 0.5703 - val_loss: 0.9296 - val_accuracy: 0.5707\n",
      "Epoch 41/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9287 - accuracy: 0.5713\n",
      "Epoch 00041: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9287 - accuracy: 0.5713 - val_loss: 0.9307 - val_accuracy: 0.5697\n",
      "Epoch 42/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9288 - accuracy: 0.5711\n",
      "Epoch 00042: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9288 - accuracy: 0.5711 - val_loss: 0.9297 - val_accuracy: 0.5705\n",
      "Epoch 43/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.5711\n",
      "Epoch 00043: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9288 - accuracy: 0.5711 - val_loss: 0.9285 - val_accuracy: 0.5717\n",
      "Epoch 44/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9284 - accuracy: 0.5715\n",
      "Epoch 00044: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9284 - accuracy: 0.5715 - val_loss: 0.9296 - val_accuracy: 0.5708\n",
      "Epoch 45/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9277 - accuracy: 0.5723\n",
      "Epoch 00045: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9278 - accuracy: 0.5723 - val_loss: 0.9288 - val_accuracy: 0.5716\n",
      "Epoch 46/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9283 - accuracy: 0.5717\n",
      "Epoch 00046: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9283 - accuracy: 0.5717 - val_loss: 0.9308 - val_accuracy: 0.5693\n",
      "Epoch 47/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9277 - accuracy: 0.5721\n",
      "Epoch 00047: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9278 - accuracy: 0.5721 - val_loss: 0.9297 - val_accuracy: 0.5704\n",
      "Epoch 48/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9270 - accuracy: 0.5730\n",
      "Epoch 00048: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9270 - accuracy: 0.5729 - val_loss: 0.9293 - val_accuracy: 0.5711\n",
      "Epoch 49/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9279 - accuracy: 0.5722\n",
      "Epoch 00049: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9277 - accuracy: 0.5723 - val_loss: 0.9292 - val_accuracy: 0.5712\n",
      "Epoch 50/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.5726\n",
      "Epoch 00050: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9274 - accuracy: 0.5725 - val_loss: 0.9291 - val_accuracy: 0.5711\n",
      "accuracy: 57.11%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 31:47 - loss: 1.0376 - accuracy: 0.4492WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_train_batch_end` time: 1.8856s). Check your callbacks.\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9973 - accuracy: 0.5064\n",
      "Epoch 00001: val_loss improved from inf to 0.98120, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9973 - accuracy: 0.5064 - val_loss: 0.9812 - val_accuracy: 0.5397\n",
      "Epoch 2/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9881 - accuracy: 0.5212\n",
      "Epoch 00002: val_loss improved from 0.98120 to 0.95817, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9881 - accuracy: 0.5212 - val_loss: 0.9582 - val_accuracy: 0.5502\n",
      "Epoch 3/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9716 - accuracy: 0.5371 ETA: 2s - loss: 0 - ETA: 1s - loss:\n",
      "Epoch 00003: val_loss improved from 0.95817 to 0.94635, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9716 - accuracy: 0.5371 - val_loss: 0.9463 - val_accuracy: 0.5563\n",
      "Epoch 4/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9567 - accuracy: 0.54 - ETA: 0s - loss: 0.9564 - accuracy: 0.5492\n",
      "Epoch 00004: val_loss improved from 0.94635 to 0.94253, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9564 - accuracy: 0.5491 - val_loss: 0.9425 - val_accuracy: 0.5589\n",
      "Epoch 5/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9475 - accuracy: 0.5553\n",
      "Epoch 00005: val_loss improved from 0.94253 to 0.93960, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9475 - accuracy: 0.5554 - val_loss: 0.9396 - val_accuracy: 0.5610\n",
      "Epoch 6/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9426 - accuracy: 0.5587\n",
      "Epoch 00006: val_loss improved from 0.93960 to 0.93833, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9428 - accuracy: 0.5586 - val_loss: 0.9383 - val_accuracy: 0.5623\n",
      "Epoch 7/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9413 - accuracy: 0.5596\n",
      "Epoch 00007: val_loss improved from 0.93833 to 0.93585, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9412 - accuracy: 0.5597 - val_loss: 0.9358 - val_accuracy: 0.5645\n",
      "Epoch 8/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9393 - accuracy: 0.5616\n",
      "Epoch 00008: val_loss improved from 0.93585 to 0.93480, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9390 - accuracy: 0.5617 - val_loss: 0.9348 - val_accuracy: 0.5652\n",
      "Epoch 9/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9370 - accuracy: 0.5632\n",
      "Epoch 00009: val_loss improved from 0.93480 to 0.93227, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9370 - accuracy: 0.5632 - val_loss: 0.9323 - val_accuracy: 0.5680\n",
      "Epoch 10/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9356 - accuracy: 0.5649\n",
      "Epoch 00010: val_loss improved from 0.93227 to 0.93208, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9355 - accuracy: 0.5650 - val_loss: 0.9321 - val_accuracy: 0.5683\n",
      "Epoch 11/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.5647 ETA: 0s - loss: 0.9\n",
      "Epoch 00011: val_loss improved from 0.93208 to 0.93020, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9354 - accuracy: 0.5647 - val_loss: 0.9302 - val_accuracy: 0.5704\n",
      "Epoch 12/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9350 - accuracy: 0.5654\n",
      "Epoch 00012: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9350 - accuracy: 0.5654 - val_loss: 0.9323 - val_accuracy: 0.5686\n",
      "Epoch 13/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9349 - accuracy: 0.5653\n",
      "Epoch 00013: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 15s 8ms/step - loss: 0.9349 - accuracy: 0.5653 - val_loss: 0.9360 - val_accuracy: 0.5643\n",
      "Epoch 14/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9342 - accuracy: 0.5657\n",
      "Epoch 00014: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9342 - accuracy: 0.5657 - val_loss: 0.9331 - val_accuracy: 0.5673\n",
      "Epoch 15/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5652\n",
      "Epoch 00015: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9351 - accuracy: 0.5652 - val_loss: 0.9330 - val_accuracy: 0.5676\n",
      "Epoch 16/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5666\n",
      "Epoch 00016: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9334 - accuracy: 0.5666 - val_loss: 0.9335 - val_accuracy: 0.5666\n",
      "Epoch 17/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9345 - accuracy: 0.5657\n",
      "Epoch 00017: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9344 - accuracy: 0.5657 - val_loss: 0.9308 - val_accuracy: 0.5695\n",
      "Epoch 18/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.5648\n",
      "Epoch 00018: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9354 - accuracy: 0.5648 - val_loss: 0.9328 - val_accuracy: 0.5679\n",
      "Epoch 19/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9338 - accuracy: 0.5663\n",
      "Epoch 00019: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9338 - accuracy: 0.5662 - val_loss: 0.9308 - val_accuracy: 0.5696\n",
      "Epoch 20/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9356 - accuracy: 0.5644\n",
      "Epoch 00020: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9355 - accuracy: 0.5645 - val_loss: 0.9351 - val_accuracy: 0.5653\n",
      "Epoch 21/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9358 - accuracy: 0.5644\n",
      "Epoch 00021: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9357 - accuracy: 0.5644 - val_loss: 0.9330 - val_accuracy: 0.5673\n",
      "Epoch 22/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9343 - accuracy: 0.5655\n",
      "Epoch 00022: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9344 - accuracy: 0.5655 - val_loss: 0.9334 - val_accuracy: 0.5669\n",
      "Epoch 23/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9340 - accuracy: 0.5659 ETA\n",
      "Epoch 00023: val_loss did not improve from 0.93020\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9340 - accuracy: 0.5659 - val_loss: 0.9350 - val_accuracy: 0.5653\n",
      "Epoch 24/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9352 - accuracy: 0.5647\n",
      "Epoch 00024: val_loss improved from 0.93020 to 0.92993, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9354 - accuracy: 0.5646 - val_loss: 0.9299 - val_accuracy: 0.5701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9352 - accuracy: 0.5649\n",
      "Epoch 00025: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9352 - accuracy: 0.5649 - val_loss: 0.9318 - val_accuracy: 0.5688\n",
      "Epoch 26/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9336 - accuracy: 0.5664\n",
      "Epoch 00026: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9336 - accuracy: 0.5664 - val_loss: 0.9332 - val_accuracy: 0.5671\n",
      "Epoch 27/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5668\n",
      "Epoch 00027: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9331 - accuracy: 0.5669 - val_loss: 0.9305 - val_accuracy: 0.5697\n",
      "Epoch 28/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.5663\n",
      "Epoch 00028: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9337 - accuracy: 0.5663 - val_loss: 0.9334 - val_accuracy: 0.5670\n",
      "Epoch 29/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9333 - accuracy: 0.5666\n",
      "Epoch 00029: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9332 - accuracy: 0.5666 - val_loss: 0.9352 - val_accuracy: 0.5651\n",
      "Epoch 30/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9325 - accuracy: 0.5675 ETA: 0s - loss: 0.9324 - accura\n",
      "Epoch 00030: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9325 - accuracy: 0.5675 - val_loss: 0.9308 - val_accuracy: 0.5694\n",
      "Epoch 31/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5670\n",
      "Epoch 00031: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9332 - accuracy: 0.5670 - val_loss: 0.9322 - val_accuracy: 0.5681\n",
      "Epoch 32/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9315 - accuracy: 0.5684 ETA: 0s - loss: 0.9315 - accura\n",
      "Epoch 00032: val_loss did not improve from 0.92993\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9315 - accuracy: 0.5684 - val_loss: 0.9327 - val_accuracy: 0.5676\n",
      "Epoch 33/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9321 - accuracy: 0.5678\n",
      "Epoch 00033: val_loss improved from 0.92993 to 0.92879, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9321 - accuracy: 0.5679 - val_loss: 0.9288 - val_accuracy: 0.5713\n",
      "Epoch 34/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9307 - accuracy: 0.5690 ETA: 0s - los\n",
      "Epoch 00034: val_loss did not improve from 0.92879\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9308 - accuracy: 0.5690 - val_loss: 0.9331 - val_accuracy: 0.5672\n",
      "Epoch 35/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9305 - accuracy: 0.5696 ETA: 0s\n",
      "Epoch 00035: val_loss did not improve from 0.92879\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9305 - accuracy: 0.5696 - val_loss: 0.9310 - val_accuracy: 0.5694\n",
      "Epoch 36/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5698\n",
      "Epoch 00036: val_loss did not improve from 0.92879\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9302 - accuracy: 0.5697 - val_loss: 0.9288 - val_accuracy: 0.5715\n",
      "Epoch 37/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9312 - accuracy: 0.5690\n",
      "Epoch 00037: val_loss did not improve from 0.92879\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9312 - accuracy: 0.5689 - val_loss: 0.9290 - val_accuracy: 0.5713\n",
      "Epoch 38/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5696\n",
      "Epoch 00038: val_loss improved from 0.92879 to 0.92837, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9303 - accuracy: 0.5697 - val_loss: 0.9284 - val_accuracy: 0.5720\n",
      "Epoch 39/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9294 - accuracy: 0.5703\n",
      "Epoch 00039: val_loss did not improve from 0.92837\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9294 - accuracy: 0.5704 - val_loss: 0.9301 - val_accuracy: 0.5704\n",
      "Epoch 40/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.5710\n",
      "Epoch 00040: val_loss did not improve from 0.92837\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9289 - accuracy: 0.5710 - val_loss: 0.9285 - val_accuracy: 0.5718\n",
      "Epoch 41/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.5701\n",
      "Epoch 00041: val_loss improved from 0.92837 to 0.92822, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.2_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9299 - accuracy: 0.5701 - val_loss: 0.9282 - val_accuracy: 0.5720\n",
      "Epoch 42/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.5713\n",
      "Epoch 00042: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9287 - accuracy: 0.5713 - val_loss: 0.9284 - val_accuracy: 0.5719\n",
      "Epoch 43/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9284 - accuracy: 0.5716\n",
      "Epoch 00043: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9284 - accuracy: 0.5716 - val_loss: 0.9287 - val_accuracy: 0.5717\n",
      "Epoch 44/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.5709\n",
      "Epoch 00044: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9289 - accuracy: 0.5710 - val_loss: 0.9286 - val_accuracy: 0.5720\n",
      "Epoch 45/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9280 - accuracy: 0.5718\n",
      "Epoch 00045: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9280 - accuracy: 0.5718 - val_loss: 0.9300 - val_accuracy: 0.5703\n",
      "Epoch 46/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9275 - accuracy: 0.5726\n",
      "Epoch 00046: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9275 - accuracy: 0.5726 - val_loss: 0.9298 - val_accuracy: 0.5706\n",
      "Epoch 47/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9285 - accuracy: 0.5713\n",
      "Epoch 00047: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9285 - accuracy: 0.5713 - val_loss: 0.9289 - val_accuracy: 0.5712\n",
      "Epoch 48/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9280 - accuracy: 0.5719\n",
      "Epoch 00048: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9280 - accuracy: 0.5719 - val_loss: 0.9284 - val_accuracy: 0.5719\n",
      "Epoch 49/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9278 - accuracy: 0.5721 ETA: 0s - loss: 0.9281 - accuracy: \n",
      "Epoch 00049: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9277 - accuracy: 0.5722 - val_loss: 0.9286 - val_accuracy: 0.5716\n",
      "Epoch 50/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9280 - accuracy: 0.5719\n",
      "Epoch 00050: val_loss did not improve from 0.92822\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9280 - accuracy: 0.5719 - val_loss: 0.9284 - val_accuracy: 0.5719\n",
      "accuracy: 57.19%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 30:35 - loss: 1.0246 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 1.8180s). Check your callbacks.\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.5081\n",
      "Epoch 00001: val_loss improved from inf to 0.98271, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9964 - accuracy: 0.5082 - val_loss: 0.9827 - val_accuracy: 0.5345\n",
      "Epoch 2/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9859 - accuracy: 0.5242\n",
      "Epoch 00002: val_loss improved from 0.98271 to 0.95607, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9857 - accuracy: 0.5243 - val_loss: 0.9561 - val_accuracy: 0.5498\n",
      "Epoch 3/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9673 - accuracy: 0.5409\n",
      "Epoch 00003: val_loss improved from 0.95607 to 0.94598, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9673 - accuracy: 0.5409 - val_loss: 0.9460 - val_accuracy: 0.5545\n",
      "Epoch 4/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9551 - accuracy: 0.5481\n",
      "Epoch 00004: val_loss improved from 0.94598 to 0.94412, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9551 - accuracy: 0.5481 - val_loss: 0.9441 - val_accuracy: 0.5560\n",
      "Epoch 5/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9478 - accuracy: 0.5539\n",
      "Epoch 00005: val_loss improved from 0.94412 to 0.93880, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9478 - accuracy: 0.5539 - val_loss: 0.9388 - val_accuracy: 0.5613\n",
      "Epoch 6/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9440 - accuracy: 0.5572\n",
      "Epoch 00006: val_loss improved from 0.93880 to 0.93574, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9440 - accuracy: 0.5572 - val_loss: 0.9357 - val_accuracy: 0.5645\n",
      "Epoch 7/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9412 - accuracy: 0.5593\n",
      "Epoch 00007: val_loss improved from 0.93574 to 0.93527, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9412 - accuracy: 0.5593 - val_loss: 0.9353 - val_accuracy: 0.5652\n",
      "Epoch 8/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9390 - accuracy: 0.5620\n",
      "Epoch 00008: val_loss did not improve from 0.93527\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9388 - accuracy: 0.5621 - val_loss: 0.9373 - val_accuracy: 0.5632\n",
      "Epoch 9/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9382 - accuracy: 0.5620\n",
      "Epoch 00009: val_loss did not improve from 0.93527\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9382 - accuracy: 0.5620 - val_loss: 0.9355 - val_accuracy: 0.5649\n",
      "Epoch 10/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9379 - accuracy: 0.5623\n",
      "Epoch 00010: val_loss improved from 0.93527 to 0.93254, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9379 - accuracy: 0.5623 - val_loss: 0.9325 - val_accuracy: 0.5680\n",
      "Epoch 11/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9365 - accuracy: 0.5640\n",
      "Epoch 00011: val_loss did not improve from 0.93254\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9363 - accuracy: 0.5641 - val_loss: 0.9328 - val_accuracy: 0.5675\n",
      "Epoch 12/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9359 - accuracy: 0.5643\n",
      "Epoch 00012: val_loss did not improve from 0.93254\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9358 - accuracy: 0.5643 - val_loss: 0.9327 - val_accuracy: 0.5677\n",
      "Epoch 13/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9362 - accuracy: 0.5638\n",
      "Epoch 00013: val_loss improved from 0.93254 to 0.93114, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9362 - accuracy: 0.5638 - val_loss: 0.9311 - val_accuracy: 0.5692\n",
      "Epoch 14/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9350 - accuracy: 0.5652\n",
      "Epoch 00014: val_loss did not improve from 0.93114\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9351 - accuracy: 0.5651 - val_loss: 0.9363 - val_accuracy: 0.5636\n",
      "Epoch 15/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5646\n",
      "Epoch 00015: val_loss did not improve from 0.93114\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9352 - accuracy: 0.5646 - val_loss: 0.9319 - val_accuracy: 0.5683\n",
      "Epoch 16/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9347 - accuracy: 0.5655 ETA: 0s - loss: 0.9347 - accuracy: \n",
      "Epoch 00016: val_loss improved from 0.93114 to 0.92998, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9346 - accuracy: 0.5655 - val_loss: 0.9300 - val_accuracy: 0.5704\n",
      "Epoch 17/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.5671\n",
      "Epoch 00017: val_loss did not improve from 0.92998\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9331 - accuracy: 0.5671 - val_loss: 0.9340 - val_accuracy: 0.5663\n",
      "Epoch 18/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5654\n",
      "Epoch 00018: val_loss did not improve from 0.92998\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9345 - accuracy: 0.5655 - val_loss: 0.9314 - val_accuracy: 0.5685\n",
      "Epoch 19/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5654\n",
      "Epoch 00019: val_loss did not improve from 0.92998\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9345 - accuracy: 0.5654 - val_loss: 0.9314 - val_accuracy: 0.5688\n",
      "Epoch 20/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5652\n",
      "Epoch 00020: val_loss did not improve from 0.92998\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9347 - accuracy: 0.5652 - val_loss: 0.9323 - val_accuracy: 0.5682\n",
      "Epoch 21/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.5663\n",
      "Epoch 00021: val_loss did not improve from 0.92998\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9339 - accuracy: 0.5663 - val_loss: 0.9320 - val_accuracy: 0.5682\n",
      "Epoch 22/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9360 - accuracy: 0.5641\n",
      "Epoch 00022: val_loss did not improve from 0.92998\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9361 - accuracy: 0.5640 - val_loss: 0.9312 - val_accuracy: 0.5691\n",
      "Epoch 23/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.5632\n",
      "Epoch 00023: val_loss improved from 0.92998 to 0.92866, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9368 - accuracy: 0.5632 - val_loss: 0.9287 - val_accuracy: 0.5716\n",
      "Epoch 24/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.5636\n",
      "Epoch 00024: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9364 - accuracy: 0.5636 - val_loss: 0.9309 - val_accuracy: 0.5697\n",
      "Epoch 25/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9349 - accuracy: 0.5653\n",
      "Epoch 00025: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9349 - accuracy: 0.5653 - val_loss: 0.9303 - val_accuracy: 0.5701\n",
      "Epoch 26/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9343 - accuracy: 0.5657\n",
      "Epoch 00026: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9342 - accuracy: 0.5658 - val_loss: 0.9316 - val_accuracy: 0.5686\n",
      "Epoch 27/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9333 - accuracy: 0.5666\n",
      "Epoch 00027: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9333 - accuracy: 0.5666 - val_loss: 0.9290 - val_accuracy: 0.5713\n",
      "Epoch 28/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9328 - accuracy: 0.5672\n",
      "Epoch 00028: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9328 - accuracy: 0.5672 - val_loss: 0.9320 - val_accuracy: 0.5684\n",
      "Epoch 29/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.5672\n",
      "Epoch 00029: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9330 - accuracy: 0.5672 - val_loss: 0.9324 - val_accuracy: 0.5679\n",
      "Epoch 30/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.5669\n",
      "Epoch 00030: val_loss did not improve from 0.92866\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9330 - accuracy: 0.5668 - val_loss: 0.9327 - val_accuracy: 0.5675\n",
      "Epoch 31/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9329 - accuracy: 0.5671\n",
      "Epoch 00031: val_loss improved from 0.92866 to 0.92854, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9330 - accuracy: 0.5670 - val_loss: 0.9285 - val_accuracy: 0.5719\n",
      "Epoch 32/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9316 - accuracy: 0.5683\n",
      "Epoch 00032: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9316 - accuracy: 0.5683 - val_loss: 0.9319 - val_accuracy: 0.5687\n",
      "Epoch 33/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5665\n",
      "Epoch 00033: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9334 - accuracy: 0.5666 - val_loss: 0.9317 - val_accuracy: 0.5687\n",
      "Epoch 34/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9317 - accuracy: 0.5682\n",
      "Epoch 00034: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9317 - accuracy: 0.5682 - val_loss: 0.9312 - val_accuracy: 0.5690\n",
      "Epoch 35/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9299 - accuracy: 0.5703\n",
      "Epoch 00035: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9297 - accuracy: 0.5704 - val_loss: 0.9298 - val_accuracy: 0.5703\n",
      "Epoch 36/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9299 - accuracy: 0.5701\n",
      "Epoch 00036: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9299 - accuracy: 0.5700 - val_loss: 0.9304 - val_accuracy: 0.5700\n",
      "Epoch 37/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9303 - accuracy: 0.5697\n",
      "Epoch 00037: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9304 - accuracy: 0.5697 - val_loss: 0.9320 - val_accuracy: 0.5682\n",
      "Epoch 38/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5700\n",
      "Epoch 00038: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9302 - accuracy: 0.5700 - val_loss: 0.9348 - val_accuracy: 0.5658\n",
      "Epoch 39/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5699\n",
      "Epoch 00039: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9301 - accuracy: 0.5699 - val_loss: 0.9297 - val_accuracy: 0.5705\n",
      "Epoch 40/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.5693\n",
      "Epoch 00040: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9306 - accuracy: 0.5694 - val_loss: 0.9296 - val_accuracy: 0.5709\n",
      "Epoch 41/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9301 - accuracy: 0.5699\n",
      "Epoch 00041: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9300 - accuracy: 0.5699 - val_loss: 0.9292 - val_accuracy: 0.5712\n",
      "Epoch 42/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9286 - accuracy: 0.5713\n",
      "Epoch 00042: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9286 - accuracy: 0.5714 - val_loss: 0.9293 - val_accuracy: 0.5711\n",
      "Epoch 43/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.5717\n",
      "Epoch 00043: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9282 - accuracy: 0.5718 - val_loss: 0.9292 - val_accuracy: 0.5712\n",
      "Epoch 44/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9281 - accuracy: 0.5720\n",
      "Epoch 00044: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9280 - accuracy: 0.5720 - val_loss: 0.9293 - val_accuracy: 0.5712\n",
      "Epoch 45/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.5709\n",
      "Epoch 00045: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9290 - accuracy: 0.5709 - val_loss: 0.9303 - val_accuracy: 0.5698\n",
      "Epoch 46/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9279 - accuracy: 0.5720\n",
      "Epoch 00046: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9280 - accuracy: 0.5720 - val_loss: 0.9288 - val_accuracy: 0.5718\n",
      "Epoch 47/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9275 - accuracy: 0.5724\n",
      "Epoch 00047: val_loss did not improve from 0.92854\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9275 - accuracy: 0.5724 - val_loss: 0.9287 - val_accuracy: 0.5717\n",
      "Epoch 48/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9278 - accuracy: 0.5723\n",
      "Epoch 00048: val_loss improved from 0.92854 to 0.92841, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9277 - accuracy: 0.5723 - val_loss: 0.9284 - val_accuracy: 0.5720\n",
      "Epoch 49/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.5726\n",
      "Epoch 00049: val_loss improved from 0.92841 to 0.92824, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_10\\best_try_10.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 14s 7ms/step - loss: 0.9272 - accuracy: 0.5727 - val_loss: 0.9282 - val_accuracy: 0.5722\n",
      "Epoch 50/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9266 - accuracy: 0.5734\n",
      "Epoch 00050: val_loss did not improve from 0.92824\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9266 - accuracy: 0.5734 - val_loss: 0.9286 - val_accuracy: 0.5717\n",
      "accuracy: 57.17%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "57.16% (+/- 0.03%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_train, y_train_0):\n",
    "    # create model\n",
    "    num = float(num)\n",
    "    num = num + 0.1\n",
    "    num = str(num)\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[19]),\n",
    "        keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.experimental.RandomFourierFeatures(output_dim=20, kernel_initializer='gaussian'),\n",
    "        keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='hinge', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    # Callbacks\n",
    "    NAME = \"Survivability-200-150-100-D-BN-He-{0}-{1}\".format(time.time(), num)\n",
    "    tensorboard = TensorBoard(log_dir=\"{0}\\\\logs\\\\{1}\".format(path, NAME))\n",
    "    \n",
    "    onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(path+folder+'best_try_'+num+'_1.h5', monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "    callbacks = [checkpoint, onecycle, tensorboard]\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train_0, epochs=epochs, batch_size=batch_size, \n",
    "                        validation_data=(X_test, y_test_0), callbacks = callbacks)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_test, y_test_0, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    savepickle(path, folder, 'history_'+num+'_1', history)\n",
    "    plotdata(path, folder, 'plot_'+num+'_1', history)\n",
    "    model.save_weights(path+folder+'try_'+num+'_1.h5')\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1N0                    -> L2N0 = [ 0.0024129  -0.26891384 -0.3272048   0.17847182 -0.5136386  -0.15533334\n",
      "  0.21267177 -0.6981733  -0.1318059  -0.1074567   0.16903602 -0.661726\n",
      "  0.17290245 -0.0131072  -0.1633152   0.5472914  -0.30002263  0.6514851\n",
      "  0.0434515  -0.31179175  0.06288417 -0.11375406  0.15358424 -0.05659465\n",
      " -0.3223114  -0.24748473  0.25225788  0.12940286 -0.13536827 -0.596138\n",
      " -0.07726951  0.18015935  0.03179678 -0.02896026  0.16621312 -0.46248668\n",
      " -0.56399304 -0.2671366  -0.21580245  0.2735189  -0.3791918  -0.19699945\n",
      " -0.08929579 -0.28869012  0.36448765  0.20909971 -0.02944583  0.04674202\n",
      " -0.00200772 -0.11501584 -0.05644314 -0.7147112  -0.5286213  -0.3242565\n",
      "  0.15268263  0.18428768 -0.04684382  0.28633788 -0.3769945   0.19116572\n",
      " -0.5058293   0.46668807  0.5369829  -0.49683553  0.18982165  0.1509458\n",
      " -0.30405086  0.3496411  -0.40144017  0.04835745  0.20422906  0.3089448\n",
      "  0.1824408   0.14018229 -0.18709964 -0.15636513  0.0741924  -0.66805685\n",
      " -0.396785    0.041357    0.60866255 -0.15289982  0.13103098 -0.0871931\n",
      " -0.26847154  0.3026026  -0.17660972  0.06911647  0.3737743  -0.2580101\n",
      "  0.34912762 -0.47364664  0.16170758 -0.574671   -0.23586172  0.47437125\n",
      "  0.17072375 -0.07629644 -0.63214266 -0.15047923]\n",
      "L1N0                    -> L2N1 = [ 3.34665209e-01 -5.38875349e-02 -1.07143514e-01 -1.47393540e-01\n",
      " -6.07999898e-02  1.54801950e-01  1.84331799e-03 -3.79365236e-01\n",
      " -1.26258934e+00 -6.90618753e-01 -2.18184128e-01 -4.00109857e-01\n",
      "  8.43710208e-04  3.40858489e-01 -5.88148117e-01 -3.56133848e-01\n",
      "  7.72968948e-01 -7.04592885e-03  5.10456273e-03 -2.44806837e-02\n",
      "  5.00448585e-01  5.92091084e-01 -4.64405298e-01  1.46470182e-02\n",
      " -8.63048285e-02  1.29813468e+00 -2.06734896e-01 -1.46611556e-01\n",
      " -1.49752343e+00  9.96775627e-02 -9.08964314e-03  2.64334176e-02\n",
      " -5.18941041e-03  7.38519371e-01  6.33181818e-03  2.41769925e-01\n",
      "  9.29842442e-02 -6.70646355e-02 -4.94497567e-01 -2.76494194e-02\n",
      "  7.99898952e-02 -1.67280480e-01  1.34281721e-02 -5.07495403e-02\n",
      " -8.28905642e-01 -5.12993000e-02 -2.00460970e-01 -3.73111159e-01\n",
      " -4.68289942e-01  2.63736188e-01 -3.56571525e-02  1.48992494e-01\n",
      "  1.04784220e-01 -3.37442994e-01 -3.38693708e-02  2.77360212e-02\n",
      "  1.69106692e-01 -1.48326233e-01  8.98958743e-02 -1.16337999e-03\n",
      " -1.15626559e-01  2.48965070e-01  2.68239915e-01  6.64294481e-01\n",
      "  8.12714815e-01  1.13826625e-01 -4.99795049e-01 -3.22733074e-01\n",
      "  3.12105030e-01  8.81102145e-01  4.70797271e-02  2.43310928e-01\n",
      " -8.79227370e-03 -7.93965816e-01 -1.16317667e-01 -7.10613206e-02\n",
      "  3.64015341e-01 -1.65555045e-01  2.34768465e-01 -4.90081497e-03\n",
      " -4.49666493e-02  2.88703013e-02  4.16725650e-02 -2.92159077e-02\n",
      " -2.19665971e-02  7.38576725e-02  1.17763810e-01  3.77223909e-01\n",
      "  7.45059028e-02  1.11256965e-01  1.52373537e-01  1.74996912e-01\n",
      "  2.85046309e-01 -4.07210626e-02 -1.00934017e+00 -1.22278869e-01\n",
      " -1.02139974e+00  2.74525657e-02  5.65766953e-02  2.02847384e-02]\n",
      "L1N0                    -> L2N2 = [-1.23956092e-01  3.95693779e-02 -2.24451780e-01 -8.02543759e-02\n",
      "  9.49604139e-02 -3.02900374e-01  2.45074723e-02 -3.90144959e-02\n",
      " -5.15578315e-02 -1.40421137e-01 -2.62765318e-01  1.73203528e-01\n",
      " -2.14830384e-01  1.28042415e-01 -2.76964251e-02  2.79006422e-01\n",
      " -8.29379708e-02  6.68185204e-02  2.23560166e-02 -5.76947024e-03\n",
      "  9.66263656e-03  4.34328705e-01  3.37860018e-01 -4.00060527e-02\n",
      " -4.19946760e-02 -2.65717894e-01 -3.68767381e-01 -5.14849834e-03\n",
      " -2.47858882e-01  1.19835190e-01 -4.21428308e-02 -2.08481066e-02\n",
      " -1.72136165e-02 -7.35249557e-03 -3.88319567e-02  2.88804565e-02\n",
      " -1.85977742e-01  5.85896820e-02 -3.20108503e-01 -4.43466008e-02\n",
      " -3.34190071e-01 -1.22494854e-01  6.11216463e-02 -1.91962123e-02\n",
      " -5.91430366e-02 -1.67662218e-01 -3.00035387e-01 -3.89721066e-01\n",
      "  8.74010921e-02  6.72516346e-01 -3.64611088e-03  1.81802586e-01\n",
      "  6.02218330e-01  6.38298616e-02 -3.47352177e-02  1.12188369e-01\n",
      " -9.04895306e-01  3.94168228e-01 -3.09539791e-02  1.53312620e-04\n",
      " -2.84830928e-01 -9.97394398e-02 -1.89826712e-01 -1.41204908e-01\n",
      "  5.06387591e-01 -2.74472147e-01 -1.62053034e-01 -3.72922689e-01\n",
      " -3.25164348e-02  8.10106564e-03 -8.85041580e-02  2.03724995e-01\n",
      "  7.93783180e-03  7.10236840e-03  7.03856349e-01  3.87471974e-01\n",
      "  2.04384655e-01 -4.80581343e-01 -5.59265554e-01 -1.81074440e-02\n",
      "  5.31967096e-02  4.33762282e-01  1.20045070e-03  2.26559401e-01\n",
      "  1.08601257e-01 -1.32333487e-01  5.45496225e-01 -2.19182014e-01\n",
      " -1.81934863e-01 -1.38194328e-02  2.15642489e-02  4.63814586e-01\n",
      " -1.65065706e-01  1.17477007e-01  1.72603235e-01 -5.77195406e-01\n",
      "  1.62444264e-03 -1.40169794e-02  1.82268098e-02  2.22432002e-01]\n",
      "L1N0                    -> L2N3 = [ 0.48037702 -0.06082846 -0.12018535  0.7621989   0.40121385  0.4482546\n",
      " -0.02747446 -0.00485945 -0.15095608 -0.00837051  0.50014406 -0.26826996\n",
      "  1.0077786   0.24180654 -0.01144035  0.01896714 -0.01760441 -0.63907003\n",
      " -0.08641378  0.4463865  -0.04320854 -0.06243162 -0.2092661   0.7526843\n",
      "  0.20507877 -0.03595139  0.21357025  0.53639805 -0.2989122  -0.24585125\n",
      " -0.5091643  -0.3138165  -0.30070043 -0.15529549  0.920939    0.02163873\n",
      "  0.2266566  -0.09916807  0.18930562 -0.9341587  -0.06028665 -0.05112357\n",
      " -0.29628286 -0.05893121  0.50010693  1.0019666   0.30471572 -0.14848351\n",
      "  0.08971219 -0.416224   -0.05411018 -0.3640019  -0.1908715   0.02406826\n",
      "  0.6139922  -0.06637167  0.10952804  0.04874509 -0.38624159 -0.12907249\n",
      "  0.78340596 -0.28263417  0.82002074  0.06760768 -0.26548928 -0.05992577\n",
      " -0.06990205  0.3908951  -0.6577988  -0.27692607  0.04783605  0.22899106\n",
      " -0.06854683 -0.49722555 -0.3603169  -0.1944844   0.2460371  -0.5947925\n",
      "  0.00730292 -0.00141657  0.46083844 -0.4204923  -0.5180223  -0.49985754\n",
      " -0.45051667  0.3219125  -0.30566645  0.2925636   0.6327294  -0.8756389\n",
      "  0.3242694   0.42547226 -0.3299369   0.90662557 -0.05700308 -0.4101971\n",
      " -0.25800803  0.9871656  -0.6568465  -0.3870258 ]\n",
      "L1N0                    -> L2N4 = [-2.62668356e-02  1.11815706e-01 -8.75136331e-02 -1.35179823e-02\n",
      " -6.01790965e-01 -2.15475205e-02 -1.10460587e-01  1.52822718e-01\n",
      " -1.41442835e-01  3.01355589e-02  8.27428326e-02  4.45593238e-01\n",
      "  1.98245551e-02 -9.50304908e-04  9.88269299e-02  1.35173976e-01\n",
      " -1.11328870e-01  1.82090431e-01  7.16037350e-03  8.92112255e-02\n",
      " -1.67937782e-02  3.76430809e-01  7.85738826e-01 -1.96943507e-02\n",
      "  1.92339972e-01 -1.43092245e-01  4.63501036e-01 -1.81066915e-02\n",
      " -6.24130405e-02 -1.93943992e-01 -3.72106507e-02  4.78092879e-02\n",
      "  8.54778886e-02 -2.87397578e-02 -9.04536154e-03 -7.04483464e-02\n",
      " -2.84562916e-01  2.21457388e-02  1.77864254e-01 -8.46238714e-03\n",
      "  3.85709256e-01 -4.46866989e-01 -1.29103974e-01  2.20303759e-02\n",
      " -2.49569297e-01 -5.70814498e-02 -8.78776073e-01 -2.44335517e-01\n",
      "  3.04700375e-01 -4.56677020e-01 -5.43965459e-01 -2.01129541e-01\n",
      " -2.32286230e-01 -1.53963238e-01 -9.32224467e-02 -1.86868832e-01\n",
      " -6.55218260e-03  3.81265342e-01 -1.79704472e-01  7.12341964e-02\n",
      "  4.85439450e-02 -2.82356888e-01  1.99431613e-01  2.23782152e-01\n",
      "  1.72117278e-01 -3.05619866e-01 -2.74802029e-01 -2.39913329e-01\n",
      "  2.23320365e-01 -1.48579162e-02  9.95881110e-02  1.46743149e-01\n",
      "  4.95028624e-04 -1.85600221e-01  5.49150631e-02 -7.35743195e-02\n",
      " -2.67664552e-01  2.27424815e-01 -1.43946216e-01  5.68442792e-03\n",
      " -1.49145275e-01  2.26522565e-01 -2.67809499e-02 -2.58139879e-01\n",
      "  4.47876826e-02 -7.97874704e-02  1.08959354e-01 -5.91639755e-03\n",
      "  1.30313300e-02 -5.27558699e-02 -1.52923927e-01 -1.80525154e-01\n",
      " -7.94523433e-02 -1.48082495e-01 -9.52803493e-02  1.24107473e-01\n",
      "  9.13831517e-02 -3.41328036e-04  1.16772555e-01  5.74623644e-02]\n",
      "L1N0                    -> L2N5 = [-0.37069497 -0.39952153 -0.3569251   0.18994707 -0.35491318  0.53831273\n",
      " -0.39185968 -0.35665357  0.26092926 -0.00801841 -0.49464348 -0.00995316\n",
      " -0.6167974  -0.21207394  0.14943185  0.10061794 -0.18670881 -0.39623365\n",
      "  0.24633215 -0.08357958  0.10194195 -0.2663098  -0.11102407 -0.5938445\n",
      " -0.6364305  -0.3475539  -0.00382769 -0.67525375  0.01895412 -0.846486\n",
      "  0.5272211   0.22138608 -0.09735163 -0.04419977 -0.30045524  0.32301742\n",
      "  0.13910133  0.13520075 -0.3336151   0.5227252   0.08830048 -0.03744618\n",
      "  0.6253731  -0.24932344  0.30383936  0.04853915 -0.16073714 -0.19390157\n",
      " -0.16507398 -0.05157652 -0.4580794   0.14359333  0.50896513 -0.02012869\n",
      " -0.04301918  0.47451767  0.26061693 -0.41618973 -0.32736066 -0.0240633\n",
      " -0.33577132 -0.73297304 -0.21595478 -0.5019808   0.25856376 -0.21032217\n",
      " -0.3860441   0.07463613  0.32417664 -0.15554671 -0.5448071  -0.37057835\n",
      " -0.03885095  0.33083615 -0.04027788 -0.37043414 -0.25392035 -0.06862352\n",
      "  0.0260333  -0.13010783 -0.5680322   0.3250883   0.06442789 -0.04476428\n",
      "  0.37441447 -0.16247009 -0.12673917  0.12111876 -0.19445539  0.28513652\n",
      " -0.7839494   0.2601576  -0.04126628  0.37290317  0.5258367  -0.26950452\n",
      "  0.29697895 -0.46931255  0.6255172   0.05761945]\n",
      "L1N0                    -> L2N6 = [ 8.95737018e-03  7.98306018e-02 -4.29374166e-02 -2.99976498e-01\n",
      " -4.30047691e-01 -3.69310200e-01  4.75398153e-02 -5.51256001e-01\n",
      " -4.27378595e-01 -9.05051976e-02 -3.64200056e-01  5.35600372e-02\n",
      "  2.03600094e-01 -1.63718358e-01  2.96714842e-01 -2.02342018e-01\n",
      " -5.79643026e-02  2.26780906e-01 -9.82435569e-02 -5.03732026e-01\n",
      "  1.88952647e-02 -5.26483357e-01 -5.45177639e-01  2.59626240e-01\n",
      "  1.17141925e-01  4.84027028e-01 -1.16253868e-01  2.50344902e-01\n",
      "  1.29140571e-01  4.11116689e-01  2.71610260e-01  2.42114708e-01\n",
      " -2.18622282e-01 -1.15249179e-01 -1.05606414e-01 -1.20462753e-01\n",
      " -1.17833667e-01  1.35825381e-01  1.47313446e-01  1.18486911e-01\n",
      " -1.63902536e-01  2.46351302e-01 -5.55658817e-01 -7.34674605e-03\n",
      "  2.15930164e-01 -3.31353962e-01 -2.20162228e-01  1.77017793e-01\n",
      "  6.54150322e-02  4.55956072e-01 -3.90190214e-01 -1.92496583e-01\n",
      " -1.01482272e-01 -3.36264037e-02  3.87135297e-01  1.56848550e-01\n",
      "  3.02214056e-01 -7.76225626e-02  5.82609065e-02  4.28161979e-01\n",
      " -1.99861646e-01 -4.52668756e-01 -2.47728065e-01 -1.71343490e-01\n",
      " -4.30305421e-01  2.28304565e-01  2.75836647e-01 -5.42279243e-01\n",
      " -1.79686844e-01 -1.33832693e-01  5.81027567e-01  1.70601666e-01\n",
      " -2.19936594e-01 -3.09472054e-01 -1.45099729e-01 -5.04941586e-03\n",
      " -3.15390602e-02 -7.96342120e-02 -5.49107119e-02 -2.20284864e-01\n",
      " -7.45001234e-05 -5.78748107e-01 -2.11624771e-01  8.71635228e-02\n",
      " -5.67993671e-02 -4.02878702e-01 -1.59091558e-02  2.09235117e-01\n",
      " -6.24423206e-01  2.40404904e-01 -2.69106328e-01  3.95753868e-02\n",
      "  9.73230228e-02 -3.76961738e-01 -9.42956656e-02 -2.77118921e-01\n",
      "  1.93549812e-01  3.07763740e-02 -8.93745795e-02  1.67937595e-02]\n",
      "L1N0                    -> L2N7 = [-0.00873752  0.06080352  0.10918351 -0.24664477 -0.07231382 -0.3242073\n",
      " -0.02768154 -0.07743083  0.38440087 -0.05453463 -0.04889091  0.17235565\n",
      "  0.17670597  0.0515877  -0.57819426 -0.6797538  -0.26372787 -0.32597128\n",
      " -0.21461456  0.28366688 -0.04048007 -0.4853562  -0.08724643  0.1097372\n",
      " -0.41312933 -0.19931762 -0.643042   -0.02744895  0.2676823   0.2980989\n",
      " -0.03968799  0.14217451  0.39758793 -0.3779227  -0.4394917   0.5150695\n",
      " -0.16243926  0.34655014 -0.504765   -0.1804818  -0.1895913  -0.3564402\n",
      " -0.08564568  0.06610513 -0.63790405 -0.33435357 -0.17298824 -0.19570784\n",
      "  0.13871484  0.03391051 -0.0236122  -0.3513481   0.50173426 -0.15913415\n",
      " -0.39756894 -0.1600162   0.0602049  -0.12364988 -0.27828407 -0.34901032\n",
      "  0.08946265 -0.03930706  0.13012812 -0.3546168  -0.6015134   0.40239024\n",
      " -0.59677804  0.25389168 -0.02237851 -0.6119232  -0.21124664 -0.32691398\n",
      "  0.31652105  0.32002383  0.06808697  0.13720323  0.0516318   0.33359584\n",
      " -0.00180191 -0.15680498 -0.55598724  0.03515881  0.23962997  0.16612908\n",
      "  0.69723964  0.45372123  0.43858403 -0.3533874   0.06630778 -0.26611212\n",
      "  0.04650132 -0.4531377   0.2393147   0.4598722   0.16210486  0.21468414\n",
      " -0.9446415  -0.00826631  0.5412884   0.05491007]\n",
      "L1N0                    -> L2N8 = [-0.10026646 -0.0423602  -0.6586196  -0.01497969 -0.11798679 -0.01606277\n",
      "  0.00094434 -0.13928667 -0.11507749 -0.22483096 -0.07823809 -0.3497889\n",
      " -0.01186155 -0.08941785 -0.08233757  0.05326536  0.04227126 -0.01046482\n",
      " -0.02158074 -0.16125844  0.00158788  0.21654087 -0.12313186  0.01425868\n",
      " -0.4065674   0.05011109  0.16875803 -0.09905519 -0.05587474  0.57162786\n",
      " -0.01003896  0.07914562 -0.01685988 -0.04810549  0.01624137  0.0245323\n",
      "  0.08197635  0.02666086 -0.59606856 -0.05507182 -0.5301896  -0.66410935\n",
      "  0.00561782 -0.00863421 -0.01499872  0.01733355  0.55268335 -0.41720527\n",
      " -0.50374985  0.12086899  0.54258996  0.03266428  0.16008085  0.6788103\n",
      " -0.00207509 -0.02365757 -0.01659882 -0.06238453 -0.12665479 -0.03042555\n",
      "  0.5064553  -0.113128   -0.03809714  0.00672243 -0.24824083 -0.01897395\n",
      " -0.10890314 -0.03618563  0.4273682   0.00295695 -0.08792762  0.19495809\n",
      " -0.02631441  0.00323668  0.01873247 -0.01950794  0.0883951   0.09425671\n",
      "  0.15828028 -0.04087055  0.11687587 -0.03573008  0.03596275 -0.00979515\n",
      "  0.02618192  0.02609334 -0.16301471  0.0513926   0.0765532   0.02728535\n",
      " -0.00762858 -0.02353947  0.15039098 -0.00593988  0.03296054 -0.25480428\n",
      " -0.1142756  -0.00089283  0.06298504 -0.00110231]\n",
      "L1N0                    -> L2N9 = [-0.48653635 -0.3764371  -0.00357887 -0.2544994   0.62200797 -0.22498237\n",
      "  0.09162443  0.21538606 -0.36934492 -0.15499018  0.4214477   0.26064754\n",
      " -0.08365469 -0.48193407 -0.29340965 -0.71467566  0.29612768  0.3463935\n",
      "  0.02545549 -0.64079094 -1.1110365  -0.04298138 -0.08240642  0.04720997\n",
      " -0.23517112  0.2759265  -0.33296686  0.29067     0.25808352 -0.05691537\n",
      "  0.1951319  -0.29496884 -0.4227004   0.3098035  -0.00753919 -0.18106544\n",
      " -0.15659495  0.28963783 -0.24176875 -0.20757717  0.3944843  -0.16397078\n",
      "  0.42730212  0.9384078  -0.4966357  -0.32797202 -0.22446878  0.16572113\n",
      " -0.15215759  0.19792728 -0.0975801   0.14434302 -0.3219571  -0.11565611\n",
      " -0.58815235 -0.26157978 -0.33262473  0.33872196  0.06333948  0.5151789\n",
      " -0.21101975  0.6068651  -0.6294459   0.05201818 -0.63358206  0.2832406\n",
      "  0.6670514  -0.31267315  0.19025406 -0.24307609  0.00503595 -0.4001612\n",
      "  0.17582914  0.14571883 -0.16884331  0.53587663  0.24002472 -0.17390266\n",
      " -0.53077245  0.28147817 -0.09191047  0.5657596  -0.32184294  0.34711668\n",
      "  0.23803109  0.40235054 -0.04874357 -0.6211138  -0.22130488 -0.29279017\n",
      "  0.7749778  -0.37596422  0.35238847 -0.52055234 -0.14920603 -0.1868227\n",
      " -0.18035866 -0.05851366 -0.22023097 -0.06297893]\n",
      "L1N0                    -> L2N10 = [ 0.32818574  1.061937    0.67951834  0.17536339 -0.31567073 -0.21268694\n",
      "  0.72016215  0.34155595  0.8526298  -0.10930051 -0.0064689  -0.17596357\n",
      "  0.11878873  1.0846101   0.6551981  -0.03419008  0.00419095 -0.24264304\n",
      "  0.10596318 -0.14736292 -0.084121   -0.15364997 -0.5905404  -0.03777463\n",
      " -0.31537062  0.03950941  0.08566263 -0.44144738  0.48691303 -0.08385038\n",
      " -0.4185622  -0.39460447  0.6905756  -0.23275705 -0.17506382 -1.5682906\n",
      "  0.04897649  0.01784885 -0.26556736  0.08110972 -0.05966223  0.24257295\n",
      " -0.3616138  -0.00291568 -0.06445125  0.04839437  0.35728773 -0.18308948\n",
      "  0.01399806 -0.01335651 -0.35329732 -0.1529598  -0.9749574  -0.60727406\n",
      "  0.05042889 -0.03403865 -0.27471238 -0.23765895  0.45851487 -0.28929004\n",
      "  0.16224262  0.31897458 -0.69921076  0.16904913 -0.4389945  -1.1465874\n",
      " -0.05554838 -0.15910427  0.11274152  0.11825274 -0.10611961  0.0158479\n",
      " -0.3256702  -0.43647304  0.396689    0.11720744 -0.69356745 -0.23746623\n",
      "  0.04215991  0.69213957 -0.17895095 -0.1447086   0.8816368   0.2288187\n",
      " -0.07209476 -0.6480079  -0.87512136 -0.45608333  0.83671796 -0.5366359\n",
      " -0.23474152 -0.01051438  0.8246765  -0.405394   -0.81872165  0.03111154\n",
      " -0.00596882 -0.11218765 -0.31965253  0.32523483]\n",
      "L1N0                    -> L2N11 = [-0.03863003 -0.13137315  0.28218448  0.23883198 -0.00423003 -0.52117616\n",
      " -0.18289264  0.010133   -0.10278298  0.12373048  0.2863663   0.03470301\n",
      " -0.24184197 -0.3403442  -0.04804812 -0.10696514  0.25760368  0.1420669\n",
      "  0.07396256  0.09467705  0.08093331 -0.89058495 -0.08925492  0.21062538\n",
      "  0.17355272  0.01936597  0.3051747   0.24221803  0.31748948  0.18800168\n",
      " -0.2266783  -0.60285085 -0.25504142 -0.26062408  0.00392012 -0.21665525\n",
      " -0.47016913 -0.57234126 -0.66696167 -0.18166263  0.2641602  -0.2390108\n",
      " -0.14233412 -0.3360104  -0.49767503  0.20656003 -0.37675282  0.13450424\n",
      " -0.6511063  -0.83715105  0.03922295 -0.04122686 -0.99947816  0.49800906\n",
      "  0.0660246  -0.8219034  -0.04753009 -0.56252563  0.3044548   0.00533287\n",
      "  0.5582545   0.23510522 -0.16859156 -0.1628944  -0.30590072 -0.37915102\n",
      "  0.6185443   0.55712223 -0.13397817  0.01380723 -0.4287338   0.64232343\n",
      " -0.20310453  0.00712906 -0.11823697  0.3302338   0.88719016 -0.5084523\n",
      "  0.02822473  0.42483664  0.07439414 -0.35280085 -0.00986515 -0.38801366\n",
      " -0.32399493  0.82773983 -0.15264525  0.04316765  0.49182194 -0.03140416\n",
      "  0.15744181  0.26470017  0.16876134 -0.06633341 -0.01344868  0.33649793\n",
      " -0.26521516 -0.09808432 -0.424282    0.13207924]\n",
      "L1N0                    -> L2N12 = [ 1.6394075  -1.1938568   0.26698264  0.44055334  0.3253085  -0.8002282\n",
      " -0.9785396   0.40815407 -1.2278622  -0.37652     0.05234786 -0.82793015\n",
      "  0.23700362 -0.6227203  -1.100059    0.31182137  0.6515241   1.3535517\n",
      " -1.7096857   1.1033852  -0.59288687 -0.5507124  -0.36410475  0.20143166\n",
      " -0.11876027 -0.9065349   1.5986514   0.91682047 -0.67297196 -0.17433128\n",
      " -1.6632668  -0.73154515  0.9070011   0.90629816  0.36370105 -0.01887328\n",
      " -0.89963984 -1.7633417   0.29426602  0.85287374  0.6938646  -0.1917179\n",
      "  0.67987496 -0.52021027 -0.09966529  0.6860048   0.19543494 -0.2110989\n",
      " -0.8342538  -0.8265372  -0.36326924  0.1398477  -0.06042024  0.21384539\n",
      "  1.0671929  -0.66902727 -1.201915   -0.8232593   0.0274284  -0.25360376\n",
      "  0.4593474  -0.02611594  0.64276457 -0.24384452 -0.07416947 -1.2046864\n",
      " -0.42677385  0.7193641  -0.13198462 -0.499795    1.7259551   0.08769602\n",
      " -1.8077255  -1.6902463  -1.1614301  -0.21301551  1.2799891   0.39863646\n",
      "  0.2128298  -0.7691672   0.80996704 -1.701274    0.25823244  0.261648\n",
      " -2.485471    0.91131926 -1.3053329   1.3518227   0.55878997  0.4708623\n",
      "  0.92595166  0.5812316  -0.65022933  0.3775345  -0.7835335   0.10346153\n",
      "  0.81506485  0.1759641   0.74779725 -0.7197744 ]\n",
      "L1N0                    -> L2N13 = [ 0.6016659  -0.50653225 -0.8165926   0.5387414  -0.08527669 -0.9827024\n",
      " -1.1130444  -0.08948684 -1.084619   -0.16207664  0.7711254   0.8120825\n",
      "  0.33776918 -0.667272   -0.7155242  -0.4835307  -0.6268913   0.5023363\n",
      " -1.9067277   0.6928903  -0.61978495 -0.7570488  -0.03666588  0.6208156\n",
      "  0.10658679 -0.66936934  0.39611244  0.5960515  -0.9704909   0.32367966\n",
      "  0.50025904 -1.5518535  -1.3063561  -0.6773523   0.4085091   0.5461251\n",
      " -0.2400278  -1.1225346  -0.5359088   1.3496724   1.0025371   0.32965204\n",
      " -1.8177613  -1.0306039  -0.6419673   1.0174594  -0.01346396  0.19490762\n",
      "  1.0473971  -0.67868286 -0.19920605 -0.41059315 -0.82884604  0.33394238\n",
      "  1.3504376  -0.69543326 -1.2190791  -1.0953106  -0.79632634 -1.2629895\n",
      "  0.6797154  -0.5414931   0.32646483  0.74136406  0.58445114 -0.5329427\n",
      " -0.44879082  1.1855885  -0.08625507 -0.48599306  0.5408212   1.3743948\n",
      " -1.2226838  -1.0957083  -1.4387482  -1.102048    0.25973144 -0.33186463\n",
      "  0.0124402  -0.46704352  1.2796972  -0.9767485  -1.0268474   0.4508548\n",
      " -0.5768256   0.7661425  -0.7119539   0.46540773  0.30529088 -0.1684947\n",
      "  0.13475417  0.01658882 -0.8065323   0.4486306  -0.31844404  0.23190424\n",
      " -0.57572687  0.22477888 -1.3400072  -1.5465372 ]\n",
      "L1N0                    -> L2N14 = [ 1.4190965   0.2329199   0.66668457 -2.2770996   0.13054717 -0.9909922\n",
      "  1.494528   -0.0079068   0.9663132  -0.72413474  0.37057605  1.8436277\n",
      " -0.9085909  -0.09811782  0.45124608  0.22373267  0.87926096 -0.30364406\n",
      "  2.1176963   0.39341125  0.05890163 -0.2735861  -0.4764289  -1.0519533\n",
      "  0.33847547  0.5176724   0.4662438   0.9614641   0.76639736 -0.16163066\n",
      " -0.08136372  1.4277394   1.3424493   0.70193577 -1.1149145   0.62338024\n",
      " -1.144978    0.36758357 -0.0542486  -1.3528136  -0.02905493 -0.23946328\n",
      "  1.7031089   0.2437569  -0.38671634 -0.9461341   1.1044484  -0.01215048\n",
      " -0.16642946 -0.5863791  -0.5278265   0.05925376  0.5255612  -0.29421338\n",
      " -0.7705857   1.8672415   0.5756262   0.9962892   0.8822943   2.3462732\n",
      " -1.2379936  -0.97823447  0.03383165 -0.35316342 -0.47092217  0.44984627\n",
      " -0.28248796  0.2793455  -0.15465371  0.43604326 -0.40379614  1.0824411\n",
      "  1.8007231   1.0870885   1.0728589   1.3574417  -1.3301134  -0.5595786\n",
      "  0.26958346  1.851802    0.9833397   1.5871682   0.51590127  1.223097\n",
      " -0.03107594  0.17119333  0.9828186   1.0500162   0.6666479  -0.18052004\n",
      " -0.6871611   1.2516198  -0.90470743 -1.1061956   0.5323042   0.24030083\n",
      "  0.21991707  0.4770179   0.6866891   1.7793353 ]\n",
      "L1N0                    -> L2N15 = [-0.56787074 -0.05013743 -0.12254392 -0.20486292  0.11443496 -0.08767087\n",
      "  0.31691208 -0.34735182  0.13329962  0.661449    0.60231996  1.2350293\n",
      " -0.55541456 -1.0999601  -0.11668676  0.35074586 -0.01422456 -1.368316\n",
      "  0.42559043 -0.4360913   0.1289576   0.8209011   0.0344877   0.35104826\n",
      " -0.03649653 -0.27590376 -0.7960455   0.53351116  0.41644815  0.37319288\n",
      "  0.28037667  0.5499928   0.7020646  -0.03879486 -0.12031595 -0.05377933\n",
      "  0.07111341  0.7334627  -0.47342542 -1.654926   -0.6569976  -0.13549528\n",
      "  0.73484516 -0.11140762  0.12967731  0.4655236   0.48298112 -0.23976524\n",
      " -0.7276255  -0.26862234  0.33721113  0.01438801  0.7184121   0.15237187\n",
      " -0.16049978  0.21207863  0.14438139 -0.04394071  0.01317736 -0.24855424\n",
      "  0.5136197  -1.0200596  -0.12845315  0.5646505   0.61941457  0.50921476\n",
      "  0.1045429  -1.1699816   0.17921719  0.42434892 -1.3826193  -0.51356065\n",
      "  0.05607963  0.5356601   0.96585643  0.19239943 -0.7237299   0.49614942\n",
      " -0.31620204  0.13686673 -0.73327994  0.8032676   0.5885398   1.0540576\n",
      " -0.2261529   0.09801283  0.61243945 -0.09323291 -0.09627707  0.11234367\n",
      " -0.40373638  0.89757854 -1.2143742   0.35088798  0.19148462 -0.27073872\n",
      " -0.31291404  0.5466925   1.4584045   1.1493018 ]\n",
      "L1N0                    -> L2N16 = [ 0.6056644   0.15568428  0.23929036 -0.13591588  0.18049055 -0.00720133\n",
      " -0.01443628 -0.0770176   0.13552326 -0.00518076  0.39358062  0.05030476\n",
      "  0.11531777 -0.1868428   0.47995523 -0.6559148  -0.05672785  0.4610784\n",
      " -0.03777064  0.3710393   0.0301101  -0.15458515  0.12484588 -0.08217267\n",
      "  0.09445733 -0.0146224   0.27475497  0.33073106 -0.04664752 -0.37047783\n",
      " -0.10363171 -0.37334305 -0.0898685   0.29797018  0.09745375  0.4400574\n",
      " -0.38806316 -0.2550552   0.3718717   0.13926437 -0.0666262   0.20509133\n",
      "  0.16433018  0.15760224 -0.40008783  0.04080868 -0.16207649 -0.3246486\n",
      " -0.09999393 -0.3525454   0.27752003 -0.60101247 -0.8627087   0.28871775\n",
      "  0.00537372 -0.10968994 -0.09426148 -0.5422111   0.03756768 -0.20951645\n",
      " -0.12757803 -0.24123165  0.22011787  0.64614236  0.27743268 -0.02343715\n",
      "  0.34912533  0.73255366 -0.2508056  -0.69853836  0.5573644   0.86820775\n",
      " -0.33664718  0.35621938 -0.66479945 -0.6418293   0.44231847 -0.05565992\n",
      "  0.06141552 -0.17417678  0.3495648  -0.38052306  0.15740466 -0.02883272\n",
      " -0.7565569   0.13537908 -0.5740456   0.60498506  0.31511924  0.23776661\n",
      "  0.36907333 -0.02352121 -0.7016381   0.0349233  -0.73278403  0.7941402\n",
      " -0.8890904   0.15314285 -0.34323508  0.0181071 ]\n",
      "L1N0                    -> L2N17 = [-1.48099333e-01  4.58839476e-01  9.23904851e-02  2.56911635e-01\n",
      "  4.11663711e-01 -6.65073991e-01 -1.19082920e-01 -4.35448349e-01\n",
      "  2.88406193e-01 -4.24287736e-01  1.31110922e-01  5.06714046e-01\n",
      "  2.01315850e-01  3.89644384e-01 -1.60518304e-01 -2.23765582e-01\n",
      " -1.67421669e-01 -3.67713012e-02  9.99930874e-02  3.10134768e-01\n",
      " -1.46958351e-01 -3.27302843e-01 -5.49237907e-01  4.87596989e-02\n",
      "  1.96378618e-01  1.29260033e-01 -5.59848621e-02 -1.74174100e-01\n",
      " -5.17499745e-02  2.06996679e-01 -1.04927158e+00 -5.41852951e-01\n",
      " -2.09158767e-04  2.22216830e-01  2.03715280e-01  1.59921244e-01\n",
      "  1.00380704e-01  7.32377768e-02 -2.04099894e-01  1.60331100e-01\n",
      "  6.31124616e-01  9.07100216e-02 -9.15681198e-02 -4.92712148e-02\n",
      " -3.68948698e-01 -1.59358427e-01 -1.44460768e-01  3.46142322e-01\n",
      "  2.48371199e-01 -6.87280655e-01 -6.38356090e-01 -1.12730987e-01\n",
      "  9.04416740e-02  9.27575767e-01  4.68560830e-02  4.13986832e-01\n",
      "  1.07268855e-01  3.41941528e-02  4.82267179e-02  1.34494811e-01\n",
      " -5.49592897e-02  3.33984056e-03  1.87780842e-01  3.26887667e-01\n",
      " -4.60079581e-01 -9.01824213e-04 -5.21805584e-01  4.69640456e-02\n",
      " -7.72797525e-01  9.18645114e-02  3.55253190e-01  6.60306737e-02\n",
      "  1.75005749e-01 -5.47377579e-02  3.30540448e-01 -1.64051235e-01\n",
      " -3.30205977e-01  4.96662408e-01 -6.36461377e-01 -6.42996579e-02\n",
      " -1.80485606e-01  4.08755183e-01 -2.28850424e-01 -4.45524342e-02\n",
      " -1.20870605e-01  4.67643857e-01 -2.41730213e-01  1.33374371e-02\n",
      " -1.90318465e-01  7.99388111e-01  1.65989593e-01  7.20410943e-02\n",
      "  3.46138597e-01  3.77563208e-01  3.04229766e-01  6.88641429e-01\n",
      " -7.79540688e-02  6.14611320e-02 -6.98860765e-01 -2.35295087e-01]\n",
      "L1N0                    -> L2N18 = [ 0.59721416 -0.44208312  0.2171654   0.7221129   0.30066642 -0.49865386\n",
      "  0.02033429  0.06431782  0.19308284  0.2564859   0.45105094 -0.28526193\n",
      " -0.5893079   0.3908097  -0.35668382 -0.5815986  -0.02629172 -0.09822422\n",
      "  0.1276321   0.29878083  0.18535574 -0.48703796 -0.2647779   0.14513527\n",
      "  0.22262524  0.20072702 -0.3425238   0.24512826  0.22768052  0.37722617\n",
      "  0.1542641  -0.59224105  0.2442752   0.43797237  0.04279381  0.01365432\n",
      " -0.5600428  -0.13180147 -0.4176623   0.08697572  0.632473    0.58287185\n",
      " -0.39518622 -0.6730982   0.57448375  0.27044368 -0.63359404  0.38020048\n",
      "  0.04149272 -0.38813654  0.08826634  0.12067178  0.03096154 -0.4322804\n",
      " -0.20135187  0.3815955  -0.15913191  0.22816414 -0.18874517  0.16054842\n",
      " -0.3916347   0.03794359  0.49488688 -0.48802444 -0.01042159  0.15016596\n",
      " -0.04204796 -0.04574114 -0.626691    0.07038873 -0.2460874  -0.5458265\n",
      "  0.67045224 -0.10672352  0.28200504 -0.13639988  0.06620013 -0.02896159\n",
      "  0.14552741 -0.19892806 -0.34668523 -0.21577592 -0.1957554  -0.06861507\n",
      "  0.09953225  0.47210774  0.10533291 -0.26351058 -0.3493604   0.30446926\n",
      "  0.49081132 -0.12246528 -0.24854669  0.03552969 -0.5725017   0.12300939\n",
      " -0.0185612  -0.63817406 -0.0472258   0.5224343 ]\n",
      "L1N1                    -> L2N0 = -0.11029629409313202\n",
      "L1N1                    -> L2N1 = -0.11747869104146957\n",
      "L1N1                    -> L2N2 = -0.11712583154439926\n",
      "L1N1                    -> L2N3 = -0.19791392982006073\n",
      "L1N1                    -> L2N4 = -0.02138650231063366\n",
      "L1N1                    -> L2N5 = 0.007467932533472776\n",
      "L1N1                    -> L2N6 = -0.24733079969882965\n",
      "L1N1                    -> L2N7 = -0.029770268127322197\n",
      "L1N1                    -> L2N8 = -0.3354896306991577\n",
      "L1N1                    -> L2N9 = 0.0\n",
      "L1N1                    -> L2N10 = 0.047718122601509094\n",
      "L1N1                    -> L2N11 = -0.05758149176836014\n",
      "L1N1                    -> L2N12 = -0.22901737689971924\n",
      "L1N1                    -> L2N13 = -0.4673284590244293\n",
      "L1N1                    -> L2N14 = 0.048413027077913284\n",
      "L1N1                    -> L2N15 = 0.2627757787704468\n",
      "L1N1                    -> L2N16 = -0.10128510743379593\n",
      "L1N1                    -> L2N17 = -0.0448165088891983\n",
      "L1N1                    -> L2N18 = -0.09409938752651215\n",
      "L1N1                    -> L2N19 = -0.1563904881477356\n",
      "L1N1                    -> L2N20 = 0.1058526411652565\n",
      "L1N1                    -> L2N21 = -0.004702212288975716\n",
      "L1N1                    -> L2N22 = 0.10975167155265808\n",
      "L1N1                    -> L2N23 = -0.17393118143081665\n",
      "L1N1                    -> L2N24 = -0.045447979122400284\n",
      "L1N1                    -> L2N25 = -0.2442876100540161\n",
      "L1N1                    -> L2N26 = 0.10153830796480179\n",
      "L1N1                    -> L2N27 = -0.08836442232131958\n",
      "L1N1                    -> L2N28 = -0.10855432599782944\n",
      "L1N1                    -> L2N29 = 0.05050542205572128\n",
      "L1N1                    -> L2N30 = 0.032552774995565414\n",
      "L1N1                    -> L2N31 = 0.037798792123794556\n",
      "L1N1                    -> L2N32 = -0.19239374995231628\n",
      "L1N1                    -> L2N33 = -0.15107868611812592\n",
      "L1N1                    -> L2N34 = -0.02479322999715805\n",
      "L1N1                    -> L2N35 = -0.07168057560920715\n",
      "L1N1                    -> L2N36 = -0.17085210978984833\n",
      "L1N1                    -> L2N37 = -0.2418108582496643\n",
      "L1N1                    -> L2N38 = 0.0\n",
      "L1N1                    -> L2N39 = 0.010480456985533237\n",
      "L1N1                    -> L2N40 = 0.0006667025154456496\n",
      "L1N1                    -> L2N41 = 0.0\n",
      "L1N1                    -> L2N42 = 0.05063479766249657\n",
      "L1N1                    -> L2N43 = -0.24616427719593048\n",
      "L1N1                    -> L2N44 = 0.2332334667444229\n",
      "L1N1                    -> L2N45 = -0.13221226632595062\n",
      "L1N1                    -> L2N46 = 0.011768002063035965\n",
      "L1N1                    -> L2N47 = -0.035815782845020294\n",
      "L1N1                    -> L2N48 = 0.03897411748766899\n",
      "L1N1                    -> L2N49 = -0.1194150373339653\n",
      "L1N1                    -> L2N50 = -0.12153523415327072\n",
      "L1N1                    -> L2N51 = -0.07513594627380371\n",
      "L1N1                    -> L2N52 = -0.04965944215655327\n",
      "L1N1                    -> L2N53 = 0.022750234231352806\n",
      "L1N1                    -> L2N54 = -0.08075346052646637\n",
      "L1N1                    -> L2N55 = -0.25026389956474304\n",
      "L1N1                    -> L2N56 = 0.08695688098669052\n",
      "L1N1                    -> L2N57 = -0.04386528208851814\n",
      "L1N1                    -> L2N58 = -0.27822136878967285\n",
      "L1N1                    -> L2N59 = -0.31413066387176514\n",
      "L1N1                    -> L2N60 = -0.05909562483429909\n",
      "L1N1                    -> L2N61 = -0.18994879722595215\n",
      "L1N1                    -> L2N62 = -0.14344088733196259\n",
      "L1N1                    -> L2N63 = -0.0028634220361709595\n",
      "L1N1                    -> L2N64 = -0.04038598760962486\n",
      "L1N1                    -> L2N65 = -0.001001159311272204\n",
      "L1N1                    -> L2N66 = -0.2358676642179489\n",
      "L1N1                    -> L2N67 = -0.1319722980260849\n",
      "L1N1                    -> L2N68 = -0.08686051517724991\n",
      "L1N1                    -> L2N69 = -0.20944133400917053\n",
      "L1N1                    -> L2N70 = 0.06843982636928558\n",
      "L1N1                    -> L2N71 = -0.4835311472415924\n",
      "L1N1                    -> L2N72 = -0.13704252243041992\n",
      "L1N1                    -> L2N73 = -0.07014399021863937\n",
      "L1N1                    -> L2N74 = -0.1560550034046173\n",
      "L1N1                    -> L2N75 = -0.25356873869895935\n",
      "L1N1                    -> L2N76 = -0.047093190252780914\n",
      "L1N1                    -> L2N77 = -0.08110606670379639\n",
      "L1N1                    -> L2N78 = -0.05185989663004875\n",
      "L1N1                    -> L2N79 = -0.35303977131843567\n",
      "L1N1                    -> L2N80 = 0.013898397795855999\n",
      "L1N1                    -> L2N81 = -0.32128235697746277\n",
      "L1N1                    -> L2N82 = -0.4572693109512329\n",
      "L1N1                    -> L2N83 = -0.18980589509010315\n",
      "L1N1                    -> L2N84 = -0.18719786405563354\n",
      "L1N1                    -> L2N85 = -0.4806680977344513\n",
      "L1N1                    -> L2N86 = -0.12207823991775513\n",
      "L1N1                    -> L2N87 = 0.06904653459787369\n",
      "L1N1                    -> L2N88 = -0.6111841201782227\n",
      "L1N1                    -> L2N89 = 0.004996905103325844\n",
      "L1N1                    -> L2N90 = 0.02241702750325203\n",
      "L1N1                    -> L2N91 = -0.07287682592868805\n",
      "L1N1                    -> L2N92 = -0.8157981038093567\n",
      "L1N1                    -> L2N93 = -0.15867163240909576\n",
      "L1N1                    -> L2N94 = 0.05993063375353813\n",
      "L1N1                    -> L2N95 = 0.03849326819181442\n",
      "L1N1                    -> L2N96 = 0.3718253970146179\n",
      "L1N1                    -> L2N97 = -0.36544620990753174\n",
      "L1N1                    -> L2N98 = 0.09986966103315353\n",
      "L1N1                    -> L2N99 = -0.23532962799072266\n",
      "L3N0                    -> L4N0 = 1.052185297012329\n",
      "L3N0                    -> L4N1 = 1.1935887336730957\n",
      "L3N0                    -> L4N2 = 0.6909457445144653\n",
      "L3N0                    -> L4N3 = 0.9541295170783997\n",
      "L3N0                    -> L4N4 = 1.3306055068969727\n",
      "L3N0                    -> L4N5 = 0.7698805928230286\n",
      "L3N0                    -> L4N6 = 1.0972483158111572\n",
      "L3N0                    -> L4N7 = 0.9775615334510803\n",
      "L3N0                    -> L4N8 = 1.0123215913772583\n",
      "L3N0                    -> L4N9 = 1.0\n",
      "L3N0                    -> L4N10 = 0.8542400598526001\n",
      "L3N0                    -> L4N11 = 0.9743634462356567\n",
      "L3N0                    -> L4N12 = 0.9232988953590393\n",
      "L3N0                    -> L4N13 = 0.8291913866996765\n",
      "L3N0                    -> L4N14 = 1.2121392488479614\n",
      "L3N0                    -> L4N15 = 1.220920443534851\n",
      "L3N0                    -> L4N16 = 1.3901621103286743\n",
      "L3N0                    -> L4N17 = 0.959640383720398\n",
      "L3N0                    -> L4N18 = 1.4345479011535645\n",
      "L3N0                    -> L4N19 = 0.9253166317939758\n",
      "L3N0                    -> L4N20 = 1.3860893249511719\n",
      "L3N0                    -> L4N21 = 0.7300288677215576\n",
      "L3N0                    -> L4N22 = 0.7767998576164246\n",
      "L3N0                    -> L4N23 = 1.2350987195968628\n",
      "L3N0                    -> L4N24 = 0.9730267524719238\n",
      "L3N0                    -> L4N25 = 1.322749376296997\n",
      "L3N0                    -> L4N26 = 0.7709211111068726\n",
      "L3N0                    -> L4N27 = 1.1220659017562866\n",
      "L3N0                    -> L4N28 = 0.92647784948349\n",
      "L3N0                    -> L4N29 = 0.6279272437095642\n",
      "L3N0                    -> L4N30 = 1.0721229314804077\n",
      "L3N0                    -> L4N31 = 1.0151830911636353\n",
      "L3N0                    -> L4N32 = 1.1355671882629395\n",
      "L3N0                    -> L4N33 = 1.438231348991394\n",
      "L3N0                    -> L4N34 = 1.0721449851989746\n",
      "L3N0                    -> L4N35 = 1.2356488704681396\n",
      "L3N0                    -> L4N36 = 0.9544726014137268\n",
      "L3N0                    -> L4N37 = 1.015310287475586\n",
      "L3N0                    -> L4N38 = 1.0\n",
      "L3N0                    -> L4N39 = 1.2732045650482178\n",
      "L3N0                    -> L4N40 = 0.8758915066719055\n",
      "L3N0                    -> L4N41 = 1.0\n",
      "L3N0                    -> L4N42 = 1.0069150924682617\n",
      "L3N0                    -> L4N43 = 1.3381267786026\n",
      "L3N0                    -> L4N44 = 1.4297887086868286\n",
      "L3N0                    -> L4N45 = 1.191069483757019\n",
      "L3N0                    -> L4N46 = 0.8074579834938049\n",
      "L3N0                    -> L4N47 = 0.9471912980079651\n",
      "L3N0                    -> L4N48 = 1.1818594932556152\n",
      "L3N0                    -> L4N49 = 0.880717933177948\n",
      "L3N0                    -> L4N50 = 0.6350759267807007\n",
      "L3N0                    -> L4N51 = 0.9690345525741577\n",
      "L3N0                    -> L4N52 = 0.8410488963127136\n",
      "L3N0                    -> L4N53 = 0.5453166961669922\n",
      "L3N0                    -> L4N54 = 1.0656903982162476\n",
      "L3N0                    -> L4N55 = 1.005350112915039\n",
      "L3N0                    -> L4N56 = 1.045329213142395\n",
      "L3N0                    -> L4N57 = 0.7585933804512024\n",
      "L3N0                    -> L4N58 = 1.0586040019989014\n",
      "L3N0                    -> L4N59 = 1.4840247631072998\n",
      "L3N0                    -> L4N60 = 0.8807946443557739\n",
      "L3N0                    -> L4N61 = 1.215393304824829\n",
      "L3N0                    -> L4N62 = 0.9095216989517212\n",
      "L3N0                    -> L4N63 = 1.3169913291931152\n",
      "L3N0                    -> L4N64 = 0.8875375986099243\n",
      "L3N0                    -> L4N65 = 0.9788548946380615\n",
      "L3N0                    -> L4N66 = 1.1020179986953735\n",
      "L3N0                    -> L4N67 = 0.8887213468551636\n",
      "L3N0                    -> L4N68 = 0.7095435261726379\n",
      "L3N0                    -> L4N69 = 1.3862249851226807\n",
      "L3N0                    -> L4N70 = 0.9192358255386353\n",
      "L3N0                    -> L4N71 = 0.5146299004554749\n",
      "L3N0                    -> L4N72 = 1.182562232017517\n",
      "L3N0                    -> L4N73 = 1.152523159980774\n",
      "L3N0                    -> L4N74 = 0.8324896693229675\n",
      "L3N0                    -> L4N75 = 0.9502265453338623\n",
      "L3N0                    -> L4N76 = 0.6238759160041809\n",
      "L3N0                    -> L4N77 = 0.8669928312301636\n",
      "L3N0                    -> L4N78 = 0.9676018953323364\n",
      "L3N0                    -> L4N79 = 1.473766803741455\n",
      "L3N0                    -> L4N80 = 0.8074610829353333\n",
      "L3N0                    -> L4N81 = 1.0439085960388184\n",
      "L3N0                    -> L4N82 = 1.036616325378418\n",
      "L3N0                    -> L4N83 = 0.7911298871040344\n",
      "L3N0                    -> L4N84 = 1.0722929239273071\n",
      "L3N0                    -> L4N85 = 0.6148421168327332\n",
      "L3N0                    -> L4N86 = 1.041333556175232\n",
      "L3N0                    -> L4N87 = 1.0533366203308105\n",
      "L3N0                    -> L4N88 = 0.7719146609306335\n",
      "L3N0                    -> L4N89 = 1.199241280555725\n",
      "L3N0                    -> L4N90 = 0.7821946740150452\n",
      "L3N0                    -> L4N91 = 0.7804788947105408\n",
      "L3N0                    -> L4N92 = 0.6957521438598633\n",
      "L3N0                    -> L4N93 = 0.7047021389007568\n",
      "L3N0                    -> L4N94 = 0.9135297536849976\n",
      "L3N0                    -> L4N95 = 0.8178727030754089\n",
      "L3N0                    -> L4N96 = 1.1062839031219482\n",
      "L3N0                    -> L4N97 = 1.3091012239456177\n",
      "L3N0                    -> L4N98 = 1.1916954517364502\n",
      "L3N0                    -> L4N99 = 1.0760762691497803\n",
      "L3N1                    -> L4N0 = -0.11391320824623108\n",
      "L3N1                    -> L4N1 = 0.11546248942613602\n",
      "L3N1                    -> L4N2 = 0.021523592993617058\n",
      "L3N1                    -> L4N3 = -0.032836608588695526\n",
      "L3N1                    -> L4N4 = -0.3077119290828705\n",
      "L3N1                    -> L4N5 = 0.17147032916545868\n",
      "L3N1                    -> L4N6 = 0.13787396252155304\n",
      "L3N1                    -> L4N7 = -0.18588946759700775\n",
      "L3N1                    -> L4N8 = 0.08844661712646484\n",
      "L3N1                    -> L4N9 = 0.30692964792251587\n",
      "L3N1                    -> L4N10 = 0.1489420235157013\n",
      "L3N1                    -> L4N11 = 0.07914648950099945\n",
      "L3N1                    -> L4N12 = -0.034928787499666214\n",
      "L3N1                    -> L4N13 = 0.26428163051605225\n",
      "L3N1                    -> L4N14 = 0.17202703654766083\n",
      "L3N1                    -> L4N15 = 0.20650984346866608\n",
      "L3N1                    -> L4N16 = 0.24696891009807587\n",
      "L3N1                    -> L4N17 = -0.09423290938138962\n",
      "L3N1                    -> L4N18 = 0.1781555414199829\n",
      "L3N1                    -> L4N19 = -0.03293314203619957\n",
      "L3N1                    -> L4N20 = 0.11961685121059418\n",
      "L3N1                    -> L4N21 = 0.10058499127626419\n",
      "L3N1                    -> L4N22 = 0.2197941690683365\n",
      "L3N1                    -> L4N23 = 0.04019085690379143\n",
      "L3N1                    -> L4N24 = 0.2416575849056244\n",
      "L3N1                    -> L4N25 = 0.33896303176879883\n",
      "L3N1                    -> L4N26 = 0.23706813156604767\n",
      "L3N1                    -> L4N27 = 0.03912824019789696\n",
      "L3N1                    -> L4N28 = 0.10574368387460709\n",
      "L3N1                    -> L4N29 = -0.05963641405105591\n",
      "L3N1                    -> L4N30 = 0.4046498239040375\n",
      "L3N1                    -> L4N31 = 0.20818708837032318\n",
      "L3N1                    -> L4N32 = 0.04394756630063057\n",
      "L3N1                    -> L4N33 = 0.14947405457496643\n",
      "L3N1                    -> L4N34 = -0.1525963544845581\n",
      "L3N1                    -> L4N35 = 0.11937740445137024\n",
      "L3N1                    -> L4N36 = -0.022670075297355652\n",
      "L3N1                    -> L4N37 = 0.2899025082588196\n",
      "L3N1                    -> L4N38 = 0.15150117874145508\n",
      "L3N1                    -> L4N39 = -0.015439167618751526\n",
      "L3N1                    -> L4N40 = -0.06527937203645706\n",
      "L3N1                    -> L4N41 = 0.19173751771450043\n",
      "L3N1                    -> L4N42 = 0.07830458134412766\n",
      "L3N1                    -> L4N43 = 0.23208200931549072\n",
      "L3N1                    -> L4N44 = 0.04763588681817055\n",
      "L3N1                    -> L4N45 = 0.13767015933990479\n",
      "L3N1                    -> L4N46 = -0.12151333689689636\n",
      "L3N1                    -> L4N47 = -0.024161720648407936\n",
      "L3N1                    -> L4N48 = -0.03622572496533394\n",
      "L3N1                    -> L4N49 = 0.021196715533733368\n",
      "L3N1                    -> L4N50 = 0.10026755928993225\n",
      "L3N1                    -> L4N51 = 0.2313564270734787\n",
      "L3N1                    -> L4N52 = 0.2672502398490906\n",
      "L3N1                    -> L4N53 = 0.2898522615432739\n",
      "L3N1                    -> L4N54 = -0.02674008719623089\n",
      "L3N1                    -> L4N55 = 0.30058324337005615\n",
      "L3N1                    -> L4N56 = 0.29179880023002625\n",
      "L3N1                    -> L4N57 = 0.0263760257512331\n",
      "L3N1                    -> L4N58 = -0.07782690972089767\n",
      "L3N1                    -> L4N59 = 0.07483591139316559\n",
      "L3N1                    -> L4N60 = 0.16794665157794952\n",
      "L3N1                    -> L4N61 = -0.02575019560754299\n",
      "L3N1                    -> L4N62 = -0.2817234396934509\n",
      "L3N1                    -> L4N63 = 0.35205429792404175\n",
      "L3N1                    -> L4N64 = 0.13598698377609253\n",
      "L3N1                    -> L4N65 = 0.19626019895076752\n",
      "L3N1                    -> L4N66 = -0.039520230144262314\n",
      "L3N1                    -> L4N67 = 0.10858108848333359\n",
      "L3N1                    -> L4N68 = 0.03115163929760456\n",
      "L3N1                    -> L4N69 = 0.060979776084423065\n",
      "L3N1                    -> L4N70 = -0.006901779677718878\n",
      "L3N1                    -> L4N71 = 0.027875950559973717\n",
      "L3N1                    -> L4N72 = 0.06592244654893875\n",
      "L3N1                    -> L4N73 = 0.04570469260215759\n",
      "L3N1                    -> L4N74 = 0.04448561742901802\n",
      "L3N1                    -> L4N75 = 0.0967973843216896\n",
      "L3N1                    -> L4N76 = -0.1265038251876831\n",
      "L3N1                    -> L4N77 = 0.04083709418773651\n",
      "L3N1                    -> L4N78 = -0.2484971284866333\n",
      "L3N1                    -> L4N79 = 0.06119387224316597\n",
      "L3N1                    -> L4N80 = -0.3601219058036804\n",
      "L3N1                    -> L4N81 = 0.12344781309366226\n",
      "L3N1                    -> L4N82 = 0.0035957940854132175\n",
      "L3N1                    -> L4N83 = 0.009887006133794785\n",
      "L3N1                    -> L4N84 = 0.3308638036251068\n",
      "L3N1                    -> L4N85 = -0.014894826337695122\n",
      "L3N1                    -> L4N86 = 0.1861594170331955\n",
      "L3N1                    -> L4N87 = 0.014902002178132534\n",
      "L3N1                    -> L4N88 = 0.00011003472900483757\n",
      "L3N1                    -> L4N89 = -0.05316904932260513\n",
      "L3N1                    -> L4N90 = 0.1955450177192688\n",
      "L3N1                    -> L4N91 = -0.11580894142389297\n",
      "L3N1                    -> L4N92 = -0.2563505470752716\n",
      "L3N1                    -> L4N93 = 0.17441193759441376\n",
      "L3N1                    -> L4N94 = -0.021069204434752464\n",
      "L3N1                    -> L4N95 = 0.246341273188591\n",
      "L3N1                    -> L4N96 = 0.18584276735782623\n",
      "L3N1                    -> L4N97 = -0.06873537600040436\n",
      "L3N1                    -> L4N98 = 0.2778146266937256\n",
      "L3N1                    -> L4N99 = 0.1409962922334671\n",
      "L3N2                    -> L4N0 = 0.03895903751254082\n",
      "L3N2                    -> L4N1 = 0.011095117777585983\n",
      "L3N2                    -> L4N2 = 0.00012834518565796316\n",
      "L3N2                    -> L4N3 = 0.04279632866382599\n",
      "L3N2                    -> L4N4 = 0.00015016035467851907\n",
      "L3N2                    -> L4N5 = 0.0036569046787917614\n",
      "L3N2                    -> L4N6 = 0.033977631479501724\n",
      "L3N2                    -> L4N7 = 1.1642990298687774e-36\n",
      "L3N2                    -> L4N8 = 0.008705591782927513\n",
      "L3N2                    -> L4N9 = 0.0\n",
      "L3N2                    -> L4N10 = 0.05008278042078018\n",
      "L3N2                    -> L4N11 = 0.052466489374637604\n",
      "L3N2                    -> L4N12 = 0.0792120024561882\n",
      "L3N2                    -> L4N13 = 0.021177757531404495\n",
      "L3N2                    -> L4N14 = 0.039077915251255035\n",
      "L3N2                    -> L4N15 = 0.016401998698711395\n",
      "L3N2                    -> L4N16 = 0.02985582873225212\n",
      "L3N2                    -> L4N17 = 0.04337449371814728\n",
      "L3N2                    -> L4N18 = 0.07881082594394684\n",
      "L3N2                    -> L4N19 = 0.0024378690868616104\n",
      "L3N2                    -> L4N20 = 0.001968262018635869\n",
      "L3N2                    -> L4N21 = 0.011209957301616669\n",
      "L3N2                    -> L4N22 = 0.00724166352301836\n",
      "L3N2                    -> L4N23 = 0.04393059015274048\n",
      "L3N2                    -> L4N24 = 1.1722414550399179e-36\n",
      "L3N2                    -> L4N25 = 0.13607405126094818\n",
      "L3N2                    -> L4N26 = 0.03831056132912636\n",
      "L3N2                    -> L4N27 = 0.0366000160574913\n",
      "L3N2                    -> L4N28 = 0.11098755896091461\n",
      "L3N2                    -> L4N29 = 0.0013034138828516006\n",
      "L3N2                    -> L4N30 = 0.060141533613204956\n",
      "L3N2                    -> L4N31 = 0.04764897748827934\n",
      "L3N2                    -> L4N32 = 0.024696022272109985\n",
      "L3N2                    -> L4N33 = 0.0076426127925515175\n",
      "L3N2                    -> L4N34 = 0.011617651209235191\n",
      "L3N2                    -> L4N35 = 0.0045438907109200954\n",
      "L3N2                    -> L4N36 = 1.1654732507195553e-36\n",
      "L3N2                    -> L4N37 = 0.13060778379440308\n",
      "L3N2                    -> L4N38 = 0.0\n",
      "L3N2                    -> L4N39 = 0.013329525478184223\n",
      "L3N2                    -> L4N40 = 0.011346912942826748\n",
      "L3N2                    -> L4N41 = 0.0\n",
      "L3N2                    -> L4N42 = 0.07954103499650955\n",
      "L3N2                    -> L4N43 = 0.00419826852157712\n",
      "L3N2                    -> L4N44 = 0.029235828667879105\n",
      "L3N2                    -> L4N45 = 0.022218869999051094\n",
      "L3N2                    -> L4N46 = 0.0010520117357373238\n",
      "L3N2                    -> L4N47 = 1.1696241433994151e-36\n",
      "L3N2                    -> L4N48 = 0.005381377413868904\n",
      "L3N2                    -> L4N49 = 0.1811448037624359\n",
      "L3N2                    -> L4N50 = 1.1692673840207857e-36\n",
      "L3N2                    -> L4N51 = 1.1687415719954202e-36\n",
      "L3N2                    -> L4N52 = 0.03478570282459259\n",
      "L3N2                    -> L4N53 = 0.08310876041650772\n",
      "L3N2                    -> L4N54 = 0.028397858142852783\n",
      "L3N2                    -> L4N55 = 0.04539700224995613\n",
      "L3N2                    -> L4N56 = 0.012283545918762684\n",
      "L3N2                    -> L4N57 = 0.05264788120985031\n",
      "L3N2                    -> L4N58 = 1.1742450652153726e-36\n",
      "L3N2                    -> L4N59 = 0.07219159603118896\n",
      "L3N2                    -> L4N60 = 0.032149698585271835\n",
      "L3N2                    -> L4N61 = 4.6975175791885704e-05\n",
      "L3N2                    -> L4N62 = 0.03756219521164894\n",
      "L3N2                    -> L4N63 = 0.000896926037967205\n",
      "L3N2                    -> L4N64 = 0.004987888038158417\n",
      "L3N2                    -> L4N65 = 0.0006329941097646952\n",
      "L3N2                    -> L4N66 = 1.164029352781915e-36\n",
      "L3N2                    -> L4N67 = 0.07554192841053009\n",
      "L3N2                    -> L4N68 = 0.0721779614686966\n",
      "L3N2                    -> L4N69 = 0.0010607506847009063\n",
      "L3N2                    -> L4N70 = 0.013883574865758419\n",
      "L3N2                    -> L4N71 = 0.1661972850561142\n",
      "L3N2                    -> L4N72 = 0.027919771149754524\n",
      "L3N2                    -> L4N73 = 0.01729739084839821\n",
      "L3N2                    -> L4N74 = 0.12100950628519058\n",
      "L3N2                    -> L4N75 = 0.033499591052532196\n",
      "L3N2                    -> L4N76 = 0.19488956034183502\n",
      "L3N2                    -> L4N77 = 1.1646313057606381e-36\n",
      "L3N2                    -> L4N78 = 1.1720678285549942e-36\n",
      "L3N2                    -> L4N79 = 0.05992523580789566\n",
      "L3N2                    -> L4N80 = 0.012891951948404312\n",
      "L3N2                    -> L4N81 = 0.04502551257610321\n",
      "L3N2                    -> L4N82 = 0.008000948466360569\n",
      "L3N2                    -> L4N83 = 0.04440123215317726\n",
      "L3N2                    -> L4N84 = 0.2471284419298172\n",
      "L3N2                    -> L4N85 = 0.16804519295692444\n",
      "L3N2                    -> L4N86 = 0.006062166765332222\n",
      "L3N2                    -> L4N87 = 0.04660147801041603\n",
      "L3N2                    -> L4N88 = 0.09817367792129517\n",
      "L3N2                    -> L4N89 = 0.0008505629957653582\n",
      "L3N2                    -> L4N90 = 0.06646924465894699\n",
      "L3N2                    -> L4N91 = 0.09752820432186127\n",
      "L3N2                    -> L4N92 = 0.05920803174376488\n",
      "L3N2                    -> L4N93 = 0.07037646323442459\n",
      "L3N2                    -> L4N94 = 0.011182432062923908\n",
      "L3N2                    -> L4N95 = 0.05048277601599693\n",
      "L3N2                    -> L4N96 = 0.023676907643675804\n",
      "L3N2                    -> L4N97 = 0.00309817586094141\n",
      "L3N2                    -> L4N98 = 0.07244083285331726\n",
      "L3N2                    -> L4N99 = 0.07096685469150543\n",
      "L3N3                    -> L4N0 = 0.014877796173095703\n",
      "L3N3                    -> L4N1 = 0.0030270556453615427\n",
      "L3N3                    -> L4N2 = 3.971621481468901e-05\n",
      "L3N3                    -> L4N3 = 0.010438044555485249\n",
      "L3N3                    -> L4N4 = 6.415678944904357e-05\n",
      "L3N3                    -> L4N5 = 0.0010233055800199509\n",
      "L3N3                    -> L4N6 = 0.009677711874246597\n",
      "L3N3                    -> L4N7 = 1.1688085652724027e-36\n",
      "L3N3                    -> L4N8 = 0.0019072182476520538\n",
      "L3N3                    -> L4N9 = 1.1719860375662285e-36\n",
      "L3N3                    -> L4N10 = 0.022306136786937714\n",
      "L3N3                    -> L4N11 = 0.030997632071375847\n",
      "L3N3                    -> L4N12 = 0.020291397348046303\n",
      "L3N3                    -> L4N13 = 0.004763240460306406\n",
      "L3N3                    -> L4N14 = 0.01904871128499508\n",
      "L3N3                    -> L4N15 = 0.007247427478432655\n",
      "L3N3                    -> L4N16 = 0.007105081342160702\n",
      "L3N3                    -> L4N17 = 0.016823241487145424\n",
      "L3N3                    -> L4N18 = 0.02612728625535965\n",
      "L3N3                    -> L4N19 = 0.0009746788418851793\n",
      "L3N3                    -> L4N20 = 0.0007078446797095239\n",
      "L3N3                    -> L4N21 = 0.005121157038956881\n",
      "L3N3                    -> L4N22 = 0.0018355813808739185\n",
      "L3N3                    -> L4N23 = 0.008921350352466106\n",
      "L3N3                    -> L4N24 = 1.1672410840205966e-36\n",
      "L3N3                    -> L4N25 = 0.0985511839389801\n",
      "L3N3                    -> L4N26 = 0.015251317992806435\n",
      "L3N3                    -> L4N27 = 0.013505643233656883\n",
      "L3N3                    -> L4N28 = 0.039825987070798874\n",
      "L3N3                    -> L4N29 = 0.0008102208375930786\n",
      "L3N3                    -> L4N30 = 0.011233757250010967\n",
      "L3N3                    -> L4N31 = 0.011952721513807774\n",
      "L3N3                    -> L4N32 = 0.005765276961028576\n",
      "L3N3                    -> L4N33 = 0.0021064779721200466\n",
      "L3N3                    -> L4N34 = 0.00316104618832469\n",
      "L3N3                    -> L4N35 = 0.0017599371494725347\n",
      "L3N3                    -> L4N36 = 1.1730969421471943e-36\n",
      "L3N3                    -> L4N37 = 0.02581918239593506\n",
      "L3N3                    -> L4N38 = 1.1719860375662285e-36\n",
      "L3N3                    -> L4N39 = 0.0031667067669332027\n",
      "L3N3                    -> L4N40 = 0.006606987677514553\n",
      "L3N3                    -> L4N41 = 1.1719860375662285e-36\n",
      "L3N3                    -> L4N42 = 0.021884968504309654\n",
      "L3N3                    -> L4N43 = 0.0013194583589211106\n",
      "L3N3                    -> L4N44 = 0.016287250444293022\n",
      "L3N3                    -> L4N45 = 0.005930176004767418\n",
      "L3N3                    -> L4N46 = 0.00029378363979049027\n",
      "L3N3                    -> L4N47 = 1.1696588507597795e-36\n",
      "L3N3                    -> L4N48 = 0.000939041143283248\n",
      "L3N3                    -> L4N49 = 0.07897190004587173\n",
      "L3N3                    -> L4N50 = 1.1668330259077852e-36\n",
      "L3N3                    -> L4N51 = 1.1687199583679065e-36\n",
      "L3N3                    -> L4N52 = 0.01304788701236248\n",
      "L3N3                    -> L4N53 = 0.07261919230222702\n",
      "L3N3                    -> L4N54 = 0.008417286910116673\n",
      "L3N3                    -> L4N55 = 0.013108151033520699\n",
      "L3N3                    -> L4N56 = 0.003520395839586854\n",
      "L3N3                    -> L4N57 = 0.01354883797466755\n",
      "L3N3                    -> L4N58 = 1.1647722875965369e-36\n",
      "L3N3                    -> L4N59 = 0.029144469648599625\n",
      "L3N3                    -> L4N60 = 0.009639328345656395\n",
      "L3N3                    -> L4N61 = 1.1364680176484399e-05\n",
      "L3N3                    -> L4N62 = 0.014812092296779156\n",
      "L3N3                    -> L4N63 = 0.00027457132819108665\n",
      "L3N3                    -> L4N64 = 0.002154703950509429\n",
      "L3N3                    -> L4N65 = 0.00017144123557955027\n",
      "L3N3                    -> L4N66 = 1.1702342575403944e-36\n",
      "L3N3                    -> L4N67 = 0.05103963986039162\n",
      "L3N3                    -> L4N68 = 0.02788442187011242\n",
      "L3N3                    -> L4N69 = 0.0003041402669623494\n",
      "L3N3                    -> L4N70 = 0.0053808679804205894\n",
      "L3N3                    -> L4N71 = 0.13739809393882751\n",
      "L3N3                    -> L4N72 = 0.008803221397101879\n",
      "L3N3                    -> L4N73 = 0.00443209009245038\n",
      "L3N3                    -> L4N74 = 0.030309559777379036\n",
      "L3N3                    -> L4N75 = 0.007403630763292313\n",
      "L3N3                    -> L4N76 = 0.0831683874130249\n",
      "L3N3                    -> L4N77 = 1.1712338653921298e-36\n",
      "L3N3                    -> L4N78 = 1.1745627227616535e-36\n",
      "L3N3                    -> L4N79 = 0.024941762909293175\n",
      "L3N3                    -> L4N80 = 0.0048491763882339\n",
      "L3N3                    -> L4N81 = 0.013506279326975346\n",
      "L3N3                    -> L4N82 = 0.0014849824365228415\n",
      "L3N3                    -> L4N83 = 0.010175296105444431\n",
      "L3N3                    -> L4N84 = 0.07847831398248672\n",
      "L3N3                    -> L4N85 = 0.14323565363883972\n",
      "L3N3                    -> L4N86 = 0.0013759714784100652\n",
      "L3N3                    -> L4N87 = 0.02198709174990654\n",
      "L3N3                    -> L4N88 = 0.04059880971908569\n",
      "L3N3                    -> L4N89 = 0.00030054638045839965\n",
      "L3N3                    -> L4N90 = 0.021049337461590767\n",
      "L3N3                    -> L4N91 = 0.03875873610377312\n",
      "L3N3                    -> L4N92 = 0.019561637192964554\n",
      "L3N3                    -> L4N93 = 0.0227202121168375\n",
      "L3N3                    -> L4N94 = 0.003127039410173893\n",
      "L3N3                    -> L4N95 = 0.04114622622728348\n",
      "L3N3                    -> L4N96 = 0.015423349104821682\n",
      "L3N3                    -> L4N97 = 0.0005468595190905035\n",
      "L3N3                    -> L4N98 = 0.019396215677261353\n",
      "L3N3                    -> L4N99 = 0.018526939675211906\n",
      "L4N0                    -> L5N0 = [-0.04455134 -0.14933828 -0.29804128 -0.15340732 -0.04627845  0.07082568\n",
      " -0.26092237  0.18783383 -0.03894729 -0.21334478 -0.26089624  0.2830455\n",
      " -0.1366889  -0.117347   -0.14500038  0.32036144 -0.17552167  0.03310964\n",
      " -0.01432414  0.2838238   0.4581754  -0.33147213  0.18483669 -0.14090334\n",
      "  0.11892302 -0.23183326 -0.11344248  0.31879854  0.30738205  0.4610867\n",
      " -0.00994632  0.30593565  0.161302    0.18086594 -0.19540647  0.00082484\n",
      " -0.68767697  0.31691334  0.23386513 -0.33642298  0.05221384  0.32154953\n",
      "  0.14886531 -0.32962638 -0.58806837  0.0575821  -0.37195203 -0.02797207\n",
      " -0.21695617 -0.14598763 -0.16632195 -0.37583917  0.11247203 -0.07695419\n",
      "  0.13162746 -0.17249897 -0.08413702 -0.21387944  0.0107868  -0.08612745\n",
      " -0.15027209  0.20071484 -0.38868278  0.01213701 -0.4801392   0.02186929\n",
      " -0.19476761 -0.38813296 -0.2610851  -0.3288375  -0.3226895  -0.01090818\n",
      "  0.14335372  0.2591475   0.06897783 -0.26852763  0.40965974 -0.09902853\n",
      " -0.14810781 -0.14630285  0.23721734  0.16442095  0.23924766  0.05061011\n",
      " -0.39463484  0.07313213  0.13622625 -0.17233546  0.4661761   0.2736163\n",
      "  0.08983655 -0.34826556  0.0726213  -0.18982893 -0.5475821   0.32695088\n",
      "  0.17720547 -0.08199522  0.5246425   0.01200757  0.37124652 -0.14883782\n",
      " -0.16772003  0.16579917  0.0484846   0.36924016 -0.2252675   0.01578482\n",
      " -0.09053246 -0.5306281   0.17671266  0.06483667  0.10790131  0.28059244\n",
      "  0.03840585 -0.04281187  0.21319744  0.14862475 -0.23332305 -0.2948358\n",
      " -0.1601979   0.20384394  0.08605663 -0.24792741 -0.4085815  -0.0071193\n",
      " -0.0066098   0.3275933   0.0366734   0.06825337 -0.2089528  -0.12609418\n",
      " -0.03389611 -0.01956323 -0.00452713 -0.10104051  0.18180312  0.06922116\n",
      " -0.04536312  0.2805942  -0.18112768 -0.5770885  -0.16988435 -0.2170718\n",
      " -0.22324924 -0.21756062 -0.46327752  0.17782927  0.22392525  0.02879119]\n",
      "L4N0                    -> L5N1 = [-5.60467541e-01 -3.96660268e-01 -1.26699477e-01 -1.66209102e-01\n",
      " -3.59665424e-01 -5.83024733e-02 -1.73898965e-01  1.75833985e-01\n",
      " -2.16706824e-02 -1.93728551e-01 -1.19121216e-01 -3.10002621e-02\n",
      " -2.82341868e-01 -1.49465278e-01 -6.95867419e-01 -8.26096535e-02\n",
      "  8.43164697e-02  1.03335463e-01 -4.07039553e-01  4.55965787e-01\n",
      " -1.32937208e-01  3.56216073e-01  1.07439667e-01  1.86133102e-01\n",
      " -2.57559747e-01 -1.41186222e-01 -1.25435635e-01  3.26489002e-01\n",
      " -3.11699927e-01 -3.56487520e-02  9.54288319e-02  4.02162957e-04\n",
      " -3.57576281e-01 -1.61659166e-01  5.95824607e-02 -1.86860904e-01\n",
      "  6.73906729e-02 -6.49213791e-02  1.30467102e-01 -1.89360455e-01\n",
      "  2.35552341e-01 -8.07994157e-02  1.39483377e-01 -6.25429526e-02\n",
      " -2.72279322e-01 -2.51727015e-01  1.18018053e-01  1.55144349e-01\n",
      "  4.03531194e-01  1.48896441e-01 -2.88580358e-02 -1.91984802e-01\n",
      " -5.27518652e-02  2.35339314e-01  1.23716518e-01  3.14441063e-02\n",
      " -2.35573620e-01 -2.57295161e-01  1.64439052e-01  9.01216269e-02\n",
      "  3.43252897e-01 -2.27935120e-01 -4.89165366e-01 -1.32362589e-01\n",
      " -2.22580910e-01  3.09793521e-02  1.22367563e-02 -1.62250936e-01\n",
      " -5.40874004e-02  1.07323922e-01 -2.16593985e-02  5.19017391e-02\n",
      "  3.29247117e-01  1.26515076e-01  2.91364580e-01  3.12532842e-01\n",
      "  3.70873548e-02 -4.18370157e-01  1.29557597e-02 -1.73372328e-01\n",
      "  3.80813517e-02  2.74263889e-01  1.99037734e-02  2.09645420e-01\n",
      "  1.59659997e-01  1.06672332e-01 -2.38368362e-02 -1.54578418e-01\n",
      "  2.34627217e-01 -3.47559273e-01  3.25609446e-01 -5.46560764e-01\n",
      "  3.69192868e-01 -3.42579544e-01 -2.62514681e-01 -1.49029300e-01\n",
      " -3.75294566e-01 -3.97550734e-03  5.86794972e-01 -4.55474481e-02\n",
      " -4.60963473e-02 -1.50866985e-01  4.43231873e-02  1.69256002e-01\n",
      " -1.55927882e-01  2.14926556e-01 -7.27735877e-01  1.20590538e-01\n",
      " -2.37348974e-01  8.81029144e-02  1.87724695e-01  1.96025312e-01\n",
      " -2.48622999e-01 -1.46828359e-02 -8.53313953e-02 -3.26713532e-01\n",
      "  3.01148385e-01 -2.64016449e-01 -5.48317730e-01 -8.00460398e-01\n",
      " -1.14742413e-01  2.29431838e-01  8.36291015e-02 -3.88706505e-01\n",
      " -7.18147755e-01 -3.98286164e-01 -2.96044141e-01  3.21144193e-01\n",
      " -4.01211798e-01 -2.45128497e-01 -2.30350986e-01  1.05068222e-01\n",
      " -4.44439322e-01 -5.28564990e-01  4.05722372e-02 -1.53425440e-01\n",
      " -3.37011039e-01  1.49045363e-01 -3.06868479e-02  4.31159645e-01\n",
      " -4.72683311e-01 -8.46081853e-01 -5.24311662e-01 -1.34275090e-02\n",
      " -2.26826057e-01 -1.04417585e-01 -1.57824218e-01 -2.30891123e-01\n",
      "  1.70527190e-01  1.46435425e-01]\n",
      "L4N0                    -> L5N2 = [-0.06172327  0.12540646 -0.06089802 -0.2090519   0.1030046   0.00949543\n",
      "  0.10885809  0.17519778 -0.01908475 -0.14853615  0.14917211  0.22718625\n",
      " -0.06274733  0.32514954 -0.05063889  0.10608373 -0.19039679  0.00282225\n",
      " -0.49326766  0.0430739   0.162271    0.1952356   0.05057391  0.06785712\n",
      " -0.4069006  -0.4671716  -0.12016912 -0.05372583 -0.07147813 -0.3721881\n",
      " -0.02570715 -0.24764054 -0.00847168  0.13479659  0.1829608   0.02897674\n",
      "  0.10728982  0.2695745  -0.32074234  0.17966628 -0.02600441 -0.18704273\n",
      " -0.12603341 -0.24622168 -0.21412292 -0.12695879 -0.05046069  0.12627077\n",
      "  0.01720286 -0.39243233  0.20359024 -0.08458201  0.0722924  -0.09154664\n",
      "  0.07943719 -0.22077216  0.06015067 -0.07373708 -0.07741275  0.08836592\n",
      " -0.29241148  0.07135183 -0.31377348 -0.07093652  0.0651577   0.00953383\n",
      " -0.02180695 -0.17741969  0.2985729  -0.05322133 -0.10418677  0.03274983\n",
      " -0.08199106 -0.16670117 -0.16078699  0.1703914  -0.09928965 -0.1640464\n",
      " -0.07346047 -0.02687565 -0.02610739  0.24092944 -0.01801319 -0.52559805\n",
      "  0.4180604  -0.21383978 -0.23332255 -0.31858656  0.23595738 -0.07164447\n",
      " -0.19274563 -0.2889615  -0.1582947   0.01416291  0.09460971 -0.07684197\n",
      " -0.1336169  -0.15755998  0.00735233 -0.00535073 -0.0476805   0.15881751\n",
      " -0.02234802  0.10591158  0.03914908 -0.11270691 -0.23350182 -0.06384287\n",
      " -0.26688907  0.1313587  -0.02398885 -0.23661573  0.01648569 -0.17531769\n",
      " -0.09171947  0.29999092 -0.12753357  0.19279042 -0.19109528  0.09090018\n",
      " -0.22837128  0.04692463 -0.01774621 -0.5844867  -0.11711169 -0.04492271\n",
      "  0.16236962  0.28068155 -0.19719051  0.17901811 -0.06891764  0.1284071\n",
      " -0.06291854 -0.02422793 -0.27529806  0.112486   -0.11965997  0.31817192\n",
      "  0.20582806  0.05697121  0.01057415 -0.14929059 -0.21511142  0.26291743\n",
      " -0.15085106 -0.01121365 -0.03596809  0.15576445 -0.0777197   0.00941419]\n",
      "L4N0                    -> L5N3 = [-0.32578808 -0.3622815   0.19992113  0.0292505   0.06567489  0.37476075\n",
      "  0.00463715 -0.6262353  -0.18615218 -0.08556329 -0.1462152   0.15639995\n",
      " -0.663068   -0.03129211 -0.03187916  0.12378112  0.3561513   0.2609203\n",
      "  0.1576424   0.13455425  0.08356905 -0.35104415  0.23470517 -0.26755148\n",
      "  0.10469984 -0.02123414  0.05548024 -0.04493331  0.24784407 -0.14070085\n",
      "  0.19051386  0.13762628 -0.10180406  0.0433623   0.00590381 -0.22171682\n",
      " -0.1651942  -0.34192044 -0.00775146  0.10350963 -0.49924782 -0.32634568\n",
      " -0.15975106 -0.40026316 -0.00709121 -0.01504953  0.03714049 -0.31781298\n",
      "  0.05707606 -0.04093889 -0.30462858  0.12114942 -0.01734517  0.17823155\n",
      "  0.08133779 -0.5790069   0.09110186  0.10349039  0.32192194  0.16159473\n",
      " -0.05278578  0.20384803 -0.26238832 -0.3285021   0.21023841  0.14423637\n",
      " -0.14258102  0.04471149 -0.19687271 -0.19548225  0.10386115 -0.438862\n",
      " -0.08648724 -0.31715944  0.28799263 -0.21184847  0.13511547  0.26504877\n",
      " -0.01693599 -0.03980295 -0.0693498  -0.27079856 -0.324922   -0.08953465\n",
      " -0.47371662  0.23530795  0.06993327  0.1866484  -0.01243054  0.07179822\n",
      " -0.03769017 -0.09587803  0.12381258 -0.1927141  -0.20502003  0.01900277\n",
      " -0.08987494  0.29652426 -0.17620249  0.43723708  0.17465205 -0.09759711\n",
      " -0.213369   -0.14651251 -0.29201302 -0.00517557  0.2551246  -0.04183076\n",
      "  0.0613308   0.23518828  0.04226762  0.2674721   0.17871071  0.0150324\n",
      "  0.23376574  0.03126592  0.37166166  0.55154854 -0.3664189   0.18641543\n",
      "  0.1401031  -0.21632606 -0.2526848  -0.5683145  -0.1363979   0.10975298\n",
      " -0.13486291 -0.08592267 -0.17704359 -0.30290765 -0.05816339  0.47010407\n",
      " -0.10619234 -0.00629037  0.06439461 -0.13674428  0.1325009  -0.48893803\n",
      " -0.17512526  0.02192122 -0.12920702 -0.1426749  -0.18232676 -0.03226433\n",
      "  0.09909685 -0.27969432 -0.28269494  0.06252135  0.08056134 -0.0446255 ]\n",
      "L4N0                    -> L5N4 = [ 0.09536579  0.02307683 -0.0893883   0.24297805  0.11977319  0.07283881\n",
      " -0.13732016  0.26657712 -0.47465375 -0.05673169 -0.02876191 -0.07867866\n",
      " -0.0117093  -0.23267354 -0.12235448  0.20063451  0.06307891  0.20921814\n",
      "  0.16387455  0.08684702  0.3088046  -0.26180875  0.18427193  0.22481936\n",
      " -0.16582263  0.3304606   0.2736497   0.1777093   0.1535987   0.31341338\n",
      "  0.03099969  0.3332749   0.13600871  0.17802405 -0.04971451  0.16383423\n",
      "  0.08247357 -0.05818152  0.11863955  0.03460301  0.09366219  0.63028073\n",
      "  0.09989179 -0.16579185 -0.15451317 -0.0051271   0.07744985  0.21185595\n",
      "  0.2506924   0.2041514   0.48945186  0.06373024 -0.13280839  0.10175002\n",
      "  0.20749465  0.2721928  -0.33060673  0.32747087  0.16144845  0.483888\n",
      " -0.10241739  0.36164176 -0.11134842 -0.14668655 -0.23961242  0.18994203\n",
      " -0.22565128  0.04415735 -0.1567206  -0.11412443  0.083086    0.02684606\n",
      "  0.07217757  0.6471858   0.15234913 -0.23252714  0.7675087  -0.0307984\n",
      "  0.21824028  0.11152077  0.21328087 -0.21702589 -0.09006876 -0.02736584\n",
      " -0.2485658   0.06901493 -0.02085654  0.43315756 -0.10765669  0.1370983\n",
      "  0.37110686  0.11275557 -0.06097366 -0.07722103  0.17757955  0.49194527\n",
      "  0.06116408 -0.22901654  0.2656275   0.6997596   0.5494522  -0.26738697\n",
      " -0.11528438 -0.11109199 -0.02782523 -0.29354623  0.2730844   0.3876226\n",
      "  0.23132509  0.43186265 -0.1837688   0.36224732  0.19990593  0.34732348\n",
      "  0.44054967 -0.1688468   0.14609809  0.4213668   0.01947884  0.05077241\n",
      " -0.03850766 -0.09515122  0.06823601 -0.08661436 -0.00832835 -0.1798654\n",
      " -0.29846555 -0.31602332  0.13661638 -0.41412055  0.37386274  0.48816225\n",
      "  0.16559455  0.02495506 -0.02468084  0.168137    0.55232745 -0.14929679\n",
      "  0.14451577 -0.11919004 -0.04223552  0.09305354 -0.2480964   0.19935529\n",
      "  0.4874203   0.01734399 -0.05230728  0.18931107  0.29975748  0.07108721]\n",
      "L4N0                    -> L5N5 = [-0.20414525  0.1037478  -0.06942632  0.16397762 -0.12575166 -0.0896081\n",
      "  0.16068357 -0.29635006 -0.16990201 -0.37563723 -0.44568965 -0.10126708\n",
      "  0.14281297 -0.0480215   0.22449322 -0.13640194  0.18782096 -0.12523016\n",
      "  0.03899679  0.13760099 -0.21604897 -0.2152251  -0.14080441 -0.09463167\n",
      " -0.07034683 -0.14442118 -0.08849017 -0.6144279  -0.0360045  -0.27496034\n",
      " -0.20014365  0.08416747  0.2140694   0.23651588  0.2533461  -0.261616\n",
      " -0.22146119  0.0050898  -0.2111714   0.15225896 -0.31335086 -0.07336549\n",
      " -0.14122526 -0.17348866  0.06100865 -0.18958552 -0.4896678  -0.04138185\n",
      " -0.03585773 -0.26819953 -0.31364313 -0.04641274  0.06261494 -0.22381389\n",
      " -0.04969756 -0.44591907 -0.08691973 -0.21609236 -0.14814602 -0.5360359\n",
      " -0.1939409  -0.01445662 -0.02529792 -0.07793338  0.01016262  0.00434316\n",
      " -0.23577698 -0.1938147  -0.00310126 -0.04961528  0.3561951  -0.3350304\n",
      " -0.2169167  -0.5905605   0.03748069  0.01554775 -0.02721675  0.04644865\n",
      "  0.02422783 -0.11317143 -0.1729631  -0.17252007 -0.1878706   0.0530525\n",
      "  0.15501407  0.13626124 -0.10659275  0.09208524 -0.3603635   0.15847646\n",
      "  0.02979913 -0.2717669  -0.38912484  0.08966506 -0.06128142 -0.23004209\n",
      " -0.1306368   0.04612727 -0.05114803  0.01302496 -0.20074207  0.3303812\n",
      " -0.02218372 -0.23748209 -0.4594195  -0.40340337 -0.02746992 -0.01564945\n",
      " -0.03565222  0.11600827  0.27528262  0.03369597  0.1239299  -0.01826741\n",
      "  0.17755698 -0.10335368  0.1937161   0.01861408 -0.36958843  0.23096292\n",
      " -0.15113452  0.2746915   0.25153607 -0.23583993  0.03177422 -0.05456693\n",
      "  0.306016   -0.6894189  -0.2648638   0.15076753  0.25555578  0.21544188\n",
      " -0.20745522 -0.09380442  0.1453923  -0.2147506   0.25218043 -0.2248297\n",
      " -0.20174286  0.27363452  0.34462982  0.11927834 -0.12700182  0.12092522\n",
      "  0.09509448 -0.26558608  0.01490032 -0.3012674   0.06438648 -0.12234496]\n",
      "L4N0                    -> L5N6 = [-0.2797426   0.22466183  0.0173015   0.27662715 -0.04992961 -0.10477003\n",
      "  0.07481613 -0.04562603  0.00850883 -0.31533158 -0.39310512 -0.5182696\n",
      " -0.12209404 -0.35828063 -0.23796648 -0.04620078  0.137844   -0.22655766\n",
      "  0.07539989  0.25988242  0.06100203 -0.0634286   0.03230422 -0.23852462\n",
      " -0.17286658 -0.61426526 -0.14717391 -0.0820867  -0.2029811   0.31762636\n",
      "  0.12910566  0.01197709  0.384336   -0.14751728 -0.14797404 -0.425288\n",
      "  0.07165226 -0.66097283  0.3940613  -0.21270077  0.34779522  0.09899324\n",
      "  0.15369758 -0.04006539 -0.1542968  -0.5984156  -0.00822567 -0.3402086\n",
      "  0.2794319   0.06405541 -0.31850126 -0.17738275 -0.38947675  0.09955075\n",
      " -0.42780942 -0.08914955 -0.2124125   0.13405515 -0.1648507   0.01410758\n",
      "  0.09115903 -0.4511735  -0.2172957  -0.1069243  -0.02815169  0.00186043\n",
      " -0.09423317 -0.11283702 -0.20293982  0.0804101  -0.5278956   0.15472661\n",
      "  0.13796577 -0.12461665  0.04826567 -0.01360922 -0.14053431 -0.30719405\n",
      "  0.11669177 -0.3420722  -0.0590888   0.01196294  0.2807228  -0.3906476\n",
      "  0.10271735 -0.03762085 -0.03160011 -0.22063519 -0.2496864  -0.26681\n",
      "  0.03207766 -0.29161215 -0.31273207 -0.20047691 -0.00913227  0.06420965\n",
      " -0.489547    0.02964843 -0.04052656 -0.2914357  -0.08873758  0.01512306\n",
      " -0.3427457  -0.01819817  0.54259944  0.03475894 -0.42535004 -0.08899347\n",
      " -0.39786428 -0.18341427 -0.34965357 -0.09433816  0.208015    0.03950011\n",
      " -0.02790506 -0.2858273  -0.10088199 -0.1284475  -0.5128693  -0.664281\n",
      "  0.02828148 -0.5061281  -0.04215673  0.07132006 -0.25836158 -0.04202984\n",
      " -0.3013808   0.1932593  -0.481954    0.18656884 -0.26901013  0.05369595\n",
      " -0.796911   -0.47199914  0.09436865  0.11777616 -0.01840235  0.13636252\n",
      "  0.32860005 -0.09912997 -0.22188656 -0.10810025 -0.18246968 -0.22731686\n",
      " -0.40503305  0.20644619 -0.03327712 -0.20320791 -0.42245206  0.04374426]\n",
      "L4N0                    -> L5N7 = [ 1.67254657e-01 -1.14557207e-01  1.78777710e-01  4.12841111e-01\n",
      "  1.58099100e-01  2.42244527e-01  7.13748857e-03  2.73237407e-01\n",
      " -2.44688824e-01  8.27013776e-02  1.83644950e-01 -2.70374060e-01\n",
      "  2.25897394e-02  3.08003724e-01 -7.63532370e-02  2.11767077e-01\n",
      "  2.73692578e-01 -6.06389623e-03  4.45575684e-01  2.19278425e-01\n",
      "  3.68955851e-01 -2.65644163e-01  2.77033802e-02 -2.04275683e-01\n",
      " -1.21085107e-01  2.99533606e-01  1.16940945e-01  5.32676041e-01\n",
      "  3.71851295e-01  2.79411614e-01  2.53555447e-01  5.00743747e-01\n",
      "  1.66391376e-02  4.74076062e-01 -7.16423914e-02 -8.66113082e-02\n",
      " -5.04917726e-02  8.80315304e-02  7.97590241e-02 -3.63002867e-01\n",
      "  7.65989199e-02  4.92189646e-01 -1.36318877e-01  1.83946356e-01\n",
      " -1.06573962e-02 -4.42246236e-02  9.97952670e-02  1.02191083e-01\n",
      " -1.30422011e-01  4.00317572e-02 -2.06312791e-01  2.39360213e-01\n",
      "  8.76596197e-02  4.87800166e-02 -1.12171546e-01  3.84650618e-01\n",
      " -1.49827436e-01  1.24113239e-01  2.75839359e-01  3.05390894e-01\n",
      " -3.63684036e-02 -1.72888096e-02  7.35718310e-02 -2.01948155e-02\n",
      " -8.09430480e-02 -1.89648733e-01 -2.58201174e-03  2.34485373e-01\n",
      " -3.55238140e-01 -1.11525744e-01 -1.97686702e-01  3.11340630e-01\n",
      "  3.16441864e-01 -6.55758902e-02  4.63612467e-01 -1.02627814e-01\n",
      "  2.38297731e-01  1.45175338e-01 -3.59244168e-01  1.02623746e-01\n",
      "  2.71668166e-01  2.56681256e-02  3.70409817e-01  5.76963983e-02\n",
      " -3.92816752e-01 -5.19010378e-03 -2.57543385e-01 -1.49715869e-02\n",
      "  1.05354130e-01 -1.58369258e-01  1.52702138e-01  7.12088495e-02\n",
      "  3.84680212e-01  1.51046827e-01 -1.26357019e-01 -1.25130489e-02\n",
      "  1.51342005e-01  4.53082437e-04  5.24789929e-01  3.20550114e-01\n",
      "  3.13497573e-01 -3.50797713e-01  8.98233280e-02  1.32455066e-01\n",
      "  3.63827169e-01 -3.22039835e-02  1.61092103e-01  3.43102068e-01\n",
      "  7.40148127e-03  1.47780627e-01 -1.91104785e-01  2.41388246e-01\n",
      " -4.12923023e-02  3.46681684e-01  2.83802271e-01 -1.98005568e-02\n",
      "  2.04250351e-01  1.02652602e-01 -5.41279353e-02 -1.88088849e-01\n",
      "  6.28070593e-01  6.18426017e-02 -8.38693753e-02  1.54050112e-01\n",
      " -2.65053697e-02 -1.30765989e-01 -2.62774795e-01 -1.20688245e-01\n",
      "  1.04654588e-01 -3.82616490e-01  2.15496063e-01  3.79645556e-01\n",
      "  4.60424125e-02  1.00921422e-01  1.78033471e-01  4.59550470e-01\n",
      "  2.64832705e-01  1.26864528e-04  3.01296473e-01 -1.67099476e-01\n",
      " -1.23337761e-01  1.06830448e-01  2.04039644e-02 -2.78603435e-01\n",
      "  1.08663440e-01 -3.38331461e-02  2.06193388e-01  4.24926400e-01\n",
      " -1.83356609e-02 -2.09340110e-01]\n",
      "L4N0                    -> L5N8 = [-0.16546631  0.03610888  0.13894404  0.14606851 -0.44263744 -0.10198501\n",
      " -0.1304376  -0.05370847  0.15618289 -0.1984219   0.04619585 -0.21081786\n",
      " -0.11089032  0.31162277 -0.329119    0.02993246 -0.18133481  0.3157494\n",
      "  0.20047092 -0.00158792  0.02360849  0.33644903 -0.141946   -0.06193062\n",
      "  0.20651087 -0.47015432 -0.5693533   0.3348266   0.05675931 -0.10625038\n",
      "  0.15368156 -0.06094396  0.2889468   0.40299487  0.04827783 -0.10719458\n",
      " -0.05017021 -0.02426427  0.14102368  0.21859612  0.22965148  0.3247236\n",
      " -0.05380482  0.02785983 -0.12395782  0.00530181 -0.14943768 -0.16625354\n",
      " -0.19486685  0.12119909  0.0220817  -0.23005664 -0.5589762  -0.14506218\n",
      " -0.40887204 -0.07740869 -0.11740004  0.12222459  0.04992666  0.19643229\n",
      "  0.59270626 -0.42554107 -0.5806499   0.1718526  -0.07211496 -0.17606698\n",
      " -0.05533247  0.15447375  0.28567958  0.06165302 -0.12957172 -0.07873187\n",
      " -0.09909371 -0.20166546  0.05552214  0.15327197 -0.2775246  -0.19624019\n",
      " -0.15166469  0.22254841  0.34384924  0.57815146 -0.6162518  -0.39972344\n",
      "  0.29812363  0.18009071 -0.3079912   0.04733267  0.5070375  -0.3719079\n",
      " -0.3068183  -0.4393035   0.55807453 -0.20970199 -0.14441898  0.06913356\n",
      " -0.13394196 -0.15663445  0.1670711  -0.23679584  0.0355275   0.22449432\n",
      " -0.11701705  0.20330259 -0.0071776  -0.47178113 -0.2998996   0.04691568\n",
      " -0.04852231 -0.26935366 -0.05510679  0.04327631 -0.14707048 -0.05510053\n",
      "  0.03799271 -0.02568961 -0.00716237 -0.19764516 -0.0799538  -0.23637633\n",
      " -0.09241623 -0.12986037 -0.16378003  0.04071536 -0.33572128 -0.30652446\n",
      " -0.1451584   0.444789    0.03469027 -0.36397618 -0.07796597 -0.2950582\n",
      " -0.08556207 -0.05642524 -0.19663168  0.06183915  0.05828559  0.4119269\n",
      "  0.06490588  0.42612022  0.00575701 -0.08564354  0.21341579  0.04417089\n",
      " -0.06553774  0.31372437 -0.21425955  0.03599618 -0.3623098   0.31319645]\n",
      "L4N0                    -> L5N9 = [ 0.0512669   0.05880334 -0.12291633 -0.0648256  -0.5784604  -0.09640869\n",
      " -0.18475103 -0.13621621  0.2239366   0.33189216 -0.38259593 -0.11717987\n",
      "  0.14284849  0.01108107 -0.15147585 -0.22103053 -0.15621202  0.03357179\n",
      " -0.19543757 -0.37039897 -0.33300722  0.2665072  -0.00104361  0.2408728\n",
      " -0.07130501 -0.38491803 -0.29451886 -0.5314029  -0.08883869 -0.16635348\n",
      " -0.44939497 -0.42581308 -0.07934842 -0.6647892   0.03526673  0.00541007\n",
      " -0.1492596  -0.05158848 -0.09147874  0.35074908 -0.26614752 -0.73766637\n",
      "  0.01919472 -0.19181605  0.07329765 -0.02056128 -0.05050761  0.40363726\n",
      " -0.21034537 -0.00431263  0.2513552  -0.2811008   0.15788978 -0.12383335\n",
      "  0.07026292 -0.27653918  0.52523273 -0.32521802 -0.35390955 -0.13412502\n",
      " -0.02113469 -0.28965363 -0.29097328  0.03201019 -0.05042814  0.20788112\n",
      "  0.08084681 -0.21077064  0.38284898 -0.02135075  0.03540125 -0.23609024\n",
      "  0.14316809 -0.14329481 -0.26793972  0.02593067 -0.28251565 -0.12721458\n",
      "  0.17396912 -0.1760234  -0.34705588  0.13000579 -0.29779273 -0.13712756\n",
      "  0.24368174  0.07492125  0.01306708 -0.24078068 -0.33006763 -0.01619916\n",
      " -0.25686625 -0.14029899 -0.27584055 -0.05601741  0.03441611 -0.04223626\n",
      "  0.01472268 -0.05457798 -0.30158544 -0.3875868  -0.48004076  0.26355267\n",
      " -0.02105295  0.09302433 -0.17753239 -0.06895164 -0.06199035 -0.41268998\n",
      "  0.18637954  0.12809658  0.40331152 -0.4007454  -0.10105594 -0.2701876\n",
      " -0.39281458  0.06835344 -0.01436554  0.12164252 -0.17242485  0.07193536\n",
      " -0.34685946  0.08276277  0.1230155  -0.31196573  0.1707815   0.3188366\n",
      "  0.17850766  0.11960646 -0.29250875  0.33424273 -0.15009008  0.05990771\n",
      "  0.12700585 -0.3641877  -0.1894548  -0.4791311  -0.7044228  -0.11005297\n",
      " -0.16492379 -0.38928467  0.00091549  0.2984154   0.0705925   0.19693613\n",
      " -0.15922174  0.07031977  0.14628819 -0.2219493   0.20182705  0.06016281]\n",
      "L4N0                    -> L5N10 = [-0.2330827  -0.33668968  0.29120943 -0.53635174  0.02754207 -0.28833714\n",
      " -0.09147313 -0.425486    0.22053972  0.02908928  0.24519125  0.21356302\n",
      " -0.08371784  0.33530164 -0.21354565  0.23556317 -0.20124847  0.21224332\n",
      " -0.2745471  -0.05636242  0.22433957 -0.09910711 -0.03916939 -0.36168265\n",
      "  0.12656745  0.0860045   0.4140505   0.12475532  0.22142984  0.01892196\n",
      " -0.15885557  0.01963958 -0.2480072   0.03299782  0.22619954 -0.3409308\n",
      " -0.03095136  0.12184558 -0.2951729  -0.1584487  -0.28823587 -0.156728\n",
      "  0.13562652 -0.22937901 -0.17523925 -0.12253401 -0.50029963 -0.0453206\n",
      "  0.15600479 -0.337979   -0.06511598 -0.20937638  0.10291041 -0.17986533\n",
      "  0.10531522 -0.15504763  0.04131059  0.07687297  0.00294002 -0.18168181\n",
      " -0.10772801 -0.19135374 -0.27542612  0.09745379 -0.01632226  0.03721927\n",
      "  0.0651662  -0.07909017 -0.14783649 -0.07311855 -0.07996367 -0.16317931\n",
      " -0.04233642  0.24321122  0.30371773 -0.05977793 -0.02904347 -0.06649299\n",
      "  0.34251022 -0.2481776  -0.14314798 -0.10267406 -0.42558914 -0.2507503\n",
      "  0.16843982 -0.3606119   0.22629023 -0.01614263 -0.5667711  -0.15323816\n",
      " -0.4629174  -0.44473037 -0.25793448 -0.28358442 -0.5046248  -0.01374826\n",
      " -0.04751699 -0.2645543  -0.12785561  0.07528101  0.23423626 -0.39325833\n",
      " -0.43746883 -0.48336142 -0.1722226   0.00287521 -0.05819273 -0.1563215\n",
      " -0.12073542 -0.07139036  0.05289749 -0.14739524 -0.49288785  0.10918062\n",
      " -0.14163543 -0.08738852 -0.09521744 -0.24506295 -0.09723996 -0.15951541\n",
      "  0.13961469 -0.4063838   0.27047214 -0.08539595 -0.52549845 -0.76448053\n",
      " -0.329023    0.09223422 -0.13791443 -0.08073366  0.20737223  0.33998775\n",
      " -0.07720425 -0.35829416  0.2832994   0.42228535 -0.00779776 -0.04645829\n",
      " -0.03917302 -0.45427328 -0.35470027 -0.40458757  0.0206944  -0.1037631\n",
      " -0.0862534  -0.07528022 -0.42827392  0.09168772 -0.16255449  0.1038023 ]\n",
      "L4N0                    -> L5N11 = [-0.28820488  0.14384784  0.19090009  0.0054939  -0.04078117 -0.13898736\n",
      " -0.36148688 -0.08972709  0.00092837 -0.3576838  -0.3740613   0.12873732\n",
      " -0.11921277  0.4510261  -0.45767254  0.03288908 -0.10208097  0.00359235\n",
      " -0.05711115 -0.3858849   0.06311287  0.28134826 -0.04669004  0.33288905\n",
      "  0.22627568 -0.1667503  -0.09065193 -0.128557    0.14800559  0.17707182\n",
      " -0.4206767   0.11879199 -0.20808731 -0.02906873 -0.0707102  -0.2212323\n",
      "  0.3076353   0.05933573  0.03435793  0.2836413  -0.24272214  0.19015338\n",
      "  0.22428769  0.19192536 -0.08512595 -0.45812237  0.01447872 -0.00748018\n",
      " -0.27104303  0.21923906 -0.18872863  0.06095814 -0.07682492 -0.06705419\n",
      "  0.350887    0.4219939   0.00530399 -0.05451415  0.07622923  0.04509072\n",
      "  0.21212587 -0.08400815 -0.03503514  0.07397942 -0.4505706   0.08559743\n",
      "  0.30276665  0.2295143  -0.20691168  0.24014847 -0.10055747 -0.23610558\n",
      "  0.1373489   0.11379451  0.20688945 -0.3361743  -0.18842895 -0.23464343\n",
      " -0.10350491  0.00852477 -0.27888265 -0.03964185  0.00211425  0.01948053\n",
      " -0.01522212  0.10231666 -0.1021357  -0.23989771 -0.3150105  -0.4067129\n",
      "  0.21877018 -0.27856913  0.05111845 -0.12770917 -0.17044067  0.06958381\n",
      " -0.47717866 -0.41413826 -0.28760648 -0.19739528  0.26097554  0.04907846\n",
      " -0.17757827 -0.41088277  0.04603278 -0.0368435  -0.42759028  0.24412693\n",
      " -0.12761338 -0.46674147  0.3127934  -0.08614663 -0.30247185  0.12072504\n",
      "  0.17163832  0.53341144 -0.14184551  0.10428189 -0.31036347 -0.28150508\n",
      "  0.24825315 -0.49937102  0.27437592  0.20053385  0.2372747  -0.26863882\n",
      " -0.37678754 -0.31783035 -0.1574213  -0.06881414 -0.5009599   0.07807581\n",
      "  0.01978727 -0.31350723  0.12125137  0.35384282  0.24210592  0.27268812\n",
      " -0.1004466  -0.00142409  0.3195065  -0.12174591  0.04496684  0.3232718\n",
      " -0.08682916  0.2074681  -0.10109276  0.0458452   0.08993074 -0.07238322]\n",
      "L4N0                    -> L5N12 = [-0.38405403 -0.17932263 -0.18905102 -0.46355468  0.35186863  0.08240798\n",
      " -0.30666453 -0.33680093 -0.36964363 -0.31368798 -0.11867535 -0.09749778\n",
      " -0.4116765  -0.35948467  0.05034825 -0.06967867 -0.00563534  0.16435505\n",
      "  0.08466941 -0.0975375   0.19500417 -0.23672001 -0.17007048 -0.11125562\n",
      " -0.08884949 -0.21079443  0.1570758   0.15138297 -0.09145138 -0.16678225\n",
      "  0.07299042 -0.12872188  0.00157744 -0.24284211  0.06087937 -0.0082895\n",
      " -0.07046157 -0.41152006 -0.00505623 -0.07996152 -0.5166956   0.4660628\n",
      " -0.22615209 -0.54713833  0.01627478  0.15878466  0.12462248  0.15191835\n",
      "  0.25428277 -0.03946222 -0.0297532  -0.32601842  0.13787206  0.45488158\n",
      " -0.32309777 -0.63476187 -0.3815316  -0.15959051 -0.04358332 -0.06656509\n",
      " -0.04883027  0.10958681  0.07064216  0.06880409 -0.02374816  0.40447056\n",
      " -0.27823073  0.21056402  0.2960196   0.21191563 -0.19306244 -0.2961434\n",
      "  0.23958775  0.07429166  0.31118235 -0.38611245  0.10808548  0.01799329\n",
      "  0.43895417  0.17045014  0.6517149  -0.06519142 -0.46395192 -0.4839853\n",
      " -0.51945776  0.25803828  0.015107    0.14791122 -0.16565879 -0.18879703\n",
      "  0.24986775 -0.08584095 -0.15279204  0.1054999  -0.08980943  0.11101593\n",
      " -0.04579461  0.21327628 -0.33870158 -0.20999075  0.08674733  0.37398168\n",
      " -0.34021196  0.18634525  0.13009441  0.23954208 -0.05969442  0.17419387\n",
      "  0.24098094  0.08624697 -0.55006486 -0.36125636  0.36079532  0.32533357\n",
      " -0.4075313   0.11662521 -0.05741321  0.04215894 -0.00939845  0.01847345\n",
      "  0.36442876 -0.33177578 -0.06623583 -0.5379745  -0.10558531  0.26233852\n",
      " -0.32313135 -0.12130471  0.27121684 -0.08373971 -0.02505439  0.01627631\n",
      "  0.122265    0.15729827  0.57468146  0.13927554  0.31716123 -0.3885044\n",
      "  0.39648864 -0.2665881  -0.37195125  0.01957091 -0.13901654  0.11468328\n",
      "  0.14274825 -0.41938815 -0.48879546  0.2584134  -0.10441276  0.33759943]\n",
      "L4N0                    -> L5N13 = [-0.45692968 -0.04975507 -0.32254085 -0.0751206   0.34528035 -0.25536335\n",
      " -0.03022487  0.03768675  0.14865783  0.26493612 -0.09570394  0.03931013\n",
      " -0.34221986 -0.17428178 -0.5160272  -0.5131158   0.1703743   0.27721053\n",
      "  0.05291669  0.3192739  -0.5357939   0.15763505 -0.23736013 -0.22487468\n",
      " -0.2322293   0.03826878 -0.0602623   0.20274119 -0.5124082   0.47522473\n",
      "  0.17991458 -0.07983272  0.06446794  0.14088863 -0.12219504 -0.35923728\n",
      " -0.06381349 -0.0621657   0.36660275 -0.41892454 -0.28961277 -0.12060173\n",
      " -0.02232494 -0.02039723  0.11423662 -0.01521165  0.07988762 -0.27834457\n",
      "  0.08250828  0.13446827 -0.03232779 -0.07571235 -0.03787122  0.55798525\n",
      " -0.10987001  0.10225341 -0.40283516 -0.07317606 -0.12038501  0.3325639\n",
      " -0.08955645 -0.24957342 -0.09584101  0.01939586  0.03004559  0.11208845\n",
      " -0.27414557 -0.21079235  0.20088652 -0.18185413 -0.14462955 -0.05487585\n",
      "  0.12557377 -0.1174435  -0.41181812 -0.41872084  0.04428068  0.13079825\n",
      "  0.08351199  0.32763317  0.39626813  0.05987995 -0.16841158 -0.0801238\n",
      " -0.08552076 -0.03784071 -0.11165267 -0.0136141   0.2525409  -0.41313815\n",
      " -0.32924336 -0.08069133  0.27491182 -0.05314254 -0.23464555 -0.49684533\n",
      " -0.28360486  0.3079313   0.25201008 -0.24149881 -0.189235    0.17379747\n",
      " -0.2263717   0.14515689  0.2235168  -0.0449327  -0.02299285 -0.14734751\n",
      "  0.13019116 -0.08950553  0.03208665  0.03083166  0.11083023 -0.13818508\n",
      " -0.21434423 -0.5522017   0.18381687 -0.21005881  0.02005952 -0.0393789\n",
      " -0.75913674 -0.14756042  0.04598804  0.059291   -0.11570211 -0.01576453\n",
      "  0.05854413 -0.00781641 -0.07137395  0.5462021   0.12654419 -0.1937651\n",
      " -0.07283779  0.07204451  0.08862147 -0.6959844  -0.5487243   0.01095802\n",
      "  0.35007304  0.17546295 -0.26247746 -0.06713668 -0.22213143 -0.04039012\n",
      " -0.04858078 -0.368486   -0.10524057  0.03451958 -0.10668734 -0.1730068 ]\n",
      "L4N0                    -> L5N14 = [ 0.10379519 -0.39487523  0.1712116   0.2702575  -0.0753015  -0.7468248\n",
      "  0.05254544 -0.08387917  0.3110432  -0.25917485 -0.4136074  -0.4461664\n",
      " -0.12517446 -0.2197031  -0.30920354 -0.29445833 -0.07782242  0.17437898\n",
      "  0.14038636  0.35203367 -0.12060796 -0.32292312 -0.0048999  -0.16858272\n",
      "  0.4514243  -0.11574557 -0.36974287  0.28929284 -0.48336542  0.2906975\n",
      "  0.16828193  0.21575421  0.0927688   0.31361738 -0.2610127   0.14359604\n",
      " -0.05961491  0.2937648   0.24960266 -0.19185898 -0.1389694  -0.216538\n",
      "  0.18651901  0.07595756  0.2430504   0.08215372  0.14767206 -0.16337584\n",
      " -0.36361536 -0.20325486 -0.287294   -0.33551863  0.34726697  0.24022269\n",
      " -0.38503778 -0.07189676 -0.20620067 -0.58063763 -0.7086589   0.11893982\n",
      " -0.2042277  -0.07961667  0.16673471 -0.10065603 -0.04938859 -0.10247993\n",
      " -0.06638845  0.02190817  0.35394442  0.00776112  0.16190824  0.3218241\n",
      " -0.03573126 -0.36349976 -0.16870654  0.34979057  0.13579655  0.20471157\n",
      "  0.00337102 -0.726245    0.29955247  0.41494843  0.16136175  0.21966125\n",
      " -0.05297755  0.10626678 -0.5696381  -0.1630746   0.3153469   0.1691307\n",
      " -0.6721146  -0.13547206  0.1707278  -0.36891618 -0.35746223 -0.28753692\n",
      " -0.24607255  0.33502468  0.22152063 -0.3139274   0.1036766   0.25522503\n",
      " -0.7955307   0.09857482  0.03707846 -0.21885787 -0.25760707  0.20451702\n",
      " -0.13882084  0.14206715  0.11599208  0.18378873 -0.11335883 -0.1935534\n",
      "  0.34520048  0.07486542 -0.07785782 -0.33502662 -0.16447346 -0.03362508\n",
      " -0.48314914  0.1683513   0.03158394 -0.600934    0.05934126 -0.00956164\n",
      " -0.00595695  0.30171913  0.0503966   0.0420032   0.2645005  -0.540368\n",
      " -0.29685476  0.00882778 -0.5377169  -0.4215824  -0.2776901   0.0304193\n",
      " -0.32292378  0.20082681 -0.01166619 -0.05144574 -0.11189664 -0.59384185\n",
      " -0.16678603  0.08960369 -0.01597925 -0.41489175 -0.11609922  0.04666579]\n",
      "L4N0                    -> L5N15 = [ 0.24749951  0.29875684  0.13719322  0.34824288 -0.23651206 -0.19345342\n",
      "  0.2564452  -0.3627232   0.04835802 -0.31676885 -0.03815924  0.02163283\n",
      "  0.01671827 -0.08742301  0.27973652 -0.01615448  0.3101748  -0.45640033\n",
      "  0.028587    0.2137571  -0.00626714 -0.14128165  0.20226394  0.02231875\n",
      "  0.01973123 -0.2799104  -0.21782039 -0.25253913  0.2922137   0.188823\n",
      " -0.28108028  0.14476915  0.43331695 -0.43580168  0.1649428   0.19348265\n",
      "  0.4550375   0.28786743 -0.00838677  0.08288301 -0.07614844 -0.25185573\n",
      "  0.22285229  0.04429642  0.03801081  0.11289174 -0.09156049 -0.00309329\n",
      "  0.23757713  0.68799496 -0.02804288  0.20584509  0.0794571  -0.06068775\n",
      " -0.01439154 -0.38497064 -0.03619281 -0.08484253  0.10916242 -0.530706\n",
      " -0.1906758  -0.05678541 -0.32341528 -0.11720231  0.15364678  0.04923954\n",
      "  0.03373474 -0.2846418   0.1627234   0.01330211  0.32638925  0.29601258\n",
      " -0.2526585  -0.23301719 -0.04155812  0.01469981  0.25553346  0.2724552\n",
      "  0.08780733 -0.13197692 -0.13452959 -0.228613   -0.25048706  0.17542696\n",
      " -0.060264    0.03684909  0.3295675  -0.47773466  0.12860061  0.19614531\n",
      "  0.04142221  0.24443701 -0.09956256 -0.6048852   0.04402904 -0.19972728\n",
      " -0.32936868  0.1754386   0.19258262  0.27842364  0.24479829  0.06511585\n",
      " -0.37833905 -0.18682241  0.06568896  0.22524044 -0.3113961   0.07637616\n",
      " -0.22227006  0.3673203   0.426825    0.2539805   0.27959475  0.35081425\n",
      "  0.19060826  0.33922365  0.10635953 -0.37925076 -0.47093588 -0.00440451\n",
      " -0.6230444   0.4212273  -0.00784435 -0.29287595  0.00610584 -0.19245997\n",
      "  0.2714265  -0.21849978 -0.4841499   0.45634118  0.14364986 -0.54811877\n",
      " -0.12946393 -0.17790344 -0.29624864 -0.32399243 -0.24278012 -0.07080098\n",
      " -0.5421333   0.32231295  0.4501354   0.16017841  0.3739195  -0.0944572\n",
      " -0.3251017  -0.1335925   0.30645144 -0.4326035  -0.25400773 -0.14605802]\n",
      "L4N0                    -> L5N16 = [-6.16772711e-01 -1.94428116e-01  2.38550946e-01  5.30880317e-02\n",
      "  2.38776162e-01 -5.05321443e-01  1.01314418e-01 -1.23878784e-01\n",
      "  2.44345307e-01  1.81109577e-01 -6.63861990e-01  1.08835794e-01\n",
      " -3.10087651e-01 -6.41254336e-02 -1.02026753e-01 -1.92880586e-01\n",
      " -7.24936008e-01 -2.91886747e-01 -3.50165218e-02  6.68822080e-02\n",
      " -4.33719158e-03  1.78373326e-02 -8.72056961e-01  2.68416461e-02\n",
      "  2.27034181e-01 -2.95201868e-01  8.06907117e-02  1.26908034e-01\n",
      " -6.80481493e-02 -6.16140291e-02  6.12716302e-02 -8.71267796e-01\n",
      " -1.69516221e-01  1.06741399e-01 -5.34287274e-01 -1.34551257e-01\n",
      "  1.40503198e-01  5.18819273e-01  2.15816438e-01 -2.07461184e-03\n",
      " -7.01558143e-02  9.26733539e-02 -6.94948852e-01  1.28456324e-01\n",
      " -2.53259957e-01  4.01884727e-02  2.59169508e-02 -4.94805761e-02\n",
      " -2.89568573e-01  1.13382959e-03 -2.38906056e-01 -5.14074378e-02\n",
      " -1.02917993e+00  1.24068677e-01 -6.01814926e-01 -2.07621045e-02\n",
      " -2.71126151e-01 -8.24507713e-01 -3.35838884e-01 -8.39184150e-02\n",
      "  1.09576643e-01 -2.29337290e-01 -2.63635963e-01  1.10638350e-01\n",
      " -8.65305122e-03  5.25626540e-02  3.41528326e-01 -2.72422642e-01\n",
      "  6.81803143e-03 -1.14578098e-01 -8.86076887e-04 -2.05497239e-02\n",
      " -6.13746569e-02 -4.01226193e-01 -2.58662641e-01 -6.97797358e-01\n",
      " -6.99850559e-01  3.21201868e-02 -7.93431103e-01  4.47296172e-01\n",
      "  3.47989635e-03  8.33840370e-02 -1.08341962e-01  6.56298781e-03\n",
      " -2.07305435e-04 -5.13101965e-02 -9.39458981e-03  3.29683274e-01\n",
      " -1.29346317e-02 -8.99675488e-01 -9.10983086e-01 -1.82459667e-01\n",
      "  1.87779069e-01  1.72509745e-01  1.06730349e-01  1.25525787e-01\n",
      " -1.02674693e-01  1.08246528e-01  1.85388565e-01 -2.29684025e-01\n",
      "  4.66844216e-02 -3.27963859e-01 -4.56883818e-01  7.81236067e-02\n",
      " -1.39502943e-01 -7.94316083e-02  3.95993963e-02 -7.23882377e-01\n",
      "  3.72008905e-02 -4.98696327e-01 -5.15783548e-01 -7.04821050e-01\n",
      "  4.06167388e-01 -7.18849003e-01 -6.60944879e-01 -3.54060024e-01\n",
      " -5.94673872e-01 -1.37318194e-01  1.97771508e-02 -1.18769489e-01\n",
      " -1.83437109e-01  1.17804855e-01 -4.41787422e-01 -2.43261993e-01\n",
      " -2.38134503e-01  2.99592495e-01  9.29902419e-02 -2.30880994e-02\n",
      " -5.10740699e-03  2.01955006e-01 -6.85130358e-01 -5.53300977e-02\n",
      " -2.12710962e-01  1.13728866e-02 -1.94017906e-02 -1.30473644e-01\n",
      " -3.37586761e-01 -7.38817826e-02  9.50176418e-02  2.69199938e-01\n",
      "  1.89739615e-01  6.71067089e-02 -2.54581124e-02 -5.39085686e-01\n",
      "  8.71247053e-02 -2.24989429e-01 -1.23005368e-01  8.81535467e-03\n",
      " -4.34852868e-01  7.13709369e-02]\n",
      "L4N0                    -> L5N17 = [-3.7887692e-01 -2.4518687e-01  8.9389324e-02 -2.0473866e-01\n",
      "  3.9246690e-02  4.3491149e-01  1.0115531e-01 -3.8783687e-01\n",
      " -1.0690208e-01  2.1221529e-01  1.4673525e-01  2.1809265e-01\n",
      " -2.0960104e-01  1.3099198e-01 -4.9458286e-01  1.6455929e-01\n",
      "  1.8297480e-02 -2.4766533e-01 -7.3755294e-02  1.7142895e-01\n",
      "  2.7114561e-01 -2.3481224e-01  7.9336457e-02 -4.4315554e-02\n",
      "  1.0587751e-01 -3.0312753e-01  1.5095903e-02  3.4834620e-02\n",
      "  4.7233808e-01 -2.0229504e-01  1.5761726e-01 -1.8717963e-01\n",
      " -2.4990508e-01  1.5085614e-01  9.4696984e-02 -3.0539200e-01\n",
      " -2.5952980e-01  2.6389951e-01 -4.2506599e-01 -2.5921287e-02\n",
      " -2.8828740e-01  2.8475124e-01 -2.0292899e-01 -6.1380090e-03\n",
      " -2.3664488e-01  4.1813709e-02 -3.1142205e-01  3.2169276e-01\n",
      " -9.8437652e-02 -3.5910442e-01  1.3749474e-01  3.1297173e-02\n",
      " -5.0242702e-03 -2.8851461e-01 -1.3695344e-02 -2.8453559e-01\n",
      " -2.7323661e-02 -2.2769313e-01  3.5242882e-01  9.1835529e-02\n",
      "  1.4786644e-01  9.7809382e-02  3.2816023e-01  1.9452864e-01\n",
      " -1.7685498e-01 -5.3556044e-02  4.3677833e-02 -8.3435066e-02\n",
      "  2.8258676e-03 -7.4361533e-01 -8.3978876e-02 -3.4322363e-01\n",
      " -3.4686905e-01 -7.5048551e-02  8.3988386e-01 -4.4093262e-02\n",
      " -1.0752151e-01 -3.3866885e-01 -1.6986589e-01 -2.1623294e-01\n",
      " -1.9539312e-02 -2.8134048e-02  4.2330265e-02 -2.7886894e-01\n",
      " -3.5179656e-02 -4.7811031e-01 -5.7559757e-04 -1.9445051e-01\n",
      " -8.3384171e-02  4.4942972e-01  1.3432825e-01 -5.3162611e-01\n",
      "  1.2690546e-01 -2.2931574e-01 -4.8411733e-01 -1.4553086e-01\n",
      " -6.3860141e-02 -4.4131553e-01 -2.3889306e-01 -1.0739877e-01\n",
      " -1.1428045e-01 -3.0547428e-01  4.7756323e-01 -4.2467245e-01\n",
      " -4.5828134e-02  7.8023307e-02  2.3346195e-01 -8.9544617e-02\n",
      "  2.8388616e-02  5.7588232e-01 -2.6317403e-01  2.7869180e-01\n",
      "  4.0418136e-01 -3.0652794e-01  2.7054900e-01  1.4952508e-01\n",
      " -3.7129086e-01 -4.1931170e-01  1.2800145e-01 -2.2144778e-01\n",
      "  1.1256039e-01  7.5602137e-02 -2.7796251e-01 -3.1764305e-01\n",
      " -3.2592830e-01 -1.6045578e-01 -5.5824000e-02  8.4329017e-02\n",
      "  1.8062275e-02 -2.0588948e-01 -1.6837331e-02  3.3658245e-01\n",
      " -1.4829976e-03  2.7418873e-01  6.9108002e-02  3.8213956e-01\n",
      "  1.1259668e-01 -2.2842782e-02  4.6033874e-02 -1.7367573e-01\n",
      "  3.5912141e-03 -1.9935213e-01 -3.6838719e-01  1.3230613e-01\n",
      "  6.0058337e-02 -2.1588689e-01 -3.4140600e-03  5.0585391e-03\n",
      " -2.9062101e-01 -5.5511218e-01]\n",
      "L4N0                    -> L5N18 = [ 0.1905657   0.31296706 -0.04331426 -0.12949677  0.02532845 -0.07197218\n",
      "  0.13995035  0.27474293 -0.05300754 -0.60425663 -0.3956586  -0.2013057\n",
      "  0.15998042  0.30978444 -0.06781492  0.12563583 -0.28197244 -0.03813589\n",
      " -0.25466862  0.39834172  0.01977849  0.47908068  0.17855085  0.08634724\n",
      "  0.05632394 -0.5169919  -0.57336974 -0.18545896  0.02235307  0.20659941\n",
      " -0.38208     0.23418316 -0.28548166 -0.16670398 -0.08262178  0.3360863\n",
      " -0.12261253  0.13221622 -0.06094967  0.19036072  0.04549805  0.09124014\n",
      " -0.10757905 -0.07174151 -0.2321453  -0.6954349   0.20449464 -0.29242107\n",
      "  0.03597942 -0.26943892 -0.3766916  -0.00489345 -0.03584768 -0.05321134\n",
      " -0.07768594  0.06367932 -0.05333894 -0.16741039 -0.6384434  -0.7664559\n",
      "  0.19451286 -0.93014354 -0.08837282  0.1382684  -0.32041818  0.05861536\n",
      " -0.12117033  0.0566294  -0.41144812 -0.06210507 -0.04708179  0.21661994\n",
      " -0.07775158 -0.08526849  0.16036889 -0.27492708  0.08542185 -0.40782154\n",
      "  0.03103767 -0.31263587  0.00803273  0.15844898  0.02229516 -0.3369616\n",
      "  0.44087848 -0.07035486  0.08712253 -0.3584344  -0.00147764  0.20885378\n",
      "  0.09864252 -0.17088081 -0.00509363 -0.3041722   0.09493619  0.04147259\n",
      " -0.5672534   0.1334512  -0.14515519 -0.4932485   0.34857482 -0.00656107\n",
      " -0.14357603 -0.05034577  0.16996375 -0.118508   -0.45551255  0.31011745\n",
      " -0.23984951 -0.1721395  -0.1046649   0.1390737   0.48209202  0.05030085\n",
      "  0.12420551  0.22943181  0.11711946 -0.03093456 -0.52313197 -0.35635033\n",
      "  0.19562599  0.12601623 -0.14185221 -0.3446043  -0.08037885 -0.19663991\n",
      " -0.09856698  0.04370198 -0.591024    0.06950819 -0.19277245 -0.49860978\n",
      " -0.72209644 -0.664007   -0.07645678  0.19342035 -0.04478184 -0.11039315\n",
      "  0.07220325  0.21956223  0.41779038 -0.2681653   0.18095677  0.16128862\n",
      " -0.7617433   0.09150491  0.2813359  -0.6033408  -0.15718345  0.24240878]\n",
      "L4N0                    -> L5N19 = [-0.31577644 -0.34835964 -0.13699666 -0.38804692 -0.3761206  -0.25707948\n",
      " -0.07481678 -0.02564916 -0.23789918  0.1864295  -0.04787305  0.00987366\n",
      " -0.24214971  0.03618594 -0.13931781 -0.04410264 -0.06663464  0.02945017\n",
      " -0.39035088 -0.06435274 -0.01057314 -0.47267392 -0.26974642 -0.49060166\n",
      " -0.14879572  0.14882097  0.16927825 -0.07081819 -0.02490693 -0.28962103\n",
      " -0.01079743  0.19898406 -0.37635037 -0.0557077  -0.12187827 -0.45511553\n",
      " -0.4738394   0.30906236  0.08328183 -0.36336038 -0.24271764 -0.13385494\n",
      "  0.13682432 -0.5727431   0.02810867  0.16989924 -0.36468413  0.42696226\n",
      "  0.03566952 -0.06268053  0.1637051  -0.32921666  0.05448985 -0.11741003\n",
      "  0.05245004 -0.31667918  0.6447331   0.19117153 -0.00186532 -0.05578613\n",
      " -0.4582056   0.08179958 -0.21975899 -0.09319697 -0.2986917  -0.09030285\n",
      " -0.24449505 -0.11968873  0.00843519 -0.31975326 -0.18696123 -0.52730924\n",
      " -0.00612127 -0.17970315  0.13026243  0.02176005 -0.04196294 -0.2244919\n",
      "  0.10307793  0.10154084 -0.02330197 -0.3027907   0.16920449 -0.16364855\n",
      " -0.3171394  -0.23577157  0.1599468   0.1223363   0.10984235 -0.33800358\n",
      "  0.17348845 -0.24698366 -0.19494    -0.33194458 -0.03826425  0.1221198\n",
      "  0.03565672 -0.4444008   0.12051012 -0.15946129 -0.01135129 -0.22405382\n",
      " -0.01827489 -0.27983803 -0.22202413  0.08751429 -0.06628352  0.26861393\n",
      "  0.5645341   0.11695392 -0.12067641  0.3651922  -0.4974695   0.16800998\n",
      "  0.27055454 -0.07770566  0.3421133   0.21319674  0.14886068 -0.25739622\n",
      "  0.0967373  -0.199872    0.06352092 -0.42063     0.06333468  0.0632464\n",
      " -0.22926295 -0.01781001  0.17857854 -0.03522921  0.31543842 -0.16044524\n",
      "  0.18191722  0.23025443 -0.04255315 -0.06173974  0.12914072 -0.34152213\n",
      " -0.11752737  0.00337117  0.19633281 -0.23181006 -0.3519913   0.14858255\n",
      "  0.43243954 -0.27089098 -0.5086846   0.44062653  0.09001326 -0.25417748]\n",
      "L4N0                    -> L5N20 = [ 0.06415561  0.20713182  0.49030256  0.22051498 -0.19081883 -0.15647033\n",
      " -0.25138357  0.24616532  0.2155985  -0.4415566  -0.20008898 -0.12981866\n",
      "  0.15273021  0.08687989  0.09953771 -0.12706274 -0.26712003 -0.04226072\n",
      "  0.23339504 -0.03822788  0.14837518  0.06230027 -0.2342836   0.23345622\n",
      "  0.19994032 -0.1796997   0.28179798  0.20625974  0.03130438 -0.3027685\n",
      "  0.25068158 -0.69833523  0.17444994  0.10030118 -0.6419246  -0.24732319\n",
      "  0.31160665  0.14859352  0.3620931   0.38876417 -0.30067393 -0.06633611\n",
      " -0.4836373  -0.08075887 -0.6404134  -0.4508898   0.07821123 -0.05350304\n",
      " -0.02790531  0.33676517 -0.60314476  0.30369338 -0.6378569  -0.5357973\n",
      " -0.21756485  0.25290114 -0.03350691 -0.10597337 -0.3954933  -0.03228721\n",
      " -0.4523545  -0.10722346 -0.03616488 -0.11194758 -0.6266636  -0.8085039\n",
      " -0.02041144 -0.3456519  -0.6300998   0.09196115 -0.11204454  0.05784151\n",
      " -0.3373378  -0.21979253 -0.10314797 -0.53454286 -0.43387708 -0.43181702\n",
      " -0.58595645 -0.19286878  0.05765099  0.32037234  0.02714912  0.10548507\n",
      "  0.222603    0.35065222  0.08241514 -0.18468793  0.29334578 -0.32684517\n",
      " -0.25610727 -0.5225021   0.45484093 -0.15436825  0.31952745 -0.29555315\n",
      " -0.16816762  0.06094746  0.39539662  0.23987886 -0.24943887  0.2859445\n",
      "  0.00507862 -0.62629265  0.28043088  0.04307357 -0.38471797 -0.3173647\n",
      "  0.10702463 -0.30418172  0.09423048 -0.78940487 -0.25015402 -0.6109896\n",
      " -0.61976296 -0.18987605 -0.41154337 -0.05298185  0.09572057 -0.5751778\n",
      "  0.0756691   0.14429559 -0.11599754 -0.00351269 -0.2235457  -0.45778045\n",
      " -0.5254491  -0.4949797   0.1131995   0.13673735 -0.5358748  -0.04213748\n",
      " -0.27799812  0.09931935  0.13757718 -0.24271302 -0.0748077  -0.24482533\n",
      "  0.05401878  0.21946017  0.08060973 -0.12706193 -0.17504165  0.13389298\n",
      " -0.1326822  -0.08609059  0.33618715 -0.16304527 -0.34620363  0.11514246]\n",
      "L4N0                    -> L5N21 = [ 0.03851206  0.3845095   0.03000922 -0.01364234  0.07099489 -0.3735017\n",
      "  0.4751125  -0.20267846 -0.11176177  0.08075147 -0.18753366  0.12363537\n",
      " -0.47103468  0.10433698  0.102587   -0.4794999  -0.21279323 -0.07657109\n",
      " -0.04420846  0.08772487 -0.08754478  0.00152328  0.05372241 -0.04733725\n",
      " -0.21834204 -0.09443615  0.22492807  0.07510164  0.3472068  -0.21103948\n",
      " -0.04093899 -0.05937334  0.10553107 -0.11899127 -0.03811877 -0.3665972\n",
      "  0.078031   -0.20300402  0.20029342  0.3124671  -0.3015831   0.2666337\n",
      " -0.34843722 -0.26652774  0.04668554 -0.19541506  0.1500334  -0.5648717\n",
      " -0.06950174  0.41059613 -0.29412     0.07092756  0.03614694  0.2907924\n",
      " -0.29007986 -0.07907224 -0.3992611  -0.35718098 -0.19689272 -0.19610637\n",
      "  0.01935218 -0.30135098  0.0466793   0.20393556 -0.0470105   0.02423184\n",
      " -0.03099975 -0.09863116 -0.3221511   0.38232303  0.03985859 -0.12361224\n",
      " -0.5667628   0.05304253 -0.26790622 -0.09655018  0.04393835 -0.33117557\n",
      " -0.13521396  0.19955169  0.0049252  -0.21483351  0.11389713 -0.01473227\n",
      " -0.22111097 -0.10565184 -0.00591844 -0.09713999  0.14061685  0.04525425\n",
      "  0.44495353  0.0195485   0.19148335 -0.05949594  0.3537661  -0.01661398\n",
      " -0.5627179   0.37925547  0.21287401 -0.03807692 -0.00100461 -0.02723919\n",
      " -0.11436541  0.31137648 -0.07437453  0.21075395 -0.44777495  0.08863223\n",
      " -0.03485064 -0.137269   -0.0980738  -0.2523257  -0.40108636 -0.11385085\n",
      "  0.01896387  0.16159222 -0.12053108 -0.34674072  0.01075442  0.01733159\n",
      " -0.3422915  -0.07480999  0.09230933  0.07201753  0.18523113 -0.14068443\n",
      " -0.27493185  0.2315686  -0.17289504  0.28048348 -0.06259999 -0.10544741\n",
      " -0.7479231  -0.11392462 -0.0046561  -0.09901753 -0.19274731 -0.1998438\n",
      "  0.12393186  0.3091631   0.05594411  0.3767216   0.43403715  0.13563994\n",
      " -0.26946467  0.15397224  0.15264875  0.08874905 -0.25427288 -0.07953966]\n",
      "L4N0                    -> L5N22 = [ 0.18728353 -0.03172581 -0.18468536  0.10453989 -0.458724    0.01235447\n",
      "  0.15815738 -0.17911236 -0.23099384 -0.08962373 -0.00683598 -0.18860438\n",
      "  0.30743885  0.08215622 -0.18602563 -0.13132799 -0.27308193 -0.4229778\n",
      " -0.04521516 -0.13008559 -0.22244057  0.23390211 -0.27801484  0.13962191\n",
      " -0.04078712 -0.31797802  0.20579587 -0.21451846  0.08976332 -0.3726982\n",
      "  0.04678022  0.01219327  0.18452269  0.13983597 -0.3028358   0.02644561\n",
      "  0.07960878  0.3029701  -0.08104374  0.38671127  0.40872106 -0.25855574\n",
      " -0.04716442  0.27531746 -0.02380563 -0.1393438   0.08414353  0.20804967\n",
      "  0.17399168  0.42432323  0.36492687 -0.06351094  0.20456085 -0.31208867\n",
      "  0.4063095   0.26865655  0.26152134  0.02412794 -0.3641854  -0.08012611\n",
      "  0.12477534 -0.20693883  0.23948507  0.22792861  0.03457988 -0.10823698\n",
      "  0.19883193  0.35447145  0.10727319  0.32670203  0.2557289   0.2271923\n",
      " -0.02994812  0.18631002 -0.39628568 -0.10396197 -0.1879585  -0.33113682\n",
      " -0.28242967 -0.06837017 -0.05557268 -0.03658155 -0.03089026  0.14856282\n",
      " -0.29250053  0.30020848  0.27071667  0.10672683 -0.14877348 -0.00577046\n",
      " -0.11457175  0.10772039 -0.33084062 -0.03613772  0.10688027 -0.3081708\n",
      "  0.0863817  -0.09634999  0.07822918 -0.12896244 -0.0919923   0.4366096\n",
      "  0.2066788   0.03588793  0.20756927  0.26824585 -0.24694882 -0.60234255\n",
      " -0.1239772   0.141124    0.5274981  -0.27593526 -0.24827275  0.07977204\n",
      "  0.1023472  -0.17612435  0.01227638  0.04555416 -0.02117364  0.03361316\n",
      " -0.06627551  0.05510562 -0.31473702 -0.05861511  0.27039978 -0.07166952\n",
      " -0.0149799  -0.10184772 -0.34074512 -0.24657236 -0.2703448  -0.40462407\n",
      " -0.02267564 -0.20492065 -0.35159644  0.04719609 -0.1071319   0.47642988\n",
      " -0.15793467  0.25038147  0.18090853  0.14995804  0.08472978 -0.13053729\n",
      " -0.15922377  0.11222617  0.27079725 -0.22575414 -0.27251402  0.09044062]\n",
      "L4N0                    -> L5N23 = [-0.27034652 -0.3514448  -0.03141515 -0.38473737 -0.00140208 -0.3513221\n",
      " -0.00172924 -0.61014444 -0.38964924  0.5111999   0.27675885 -0.17835166\n",
      " -0.33056283  0.09988879 -0.06500425  0.42255035  0.0030667   0.19256562\n",
      " -0.19209948 -0.47657117  0.77034634 -0.01769727  0.3778697  -0.23491056\n",
      "  0.19634071  0.03855575  0.06480606  0.11373623 -0.13091944 -0.26591563\n",
      " -0.0906594  -0.08939295 -0.0108901   0.13068534  0.47080356 -0.22624436\n",
      " -0.20726669 -0.24383344 -0.4162643  -0.13359047 -0.2259337   0.04452068\n",
      "  0.22258425 -0.4694431   0.18838052 -0.23107333 -0.36061063  0.03651668\n",
      " -0.09970336 -0.02408429 -0.11308353 -0.04597638 -0.17604466 -0.16689754\n",
      "  0.29811072 -0.68580997  0.22958294  0.06477859  0.29590237 -0.21427727\n",
      " -0.05007196  0.09102801  0.07181682  0.07394857  0.3224839   0.6648982\n",
      " -0.15799856  0.18810196  0.19958721  0.10631835  0.00482826 -0.48441166\n",
      " -0.20376465 -0.17357278  0.3359963  -0.21892136  0.04068919 -0.35705563\n",
      "  0.3948586  -0.0656287  -0.12111364 -0.21537732 -0.29899272 -0.26595828\n",
      " -0.48482394  0.20282184  0.04949751  0.4753806  -0.10590106 -0.23792799\n",
      "  0.24152224  0.05564905 -0.00682454  0.24150036 -0.05458246  0.48253375\n",
      "  0.18423991  0.06023224 -0.2833351   0.0967676   0.1871578  -0.25020292\n",
      "  0.14461248 -0.03983929 -0.26363605 -0.05489001 -0.13796526  0.03391011\n",
      "  0.130998   -0.09511693 -0.08447983  0.25158855 -0.01333683 -0.00557784\n",
      " -0.03788539 -0.1105118  -0.28882343 -0.49912587 -0.28534055 -0.16865063\n",
      "  0.14382856 -0.28361478 -0.05890858 -0.3295429   0.04865066  0.11861838\n",
      " -0.03122436 -0.2689885   0.14159885 -0.26230338  0.2276546   0.24454322\n",
      "  0.03882946 -0.19070241  0.31116366  0.30238518 -0.00453859 -0.41451058\n",
      "  0.15715149 -0.50495106 -0.45953175  0.12444736 -0.16015436 -0.16791168\n",
      " -0.16278447 -0.43513718 -0.4106811   0.08865598 -0.58344287  0.04408808]\n",
      "L4N0                    -> L5N24 = [-4.38823938e-01 -2.77873874e-01 -1.14991136e-01 -1.85595796e-01\n",
      " -4.53442276e-01 -1.20956115e-01 -1.83320850e-01 -4.07750696e-01\n",
      "  3.21048975e-01 -3.62477511e-01 -4.16525722e-01  4.54992577e-02\n",
      "  2.04800200e-02 -7.20346272e-02 -1.15661077e-01  2.03968227e-01\n",
      " -4.27703649e-01 -1.51038975e-01 -3.54955852e-01 -3.08951735e-01\n",
      " -4.36916202e-01  1.95715070e-01  3.02659988e-01  9.64971781e-02\n",
      "  3.91828232e-02 -1.33355036e-01 -2.42184177e-01 -3.38720828e-01\n",
      " -4.86254811e-01 -2.01449186e-01 -4.81574655e-01 -1.46827802e-01\n",
      " -1.77321568e-01 -2.52481163e-01 -1.57321412e-02  1.28200218e-01\n",
      "  1.16970859e-01 -6.74320459e-02 -2.39367008e-01  1.98389620e-01\n",
      "  1.45351579e-02 -3.63695979e-01  1.52447507e-01 -3.87491554e-01\n",
      " -1.88524023e-01  1.54323336e-02  6.22131228e-02  1.43335611e-01\n",
      "  3.14378110e-03 -3.08818184e-02  3.12169671e-01 -2.86635667e-01\n",
      " -7.06385775e-03 -3.23866695e-01  1.76486254e-01 -2.86069483e-01\n",
      "  4.23968017e-01 -2.43340582e-01 -1.84595227e-01 -2.23738253e-01\n",
      "  3.63272697e-01 -1.12874605e-01 -1.98167294e-01 -1.66549280e-01\n",
      " -3.96632552e-02  5.90093099e-02 -2.49318387e-02 -1.66053474e-02\n",
      "  3.53920400e-01  3.66494469e-02  1.65196024e-02 -1.51199654e-01\n",
      " -1.46978095e-01 -1.72356486e-01 -3.76151294e-01  1.12846904e-01\n",
      " -2.74126202e-01 -2.94980966e-02  6.83089048e-02 -2.67308056e-01\n",
      " -1.00610688e-01  2.91185111e-01 -2.50421435e-01 -4.48574574e-05\n",
      "  1.52620999e-02 -2.09040433e-01  4.73747365e-02 -1.13504134e-01\n",
      " -3.44463736e-01  2.02342138e-01 -7.71936541e-03 -3.55546594e-01\n",
      " -2.96439230e-01  3.23373042e-02  7.62116760e-02 -1.17909778e-02\n",
      " -1.31637320e-01 -1.75234616e-01 -3.36864054e-01 -3.51292193e-01\n",
      " -4.35773015e-01 -2.97156610e-02  1.20375700e-01 -2.10532054e-01\n",
      "  4.80918773e-02 -1.26221403e-01 -3.19166154e-01 -2.78031230e-01\n",
      "  2.12832853e-01  8.96773636e-02  3.91777843e-01 -2.63205856e-01\n",
      " -6.77566081e-02 -1.94802284e-01 -3.23789656e-01 -1.23234771e-01\n",
      "  1.82010476e-02 -6.72397390e-02 -4.69825804e-01 -9.89124626e-02\n",
      " -2.76816308e-01 -2.02636525e-01  2.04924271e-01 -3.53549361e-01\n",
      " -1.03326693e-01  2.34252382e-02  8.95310566e-02  2.80427366e-01\n",
      " -4.69870210e-01  3.05286050e-01 -1.10790677e-01 -2.55704015e-01\n",
      "  2.87124906e-02 -1.70212254e-01  3.72270197e-01 -4.00822043e-01\n",
      " -6.46135569e-01 -1.61545295e-02 -9.04258490e-02 -9.20492709e-02\n",
      "  2.87789889e-02  3.53767186e-01 -2.87618369e-01 -1.45024627e-01\n",
      " -1.49605140e-01 -1.09160013e-01 -1.00421302e-01 -2.56819248e-01\n",
      "  3.10113400e-01  5.33876084e-02]\n",
      "L4N0                    -> L5N25 = [-2.90285379e-01 -3.78793567e-01  3.39066923e-01  2.08011940e-01\n",
      "  2.74583608e-01 -4.56087023e-01  4.66334045e-01  5.91436215e-02\n",
      "  2.63530523e-01 -1.39819007e-04 -3.75477880e-01  5.19566387e-02\n",
      "  1.06097274e-02  9.73838046e-02 -2.58934554e-02 -1.80999875e-01\n",
      " -6.14263058e-01  2.83650547e-01 -1.21950395e-02 -4.21471484e-02\n",
      " -1.25644729e-02  3.73737544e-01 -1.02895248e+00 -1.34105071e-01\n",
      "  3.41428071e-01 -1.85429864e-02  1.70375735e-01  1.82494476e-01\n",
      " -2.49417454e-01 -9.71784517e-02  1.31383345e-01 -6.54272258e-01\n",
      "  1.59559086e-01  2.81160533e-01 -7.45969653e-01 -1.42419487e-01\n",
      "  1.45597517e-01  2.82259136e-01  9.96562988e-02 -2.65704721e-01\n",
      "  2.59543639e-02  1.34441808e-01 -6.13950968e-01  8.55266899e-02\n",
      " -1.82481617e-01 -1.26670539e-01  3.33045900e-01 -4.00752090e-02\n",
      " -3.61306638e-01  1.61511838e-01 -4.00542408e-01 -8.74008834e-02\n",
      " -8.85270834e-01  4.46583629e-01 -6.85410738e-01 -9.37398076e-02\n",
      " -7.50475526e-02 -3.70502025e-01 -2.29146883e-01 -1.58019036e-01\n",
      "  2.12334886e-01 -1.18964300e-01 -1.19339302e-01  3.27928811e-02\n",
      " -1.32914886e-01 -1.23294279e-01  2.49388143e-01  1.29538849e-02\n",
      "  1.53585464e-01 -6.26822412e-02  2.04613343e-01 -5.81013672e-02\n",
      "  3.61019298e-02 -1.79286988e-03 -1.28291741e-01 -7.79503465e-01\n",
      " -6.71848118e-01  3.39837396e-03 -9.34756279e-01  9.96501222e-02\n",
      "  3.00814986e-01  2.86620483e-02  4.06641653e-03  3.67067233e-02\n",
      "  2.61213463e-02  3.24725434e-02  1.90718159e-01  3.44452560e-01\n",
      " -3.57834287e-02 -3.89347225e-01 -1.02201581e+00  4.46880311e-02\n",
      " -1.06133096e-01  1.77015200e-01  1.51945606e-01 -2.51057595e-01\n",
      "  8.56774002e-02  9.98220965e-02 -1.14886090e-01 -3.93007904e-01\n",
      " -4.08507511e-02 -5.30120805e-02 -2.19538480e-01  1.67874277e-01\n",
      " -1.02993891e-01 -1.88801780e-01  4.27126512e-02 -6.89757347e-01\n",
      "  1.64112672e-01 -6.70603096e-01 -2.57607698e-01 -8.23933601e-01\n",
      "  3.39839578e-01 -8.66222084e-01 -8.57807636e-01 -2.66682625e-01\n",
      " -3.84774297e-01 -6.60953999e-01  9.81884524e-02 -1.43095404e-01\n",
      " -3.92297924e-01 -1.35396942e-01 -1.71675280e-01 -1.88587591e-01\n",
      " -2.81143878e-02 -1.37891054e-01 -1.42685147e-02  2.48739168e-01\n",
      "  2.03160346e-01  1.36902601e-01 -4.33566272e-01  2.86679473e-02\n",
      " -1.96735010e-01  1.66580722e-01  3.03377360e-01 -2.47393817e-01\n",
      " -3.14421237e-01 -1.47149665e-02  9.05119553e-02  1.59203131e-02\n",
      " -1.28820062e-01  1.97719708e-01 -9.61165354e-02 -3.96776021e-01\n",
      "  6.33138642e-02 -9.12880674e-02 -7.97654167e-02 -2.13585924e-02\n",
      " -6.75227702e-01 -1.90430060e-01]\n",
      "L4N0                    -> L5N26 = [-0.09938279 -0.1598603   0.00119608  0.01904534 -0.63012105 -0.07811572\n",
      "  0.23048699 -0.16617738 -0.02247301 -0.1709883  -0.05840594 -0.06140115\n",
      " -0.1389437  -0.13283843  0.04895961  0.01736907  0.03198438  0.01941368\n",
      " -0.42375734 -0.05973918  0.03072253  0.23800777  0.6008123  -0.11283035\n",
      " -0.167766    0.21522962 -0.36823553  0.00108585 -0.12386678 -0.38435724\n",
      " -0.11478088  0.28443533 -0.6516631  -0.33734375  0.13345204 -0.00812157\n",
      " -0.14734955 -0.20881018 -0.00581014  0.14944929 -0.34998783 -0.16036217\n",
      "  0.09718112 -0.2956898   0.38971427 -0.02780875 -0.05234068  0.03126683\n",
      " -0.07345137 -0.19995497 -0.08640672 -0.34745604  0.05774874 -0.390406\n",
      "  0.38549015 -0.57328814  0.04425503 -0.10321698  0.10590696  0.11087435\n",
      " -0.14948879  0.35387284 -0.31082466  0.10468861  0.08859571 -0.09382953\n",
      "  0.06550341 -0.5332953   0.09063288 -0.38563234  0.14751375 -0.23100674\n",
      "  0.1559316  -0.06579207  0.45251969  0.09604034  0.29402378 -0.07561204\n",
      "  0.34161782 -0.19677822 -0.44128984  0.02302844 -0.01529278 -0.02581382\n",
      "  0.4161863  -0.23152179  0.46196544 -0.11472283  0.01008502  0.4446538\n",
      "  0.46786845 -0.19122207 -0.03286853 -0.45169398  0.16021194  0.30288875\n",
      "  0.12009428 -0.01983342  0.15972711  0.17822418  0.28362164 -0.22141466\n",
      " -0.2078459  -0.29475686  0.02499912  0.26827288 -0.26805565 -0.03842686\n",
      "  0.05090801 -0.03685734  0.14072867 -0.12579541 -0.48974144  0.2497748\n",
      "  0.05701894 -0.09905387  0.12971236 -0.00830419 -0.45378426 -0.04583934\n",
      " -0.13729607  0.23889488  0.21203212 -0.3077278  -0.249604    0.00845194\n",
      " -0.22895756  0.12396517 -0.1028896   0.09605711  0.03522109 -0.16962022\n",
      " -0.19107156 -0.05003426 -0.45326298  0.34439933  0.0980369   0.03798022\n",
      " -0.05529608 -0.2471235  -0.11291181  0.23019034 -0.05104874  0.08931888\n",
      "  0.03195984  0.03466394  0.08081689 -0.06464358 -0.32248187 -0.2905467 ]\n",
      "L4N0                    -> L5N27 = [ 0.01827857 -0.27523792 -0.1076979  -0.17929132  0.1327213  -0.00914753\n",
      " -0.04255154 -0.5021549   0.14095528  0.0040636   0.08862071 -0.03888485\n",
      " -0.06535739  0.08952097 -0.20104125  0.2874465  -0.07664985 -0.24367751\n",
      " -0.27344874 -0.26667345  0.3178114   0.01708268  0.05308217 -0.19634348\n",
      " -0.0124433   0.07907715  0.1783663   0.18892622  0.03310426 -0.49325377\n",
      " -0.06954927  0.05979085 -0.3614939   0.16295205 -0.12329478 -0.3229454\n",
      " -0.15941268  0.03825406 -0.07524055  0.1050069  -0.20664743  0.34714085\n",
      "  0.01134946  0.11754962 -0.6614398  -0.10147613 -0.42219496 -0.36494467\n",
      "  0.12703854 -0.33914816 -0.21207862  0.12141929  0.18630162 -0.49035105\n",
      "  0.10896542 -0.05397337  0.01162744  0.31008944 -0.09383675 -0.01858894\n",
      "  0.14491263 -0.02809453  0.1857913   0.36018804 -0.33569366  0.08302908\n",
      "  0.28112948  0.2037494  -0.00415596 -0.07679132 -0.2516224  -0.24958466\n",
      " -0.25341463  0.07771167  0.63655347 -0.46628729  0.08698649 -0.43977278\n",
      "  0.02578384  0.13477755 -0.513795    0.03176185 -0.09894396  0.28164837\n",
      " -0.13028483 -0.6412588   0.14890781  0.08468813 -0.1498586  -0.16860801\n",
      " -0.06052603 -0.5451902   0.10693735 -0.28092813 -0.31684074  0.20448966\n",
      " -0.12105662 -0.6284801  -0.15277368 -0.17051229  0.11953219 -0.5829026\n",
      " -0.13396408 -0.7612525  -0.2697248   0.0750361  -0.10104378 -0.11817902\n",
      "  0.06720889 -0.22037898 -0.2469509  -0.06551619 -0.26482204  0.4567497\n",
      " -0.08057299  0.34027246  0.26312056  0.0169479  -0.26932243 -0.64852315\n",
      " -0.05421193 -0.45082948 -0.14152011  0.17119154 -0.4187161  -0.42250323\n",
      " -0.59913164 -0.18737036 -0.0911773  -0.53916496 -0.32210442 -0.0259492\n",
      " -0.15091848 -0.28592935  0.41044623  0.20456246 -0.05370754 -0.16400746\n",
      "  0.07456676 -0.47709188 -0.1397752  -0.27459744  0.00337161  0.05052099\n",
      "  0.0018795  -0.19516502 -0.09332408 -0.15547402 -0.04037283 -0.58224565]\n",
      "L4N0                    -> L5N28 = [ 2.81510800e-01 -4.73971255e-02  1.46306738e-01 -9.49187204e-02\n",
      " -3.89378658e-03 -1.15527093e-01  2.64564693e-01  2.12505773e-01\n",
      "  2.60544330e-01  8.99721384e-02 -2.28562102e-01  2.05539823e-01\n",
      " -2.29091421e-01  1.85909912e-01 -4.37914521e-01  2.91830394e-02\n",
      " -3.33660275e-01  4.23809767e-01  9.27998051e-02 -2.13173300e-01\n",
      "  1.01210326e-01  4.14894409e-02 -1.44580081e-01 -1.41272172e-01\n",
      "  2.93963015e-01  4.92126308e-02 -2.33822763e-01  3.49209636e-01\n",
      " -1.20983295e-01 -4.12851393e-01  1.97750792e-01 -4.01183218e-01\n",
      "  1.94056034e-01  3.80128443e-01  2.21327513e-01  1.02014005e-01\n",
      " -2.11314652e-02  1.85153574e-01 -1.15089245e-01 -1.09334327e-01\n",
      " -4.27402049e-01  9.80455279e-02 -1.55075267e-01 -3.06590218e-02\n",
      " -3.34858030e-01  5.38420165e-03 -2.61309862e-01  2.16159686e-01\n",
      " -5.12659907e-01  1.19912870e-01 -2.60405242e-01  2.26505429e-01\n",
      " -4.48906988e-01  1.83491364e-01 -6.76732004e-01  4.11402583e-02\n",
      "  6.43333793e-02 -2.91296303e-01 -1.43192545e-01  1.41498387e-01\n",
      "  3.48390847e-01 -7.49119744e-02  2.54497737e-01  5.83253689e-02\n",
      " -4.85972255e-01 -2.47716699e-02  1.52630538e-01 -6.88489154e-02\n",
      "  2.49126583e-01 -2.51094520e-01 -3.04182261e-01 -5.01597673e-02\n",
      " -8.84142742e-02 -3.34364593e-01  5.41304648e-02  1.61018401e-01\n",
      " -5.10154784e-01 -4.41677719e-02  3.30194235e-02 -2.57742018e-01\n",
      "  2.50587195e-01  3.26324284e-01 -4.63999845e-02  3.33450794e-01\n",
      "  1.51539281e-01  2.78838375e-03  4.82130945e-02  7.19688833e-02\n",
      "  2.05017656e-01  9.58125517e-02 -2.14039430e-01  1.31508468e-05\n",
      "  1.74498916e-01  2.03965619e-01 -2.27785125e-01  4.83826138e-02\n",
      "  1.29622743e-01 -2.69772768e-01  1.80574164e-01  1.25671893e-01\n",
      " -1.88661352e-01 -2.47254416e-01 -1.66816399e-01 -9.75385830e-02\n",
      " -2.20112443e-01 -4.22457099e-01  1.61414489e-01 -6.62745163e-02\n",
      " -5.86649291e-02 -4.64624614e-01 -4.16451871e-01 -5.07652164e-01\n",
      " -1.78635016e-01 -1.40913084e-01 -3.57329279e-01  1.15069941e-01\n",
      " -2.19837978e-01 -4.62814361e-01  1.64449528e-01  5.81795070e-03\n",
      " -1.38408318e-01 -2.43604615e-01  1.49507701e-01 -4.86541130e-02\n",
      " -1.60465702e-01 -1.63304597e-01 -2.24742904e-01  3.43451321e-01\n",
      "  8.86917785e-02 -2.80283600e-01 -2.15768456e-01 -1.12231009e-01\n",
      " -7.99811706e-02  1.40478769e-02 -1.58106625e-01  1.67692855e-01\n",
      "  1.41199544e-01  1.85300469e-01  1.01787239e-01 -2.00996641e-02\n",
      " -5.47120459e-02  1.48267582e-01 -2.63001453e-02 -2.32651293e-01\n",
      " -1.93812832e-01 -3.79573882e-01 -4.11102436e-02 -5.24684116e-02\n",
      " -1.23919480e-01 -2.85172343e-01]\n",
      "L4N0                    -> L5N29 = [-0.24680962 -0.34123197  0.20328143 -0.20017524  0.04841882 -0.24875814\n",
      " -0.19711304  0.01298599  0.07517198 -0.33758008  0.09981284  0.27993706\n",
      " -0.2502986  -0.08371742 -0.19529882  0.02104221 -0.0399573   0.02655078\n",
      " -0.0677803  -0.03770058  0.19736834 -0.02717655 -0.33346793 -0.1094301\n",
      "  0.08565444  0.00259751  0.2503108   0.07491495 -0.27147475  0.3265596\n",
      " -0.01361349  0.20500743 -0.2451284  -0.47244906 -0.0989473  -0.16571788\n",
      "  0.23234724 -0.23165187  0.18472867 -0.32155073 -0.12028555  0.34232068\n",
      "  0.04599114 -0.07934063 -0.298536   -0.07670984 -0.15154116 -0.01066943\n",
      "  0.03406172 -0.30227718  0.2640266  -0.17620416 -0.3845072  -0.06678151\n",
      " -0.11181059 -0.14209637 -0.29964912 -0.07422149  0.20788033  0.02194625\n",
      "  0.27079347  0.22453845 -0.38477194  0.04822655 -0.34317884  0.16728462\n",
      " -0.49082208  0.07421742 -0.23879607  0.12918966 -0.17798755  0.05618104\n",
      " -0.08126349  0.00507509  0.10709991 -0.06321036  0.02689034 -0.10773365\n",
      "  0.00175711  0.24109901 -0.09416637 -0.12742795 -0.16285364 -0.4262503\n",
      " -0.0627221   0.02167718 -0.02422361  0.10713826  0.12679073 -0.11636405\n",
      "  0.08411361 -0.19629894  0.07824704  0.30686054  0.18903542 -0.19865519\n",
      "  0.01638897  0.08957072 -0.31630164  0.05152006  0.4088827   0.07541687\n",
      "  0.07656803 -0.28917402 -0.14291301 -0.23950423  0.04103686  0.12283815\n",
      " -0.11737378  0.13565484  0.01728732  0.02690847 -0.21879797  0.00676993\n",
      " -0.09410924 -0.07645629 -0.00757382  0.10871615 -0.18863526 -0.12644114\n",
      "  0.43196338 -0.10392985 -0.06826892 -0.30233312 -0.15906894 -0.0041166\n",
      " -0.03700978 -0.08210182  0.16934274 -0.03046307 -0.10168669  0.00529827\n",
      "  0.01413452  0.23315006  0.16701469  0.3626051   0.5163917  -0.2075846\n",
      "  0.05689323 -0.21786956 -0.12347522 -0.05538702 -0.05164002  0.35562953\n",
      "  0.11191241  0.29247266 -0.4802254   0.16687474  0.3180035   0.20166357]\n",
      "L4N0                    -> L5N30 = [ 0.21806698  0.23585618 -0.02029959  0.49587113 -0.25533918 -0.29400405\n",
      "  0.21551888  0.00874718  0.18928553  0.04073817 -0.48040134 -0.08849601\n",
      "  0.01030797 -0.71264076  0.06587403 -0.49659288 -0.3031914  -0.32219192\n",
      " -0.3055982  -0.18219411 -0.41478485 -0.03703459  0.05357976 -0.05369457\n",
      "  0.24781778 -0.58914113 -0.11767678  0.09284975  0.05418834 -0.17163245\n",
      " -0.35118207  0.23135875  0.13256373  0.0108984   0.24136612  0.32643887\n",
      "  0.3214293  -0.29338998 -0.13940068  0.06730945 -0.02760309 -0.35980862\n",
      "  0.01004887  0.56018054  0.10005599 -0.04079453  0.20797153  0.05315224\n",
      "  0.18126744  0.10774478 -0.04104945  0.22832258 -0.04145063 -0.06679489\n",
      " -0.3150974   0.1369047  -0.14264667  0.44134152 -0.0935353  -0.55587035\n",
      " -0.23913042 -0.30573615 -0.15862143 -0.18515423  0.19525345 -0.05628924\n",
      " -0.24680044  0.7148034   0.18027413 -0.03170127  0.35088402 -0.11621417\n",
      " -0.3450828   0.3092855  -0.27982935  0.28234595  0.00885269 -0.07013196\n",
      "  0.03220288 -0.19596416 -0.12384259 -0.13606296 -0.20933016  0.12064789\n",
      "  0.06851152 -0.0404079   0.2265924  -0.15610625  0.05503074  0.2969868\n",
      " -0.57559806  0.21410918 -0.17570247  0.27363187  0.20155849 -0.6566036\n",
      "  0.00378119 -0.04475231  0.3463077  -0.50838685 -0.23999166  0.1934598\n",
      " -0.44382477  0.11802103 -0.30828148  0.46599746  0.12633756  0.02216377\n",
      " -0.04817089 -0.10219501  0.01946711  0.0975104   0.3552233  -0.34119803\n",
      "  0.1623763  -0.03619246 -0.16361174 -0.11021838  0.22438994 -0.10408713\n",
      " -0.45706853  0.12489703 -0.3421638   0.1629829   0.416035    0.15836231\n",
      "  0.3616114   0.37098822  0.12828033  0.4398362   0.00126879 -0.23374157\n",
      " -0.46512622  0.24784826 -0.00873428 -0.31567693 -0.7038929   0.14060113\n",
      " -0.52249134  0.06500092 -0.30907226  0.13234547  0.0360281   0.02259149\n",
      " -0.17869118 -0.04541439  0.0862743  -0.38628265 -0.04100062  0.0247901 ]\n",
      "L4N0                    -> L5N31 = [-0.21589611 -0.12924382  0.17269608 -0.00922627 -0.51491326  0.08225796\n",
      "  0.09530349 -0.36489552  0.03386389  0.03327667 -0.26039666 -0.57383287\n",
      "  0.0420477   0.09076851  0.0510009  -0.15419291 -0.02536377 -0.47956726\n",
      " -0.1731567  -0.05896004  0.1083147  -0.02552877  0.09794284  0.09749861\n",
      " -0.07037883 -0.22504383 -0.03179088 -0.0313079  -0.02209774  0.26214483\n",
      " -0.42364424 -0.21537174  0.49091727 -0.08890012  0.0422268  -0.12144948\n",
      " -0.00219374  0.2892863   0.03945401  0.08207437  0.46182874  0.0644854\n",
      " -0.5731292   0.10498627 -0.14336781 -0.4796426   0.13305569 -0.02528971\n",
      " -0.13272841 -0.09473335 -0.36967102  0.19747934 -0.137267   -0.11427803\n",
      "  0.15086731 -0.09677527 -0.26570696  0.05078589 -0.26430532 -0.4973598\n",
      " -0.17130543 -0.4272525  -0.08509392 -0.08614049 -0.07685567 -0.23876391\n",
      "  0.11656642 -0.1309602   0.08556639  0.19952372  0.26107728  0.20515208\n",
      " -0.05350782  0.03063138  0.1215121   0.05276732 -0.33569807 -0.309543\n",
      " -0.11594637 -0.50061125  0.14083977  0.38573334 -0.14598387  0.24475579\n",
      "  0.20318738 -0.19206691  0.04632136 -0.101399    0.14519559 -0.15119621\n",
      "  0.1653404  -0.01700188 -0.5594207  -0.05154866  0.4307258   0.08743208\n",
      " -0.16246405  0.21757984  0.24390478  0.07640643 -0.26027587 -0.09660412\n",
      " -0.14190704 -0.05913666 -0.05982682 -0.02333803 -0.03723981 -0.22632654\n",
      " -0.2524554  -0.1993751  -0.36105344  0.0260914   0.3381966   0.03101267\n",
      "  0.05957808 -0.13783829 -0.1292598  -0.01998938 -0.1968194  -0.25788403\n",
      "  0.14821087 -0.21172738 -0.6475883  -0.24239872 -0.06541181  0.08112577\n",
      " -0.35744676 -0.01811191 -0.02718159 -0.24192843 -0.7525771   0.2006682\n",
      " -0.49314648 -0.06541973  0.0951599   0.24648386 -0.14616989 -0.3734822\n",
      "  0.31607544  0.31067884  0.11372755 -0.01626803  0.37398168  0.2147477\n",
      " -0.6724942  -0.30941436 -0.26661944 -0.6164776  -0.0791861   0.05623191]\n",
      "L4N0                    -> L5N32 = [-5.89631358e-03  4.13943827e-03  1.15672983e-01  1.44856989e-01\n",
      " -4.55906451e-01 -5.03361858e-02 -4.04784493e-02 -1.97201684e-01\n",
      "  2.40689173e-01 -3.13536853e-01 -2.01878935e-01 -3.54406953e-01\n",
      "  6.75698966e-02 -1.36030734e-01 -2.92515308e-01  1.02973379e-01\n",
      " -2.59702682e-01  1.36497572e-01  4.27951753e-01  8.10121447e-02\n",
      "  9.44658592e-02 -2.79223889e-01  5.80034554e-02  1.19695373e-01\n",
      " -2.21421525e-01 -1.58673748e-01 -6.12857580e-01  2.78789848e-01\n",
      "  2.09542438e-01 -1.89944565e-01  3.46236706e-01 -8.07675421e-02\n",
      "  2.84022167e-02  5.50423682e-01 -1.71127513e-01 -4.53230888e-01\n",
      " -2.68181926e-03  2.96667576e-01  1.70164958e-01 -1.32641554e-01\n",
      "  3.22825015e-02 -2.81807631e-02 -3.61817718e-01 -4.82593179e-02\n",
      " -1.29381269e-01 -1.57434806e-01 -1.19342498e-01 -5.45378588e-03\n",
      " -3.35352063e-01  5.37032366e-01  1.62496030e-01  1.67504400e-01\n",
      " -2.68705577e-01 -3.52225490e-02  2.06402361e-01 -2.35246360e-01\n",
      "  2.18248498e-02 -3.01350802e-01 -5.81118345e-01 -2.49657243e-01\n",
      "  6.50925636e-02 -3.48832220e-01 -5.26368260e-01  4.56268713e-02\n",
      " -3.04342777e-01 -2.99119800e-01 -7.66937286e-02 -1.76298827e-01\n",
      "  1.49737358e-01 -1.26977414e-01 -2.54811384e-02  1.40347973e-01\n",
      "  4.66614328e-02  2.39734843e-01  3.64464782e-02 -2.83178806e-01\n",
      " -2.14255631e-01 -1.81677967e-01 -2.02835873e-01 -4.12052631e-01\n",
      "  2.61208236e-01  1.77439332e-01  1.05037689e-01  2.33641371e-01\n",
      " -4.92904671e-02  2.42234915e-01 -4.97336267e-03 -3.96656156e-01\n",
      "  2.53329098e-01 -1.66275017e-02  1.15327954e-01 -9.69303697e-02\n",
      "  3.04844260e-01 -2.61450559e-01  4.31431025e-01  2.99067702e-02\n",
      " -1.30237803e-01 -1.18230082e-01  2.08684221e-01 -2.15564653e-01\n",
      " -1.21622518e-01 -3.91912945e-02 -1.35701790e-01  1.03245124e-01\n",
      "  7.48015791e-02 -2.82651901e-01 -3.69772583e-01 -2.61252254e-01\n",
      " -5.07054567e-01 -9.81599912e-02  1.01990201e-01  3.46712000e-03\n",
      " -4.40862358e-01 -1.12287171e-01 -5.55762323e-04  1.89856589e-01\n",
      " -2.56319195e-01  4.31165751e-03 -1.06655680e-01  1.03915937e-01\n",
      "  2.42138401e-01  3.81768107e-01 -1.46921456e-01  3.69796418e-02\n",
      "  4.91264760e-02  1.76068515e-01 -1.88053176e-01 -8.05892572e-02\n",
      " -5.34923911e-01 -1.05047777e-01 -5.28408706e-01 -3.57544184e-01\n",
      " -3.72777015e-01 -4.98929411e-01 -5.59979677e-01  1.48472697e-01\n",
      "  2.20602468e-01  2.60715783e-01  1.44053653e-01  3.13149720e-01\n",
      "  1.14829876e-01 -1.79744437e-01  5.47029376e-01 -2.92159438e-01\n",
      " -3.35859686e-01  7.98754767e-02 -7.31239021e-02 -5.71173668e-01\n",
      " -3.69322836e-01  2.17044950e-01]\n",
      "L4N0                    -> L5N33 = [-2.23695651e-01 -1.08010015e-02 -2.13856906e-01  1.24359235e-01\n",
      "  1.42504573e-01 -5.12399018e-01  4.68453228e-01 -8.37057305e-04\n",
      "  1.96772277e-01  1.95776582e-01 -4.73401517e-01  1.99679047e-01\n",
      " -2.28687391e-01  4.59968261e-02  1.90746456e-01 -6.37503490e-02\n",
      " -5.89283824e-01  4.33695376e-01  2.23862514e-01 -1.69947073e-01\n",
      "  2.75613874e-01 -1.64189339e-02 -9.13732290e-01  6.14547968e-01\n",
      "  1.50062442e-01 -3.37256998e-01  1.60609618e-01 -1.73634306e-01\n",
      "  8.42264593e-02  1.57406598e-01 -2.27296397e-01 -5.75569868e-01\n",
      "  9.52626392e-02  1.15791373e-01 -4.76506501e-01  1.97094694e-01\n",
      " -9.29613709e-02 -2.70288467e-01  4.93874326e-02  1.92846477e-01\n",
      "  1.49114624e-01  3.48997086e-01 -5.55757999e-01  5.21213293e-01\n",
      " -6.36763394e-01 -2.45454296e-01  9.08325538e-02 -1.34657621e-01\n",
      "  9.06436592e-02  1.74470618e-01 -2.85163194e-01  9.61024035e-03\n",
      " -7.01138854e-01 -9.18254443e-03 -6.06775284e-01  2.73335222e-02\n",
      "  1.04224822e-03 -3.69802415e-02 -2.21210480e-01 -2.82170326e-01\n",
      "  1.74016461e-01 -2.01592699e-01 -4.33841318e-01  3.00705105e-01\n",
      " -4.73513216e-01 -6.68438151e-02  1.81276500e-01 -2.95876831e-01\n",
      " -5.30238152e-01  3.80964801e-02  5.69599390e-01  5.63041074e-03\n",
      " -5.29818356e-01 -1.68122008e-01 -1.07785143e-01 -4.31663334e-01\n",
      " -5.79509735e-01 -5.27561963e-01 -5.90577543e-01 -6.88995123e-02\n",
      " -1.43305480e-01  2.68325746e-01  2.13068783e-01 -2.18140357e-03\n",
      " -2.13145196e-01 -3.90738726e-01  8.51696879e-02  1.30860135e-01\n",
      "  6.74497187e-01 -2.83249795e-01 -6.88693225e-01 -5.72863162e-01\n",
      " -1.64309487e-01  1.06913626e-01 -6.63376302e-02 -2.66249001e-01\n",
      " -8.39482695e-02 -1.31005511e-01  1.98676676e-01 -2.01508045e-01\n",
      "  3.59008402e-01  3.88287276e-01 -2.02600896e-01 -1.27214506e-01\n",
      " -1.84319288e-01 -3.55316214e-02 -2.49496996e-02 -4.75559205e-01\n",
      "  1.12573177e-01 -4.91407514e-01  8.79296139e-02 -6.32971346e-01\n",
      "  3.28108609e-01 -4.00711238e-01 -5.03324091e-01 -1.49542332e-01\n",
      " -4.70928699e-01  2.09320970e-02 -1.28966104e-02 -8.62302259e-02\n",
      " -2.45680153e-01  1.90990455e-02 -1.40307307e-01  3.68681438e-02\n",
      "  8.68832767e-02  3.26006740e-01 -1.08296864e-01  1.73114061e-01\n",
      " -2.11237460e-01  2.81383544e-01 -5.74786723e-01  4.24992852e-02\n",
      " -1.22434773e-01 -1.03009604e-01 -1.46269007e-02 -6.04438111e-02\n",
      " -3.21957618e-01  1.13816984e-01 -2.55982161e-01  3.90174985e-01\n",
      "  6.34028792e-01 -2.56749719e-01  2.73204565e-01 -3.75167072e-01\n",
      " -2.58449942e-01  6.52055085e-01  7.82794505e-02 -1.37182102e-01\n",
      " -2.67822623e-01 -5.53261459e-01]\n",
      "L4N0                    -> L5N34 = [-0.13789174 -0.19014156  0.22434247  0.2295804   0.09054845  0.05819037\n",
      "  0.09478987  0.02619774 -0.25532046  0.4098457   0.34241343  0.31644717\n",
      " -0.41455582 -0.15990254 -0.05924014 -0.07560491 -0.12444621 -0.08536229\n",
      "  0.19290946  0.03042835  0.19838077 -0.52700245 -0.02270768 -0.33362368\n",
      " -0.03974307  0.01097594  0.32902646 -0.05917731  0.1334093   0.25585994\n",
      "  0.09242608  0.02080806  0.01864987 -0.21144733  0.05449931  0.02142948\n",
      "  0.01807336 -0.2061143   0.14182906  0.0600674  -0.28619298  0.03972907\n",
      "  0.13246173  0.01085747 -0.00753332  0.3425824  -0.15392007  0.07103983\n",
      "  0.44988987  0.40235656  0.44441167  0.23247214  0.02924437  0.16475695\n",
      "  0.18819764 -0.1541272  -0.19739811  0.3747987   0.19888835  0.34327376\n",
      " -0.39621386  0.14998505 -0.03156337 -0.05327348 -0.11656797  0.05278889\n",
      " -0.24255906  0.02728144 -0.4404775  -0.31584072 -0.11570317  0.07652891\n",
      " -0.11807877  0.39611056  0.19230928 -0.26062766  0.08529805 -0.30026475\n",
      " -0.18375248  0.1619852  -0.3132566  -0.37512174 -0.15561469 -0.36446598\n",
      " -0.46649322  0.23771551  0.21174078  0.32100874 -0.08236907  0.0177891\n",
      " -0.05682501  0.02323301 -0.00461889  0.09770747 -0.31969252 -0.1435748\n",
      "  0.41583535  0.02850448  0.18142541  0.17496623 -0.04995685 -0.05273908\n",
      "  0.4045681   0.03301235 -0.09749651  0.60774946 -0.15879548  0.08559506\n",
      "  0.10826762  0.11814411  0.45203498  0.07498385 -0.10742585  0.24834882\n",
      " -0.03417879 -0.4572603   0.32802895  0.20221686  0.15559204  0.26967502\n",
      "  0.41740498 -0.11124974  0.29662716 -0.05258905 -0.20311822  0.18578921\n",
      " -0.23058459 -0.2756875   0.24999326 -0.12091273 -0.1683627  -0.02215827\n",
      "  0.18937443 -0.2122275   0.0463341   0.00190291 -0.04013849 -0.47007427\n",
      " -0.09041532 -0.03447104 -0.16798803  0.18179074 -0.3018317  -0.03946375\n",
      " -0.18217608 -0.2619537   0.18420167  0.20542087 -0.05622195 -0.10526801]\n",
      "L4N0                    -> L5N35 = [ 0.27451995  0.12828651 -0.84026885  0.42096335 -0.72634035  0.15516892\n",
      "  0.24935502  0.08265288 -0.05215632 -0.4103218   0.10776739 -0.12785383\n",
      "  0.19185086 -0.8917208   0.10841946 -0.00410189  0.27372602  0.07816128\n",
      "  0.27434418  0.04762634 -0.01818118  0.24672021  0.13308358  0.14929003\n",
      " -0.6552326   0.3926549  -0.10158155 -0.7109031   0.39801896  0.29027453\n",
      " -0.18605544  0.00914487  0.23302788 -0.5901841  -0.31996915  0.30479753\n",
      "  0.10307116 -0.33992052  0.23555036 -0.6684929   0.34160596  0.08893408\n",
      " -0.07647247  0.16321985 -0.52880305 -0.24597801  0.06757771  0.29894862\n",
      "  0.5329346   0.16754195 -0.01939866 -0.09491998 -0.17949395 -0.1884379\n",
      "  0.2730985  -0.4878044  -0.31090522  0.27729225 -0.07154541  0.09706104\n",
      " -0.49693862 -0.10829896  0.37625298 -0.50449336 -0.42126542 -0.28041622\n",
      " -0.14515334 -0.03993207 -0.39516836  0.09155139 -0.3388915  -0.29654232\n",
      "  0.05722076  0.30559117 -0.08689318 -0.39336646  0.05882077 -0.46233344\n",
      " -0.03358261 -0.12229362 -0.19364537 -0.85650575 -0.0362956   0.17251995\n",
      " -0.31911987 -0.4749344   0.05130474 -0.047289    0.14333324 -0.15742904\n",
      "  0.15396827  0.3717206  -0.7211194   0.30782482  0.45451233  0.10973135\n",
      " -0.10460183 -0.5679182   0.1173675   0.06397756  0.12730302 -0.04832568\n",
      "  0.22944033 -0.36169234 -0.7879441  -0.35112217 -0.2686679   0.02978401\n",
      " -0.18608397 -0.07883652  0.24501467  0.09876361  0.31203115  0.01928082\n",
      " -0.07655248 -0.46705315 -0.2122166   0.13173102 -0.293756   -0.39218536\n",
      " -0.09351269  0.20131096  0.14595653  0.38006335  0.14669783 -0.1707985\n",
      " -0.40684515 -0.5013496  -0.09802795 -0.20410794  0.04314916 -0.23760432\n",
      "  0.01356174 -0.05574167 -0.05957101 -0.11594075  0.02671947 -0.6783224\n",
      " -0.14034623 -0.1199597  -0.15833335 -0.50309205  0.267819    0.3104731\n",
      "  0.3819607  -0.20265085 -0.06955697  0.03628747  0.01395497  0.09784863]\n",
      "L4N0                    -> L5N36 = [ 1.63893789e-01 -1.30508557e-01 -1.01943493e-01  2.06448227e-01\n",
      "  1.96271658e-01 -3.09409499e-01  3.14016007e-02  4.02161432e-03\n",
      " -6.27192035e-02  3.96337032e-01 -4.28559929e-02 -1.53779620e-02\n",
      " -1.19183734e-01 -2.28961706e-01  3.40342194e-01  7.02587590e-02\n",
      "  6.75673187e-02 -1.04012825e-01  1.37595795e-02 -5.56706339e-02\n",
      "  1.91395402e-01  5.27970120e-02 -3.61201763e-02 -1.77211523e-01\n",
      "  1.18130192e-01  2.98898574e-02  1.15475506e-01  1.33867890e-01\n",
      "  4.95204367e-02 -1.24460682e-01 -2.76034415e-01  1.06814027e-01\n",
      " -4.46029097e-01 -7.45257810e-02 -5.89262228e-03 -9.10511538e-02\n",
      " -2.28226393e-01  3.52003612e-02  1.58240467e-01 -8.29560682e-02\n",
      " -2.19600305e-01 -1.48590542e-02  1.23297401e-01  3.25056724e-03\n",
      " -1.73595309e-01 -2.38748416e-02 -1.08464457e-01 -2.20715869e-02\n",
      " -2.21966326e-01  2.36441523e-01 -4.87759127e-04 -6.75794855e-02\n",
      " -7.69983307e-02  2.18701437e-01 -1.77850246e-01  2.98008502e-01\n",
      "  2.32996002e-01 -1.99584022e-01  2.02179387e-01 -1.81486413e-01\n",
      "  6.52366057e-02  1.15962066e-01  2.67528184e-02  4.95232344e-01\n",
      "  2.23878976e-02  1.01298191e-01 -5.13776839e-02  7.39928335e-02\n",
      " -3.03953849e-02 -1.58430234e-01  2.80478030e-01  1.46944784e-02\n",
      "  1.74281020e-02 -4.45282236e-02  1.58863608e-02  1.35723621e-01\n",
      " -6.16045371e-02  1.04873635e-01 -2.14536250e-01 -7.33375363e-03\n",
      "  2.28028432e-01 -8.82766023e-03 -1.21828206e-01  3.72528769e-02\n",
      " -2.47417539e-01  4.29227978e-01 -5.24343103e-02  1.30573735e-01\n",
      " -1.19108170e-01  2.20026314e-01  9.51457471e-02  4.59122397e-02\n",
      "  3.00821841e-01 -2.07143184e-02  7.96913356e-02 -1.19530514e-01\n",
      " -2.96563238e-01  2.68114746e-01 -1.41278252e-01  6.93727806e-02\n",
      " -3.97609100e-02 -8.11781883e-02 -4.35522318e-01  2.74389982e-01\n",
      " -9.91244614e-02 -4.08233851e-01 -1.69346139e-01  9.40522924e-02\n",
      " -2.18173862e-03  1.05687000e-01 -1.30292801e-02 -5.23245968e-02\n",
      " -2.16140777e-01 -2.66485512e-01  1.57403067e-01 -2.36856818e-01\n",
      " -3.61043252e-02  2.62983322e-01 -2.96265054e-02 -7.33528510e-02\n",
      "  3.30226272e-02 -4.88383919e-02 -1.67329118e-01 -1.52883261e-01\n",
      "  2.83135157e-02  1.19081557e-01  6.00905064e-03  8.66545960e-02\n",
      "  1.52441472e-01  1.17037348e-01  1.56503871e-01  2.55974621e-01\n",
      " -1.71493683e-02 -1.73083261e-01  3.87223670e-03 -1.12950280e-02\n",
      "  2.02705204e-01  1.18691273e-01  1.24721430e-01  8.60267803e-02\n",
      " -8.15299079e-02  6.58629611e-02  6.95486553e-03  2.25289717e-01\n",
      " -1.12047251e-02 -1.22558087e-01  2.49168828e-01  6.92200661e-03\n",
      " -1.35893330e-01 -4.02312368e-01]\n",
      "L4N0                    -> L5N37 = [-2.68451601e-01 -1.66950196e-01  1.43443868e-01  9.75600258e-02\n",
      " -2.05233276e-01 -4.17618871e-01  2.26966441e-01 -1.97770327e-01\n",
      " -9.56115574e-02  4.19022366e-02 -3.29479814e-01 -4.45391506e-01\n",
      "  4.20874692e-02  2.29668051e-01 -2.24400952e-01 -6.44460797e-01\n",
      " -5.01344986e-02  3.37610580e-02 -2.60019183e-01 -1.69085339e-01\n",
      " -3.39156568e-01 -2.80408680e-01 -3.41624111e-01 -3.06113541e-01\n",
      "  2.72763334e-02 -7.44291991e-02 -1.77545860e-01  3.28299612e-01\n",
      " -2.77748436e-01 -2.51359232e-02 -2.65978009e-01 -2.07496777e-01\n",
      " -7.03866477e-04 -2.66399860e-01  2.01129526e-01 -3.04541690e-03\n",
      "  3.87844801e-01 -2.76971012e-02 -3.16797309e-02  2.07853466e-01\n",
      "  4.01380360e-01 -1.93626896e-01 -4.90520783e-02  2.67138630e-01\n",
      "  1.04746841e-01 -2.05058962e-01  1.06764086e-01 -5.67408502e-02\n",
      " -2.77703375e-01  1.60070330e-01  1.02719977e-01  2.38750860e-01\n",
      " -3.36126238e-02  2.28119880e-01 -1.25265658e-01  3.70735116e-02\n",
      " -3.30046117e-01 -4.59207982e-01 -1.20322265e-01  7.87159353e-02\n",
      "  3.02205563e-01 -2.88981907e-02 -2.06048742e-01 -8.43088865e-01\n",
      " -1.71710178e-01  2.75727749e-01  2.52633303e-01 -8.82539302e-02\n",
      " -7.25777671e-02 -1.08384620e-02  4.20350879e-01  1.74143404e-01\n",
      " -2.94813514e-01  1.36824340e-01 -6.92569375e-01 -2.19553426e-01\n",
      " -2.05988571e-01 -1.05526470e-01  3.19089353e-01 -1.05326764e-01\n",
      " -1.87580749e-01  1.95941463e-01 -6.16955161e-02 -1.55855734e-02\n",
      "  2.46978223e-01  3.89749259e-01 -3.40776235e-01  4.45637144e-02\n",
      "  5.48152737e-02 -2.67515063e-01 -3.15409750e-01  2.26539224e-01\n",
      "  1.50433868e-01  1.03013456e-01 -4.81640808e-02 -3.82903486e-01\n",
      " -7.85038397e-02  4.68229912e-02 -1.42660260e-01 -3.93421471e-01\n",
      " -2.95091391e-01  1.78565219e-01 -6.45969093e-01 -1.09617203e-01\n",
      "  6.19438626e-02 -2.39458904e-01  2.12051660e-01 -3.30123782e-01\n",
      " -8.85386318e-02 -6.89083040e-02 -9.87887289e-03 -4.03735906e-01\n",
      "  2.13455468e-01 -2.35898778e-01 -3.28361064e-01 -3.12747449e-01\n",
      " -1.98084980e-01 -1.08988725e-01  2.11572111e-01  3.21356416e-01\n",
      " -2.83993840e-01 -1.40225276e-01  1.61550045e-01 -1.00071065e-01\n",
      "  1.96333826e-01 -4.57974784e-02 -5.04262105e-04 -1.83368437e-02\n",
      " -3.64493802e-02 -1.53645650e-01 -2.84924686e-01  2.39366770e-01\n",
      " -5.30642211e-01 -1.67980909e-01  2.92142779e-01 -4.15803403e-01\n",
      " -4.84498978e-01  2.96119541e-01  1.00363612e-01 -2.07783487e-02\n",
      "  8.26024488e-02  1.62210509e-01  5.11907004e-02 -3.86072218e-01\n",
      "  1.02539565e-02  8.66272897e-02  1.77332252e-01 -2.45978847e-01\n",
      " -3.81385395e-03 -1.24785118e-01]\n",
      "L4N0                    -> L5N38 = [ 0.13385269 -0.01532825 -0.3414806  -0.32129082 -0.33552337  0.03925014\n",
      " -0.23573214 -0.28740683  0.41115555  0.07174745 -0.2646809   0.04561988\n",
      "  0.09655703 -0.12048809  0.06165956 -0.30423215  0.01524569 -0.03232934\n",
      " -0.43820852 -0.3307417  -0.37959597 -0.12740068  0.15554887  0.13036391\n",
      " -0.10198814 -0.3733755  -0.23680714 -0.3573032  -0.23068544 -0.14342564\n",
      " -0.31170356 -0.6413433  -0.03945987 -0.5957752  -0.1331313  -0.25742954\n",
      " -0.00702506 -0.15072785 -0.22916546  0.20465949 -0.0413302  -0.73356974\n",
      " -0.2705161  -0.03352609 -0.20182444 -0.1993184  -0.1931527   0.4643662\n",
      " -0.03998102 -0.2656927   0.07830311 -0.14546405  0.0651302   0.00600336\n",
      "  0.08856377 -0.26951867  0.3387601   0.03677104 -0.42048562 -0.07791954\n",
      "  0.04273516 -0.20173806 -0.11898016 -0.1471726  -0.10251698 -0.04124502\n",
      "  0.21718758 -0.11008888  0.5114915   0.26753455  0.12167221 -0.20619267\n",
      " -0.20155531  0.01693342 -0.5409039   0.25075468 -0.2470478  -0.01341871\n",
      "  0.07494453 -0.09741106  0.00405469 -0.0704904  -0.2356717  -0.24482588\n",
      "  0.18970339 -0.30107126 -0.0314348   0.04965335 -0.12318257  0.21406984\n",
      " -0.2095559  -0.29005277 -0.408464   -0.07239601  0.05610276 -0.2906793\n",
      " -0.14877523  0.01960044  0.06472905 -0.1685548  -0.63605905  0.36177662\n",
      "  0.00966745  0.03674815 -0.24516164 -0.14096074  0.00607706 -0.10673928\n",
      "  0.2971066   0.177458    0.22933713 -0.51413924  0.02056681 -0.2967866\n",
      " -0.3961736  -0.06882452 -0.11076412 -0.09072036 -0.10113803  0.0677642\n",
      " -0.25596407  0.084094    0.21013364 -0.34937996 -0.18193826  0.1003811\n",
      " -0.01520352  0.13829958 -0.09191254  0.06647664 -0.05925271 -0.38829246\n",
      " -0.14224485  0.10522433 -0.0546705  -0.39725175 -0.16900232  0.01283101\n",
      " -0.07714563 -0.15572903 -0.08509922  0.09152248  0.20788017  0.28321594\n",
      " -0.5222512  -0.36971527  0.16157287  0.05959703  0.00547231  0.16401862]\n",
      "L4N0                    -> L5N39 = [-0.16488647 -0.17994149  0.08171286 -0.05398765  0.30447677  0.28838742\n",
      "  0.33632803 -0.3392696  -0.16828966  0.1553498   0.39717272 -0.22626278\n",
      " -0.38496456  0.14485408 -0.13603453  0.12372524 -0.24447231 -0.32147408\n",
      " -0.27061325  0.32365853  0.5968547  -0.3309748   0.25329962  0.22593077\n",
      "  0.29019943  0.18018888  0.13202153  0.22228245  0.16463964 -0.4168046\n",
      "  0.0280626   0.30144283 -0.11242689  0.3096577  -0.22555417 -0.202982\n",
      " -0.16021827 -0.46014956 -0.20589717 -0.292974   -0.68027407 -0.00987195\n",
      " -0.15402402 -0.38309318 -0.18965688 -0.06618237 -0.3405323   0.05780993\n",
      "  0.04325637  0.03312495 -0.00775426  0.05250449  0.06768335 -0.51706594\n",
      "  0.11887903 -0.6455063   0.03419906 -0.5615296   0.09382251 -0.15347943\n",
      " -0.14219597 -0.1499807  -0.2777233   0.03478146  0.3706894  -0.41714692\n",
      " -0.43410406 -0.21221282  0.40427694 -0.36590877  0.04455775 -0.46157637\n",
      " -0.07690889 -0.08667655  0.22386858  0.16192947  0.30494764 -0.1945231\n",
      " -0.39923412 -0.22055313  0.24135908 -0.12095558 -0.21615753  0.15318517\n",
      " -0.0991747   0.18733451  0.05338984  0.08129894  0.03250089  0.5342988\n",
      "  0.08885755 -0.14914611 -0.12476742 -0.11539108 -0.0748919   0.07797632\n",
      " -0.2989662   0.34762073  0.05272504  0.3051499  -0.07406969 -0.29578787\n",
      "  0.3367063  -0.17644781 -0.54044175 -0.2539258   0.18885994  0.24811073\n",
      "  0.06553772  0.23093171 -0.14874995  0.6635222  -0.12872612  0.18274148\n",
      "  0.504968   -0.39529714 -0.06768329  0.12360411  0.02180423  0.12601155\n",
      "  0.1238314   0.0868011  -0.64959353 -0.624818   -0.2228317   0.28888616\n",
      "  0.21418191 -0.15327959 -0.08833022  0.06444336  0.02867376  0.15246375\n",
      "  0.07853908 -0.00715466 -0.5254632  -0.13962302  0.28849977 -0.02968327\n",
      "  0.03664667 -0.08566669  0.03381133  0.07916413 -0.21898563 -0.04012553\n",
      " -0.20410204 -0.13331366 -0.09838439 -0.1601994  -0.17873934 -0.05060869]\n",
      "L4N0                    -> L5N40 = [-0.48304898 -0.1392185   0.30147788 -0.37651327 -0.0729527  -0.35759073\n",
      " -0.10799852  0.25089005 -0.212721   -0.05764965 -0.29754412  0.5318647\n",
      " -0.42385715  0.04664977 -0.07848987  0.24316987  0.080452    0.16424012\n",
      " -0.20858489  0.16651037  0.3090057  -0.14271286 -0.1737897   0.13613255\n",
      "  0.22528534 -0.37024888  0.1965843   0.2643305   0.06789812  0.0587729\n",
      " -0.34400523 -0.02044741 -0.52602917 -0.18805088  0.444616   -0.58035535\n",
      "  0.09466547  0.10465434  0.27353424 -0.1997847  -0.32272798 -0.00910338\n",
      " -0.08315372 -0.18904997 -0.14089647  0.00559361 -0.09121123  0.361824\n",
      " -0.01399421 -0.13233691 -0.12503326  0.11568064 -0.1817652  -0.01619656\n",
      " -0.01711556  0.12851454 -0.04420581  0.04304389  0.17047027 -0.3989539\n",
      " -0.12913473 -0.0703291  -0.18019243  0.12025297  0.18797195 -0.32610586\n",
      " -0.35745624  0.01347032 -0.10777427 -0.33669686 -0.54003066 -0.09895069\n",
      " -0.09615236 -0.5026974   0.2585822  -0.259928    0.00283567 -0.03436206\n",
      "  0.35312542 -0.03254049 -0.08191156 -0.19308023 -0.00599016  0.08105312\n",
      " -0.5427262   0.26765266 -0.20414275  0.0028657   0.04735682  0.07653788\n",
      " -0.17396826 -0.1096705   0.28210935 -0.20200689  0.02639898  0.30362046\n",
      "  0.06985424  0.2001846  -0.10025936 -0.31583866  0.33943233 -0.34787515\n",
      "  0.251641   -0.10539674 -0.29105252  0.00145556 -0.19525982 -0.21866165\n",
      "  0.14321089  0.0122652  -0.13693784  0.00705289 -0.26214743  0.15911107\n",
      "  0.19480841  0.15116543  0.35209244 -0.07223225 -0.09416259 -0.0934159\n",
      "  0.2513478  -0.29818428  0.03621056 -0.32043448 -0.34947312  0.0931167\n",
      " -0.01618164  0.21156596  0.03849251 -0.27459636  0.22818914 -0.01847861\n",
      "  0.11597337  0.2762413  -0.1467174   0.1113506   0.2208456  -0.2725505\n",
      " -0.16280249 -0.366481   -0.23014487 -0.23942564 -0.52770114 -0.00477822\n",
      " -0.07429737  0.20065956 -0.1921028  -0.01644502  0.01683137  0.00472117]\n",
      "L4N0                    -> L5N41 = [-1.87556475e-01 -2.06981048e-01 -2.86210388e-01 -2.63337195e-01\n",
      " -3.57981056e-01 -1.37015060e-01 -3.03250104e-01 -2.58984774e-01\n",
      "  1.21578179e-01  1.91583127e-01 -3.77261221e-01  2.80344576e-01\n",
      "  7.69360214e-02  1.80642694e-01 -6.49858415e-02 -1.93035558e-01\n",
      " -4.01027948e-01  2.51616389e-01 -1.55830622e-01 -1.24668613e-01\n",
      " -1.87755063e-01  7.69631714e-02  6.85546324e-02  2.17817903e-01\n",
      " -9.87727046e-02 -3.65313739e-01  1.23605411e-02 -4.68807608e-01\n",
      " -3.79848540e-01 -4.56088960e-01 -2.72176296e-01 -2.07615286e-01\n",
      " -7.93219134e-02 -6.80277348e-01 -1.72293469e-01 -2.32770041e-01\n",
      " -1.43180445e-01 -5.00554442e-02 -3.38553548e-01  2.71658480e-01\n",
      " -1.61142871e-01 -7.89045095e-01 -1.52917311e-01 -3.69857065e-02\n",
      "  1.01674870e-01 -1.70081258e-01 -3.39570176e-03 -2.39645746e-02\n",
      "  1.20404810e-01 -2.81640679e-01  2.83752948e-01 -3.53550971e-01\n",
      "  1.40632987e-01 -2.45380700e-01  8.78281146e-02 -2.08593741e-01\n",
      "  2.51389384e-01 -7.18218163e-02  4.93343137e-02 -2.80217946e-01\n",
      " -2.54511684e-01 -2.15467408e-01 -8.89168233e-02  2.42533237e-01\n",
      "  2.53135469e-02 -2.15961859e-02  1.16344295e-01  1.44172192e-01\n",
      "  3.01097065e-01  6.53461590e-02  1.05113434e-02 -2.35477984e-02\n",
      "  2.32183728e-02  1.82810649e-01 -2.13134304e-01  2.01136023e-01\n",
      " -4.83615607e-01  1.85572505e-02  2.99449146e-01 -1.39442652e-01\n",
      " -4.02092412e-02 -4.41197597e-04 -4.43590641e-01 -2.87941337e-01\n",
      "  4.67232950e-02 -7.76113272e-02  3.89498115e-01  9.53505039e-02\n",
      " -3.42307538e-01  2.80172348e-01 -1.81693196e-01 -3.25723067e-02\n",
      "  3.05965431e-02 -2.49732025e-02 -1.70708343e-01 -9.57739912e-03\n",
      " -1.86184812e-02  1.02710845e-02 -2.41624519e-01 -2.39130199e-01\n",
      " -3.78265589e-01  4.19036686e-01  8.08777362e-02 -2.87376285e-01\n",
      " -1.66214958e-01 -3.99394155e-01 -1.84263349e-01 -2.81081766e-01\n",
      " -1.05232425e-01  1.12356678e-01  1.38435245e-01 -1.18917800e-01\n",
      "  1.46669433e-01 -2.70822406e-01 -1.26118124e-01 -7.27798343e-02\n",
      " -2.86937565e-01 -1.81224689e-01 -2.98150867e-01  1.10990182e-01\n",
      " -3.79184276e-01  7.29739433e-03  7.41693145e-03 -5.24597883e-01\n",
      " -1.39239430e-01 -1.77730232e-01  3.80725652e-01 -4.89960657e-03\n",
      " -3.80922109e-01 -3.65024582e-02  1.28866538e-01 -5.17148413e-02\n",
      " -7.44232386e-02 -2.27796122e-01  1.14285834e-01 -5.90377688e-01\n",
      " -5.46278238e-01  1.03412107e-01 -3.20258737e-01  4.31061871e-02\n",
      " -6.30860701e-02 -1.72999427e-01 -9.89268124e-02  4.14897650e-01\n",
      " -3.51485282e-01 -3.07769421e-02 -2.08783016e-01 -8.44370127e-02\n",
      "  1.38771772e-01 -1.17838882e-01]\n",
      "L4N0                    -> L5N42 = [-0.11560338 -0.02546177  0.00175396  0.33280805 -0.270483   -0.10307711\n",
      "  0.20869207  0.06865823 -0.06705084 -0.27911323 -0.16678177 -0.34907025\n",
      "  0.01748256  0.18168768 -0.1451198   0.07099618  0.19205199 -0.644378\n",
      " -0.0536583  -0.05241958  0.08291364 -0.09806722  0.24488531  0.30558354\n",
      "  0.35518035 -0.36651108 -0.29034257  0.17806885  0.26204765  0.2030886\n",
      " -0.9026798   0.07016353 -0.01935816  0.06757398 -0.13763489  0.07700126\n",
      "  0.34812284  0.319864   -0.04436331 -0.274562    0.08028535  0.08476705\n",
      "  0.07145845  0.06717399  0.16830567 -0.11238539  0.13124743 -0.25424263\n",
      " -0.07332813  0.1324147  -0.03638456 -0.02559266  0.23656867 -0.00935554\n",
      " -0.0067511   0.09881578 -0.14216053 -0.21908994 -0.19277513 -0.34242752\n",
      " -0.0852279  -0.56974447  0.12223475  0.07296736  0.04129224  0.03842257\n",
      "  0.15611078 -0.01534497 -0.34971243  0.10260533  0.1813236   0.19393736\n",
      " -0.3624203  -0.16400242  0.13016419 -0.02263471  0.15702851  0.155872\n",
      "  0.12062255 -0.41369802 -0.41595566  0.08218872 -0.02991651  0.04957933\n",
      " -0.42983586  0.02561573 -0.12291484 -0.3772137  -0.0076837   0.1718508\n",
      "  0.10085123 -0.25049764 -0.08864295 -0.10174754  0.1649994  -0.10835786\n",
      " -0.21982527 -0.19004516  0.00488846 -0.35494864  0.02822902 -0.04012499\n",
      " -0.00991573 -0.2478994  -0.09087025  0.16308406 -0.25142044 -0.11148026\n",
      " -0.2848881   0.22395884  0.40271625  0.23711336  0.12235485 -0.03607848\n",
      "  0.20978317  0.22260714  0.02359882  0.06235643 -0.37775555 -0.0907784\n",
      " -0.03122449  0.18024252 -0.03514084 -0.00702547 -0.08089112  0.28320923\n",
      "  0.07598428  0.06677136 -0.5017514  -0.0921622   0.25057223 -0.3374232\n",
      " -0.3662428  -0.23927356 -0.2810914  -0.00616276  0.15170152 -0.071246\n",
      " -0.25404114  0.23994997  0.25518486 -0.09646464 -0.01484779 -0.39655527\n",
      " -0.25325477  0.09552303  0.00977092 -0.71394557 -0.3883912  -0.2744639 ]\n",
      "L4N0                    -> L5N43 = [-0.24500637 -0.37601322  0.19440371  0.18822071 -0.21927282 -0.3742279\n",
      " -0.15550278  0.3238709  -0.15698431 -0.01137728 -0.21385463 -0.15782987\n",
      "  0.12417563 -0.37786317 -0.23694493 -0.36263606 -0.03558784 -0.24812664\n",
      "  0.34163946 -0.46302202 -0.02607696  0.18741412  0.11936921 -0.24032563\n",
      " -0.27945092 -0.28160045 -0.43186164 -0.09996018 -0.00342633 -0.12644792\n",
      " -0.5201759  -0.5910886   0.02096749 -0.05772129 -0.31408283 -0.17817633\n",
      "  0.49937665 -0.0528395   0.16962257  0.38240203 -0.1937948  -0.27413368\n",
      "  0.10819972  0.32392743 -0.14968126 -0.2589161   0.51484776  0.00657366\n",
      "  0.39461952  0.01717557 -0.07076156  0.67253506 -0.26661202 -0.19508594\n",
      " -0.06186296 -0.0170264  -0.16470392 -0.07342373  0.04577044 -0.30735242\n",
      "  0.10947262 -0.12273462 -0.26601288 -0.3345676  -0.6999767  -0.32160735\n",
      "  0.54433584 -0.16650629 -0.1275308  -0.1169095  -0.34284347 -0.19844852\n",
      " -0.34054527  0.34528586 -0.2623589  -0.04950287 -0.41671988 -0.29000342\n",
      " -0.09113298 -0.1158777  -0.37058318 -0.59408104  0.05667726  0.65684533\n",
      " -0.2450731   0.08268552  0.09776554 -0.1971817   0.18034828 -0.27480552\n",
      " -0.15965055 -0.39116636 -0.08752568 -0.2929748   0.09411371 -0.06810824\n",
      " -0.27533433 -0.00117854  0.12361433 -0.14771727 -0.1655684   0.2495825\n",
      " -0.16973722  0.02474906 -0.32046747  0.27332097 -0.4359041  -0.6535613\n",
      " -0.22113095  0.05831905 -0.44187337 -0.19829549  0.19429405 -0.33392736\n",
      " -0.03227693 -0.3145203  -0.08977462 -0.39278156 -0.42638302 -0.5870284\n",
      " -0.21684042  0.04648047  0.16057996 -0.13184454 -0.6224106   0.2975782\n",
      " -0.5540704   0.2908752  -0.34533396  0.153024   -0.6306856   0.08131545\n",
      " -0.2049879  -0.3574067   0.00224464 -0.2188923  -0.17338459 -0.00999319\n",
      "  0.1840535   0.02851165 -0.2845772  -0.49793747 -0.45986742 -0.3465143\n",
      " -0.2846674   0.09608452  0.6760622   0.18390112 -0.31713307 -0.23282047]\n",
      "L4N0                    -> L5N44 = [ 0.2438391   0.10253077  0.41422424  0.2041028   0.19852337 -0.45492685\n",
      "  0.16047308 -0.14836684 -0.10007152 -0.04786957 -0.26428297  0.33781967\n",
      "  0.21966092 -0.23118412  0.04589344  0.2950867   0.10086704 -0.5882538\n",
      "  0.11523417 -0.12012548 -0.15779749 -0.30825216  0.20699294  0.43317515\n",
      "  0.37705812 -0.43111244  0.01932788 -0.37122533  0.10946742 -0.04760474\n",
      " -0.28824732  0.22469938  0.14330456  0.01817563  0.23857793  0.03313506\n",
      " -0.01405215  0.05801153  0.28789082  0.0284664  -0.17895629 -0.53295445\n",
      "  0.42589405  0.09827167  0.268438    0.01803406 -0.15495946  0.52928066\n",
      " -0.15648408 -0.0424777   0.16905683  0.47865832  0.07494286  0.26685238\n",
      " -0.46947503  0.16573511  0.3255808  -0.16393799 -0.05510524 -0.33857664\n",
      " -0.33064163  0.186214    0.17789213 -0.08193748  0.3030012   0.30208144\n",
      "  0.21789299  0.30998263 -0.26821733 -0.14898652 -0.00966005  0.6282856\n",
      "  0.07920481 -0.17994606  0.06933449 -0.03646806  0.12399645  0.31210625\n",
      "  0.1380282  -0.12265804 -0.41912434 -0.44938788  0.16379575  0.29176295\n",
      " -0.31268254  0.3244283  -0.30932212 -0.3909691  -0.3921285   0.16050735\n",
      "  0.17027606  0.19371316 -0.25519592  0.07997387  0.17377461 -0.01983858\n",
      "  0.03916629  0.29672444 -0.07943714  0.0844001   0.27694362  0.39021096\n",
      " -0.24373552 -0.24254018 -0.25695476  0.08648437  0.21027449 -0.0551673\n",
      " -0.05187517 -0.22101016 -0.09505571  0.05635161  0.17956358  0.26232964\n",
      "  0.29877582  0.5769426   0.32806516 -0.10856107  0.19932733  0.04372776\n",
      " -0.08423427  0.3120305   0.33569437 -0.20560348  0.26810706  0.53584456\n",
      "  0.19458811 -0.25391346 -0.16363199  0.06105707  0.47532502 -0.39029172\n",
      " -0.07463019 -0.45820913 -0.48321256 -0.58116007  0.00287707 -0.11600255\n",
      " -0.40286738  0.23434688  0.35203663  0.165345    0.05402995 -0.27103436\n",
      " -0.1577116   0.26430705 -0.00099697 -0.41599286 -0.38444364 -0.09655774]\n",
      "L4N0                    -> L5N45 = [-1.21814385e-01 -1.38538510e-01 -7.39732233e-04 -1.96977958e-01\n",
      "  1.47173658e-01 -3.65791470e-01  1.08171538e-01 -8.27591896e-01\n",
      " -2.46156752e-01  1.97566878e-02 -3.76028866e-02  5.38429879e-02\n",
      " -3.75674158e-01 -1.81277961e-01  4.11183648e-02  4.42939341e-01\n",
      " -1.00841150e-02 -3.95116396e-02  3.11419163e-02 -2.53483862e-01\n",
      "  9.12094116e-02 -5.95092893e-01  1.81216776e-01  1.21363357e-01\n",
      "  2.69505978e-01  3.06396812e-01  1.38936177e-01  1.42839747e-02\n",
      " -4.79544997e-02 -4.27557558e-01 -2.04784349e-01  1.29689546e-02\n",
      "  1.63796082e-01  1.68898419e-01 -8.17905739e-03 -1.91826820e-01\n",
      " -1.55592531e-01 -2.32630372e-01 -5.88234425e-01 -8.53102654e-02\n",
      " -2.57611036e-01  1.79640904e-01  1.21075772e-02 -4.43019032e-01\n",
      "  1.01682045e-01  2.03367114e-01 -1.37822941e-01  2.95135587e-01\n",
      "  8.42102021e-02 -9.20863450e-02  1.61617383e-01  2.03015521e-01\n",
      " -5.79093508e-02 -7.01842159e-02  4.07934636e-01 -7.51262009e-01\n",
      " -9.27877575e-02  5.50582856e-02 -5.91879249e-01  4.15696017e-02\n",
      " -2.66317278e-01 -1.62215978e-01 -2.55026609e-01 -4.41446193e-02\n",
      "  1.31692111e-01  1.36548549e-01 -2.17977166e-01 -1.63251549e-01\n",
      "  5.18607616e-01 -1.14112869e-01 -1.20164968e-01 -4.26935524e-01\n",
      "  4.46453899e-01  1.86157838e-01  1.42965615e-01  2.53948808e-01\n",
      " -5.54393120e-02 -4.37081270e-02  4.33991075e-01 -2.80127488e-03\n",
      " -2.25915983e-01 -3.62428278e-01 -3.11273694e-01 -6.25861883e-02\n",
      " -4.94583398e-01  1.16416998e-01  1.82709888e-01 -1.26047269e-01\n",
      " -3.32229864e-03  1.89236447e-01 -1.31752761e-02 -3.98885943e-02\n",
      " -1.36264311e-02 -2.60319859e-01  2.89811105e-01 -2.97537774e-01\n",
      " -4.49808359e-01  2.07998261e-01 -2.88534671e-01 -9.72377583e-02\n",
      "  2.45184600e-01 -1.74336717e-01 -2.11299598e-01 -1.97857425e-01\n",
      " -2.76246756e-01  8.82666782e-02  2.49932155e-01 -9.73540917e-02\n",
      " -1.74167395e-01 -8.71357396e-02  2.01779395e-01  3.78139287e-01\n",
      " -1.47038810e-02  1.26506194e-01  8.79348367e-02 -4.81445640e-02\n",
      "  3.84855896e-01 -2.67104954e-01  5.73485017e-01  1.05759583e-01\n",
      " -1.01154171e-01 -2.65549030e-02  1.03179768e-01 -4.51501548e-01\n",
      " -1.76641926e-01  4.95396554e-02  5.46055555e-01 -2.86877275e-01\n",
      " -2.68841654e-01 -1.11087605e-01 -1.99035909e-02 -2.74964631e-01\n",
      "  8.70089978e-02 -2.97758907e-01  2.41459101e-01  6.44109726e-01\n",
      "  4.07951891e-01 -7.06570864e-01  5.21111131e-01 -1.20345682e-01\n",
      " -9.75938439e-02 -6.98842034e-02 -1.50063634e-01  6.43486157e-02\n",
      " -1.46962274e-02 -3.60615015e-01 -9.97362584e-02  1.15142344e-02\n",
      "  1.09007321e-01 -2.76761264e-01]\n",
      "L4N0                    -> L5N46 = [ 1.58089116e-01 -3.02097678e-01 -1.90210372e-01 -1.14310952e-02\n",
      "  4.91336316e-01 -4.05774027e-01 -4.14902956e-04  3.13017354e-03\n",
      " -1.31740138e-01 -1.95666686e-01 -1.28791019e-01 -2.33980198e-03\n",
      "  1.97980716e-03  1.93099484e-01  3.24650049e-01  2.60929108e-01\n",
      "  4.34107631e-01  1.29158096e-02  5.06833494e-02  1.91195130e-01\n",
      "  1.97116151e-01  1.80913582e-02  2.32006848e-01 -1.48426265e-01\n",
      "  1.99893221e-01  3.82094979e-01  1.86090678e-01  7.83381909e-02\n",
      "  1.31077066e-01 -1.36797652e-02  1.19787730e-01 -4.03482392e-02\n",
      "  2.87888348e-01  2.11676404e-01  4.32245851e-01  3.11939776e-01\n",
      " -2.74236649e-01 -2.53386386e-02 -4.26903009e-01  9.62070562e-03\n",
      " -1.41445085e-01  2.55191237e-01  3.86945397e-01  7.76688084e-02\n",
      "  1.43315360e-01 -1.81961089e-01 -4.06648844e-01 -1.74368307e-01\n",
      " -3.22488397e-01 -2.74216771e-01 -3.19651105e-02  3.14144753e-02\n",
      "  2.13283271e-01  2.80179858e-01 -9.94064957e-02 -1.49726849e-02\n",
      " -3.60296488e-01 -8.29166695e-02  1.37547806e-01 -2.64375001e-01\n",
      " -1.26375809e-01  1.24221496e-01  1.23380758e-01  3.99885774e-01\n",
      "  9.57982149e-04  3.11493397e-01 -8.31789970e-02 -1.56695377e-02\n",
      "  8.72856453e-02 -3.04706842e-01 -2.28037819e-01 -7.14123547e-02\n",
      "  8.19441304e-02  3.36344540e-02  8.50633308e-02  1.55243590e-01\n",
      "  2.69602567e-01  2.57488966e-01  3.68924826e-01  1.09993182e-01\n",
      "  2.01632082e-01 -4.54986952e-02 -1.70684367e-01 -2.24283740e-01\n",
      " -2.16956940e-02  1.01969644e-01  1.75516486e-01  3.06094289e-01\n",
      " -2.73468614e-01 -2.68582374e-01 -6.10695891e-02 -1.52401015e-01\n",
      " -2.98397988e-02 -1.54883921e-01  2.57355690e-01  3.05522382e-01\n",
      " -7.81862997e-03  6.00476190e-02  7.17791840e-02 -1.37272909e-01\n",
      "  4.40113187e-01 -1.32998228e-02 -3.73349518e-01 -2.36346006e-01\n",
      " -1.27930582e-01 -1.01219617e-01 -3.12703848e-01  2.88076401e-01\n",
      " -5.71872629e-02  8.87622461e-02  1.56311706e-01 -8.27445984e-02\n",
      " -1.03171840e-01  1.37496844e-01  1.91958070e-01 -1.10353097e-01\n",
      " -6.57938346e-02 -1.75301552e-01 -2.08085045e-01  6.73533604e-02\n",
      " -1.17991716e-01  2.45198697e-01  2.59556651e-01  1.57965466e-01\n",
      " -7.42582083e-02  1.51418913e-02 -2.45972089e-02 -6.68671951e-02\n",
      " -2.39190869e-02  2.34309733e-02  1.56058475e-01  1.40371501e-01\n",
      "  1.35585114e-01 -1.68661475e-01  3.81868869e-01  1.09287366e-01\n",
      "  1.54936925e-01 -1.59529373e-01  3.40023071e-01 -3.37133676e-01\n",
      "  1.46421582e-01  2.67553538e-01 -6.92161545e-02 -4.43859726e-01\n",
      "  2.97339670e-02 -1.98422313e-01  8.99775699e-03 -3.13328728e-02\n",
      "  1.10447273e-01 -2.37627223e-01]\n",
      "L4N0                    -> L5N47 = [ 4.28024791e-02  9.14835334e-02  3.30174435e-03  8.26159790e-02\n",
      " -6.33889586e-02 -3.47807616e-01 -7.15431750e-01 -2.37974256e-01\n",
      "  2.65766140e-02  5.22371987e-03  6.93298057e-02  2.61949778e-01\n",
      "  2.40996748e-01  2.67153859e-01 -6.62365332e-02 -2.03265682e-01\n",
      " -3.40231657e-01 -2.83975303e-01  2.94724964e-02 -2.66562045e-01\n",
      "  1.99316651e-01  1.20677017e-01  1.40213042e-01 -1.22781254e-01\n",
      " -1.54698163e-01 -1.29438072e-01 -7.29264226e-03  3.80308786e-03\n",
      "  1.78383470e-01 -2.45249674e-01 -2.28774138e-02 -2.05238029e-01\n",
      " -3.24258804e-01 -4.45138216e-02 -1.42674912e-02 -2.12198541e-01\n",
      " -1.64625689e-01  4.86399561e-01  1.21133581e-01  1.38393417e-01\n",
      " -4.29945111e-01 -3.66179645e-01  5.44688702e-01  2.19249353e-02\n",
      " -1.46694571e-01  3.81172329e-01  9.25104246e-02  6.84459209e-02\n",
      "  3.40094656e-01  2.23408297e-01 -1.13159761e-01  5.18149734e-02\n",
      " -2.20773071e-01  8.02824125e-02  4.62027006e-02 -3.74604374e-01\n",
      "  2.99676638e-02  5.27386628e-02  1.13303542e-01  2.87637413e-01\n",
      "  4.22766149e-01 -5.78765832e-02  2.40917001e-02  1.07538030e-01\n",
      " -1.45387407e-02  1.91115454e-01 -3.76174226e-02  5.51613560e-03\n",
      " -1.74449146e-01  2.32349917e-01  4.10369575e-01 -6.51099309e-02\n",
      "  3.27968150e-01 -3.81348819e-01  1.89054146e-01  3.06170046e-01\n",
      " -9.96017233e-02  9.07134339e-02 -4.23154458e-02 -2.93030083e-01\n",
      "  1.33828849e-01 -2.47530997e-01 -2.92034268e-01 -2.52577931e-01\n",
      "  1.46078512e-01  1.35912389e-01 -3.87754291e-03  2.04511195e-01\n",
      " -2.19682828e-01 -7.01720193e-02  3.41725439e-01 -4.06610221e-02\n",
      " -2.47255340e-01  4.17473055e-02 -3.96620445e-02 -1.13716803e-01\n",
      " -5.81515990e-02  7.45637566e-02 -1.30890235e-01  3.58919591e-01\n",
      " -9.76217166e-02 -7.55735412e-02  1.22868456e-01  1.00139260e-01\n",
      " -3.46101113e-02 -1.13217123e-01 -2.06599817e-01 -1.67796046e-01\n",
      " -1.17577344e-01 -7.96280243e-03  2.40998805e-01  1.25048339e-01\n",
      " -2.57531144e-02 -4.62660789e-02  3.03482451e-02 -5.45250364e-02\n",
      " -8.03256258e-02  7.24176988e-02  1.10458648e-02 -1.30998760e-01\n",
      " -4.09964025e-01  2.72017181e-01  1.80008367e-01 -1.89647794e-01\n",
      " -3.85025114e-01 -2.59656571e-02 -1.04165219e-01  8.83207843e-02\n",
      " -1.46894827e-01  7.69185275e-02  4.65595126e-02 -3.12188685e-01\n",
      "  1.64325103e-01 -1.02908626e-01 -2.75125682e-01 -6.09658472e-02\n",
      " -3.09554696e-01  3.58925700e-01  2.73595597e-05 -7.78528228e-02\n",
      " -2.65774816e-01 -2.82595485e-01 -6.55134320e-02  2.72679124e-02\n",
      "  1.42772838e-01 -1.61147624e-01  1.58833295e-01  2.54905403e-01\n",
      "  1.05246872e-01  2.72298634e-01]\n",
      "L4N0                    -> L5N48 = [-0.28840074 -0.00778023  0.46665007 -0.0438717   0.181927   -0.11398871\n",
      " -0.08067352 -0.08904938 -0.02186165 -0.30608436  0.03465275  0.05104502\n",
      " -0.22915696  0.22514838  0.04293567 -0.31670332 -0.29722697  0.24462599\n",
      "  0.24278201 -0.13578045  0.4898004  -0.30990243 -0.32840937 -0.2600128\n",
      "  0.13037041  0.04379846 -0.17833167  0.4848279  -0.04397571  0.10633849\n",
      "  0.19209464 -0.15435895  0.10271936  0.5897433  -0.24557099 -0.282723\n",
      "  0.09731197  0.19132344 -0.13072543 -0.24770574 -0.1980196   0.11332208\n",
      " -0.15113947 -0.18258984 -0.24676195  0.03386686 -0.26552075 -0.41627008\n",
      " -0.5472066  -0.12085024 -0.06695886  0.40595898 -0.06058279 -0.00320576\n",
      " -0.72544396 -0.10676827  0.00346987 -0.23802078 -0.07040475 -0.02470589\n",
      " -0.20477685  0.17285639  0.5155314   0.36592    -0.12956242 -0.1012419\n",
      " -0.19052356  0.24116208 -0.1490535  -0.05925124  0.0646565   0.06058744\n",
      " -0.360498   -0.16367753  0.13717574  0.0172614  -0.2605122   0.05779181\n",
      "  0.02202759  0.15525423 -0.00668118 -0.10837385  0.25566453 -0.20335485\n",
      " -0.08883896  0.4695492  -0.25976524 -0.10424732  0.19856785  0.05423548\n",
      " -0.34099948  0.30638096  0.1659694  -0.03790122  0.05356444 -0.20863634\n",
      "  0.04295824  0.12322531  0.15035963 -0.22659004  0.04776375 -0.34065172\n",
      " -0.40213814 -0.2738756  -0.02052085 -0.18928926  0.03469937 -0.50878173\n",
      "  0.09588856 -0.02450149 -0.13584697 -0.57446635  0.12817763 -0.08641542\n",
      " -0.16978407  0.00281379 -0.3512131  -0.21096808  0.02402391  0.02026109\n",
      " -0.08138563 -0.01122251 -0.16620544 -0.10132723  0.15716481 -0.03071175\n",
      " -0.1256068  -0.00975583  0.02356706  0.58975315 -0.1573197  -0.17107221\n",
      " -0.5172593  -0.09578946  0.12331898  0.23877738 -0.17273445  0.22891119\n",
      "  0.0317704   0.03757561  0.22064161 -0.11936484 -0.15831056 -0.18738087\n",
      "  0.13907182  0.20700692 -0.14597988 -0.15416975 -0.05556801 -0.8030595 ]\n",
      "L4N0                    -> L5N49 = [ 0.03327547  0.22370124  0.17920417  0.45469543  0.1186242  -0.13178495\n",
      "  0.14386907  0.2848308   0.28844625  0.01565936 -0.30537823 -0.23032796\n",
      "  0.02098574 -0.10503674  0.39230642 -0.38054928  0.4009558  -0.1268741\n",
      "  0.01930547 -0.16119142  0.01742507 -0.08301624 -0.5342614  -0.06468272\n",
      " -0.11230727 -0.00969008  0.03504971 -0.15186113 -0.5662895   0.2202237\n",
      " -0.10732532  0.06889314  0.4023899  -0.27896374  0.12459905  0.08922362\n",
      "  0.24288735  0.0993168   0.3056486  -0.01842376  0.05521007  0.02765864\n",
      " -0.34160933  0.12545952  0.2769109  -0.08928279  0.07839657 -0.58503056\n",
      "  0.1547302  -0.12888455  0.01627017  0.1441967  -0.09214472  0.12194132\n",
      " -0.34432566  0.13321339 -0.46415827 -0.22891016 -0.03639123 -0.14334764\n",
      " -0.25635928 -0.3511355   0.05532973 -0.04807099  0.19157399  0.08004557\n",
      " -0.29901683  0.4077112  -0.02247798 -0.06892962  0.0718917   0.0043937\n",
      "  0.10831542  0.12843487 -0.33899555 -0.03363037  0.041508   -0.01986447\n",
      " -0.0578139   0.1300074   0.0703728  -0.0527155   0.10768832 -0.1025594\n",
      "  0.04438815  0.5010758  -0.4667364   0.3468944   0.10949507 -0.08373436\n",
      " -0.42018798  0.06026907  0.07288047  0.25571027  0.10434731 -0.5806484\n",
      " -0.2740457   0.05904819 -0.01265669 -0.26006055 -0.20297867  0.40767357\n",
      " -0.4652343   0.22088334  0.012639    0.19681583  0.22831784 -0.2592641\n",
      "  0.18222865 -0.35020006  0.34563586 -0.02869521 -0.04736565  0.10855886\n",
      "  0.03026511 -0.2285518  -0.10510371 -0.22456472  0.09228396 -0.01293305\n",
      " -0.46671638  0.12787026 -0.68088585  0.06447694  0.41372028  0.31696025\n",
      "  0.14399329  0.28430715 -0.11207383 -0.01473695  0.02141249  0.0605143\n",
      "  0.04757208  0.06482489  0.09673171 -0.44509867 -0.01789313 -0.01652553\n",
      " -0.21832556  0.10722321  0.19560266  0.08144438  0.16720854 -0.32139128\n",
      " -0.04018947 -0.15819567  0.33743528  0.04792689 -0.21106744  0.07968139]\n",
      "L4N0                    -> L5N50 = [ 4.51133102e-02  2.80143797e-01 -4.09782320e-01 -1.98346138e-01\n",
      " -3.09844345e-01  5.34385145e-02 -1.23819113e-01 -7.16277957e-02\n",
      "  3.62505943e-01 -1.67514786e-01  1.84573367e-01  8.86862576e-02\n",
      "  2.12436959e-01 -1.73857093e-01  3.23993750e-02 -4.02231095e-03\n",
      "  5.26869297e-02 -1.53112477e-02  3.75083610e-02 -1.25278875e-01\n",
      " -1.45844072e-01  1.07019097e-01  3.41468304e-02  2.22678035e-01\n",
      " -1.16157107e-01 -1.28026754e-01 -3.40328097e-01 -6.15369737e-01\n",
      " -2.87163317e-01 -1.66072026e-01  2.38824468e-05  1.43284082e-01\n",
      "  4.75263655e-01 -9.52938199e-02  3.07948232e-01  2.30296254e-01\n",
      "  5.19448519e-02  1.46675836e-02 -3.23418796e-01  1.81441858e-01\n",
      " -4.16575968e-01 -3.67189735e-01  6.73603415e-02  1.26640545e-02\n",
      "  1.80234551e-01  2.74429414e-02 -1.28533617e-01 -3.57865207e-02\n",
      " -7.94975013e-02 -4.52997088e-01  4.06868666e-01  2.85880617e-03\n",
      " -2.60201562e-02 -2.27805912e-01 -5.58989681e-02  8.01451728e-02\n",
      "  4.21536297e-01  1.66470796e-01  4.97752726e-02 -2.28630509e-02\n",
      " -2.99993902e-01 -8.10688138e-02 -2.41520464e-01  4.66464087e-02\n",
      "  7.46465800e-03  1.65653378e-01 -3.52164730e-02 -2.81770408e-01\n",
      "  1.45113602e-01 -9.92708951e-02  1.05151497e-01  1.71128750e-01\n",
      " -1.07256331e-01  7.20187202e-02 -8.98658708e-02  2.08316535e-01\n",
      " -3.73709500e-02  3.44700441e-02  7.69217089e-02 -3.05131555e-01\n",
      " -3.35910410e-01 -2.73693446e-02 -2.00647235e-01  6.38951957e-02\n",
      " -1.11561067e-01 -2.28390634e-01 -1.56405613e-01  1.45752290e-02\n",
      " -1.78592905e-01 -1.37786895e-01  1.95972491e-02 -7.95424078e-03\n",
      " -1.94729432e-01  1.75212279e-01  1.12005122e-01  8.79108235e-02\n",
      " -6.93485886e-02 -3.74778360e-01 -1.68859586e-01 -3.82920921e-01\n",
      " -1.45786605e-03 -7.60514885e-02  9.84749869e-02 -2.19168276e-01\n",
      " -9.47707966e-02  6.73776940e-02 -5.00619769e-01 -1.47844076e-01\n",
      "  5.20700077e-03 -1.11641146e-01  3.19745354e-02 -8.98049399e-02\n",
      "  1.07627846e-01  2.55329796e-04 -1.45592660e-01 -1.27896890e-01\n",
      "  3.07717770e-02 -1.42394617e-01 -1.02476425e-01 -2.29992550e-02\n",
      "  1.23222776e-01  8.32332373e-02  2.01291576e-01 -1.86170489e-01\n",
      " -1.19001918e-01  3.09445485e-02  2.68371820e-01  2.28037149e-01\n",
      " -1.97586507e-01  4.59781624e-02  8.46064687e-02  3.56136739e-01\n",
      " -8.25710967e-02 -1.38559699e-01  2.70975351e-01 -2.16811318e-02\n",
      " -5.90411685e-02 -1.64039671e-01 -1.93873897e-01 -3.15603733e-01\n",
      "  1.89120099e-01  1.91108122e-01 -2.90308803e-01  6.66888505e-02\n",
      " -1.05161838e-01 -2.98769534e-01 -2.71515518e-01 -4.28242594e-01\n",
      "  9.76338238e-02  2.33100697e-01]\n",
      "L4N0                    -> L5N51 = [-2.91261002e-02 -1.79111063e-01 -2.48717099e-01 -1.39661223e-01\n",
      " -4.79020834e-01 -1.06764376e-01 -2.19947919e-01 -1.21868879e-01\n",
      "  1.82881787e-01 -4.58399728e-02 -2.14069709e-01  6.07496090e-02\n",
      "  2.43555263e-01 -7.33984113e-02  2.26524770e-02  2.22334132e-01\n",
      " -4.55633372e-01 -4.01138701e-02 -5.78475893e-01 -5.41909672e-02\n",
      " -2.45147273e-01  2.65351027e-01  2.24975035e-01  1.99367523e-01\n",
      "  5.61018884e-02 -4.73846078e-01 -3.37140486e-02 -2.96333373e-01\n",
      " -4.04952019e-01 -6.07048333e-01 -2.46694356e-01 -3.88713807e-01\n",
      "  6.06025523e-03 -3.19037944e-01 -6.42012954e-02 -1.08524181e-01\n",
      "  2.49225035e-01  5.40630519e-02 -1.64381191e-01  8.60182643e-02\n",
      " -1.30171359e-01 -5.98084807e-01  8.06087703e-02 -1.43525109e-01\n",
      "  1.51295125e-01 -1.62223965e-01  7.74871205e-06  2.85912424e-01\n",
      "  2.13934910e-02  7.10229054e-02 -1.80478409e-01 -2.37596750e-01\n",
      " -4.77866530e-02 -2.03269780e-01  1.75342962e-01 -2.31890798e-01\n",
      "  6.48229569e-02 -3.31355870e-01 -3.43175628e-03 -2.79618561e-01\n",
      "  1.03192873e-01 -3.59803259e-01 -1.57897159e-01 -8.41486547e-03\n",
      "  8.28399807e-02  1.92514155e-02  1.07953712e-01 -1.70643687e-01\n",
      "  5.55411994e-01  1.01888128e-01  3.54480863e-01 -1.11528590e-01\n",
      " -6.96073249e-02 -1.47917166e-01 -2.02662736e-01 -3.30413179e-03\n",
      " -1.32185623e-01 -9.95396525e-02 -5.99246323e-02 -5.89258075e-02\n",
      " -3.92076641e-01  1.11134306e-01 -2.07811221e-01  8.70156512e-02\n",
      "  8.16719159e-02 -2.95978516e-01  4.36792225e-02 -3.57993543e-01\n",
      " -1.86404020e-01 -3.49223375e-01 -9.90993157e-02 -3.94772381e-01\n",
      " -9.58303064e-02 -5.34682162e-02  3.42407003e-02 -4.44946229e-01\n",
      " -1.52326887e-02  5.73854567e-03 -3.11558187e-01 -2.02647716e-01\n",
      " -3.20351094e-01  2.62201577e-01  3.12236771e-02  4.05910350e-02\n",
      " -8.65548849e-02 -4.32919979e-01 -4.97080803e-01 -2.11165339e-01\n",
      " -1.04544424e-02  1.79285351e-02 -3.12377606e-02 -3.86559367e-01\n",
      " -2.42391065e-01 -3.57363760e-01 -1.45992815e-01  1.04542941e-01\n",
      " -1.85604334e-01 -7.34630823e-02 -1.25466391e-01  5.04808761e-02\n",
      " -5.09105921e-01 -2.24065065e-01  1.50681093e-01 -3.07005256e-01\n",
      "  1.46643922e-03  3.24879110e-01 -1.26051744e-02  2.04908833e-01\n",
      " -1.31848484e-01  3.02476227e-01 -1.83659926e-01  1.39633790e-01\n",
      "  2.04595812e-02 -2.44598407e-02  1.69736668e-01 -6.80087090e-01\n",
      " -6.15940630e-01  1.36057645e-01  1.19426101e-01  3.33947912e-02\n",
      " -1.45586208e-01 -1.40501961e-01  2.61899233e-01 -1.58691674e-01\n",
      " -3.98658291e-02 -1.17999971e-01 -2.51808912e-02  3.43223996e-02\n",
      "  1.18840344e-01 -3.95090133e-03]\n",
      "L4N0                    -> L5N52 = [ 0.24491991 -0.24699236 -0.05894068  0.3949687  -0.17371207 -0.05303621\n",
      "  0.19896588  0.41381502  0.11613329 -0.04493724 -0.3835988  -0.19448297\n",
      "  0.15449566 -0.16533244  0.21203731 -0.10785877  0.11479919 -0.26661545\n",
      "  0.331354   -0.34200937 -0.27147436  0.03528554 -0.05140076  0.3216026\n",
      " -0.06126018 -0.2527429  -0.2335032  -0.07233776  0.08290623 -0.08241684\n",
      " -0.32793048 -0.09588096  0.04707364 -0.57777166  0.14709091  0.14415197\n",
      " -0.19979754  0.19140628 -0.5009243   0.2909588   0.08966995  0.02614213\n",
      " -0.29916638 -0.14066318  0.05948153 -0.16211043 -0.31834584 -0.17656882\n",
      "  0.14810188  0.28532094  0.27187473  0.25902435 -0.13994586 -0.25937292\n",
      "  0.11451648 -0.19801074 -0.11882179 -0.1878039   0.00479061 -0.37211877\n",
      " -0.0891064  -0.43315467 -0.12633482 -0.25000513  0.10240179  0.13559361\n",
      "  0.48167896  0.13823898  0.05869929  0.10428612  0.4476908   0.10493393\n",
      " -0.02498046  0.3833496  -0.04302819 -0.14201118  0.04345419 -0.2948921\n",
      "  0.20298819 -0.42770284  0.05839601  0.05456458  0.1422303   0.03362777\n",
      "  0.28154424 -0.10398688  0.11674226  0.14176339  0.17264402 -0.35920003\n",
      " -0.01458544  0.10281194 -0.11215899 -0.08986196  0.34661302 -0.1030917\n",
      " -0.36662957  0.11690235 -0.24098031  0.13869165 -0.00246643  0.21661964\n",
      " -0.43427303 -0.5639813  -0.06130978 -0.2158061  -0.0765892   0.04263239\n",
      " -0.42995784 -0.10979687  0.1853047  -0.2578902   0.09380984  0.0685704\n",
      " -0.05083856 -0.27556983 -0.29255196 -0.36347985 -0.1258796  -0.08586481\n",
      " -0.09254132  0.18019192 -0.59535015 -0.10240695  0.256037    0.173694\n",
      " -0.19290037 -0.1598176  -0.01826219 -0.35480082 -0.212227    0.34021947\n",
      " -0.35053065 -0.01517875  0.01551597  0.18318185 -0.06087082  0.27341408\n",
      "  0.10463917  0.15769364  0.08632442 -0.09285092  0.4550616   0.09262345\n",
      " -0.2987326  -0.09026416  0.45074388 -0.5124149   0.07199057  0.16498663]\n",
      "L4N0                    -> L5N53 = [ 1.87036052e-01 -8.44274908e-02  5.19646481e-02 -8.15241560e-02\n",
      "  8.84427354e-02  1.09113991e-01 -4.48471010e-01 -2.14486912e-01\n",
      "  4.85771120e-01 -2.98271149e-01 -6.91323504e-02  2.52270699e-02\n",
      "  1.57671035e-04  9.39102769e-02 -1.18026696e-01  2.11825550e-01\n",
      "  2.17520371e-01  9.52995494e-02 -6.32936582e-02 -2.31536716e-01\n",
      " -2.68435478e-01  4.54806864e-01 -7.41942301e-02  1.33723408e-01\n",
      " -1.92556337e-01 -1.30047828e-01 -3.06440860e-01 -1.79689690e-01\n",
      "  2.74254736e-02 -8.25520754e-02  9.39479750e-03  3.32032442e-02\n",
      " -8.68000686e-02 -4.48930383e-01 -3.78752537e-02 -8.74781311e-02\n",
      "  9.52281151e-03 -5.85968867e-02  1.02509677e-01  1.89906642e-01\n",
      " -1.05277896e-02 -1.26364067e-01  1.13192581e-01 -1.02778047e-01\n",
      " -5.18011339e-02 -1.01599962e-01 -2.65970081e-01  2.18151674e-01\n",
      " -7.37346858e-02 -4.44240183e-01  5.16048133e-01 -3.06266192e-02\n",
      " -4.78083175e-03 -4.74712431e-01  2.16005057e-01  7.38835409e-02\n",
      " -6.13691062e-02 -2.93177575e-01  6.90836459e-02 -2.45984763e-01\n",
      "  1.72496796e-01  1.86264306e-01 -1.10464595e-01 -3.38633120e-01\n",
      "  1.19831137e-01  2.79210687e-01  2.68186688e-01 -1.64019555e-01\n",
      " -5.56206778e-02  9.45996493e-02  4.87095974e-02 -1.87136933e-01\n",
      " -4.27817833e-03 -1.53421566e-01  1.78536221e-01  2.24285617e-01\n",
      "  2.26070449e-01 -3.08828235e-01  5.20248972e-02  2.36827850e-01\n",
      " -7.22634122e-02  1.92299947e-01 -2.67069429e-01  4.42784548e-01\n",
      "  3.22101593e-01 -1.40392065e-01  3.45519818e-02  5.48564374e-01\n",
      " -1.14467077e-01  1.74197871e-02 -2.15401962e-01 -3.31403166e-01\n",
      "  7.34732067e-03 -1.95203871e-01 -2.32499048e-01  3.13810945e-01\n",
      " -3.38455811e-02 -2.38343790e-01 -2.91834742e-01  8.63216072e-02\n",
      "  1.39718845e-01  1.52977720e-01  1.63131356e-01 -4.35501397e-01\n",
      "  8.33284110e-03 -1.06075682e-01 -2.99934924e-01 -1.83688760e-01\n",
      "  2.96040680e-02  1.89213291e-01  2.37192914e-01  6.06413223e-02\n",
      " -3.91681194e-01  1.09670095e-01  6.93283305e-02 -5.31214476e-01\n",
      "  2.67765462e-01 -5.69849350e-02 -1.48608834e-02 -1.03736982e-01\n",
      " -5.16173169e-02  1.34760179e-02 -1.57522887e-01 -1.17221922e-02\n",
      " -1.53572619e-01 -2.71421731e-01 -1.54455125e-01 -1.13843139e-02\n",
      " -1.27836183e-01 -1.07346080e-01 -7.68571198e-02  1.60235345e-01\n",
      "  1.34710282e-01 -4.12398487e-01  8.28147605e-02 -2.31207773e-01\n",
      " -2.07950860e-01 -1.65063962e-01  4.72280895e-03 -3.51315826e-01\n",
      "  1.69298649e-02  5.71859255e-02  9.04735327e-02 -1.34759143e-01\n",
      " -1.78580806e-01 -4.07495439e-01  2.16521144e-01  1.66886106e-01\n",
      "  1.15967870e-01 -5.34368940e-02]\n",
      "L4N0                    -> L5N54 = [-0.11527947 -0.1203776   0.28606284  0.3509094   0.17404646  0.10991063\n",
      "  0.26624337 -0.23750874 -0.03126413  0.10658316  0.06046028 -0.02661398\n",
      " -0.22659414 -0.26167944 -0.01841607 -0.12384935  0.20612706 -0.17439398\n",
      "  0.11026543 -0.22639953 -0.15720482 -0.714176   -0.02900659  0.24916518\n",
      "  0.08670215  0.11415204 -0.22508018 -0.03995381  0.2457687  -0.215911\n",
      "  0.09269612  0.03820479 -0.18470103 -0.01894895  0.11022403 -0.21814585\n",
      "  0.11860947 -0.13395655 -0.38336024  0.04759449 -0.29499     0.07967149\n",
      "  0.14058168 -0.24415235  0.04250059  0.15162146 -0.4643426   0.00216033\n",
      "  0.49255657  0.09652632 -0.19894359  0.28955105  0.31305215 -0.21241014\n",
      " -0.2109984  -0.2549035   0.07493067 -0.2120027   0.07315069  0.0689011\n",
      " -0.72016644 -0.00918547 -0.21130091  0.09078415 -0.0713296   0.15018816\n",
      " -0.49478328 -0.1071717  -0.2677945  -0.14334068  0.07761227 -0.05526304\n",
      " -0.04493229  0.41581824  0.06979579  0.1563924  -0.07823635 -0.01921417\n",
      "  0.04423086  0.40086353 -0.1261549  -0.71942073 -0.12885661  0.24850222\n",
      " -0.15599865  0.1790195   0.12680466 -0.05169718 -0.118578   -0.01082146\n",
      "  0.01908343  0.01874027 -0.22649588 -0.4917535   0.22662036  0.343434\n",
      "  0.00295078  0.06501919 -0.29585624  0.21079601  0.23847036 -0.01922435\n",
      "  0.12628774 -0.25019383 -0.5390304  -0.23858073 -0.14052837  0.37780383\n",
      "  0.29630733 -0.03977839  0.46379444  0.294416   -0.21324585  0.47469932\n",
      "  0.0374398   0.00648813  0.144102   -0.07696026 -0.50233126 -0.24035755\n",
      " -0.09361655  0.1190445   0.1957116  -0.25449076 -0.13938044  0.16194938\n",
      "  0.01771026 -0.4837883   0.14040998 -0.19956082  0.11269624 -0.11443558\n",
      "  0.11026522 -0.20117885  0.19025744  0.07744121 -0.35570487 -0.7679231\n",
      " -0.31807637  0.1716949   0.15510643 -0.1726786   0.06163855  0.2548309\n",
      " -0.11934959  0.13225377  0.21614927  0.00615697  0.29969603 -0.18713814]\n",
      "L4N0                    -> L5N55 = [-2.82969505e-01 -3.19446534e-01 -7.65416697e-02  7.71414861e-02\n",
      "  5.25817312e-02 -2.62015797e-02 -1.05072863e-01  4.99675458e-04\n",
      "  1.45704970e-01 -2.86725134e-01 -7.38182217e-02 -1.80015743e-01\n",
      " -3.21080118e-01 -2.27094427e-01  1.73973516e-01 -9.39263105e-02\n",
      "  3.70234214e-02 -3.70431364e-01 -8.22268277e-02  9.86289531e-02\n",
      " -1.49343103e-01  8.78712535e-02  1.82737827e-01  1.84766367e-01\n",
      " -8.65552947e-02 -2.83241104e-02 -3.79662484e-01 -2.85482228e-01\n",
      " -1.40034676e-01 -1.82985440e-01 -1.74457803e-01  9.51183885e-02\n",
      " -4.15921994e-02 -3.11564207e-01  2.59633698e-02  2.64807865e-02\n",
      "  2.53016949e-01  2.46885985e-01 -3.30185257e-02  6.37737930e-01\n",
      " -3.49568501e-02  4.42705229e-02  6.85689002e-02 -1.58467278e-01\n",
      " -2.35542744e-01 -7.41127908e-01  5.18101230e-02 -4.52805728e-01\n",
      "  1.49200305e-01  4.93178889e-02 -1.69662371e-01  3.07759017e-01\n",
      "  7.51010329e-02 -1.26091719e-01 -1.94515113e-03  8.35130364e-02\n",
      " -5.19049764e-01 -1.95671201e-01 -3.70154709e-01 -2.96019375e-01\n",
      "  2.61662692e-01 -1.31695986e-01 -2.64129162e-01 -4.38918054e-01\n",
      " -2.43768364e-01  1.67912394e-02  1.28323957e-02 -3.86841483e-02\n",
      "  7.34009296e-02  3.35176915e-01  3.06885540e-01 -2.01563552e-01\n",
      "  2.04583053e-02  1.42808974e-01 -1.63958773e-01 -7.47164860e-02\n",
      "  2.26745531e-01 -1.95058405e-01 -8.46551433e-02 -2.44958818e-01\n",
      " -2.12456539e-01  2.00648040e-01 -2.84217894e-01 -9.07964334e-02\n",
      "  8.57050270e-02  5.19515425e-02 -1.50470704e-01 -1.61294907e-01\n",
      "  1.03762478e-01 -1.84219539e-01  2.79345155e-01 -1.16940595e-01\n",
      " -5.77450395e-01 -1.74888730e-01  5.74090123e-01  4.51876177e-03\n",
      " -5.93126714e-01  1.95749104e-02 -2.37798825e-01 -4.30129282e-02\n",
      "  1.53086066e-01  2.90244848e-01 -3.43728513e-01 -3.47885966e-01\n",
      "  4.24735606e-01 -1.76240280e-01 -4.22149271e-01  2.47720465e-01\n",
      " -3.44845235e-01 -2.69149318e-02  2.79636294e-01  1.77036881e-01\n",
      " -9.06907022e-02  9.76994932e-02  1.67773023e-01  4.75657396e-02\n",
      "  1.38105196e-03 -1.60430148e-01 -5.57734370e-01 -4.37807143e-01\n",
      "  1.59605414e-01 -1.29783005e-01 -5.53344548e-01  1.69363454e-01\n",
      " -2.56781161e-01  1.17570385e-01  6.76522851e-02  2.14555144e-01\n",
      " -6.59435630e-01 -1.89724311e-01 -2.74985172e-02 -1.48287907e-01\n",
      " -2.01080829e-01 -5.40362895e-01 -3.07730883e-01  3.63306180e-02\n",
      "  4.58083302e-02 -8.76450092e-02  1.09882146e-01  2.27470919e-01\n",
      "  1.66838646e-01 -2.41378084e-01  1.69142440e-01  4.26312178e-01\n",
      " -6.23128951e-01  1.38592109e-01  2.67024398e-01 -4.68762577e-01\n",
      " -7.27047548e-02  2.10286677e-01]\n",
      "L4N0                    -> L5N56 = [ 1.81745961e-01  3.15088272e-01  1.22228473e-01  1.38074964e-01\n",
      " -3.71009856e-02 -9.86310765e-02 -1.36115551e-01 -5.60923666e-02\n",
      " -1.41181022e-01  1.91024914e-01 -2.72862483e-02 -9.05497745e-02\n",
      " -7.52756149e-02 -6.79976586e-03  1.74590275e-01 -3.52634303e-02\n",
      " -4.13986385e-01 -2.16378510e-01  4.69725609e-01  1.43280283e-01\n",
      "  1.15784474e-01  5.93857467e-02  1.32100191e-02  2.65819002e-02\n",
      " -5.26686795e-02  1.35767177e-01  2.12269038e-01  5.13431132e-02\n",
      "  1.16718344e-01 -9.26770642e-02  1.39091566e-01 -5.59161231e-02\n",
      "  4.30307418e-01 -5.08974306e-02  1.33409575e-01 -1.77241474e-01\n",
      " -1.58267200e-01 -3.54623854e-01  7.54759535e-02  1.10773675e-01\n",
      "  1.71080142e-01 -2.54453152e-01 -3.62650454e-01 -1.80825010e-01\n",
      "  1.28304511e-01  1.14422843e-01  3.85678142e-01  2.74894908e-02\n",
      " -2.81904638e-01 -1.77934110e-01 -2.63193309e-01  1.09367408e-01\n",
      "  8.54539126e-03 -2.37246782e-01 -4.06071842e-01 -1.71058461e-01\n",
      "  5.15652038e-02  1.10747464e-01 -1.70787081e-01 -3.80016834e-01\n",
      " -2.30116934e-01 -3.33625227e-01 -3.47232409e-02 -4.97711450e-01\n",
      "  1.16545565e-01 -5.80479503e-02 -1.35309249e-01 -2.48152018e-01\n",
      " -2.29218692e-01  3.10019284e-01 -7.86567181e-02 -1.19201384e-01\n",
      " -6.33772731e-01 -2.23601207e-01 -1.76436633e-01  4.08118665e-01\n",
      " -4.62513596e-01  2.54691727e-02 -2.98835069e-01 -2.59393811e-01\n",
      "  1.17275618e-01 -2.51994252e-01 -1.46394357e-01 -3.68734330e-01\n",
      " -2.40899203e-03 -1.11164249e-01  3.45915616e-01 -6.70229942e-02\n",
      "  6.56196833e-01 -2.84955680e-01 -4.30500269e-01 -1.71853915e-01\n",
      "  2.21807346e-01 -1.99033469e-01 -1.36329159e-01 -1.68301314e-01\n",
      "  7.31266886e-02  2.05690295e-01  4.84404564e-02 -1.55919388e-01\n",
      " -7.43420348e-02  2.26214137e-02 -3.11627835e-01  3.98607463e-01\n",
      "  2.25164801e-01 -1.96637362e-01  1.01396538e-01 -2.13220641e-01\n",
      "  2.23725364e-01  6.13350086e-02 -4.43955958e-02  2.65982896e-02\n",
      " -3.15884829e-01 -3.68821681e-01 -1.18661083e-01  6.80396497e-01\n",
      " -7.46241733e-02 -3.81912798e-01 -8.65352922e-05  1.39872923e-01\n",
      " -4.47024763e-01  2.01246351e-01 -4.32269186e-01 -2.15081975e-01\n",
      "  4.04990353e-02  9.57725793e-02 -2.28114594e-02  4.54368919e-01\n",
      "  8.58594477e-03  1.88287318e-01 -5.91556206e-02  2.21693963e-01\n",
      "  1.12454325e-01  1.69127658e-02  5.04152067e-02 -3.76197964e-01\n",
      " -4.10162985e-01 -1.19439095e-01 -3.00710082e-01  6.90338109e-03\n",
      "  2.60266900e-01  9.63188857e-02  3.40205319e-02 -4.22483146e-01\n",
      " -1.79844260e-01 -4.06374842e-01  3.19630325e-01 -1.54435905e-02\n",
      " -4.34174001e-01  5.16012847e-01]\n",
      "L4N0                    -> L5N57 = [ 1.64797068e-01  8.23285151e-03  2.73100764e-01 -2.13919599e-02\n",
      " -1.20427690e-01 -1.58624157e-01  1.11549877e-01  3.37134808e-01\n",
      "  1.05936892e-01 -1.22532636e-01 -1.10264001e-02 -3.60514343e-01\n",
      " -7.87776336e-02 -2.34253094e-01  2.99487323e-01 -6.24600351e-01\n",
      " -1.95857525e-01 -2.89920885e-02 -2.00740546e-01  4.37201709e-02\n",
      "  1.84594467e-01 -1.37963638e-01 -2.16476321e-01  1.23782307e-01\n",
      "  9.83279124e-02 -8.63716453e-02 -3.76207680e-01 -1.67746451e-02\n",
      " -5.02515933e-04  3.52797031e-01 -2.14782298e-01  4.97777276e-02\n",
      " -2.27556065e-01  1.52202070e-01  1.43871918e-01  1.65488616e-01\n",
      "  2.23296002e-01 -2.57610351e-01 -1.45927384e-01  3.34572881e-01\n",
      " -3.17712307e-01 -1.14046365e-01 -4.26099688e-01 -2.72140354e-01\n",
      " -7.60888010e-02  1.43014332e-02  3.56915802e-01 -9.64894742e-02\n",
      "  9.44083557e-02  3.20503026e-01 -3.87663841e-01  9.37986150e-02\n",
      "  2.38920990e-02  2.01041892e-01  1.55799180e-01 -2.76988372e-02\n",
      " -4.67657298e-01 -2.62571484e-01 -3.31930146e-02  5.95257729e-02\n",
      " -2.68655628e-01  6.32667989e-02  3.71218890e-01 -4.50967066e-03\n",
      "  9.41990390e-02  8.57242793e-02  1.84701666e-01  2.87713736e-01\n",
      "  1.10475816e-01  8.57188273e-03 -2.52432495e-01 -4.68856245e-02\n",
      " -3.72224420e-01  2.78973877e-02 -2.18912289e-02 -1.81046352e-02\n",
      " -1.37810364e-01 -1.44559264e-01  2.59569317e-01 -2.89195657e-01\n",
      " -2.74459034e-01 -1.79374680e-01  1.09414838e-01  1.66749850e-01\n",
      " -1.08197883e-01  3.13484579e-01  1.86898947e-01 -1.66862875e-01\n",
      "  6.92803040e-03 -4.96880561e-02  2.00576559e-01  1.66498378e-01\n",
      " -3.34325761e-01  5.39901061e-03  2.78750479e-01 -3.23477000e-01\n",
      " -6.05976060e-02  1.23708859e-01  2.11271390e-01 -1.64040715e-01\n",
      " -9.43885650e-03  8.43174979e-02 -3.99719030e-01  3.28084439e-01\n",
      "  1.40619531e-01 -3.18897098e-01  9.57483612e-03  1.04893081e-01\n",
      " -4.18628395e-01 -7.96173289e-02 -8.70299712e-02 -1.67360380e-01\n",
      " -1.28712088e-01  1.80206761e-01  1.83224097e-01  2.10097525e-02\n",
      " -2.69947886e-01 -2.75367439e-01 -6.07335679e-02  2.07215756e-01\n",
      " -1.04305856e-01  1.48531228e-01 -1.18737496e-01  1.70226723e-01\n",
      "  1.47696868e-01  1.79324225e-01 -2.05341339e-01 -1.31309614e-01\n",
      " -1.01766750e-01  5.13831116e-02  3.24551687e-02 -3.17043483e-01\n",
      " -1.51652172e-01  3.18113789e-02 -1.66340992e-01 -1.28852025e-01\n",
      " -4.35156167e-01 -2.26510353e-02 -2.00777516e-01  1.96910650e-01\n",
      " -2.37726480e-01  1.18751325e-01 -9.67535004e-03 -1.87610880e-01\n",
      " -1.49974898e-01 -4.58419062e-02  5.58806837e-01 -2.12514713e-01\n",
      "  1.35287018e-02 -1.54215824e-02]\n",
      "L4N0                    -> L5N58 = [-0.3798596  -0.22755279 -0.01937896 -0.05604932  0.39380926 -0.06709035\n",
      "  0.11211252 -0.07309155 -0.0148575   0.13024803  0.21229957  0.262086\n",
      "  0.00691466  0.11409456 -0.02327088  0.08508523 -0.08385832 -0.26186123\n",
      "  0.45460263  0.13226561  0.16745101 -0.47749293 -0.32215393  0.06170093\n",
      "  0.29399455  0.40388274 -0.15725903  0.34427792 -0.0046273   0.47243372\n",
      " -0.10973671  0.18666394 -0.46544555  0.51216257 -0.05154558 -0.04669267\n",
      "  0.10094251  0.26714987  0.20715077 -0.00915411  0.05497011  0.2824453\n",
      " -0.0209605   0.12273294 -0.2806236  -0.09727559 -0.01964738 -0.12312172\n",
      "  0.14992023  0.44713673 -0.09679595  0.10883144 -0.12972423  0.24126649\n",
      " -0.22478308  0.20505744 -0.26679662 -0.1530713  -0.28769153 -0.05352588\n",
      "  0.00267855  0.3328144   0.09043623  0.30359003 -0.24009688 -0.29705966\n",
      "  0.2480893   0.03361245 -0.46170807  0.29502043 -0.23815031  0.16889276\n",
      " -0.03448699  0.18042718  0.38545603 -0.12999849  0.17174226 -0.21313831\n",
      "  0.19788095  0.15959656  0.22255042  0.0145515   0.3543698   0.0459406\n",
      " -0.3239728   0.1820524  -0.12922506 -0.02636675  0.30923298 -0.14372212\n",
      "  0.22477922 -0.18007416  0.56948704 -0.02172812 -0.03988103  0.08620101\n",
      "  0.08841743  0.00136518  0.18592247 -0.04526471  0.3846774   0.08433857\n",
      " -0.17680702  0.2458656  -0.03340323  0.18660477  0.01044206  0.38241947\n",
      " -0.10127095  0.20648614 -0.02918023  0.14632013  0.4024986   0.25404724\n",
      "  0.4006564   0.04527263 -0.1676516   0.03654138 -0.08148395 -0.05222212\n",
      "  0.25684008  0.01726325 -0.27975687 -0.23236756 -0.15858296  0.20677441\n",
      " -0.10128926  0.1335639   0.3104794  -0.27437985  0.21201333  0.14384767\n",
      " -0.1326318  -0.06205178 -0.17949416  0.26007542  0.13095266  0.04241605\n",
      "  0.23513578  0.14233612  0.14143097 -0.40395886 -0.0242978   0.02098044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.2329446  -0.1395209   0.19070674 -0.04894316  0.00913923 -0.06846374]\n",
      "L4N0                    -> L5N59 = [-1.55988364e-02 -9.13143009e-02  8.04560035e-02  4.08776373e-01\n",
      " -6.67873025e-02  9.86264497e-02  3.28828752e-01 -3.40137654e-03\n",
      "  3.09049845e-01 -4.74319965e-01 -3.23812783e-01 -1.39358252e-01\n",
      "  1.84271976e-01  2.41262227e-01  1.64781690e-01  1.18662976e-01\n",
      " -6.06865212e-02 -1.35978088e-01  2.06482559e-01 -1.28447143e-02\n",
      "  1.57063425e-01 -1.00568496e-01  7.22162202e-02 -5.23709729e-02\n",
      "  4.22989391e-02 -3.35582972e-01 -5.16901851e-01 -3.37678462e-01\n",
      "  3.34901720e-01  3.43246907e-01 -5.70273519e-01  5.62786311e-02\n",
      " -3.85100879e-02 -3.04329246e-01  1.86313912e-01  3.98775727e-01\n",
      "  3.19731422e-02  6.52042925e-02  2.34024972e-01  1.36438325e-01\n",
      "  3.39355282e-02  1.51369557e-01 -5.62339164e-02  1.33447304e-01\n",
      " -3.47019762e-01 -6.12612009e-01  9.16742757e-02 -1.02844156e-01\n",
      "  2.31170967e-01 -3.12559217e-01 -7.05057442e-01  5.25161549e-02\n",
      "  1.20857351e-01  1.27169341e-01 -1.99264288e-01 -5.25364950e-02\n",
      "  1.34070024e-01  4.70579006e-02 -5.28696954e-01 -6.50044918e-01\n",
      "  1.52764753e-01 -2.65427053e-01 -9.01339948e-02  1.19908586e-01\n",
      " -3.30306232e-01 -5.30118831e-02  5.14683984e-02 -4.13958102e-01\n",
      " -1.93396345e-01  3.85706648e-02 -3.64212040e-03  2.26782486e-02\n",
      " -8.25090632e-02  1.25266150e-01 -7.21626275e-04  6.04186431e-02\n",
      "  1.89726613e-02 -5.50678432e-01  1.68805987e-01 -1.48545504e-01\n",
      " -2.57659167e-01 -2.86944032e-01 -8.74152482e-02  2.57625431e-01\n",
      " -1.08219013e-01 -4.87037078e-02  1.04267620e-01 -6.76744580e-01\n",
      "  9.50521305e-02  1.42132521e-01  5.47753982e-02 -2.71955460e-01\n",
      " -1.22652827e-02 -6.93391681e-01 -3.05524260e-01  1.61607981e-01\n",
      " -6.21215343e-01  3.11921597e-01  3.59310210e-01 -4.35505778e-01\n",
      "  3.68252903e-01  2.26448536e-01 -6.99100122e-02  2.26329297e-01\n",
      "  9.90289077e-02  1.67481989e-01 -5.79587400e-01  1.32484093e-01\n",
      " -3.65696460e-01  2.36517951e-01 -1.44273877e-01  2.09127545e-01\n",
      " -4.26843064e-03  2.97065347e-01  1.84385747e-01  1.44214764e-01\n",
      "  4.85378876e-03 -9.45433080e-02 -6.12153769e-01 -2.55799502e-01\n",
      "  3.83171827e-01  2.41088822e-01 -2.08643094e-01 -1.01930194e-01\n",
      " -2.79142916e-01  3.41250479e-01 -5.30705392e-01  7.16694221e-02\n",
      " -6.11927867e-01  2.91208386e-01 -1.46016115e-02 -2.88061857e-01\n",
      " -7.79599726e-01 -6.07185006e-01 -1.94767952e-01  2.95416981e-01\n",
      " -6.99620228e-03  4.57109988e-01 -2.76787162e-01  6.15102910e-02\n",
      " -1.25972092e-01 -4.45417970e-01  1.13367878e-01 -9.66174603e-02\n",
      " -3.39861900e-01  1.27152326e-02  4.22999561e-01 -3.17530930e-01\n",
      " -1.30209595e-01 -1.21219240e-01]\n",
      "L4N0                    -> L5N60 = [-1.32672712e-01 -1.15701202e-02 -7.97214881e-02 -6.63275644e-02\n",
      "  2.04011947e-01 -3.67300183e-01  1.30564123e-01 -3.23999465e-01\n",
      " -1.89942777e-01 -7.25465119e-02 -3.02827835e-01 -1.17822446e-01\n",
      " -2.13915423e-01 -6.86500147e-02  1.15250498e-01  2.38936469e-01\n",
      " -3.15996528e-01  2.32063219e-01 -6.65483251e-02  1.46501347e-01\n",
      "  2.74534255e-01 -4.23179590e-04  6.61141202e-02  1.00538976e-01\n",
      " -3.09491809e-02 -9.23962891e-02  1.15260676e-01 -2.67547532e-03\n",
      " -2.25021824e-01  9.19692442e-02  2.06854045e-02  2.13447317e-01\n",
      " -1.86445907e-01 -6.28466681e-02  4.45116878e-01 -2.72277314e-02\n",
      " -1.88842893e-01 -2.35757560e-01  1.54887334e-01 -3.07713062e-01\n",
      " -3.01325738e-01  4.79206294e-02  2.00166866e-01 -1.65408477e-01\n",
      "  1.48240730e-01 -2.96492875e-02  1.11660451e-01  2.71732718e-01\n",
      " -5.80218509e-02 -2.10087448e-01  1.20174900e-01 -1.41965255e-01\n",
      "  2.57405579e-01  3.06808263e-01  1.28216013e-01 -3.44835460e-01\n",
      "  1.66626405e-02 -8.30264613e-02  2.27705836e-01  1.08857557e-01\n",
      " -5.08237481e-02 -1.30980387e-01 -4.11311388e-01  1.26965627e-01\n",
      "  3.21593910e-01  1.83630630e-01 -1.97647393e-01  1.67458542e-02\n",
      " -2.05733955e-01 -1.86980978e-01  5.34563772e-02 -1.18439183e-01\n",
      " -2.80083627e-01  1.96428061e-01 -1.70046747e-01 -1.70949385e-01\n",
      " -5.27548850e-01  2.52127916e-01  9.31412652e-02 -1.39116570e-01\n",
      " -1.08003989e-01 -3.68191391e-01 -7.92809352e-02  3.08230221e-01\n",
      " -2.19432324e-01 -4.80801016e-02  1.81064457e-01 -1.25706553e-01\n",
      "  1.48569465e-01 -1.11387232e-02  3.23272616e-01  1.33336499e-01\n",
      " -1.26871124e-01 -3.58126983e-02  2.00020835e-01  1.58223748e-01\n",
      " -1.34190276e-01  4.06305566e-02  3.38617593e-01 -1.55662790e-01\n",
      "  5.61981976e-01 -5.41002527e-02 -2.55826354e-01  1.92372978e-01\n",
      "  1.52938142e-02  8.80322233e-02 -4.60279137e-01 -7.89509863e-02\n",
      "  2.97981594e-02  2.77494043e-01  1.28269330e-01  2.41555274e-01\n",
      " -7.74150491e-02  4.03961182e-01 -1.25340194e-01 -1.09860972e-01\n",
      "  1.20587228e-02 -3.80930424e-01 -4.02817205e-02  3.16361219e-01\n",
      "  2.71904141e-01 -6.98857894e-03  5.95127754e-02 -4.93497550e-01\n",
      "  6.94591999e-02  6.26578107e-02  1.76319275e-02 -2.27119431e-01\n",
      " -6.45128265e-02  1.81765154e-01 -2.36294404e-01  1.33358374e-01\n",
      " -1.79200210e-02 -3.51988137e-01  4.82855707e-01  1.58578441e-01\n",
      " -1.56982973e-01  4.73748613e-03  1.86260924e-01 -4.15922225e-01\n",
      " -3.29523057e-01  3.77037004e-02 -6.98812306e-02 -3.61958325e-01\n",
      "  1.68733835e-01 -4.48073633e-02 -2.31777743e-01  9.37729031e-02\n",
      "  2.51889080e-01  3.84012759e-02]\n",
      "L4N0                    -> L5N61 = [-6.26184195e-02  5.48640080e-02 -4.22434986e-01 -1.72222495e-01\n",
      " -6.04557693e-01  2.23174542e-01 -2.95299441e-01  2.56846845e-02\n",
      "  1.85357586e-01  1.82091579e-01  3.93157929e-01  1.22074038e-01\n",
      " -1.77640527e-01 -1.34811044e-01 -2.68326163e-01  1.04341120e-01\n",
      "  1.77513763e-01  1.45061314e-01  5.81518374e-02  9.19834003e-02\n",
      " -1.51376858e-01  1.50378183e-01 -1.28923446e-01  1.19411141e-01\n",
      " -4.37049270e-01  2.45001331e-01  2.60266304e-01 -5.79495057e-02\n",
      " -3.60231966e-01  2.46676415e-01  2.45875269e-01 -1.05597220e-01\n",
      " -2.22502246e-01 -1.74675375e-01  1.03953056e-01 -8.90841894e-03\n",
      " -1.97539404e-01  1.83880731e-01  2.95815527e-01 -2.19283313e-01\n",
      "  1.41377836e-01 -6.78280666e-02  2.87929028e-01 -3.97922546e-02\n",
      " -1.00544468e-01  9.74587873e-02  1.73239872e-01  1.84705436e-01\n",
      "  4.46981966e-01  7.01002553e-02  2.42094025e-01  1.81910545e-01\n",
      " -6.10360384e-01 -7.02537671e-02 -1.65026658e-03  1.78621501e-01\n",
      " -1.83041487e-02  1.33486956e-01  2.90547282e-01  6.42250240e-01\n",
      " -3.62484455e-01  6.38877690e-01 -1.17166974e-01 -6.46843255e-01\n",
      " -1.57162711e-01  1.23986639e-01  1.24761770e-02 -2.10684910e-01\n",
      "  3.19913626e-02 -1.44096494e-01 -3.23662579e-01  3.54617178e-01\n",
      "  3.39167655e-01  1.64470375e-01  2.00931579e-01  9.22091007e-02\n",
      "  2.17320487e-01 -1.11458346e-01  3.88413131e-01  1.49513245e-01\n",
      " -2.05580279e-01 -1.26089245e-01  3.39331552e-02 -2.52082199e-01\n",
      " -8.38751569e-02 -1.93782493e-01  3.15079093e-02  9.70780551e-02\n",
      " -6.38155118e-02 -1.71016693e-01 -1.09949969e-01 -3.58567744e-01\n",
      " -2.07313463e-01 -1.96638286e-01 -2.52987236e-01 -1.78880021e-01\n",
      "  5.87893963e-01  5.85860126e-02  2.96148565e-02  2.94945568e-01\n",
      " -3.51692140e-01 -1.15330247e-02  2.82933235e-01  1.73382625e-01\n",
      "  5.46336435e-02  5.46716988e-01 -3.04729849e-01  3.08460165e-02\n",
      "  8.40076953e-02  3.51405174e-01 -4.23266290e-04 -1.46662787e-01\n",
      " -2.60956764e-01 -1.04470134e-01 -1.32056743e-01 -2.73962468e-01\n",
      " -2.92219460e-01 -3.76545906e-01 -6.06780462e-02 -2.90965617e-01\n",
      "  9.92948040e-02  1.92086279e-01  3.97250563e-01 -2.06589267e-01\n",
      " -5.84336407e-02 -5.82392551e-02 -1.68417230e-01 -2.44413272e-01\n",
      "  2.73871422e-01 -3.12225311e-04  2.77145863e-01  2.41357520e-01\n",
      "  2.74220079e-01 -1.20096721e-01  1.15692906e-01  1.55185573e-02\n",
      "  2.03546643e-01  1.49350658e-01  2.44547620e-01  8.04791227e-02\n",
      " -2.39889488e-01 -1.91771999e-01 -2.72711217e-01 -4.34550531e-02\n",
      "  3.81874919e-01  2.96946019e-01 -3.75492126e-02  3.32710087e-01\n",
      "  1.74294829e-01 -2.76139796e-01]\n",
      "L4N0                    -> L5N62 = [ 0.33517045  0.25965947 -0.43882152  0.14866228  0.46690965  0.22035672\n",
      " -0.17722023 -0.00970525 -0.03018353 -0.2074889   0.2991235   0.22000386\n",
      "  0.07398923 -0.16835746  0.2559451   0.27899542 -0.22730169 -0.14950052\n",
      " -0.03867166 -0.28820142  0.425199    0.44809943  0.05859302  0.08789542\n",
      " -0.37524706 -0.17186771  0.1835763  -0.324695    0.12325974  0.09881925\n",
      "  0.19711614  0.33979636 -0.06444426 -0.05233071  0.27640375  0.30523762\n",
      " -0.6266712  -0.16964635  0.07799092 -0.50554717  0.36168462 -0.00070752\n",
      " -0.07856677  0.08378317 -0.39511204  0.11804527 -0.0679991   0.17521784\n",
      "  0.49442297 -0.26275456 -0.2605539  -0.3523526   0.210233   -0.37605688\n",
      "  0.04642871 -0.08357023 -0.13268238  0.31847677  0.05787439  0.12117419\n",
      " -0.4258955   0.08553219  0.29819855 -0.25144145 -0.22317497 -0.34861097\n",
      "  0.03127748 -0.155825   -0.2148699  -0.09309387 -0.40258506 -0.22697875\n",
      "  0.12013227 -0.02560293  0.1619417   0.08944865  0.21695812 -0.26822877\n",
      "  0.0240127   0.25721237 -0.34628996 -0.14106488  0.18604942  0.41702288\n",
      " -0.07813685 -0.11911606  0.26806954 -0.17859581 -0.03273278 -0.01224694\n",
      "  0.09048767 -0.12839742 -0.12887722  0.00425426 -0.18756093  0.22049576\n",
      "  0.23505247 -0.11879593 -0.21334028  0.00069458  0.12436532 -0.18221453\n",
      "  0.07127707  0.29361463  0.05221594  0.07673202  0.03944499  0.17555606\n",
      " -0.00558123 -0.44228533  0.05902823 -0.24451472  0.14837523  0.09202536\n",
      "  0.29366052 -0.11434641  0.343256   -0.24735042 -0.09694363 -0.16442768\n",
      "  0.3061954   0.32383826 -0.20170076  0.08648075 -0.07450162 -0.31238818\n",
      " -0.27850136  0.03948744  0.15601419 -0.19293736  0.07984244 -0.04172254\n",
      "  0.14878358 -0.02675106 -0.22033983  0.02601393  0.35024232 -0.2624914\n",
      "  0.13699454 -0.036307    0.38609573  0.04910493  0.3256905  -0.12744403\n",
      " -0.02263501 -0.11236271 -0.24250068 -0.32386014 -0.09092803  0.0729065 ]\n",
      "L4N0                    -> L5N63 = [-5.11871465e-02 -1.05862640e-01 -3.53041708e-01 -3.00620347e-01\n",
      " -9.98024736e-03 -1.82127324e-03 -6.64320529e-01  5.83084300e-02\n",
      " -1.95462048e-01  3.59712392e-01 -1.27097920e-01  1.39863431e-01\n",
      " -1.65094715e-02 -1.78390354e-01  4.33120243e-02 -1.92997813e-01\n",
      " -7.19445944e-02 -2.23114118e-01 -3.42883855e-01 -5.03268957e-01\n",
      " -2.46117532e-01  9.01257917e-02  1.86364613e-02  4.98602018e-02\n",
      "  2.08195038e-02 -6.40275851e-02  2.91621268e-01 -5.47963142e-01\n",
      " -4.01659131e-01 -4.07838166e-01 -3.40087116e-01 -5.81669807e-02\n",
      " -2.72318006e-01  5.42367399e-02  2.12485284e-01 -1.64416432e-01\n",
      " -1.29778460e-01  1.39283380e-02 -4.46404725e-01  1.70058440e-02\n",
      "  3.12236454e-02 -2.54394799e-01  1.01744704e-01 -3.78394932e-01\n",
      " -7.51305779e-05 -1.82445541e-01 -1.63353961e-02  1.57415763e-01\n",
      "  1.73892766e-01 -2.59184331e-01  4.72323120e-01 -3.53464514e-01\n",
      " -1.03841752e-01 -2.21431255e-01  7.93427527e-02 -1.81919947e-01\n",
      "  3.39904904e-01  7.60096833e-02  1.86419860e-01  2.99890518e-01\n",
      " -1.41633064e-01 -6.57561496e-02 -1.44272596e-01  1.12957478e-01\n",
      " -4.18397784e-03  6.19897366e-01 -1.28539965e-01 -3.80513161e-01\n",
      "  1.78579286e-01  2.17822850e-01 -3.15330952e-01  7.99444392e-02\n",
      "  1.47807732e-01  3.36469337e-02 -1.61066517e-01 -4.84462529e-02\n",
      "  4.93123606e-02 -6.13060780e-02  3.81411791e-01  2.18885109e-01\n",
      " -5.84940851e-01 -2.36589715e-01 -2.89549768e-01 -1.82684436e-02\n",
      " -1.94037989e-01 -2.55869538e-01 -6.13837037e-03  2.30491400e-01\n",
      " -1.82455003e-01 -4.32008952e-01 -7.89114088e-02 -2.40394533e-01\n",
      " -4.55886930e-01  2.07311630e-01 -3.23362917e-01 -2.39936009e-01\n",
      "  3.27195287e-01 -4.84151840e-01 -7.27570534e-01  2.67052323e-01\n",
      "  2.43561506e-01  1.72225848e-01  2.66207874e-01 -5.70302367e-01\n",
      " -9.66351405e-02 -5.16185701e-01 -1.60377741e-01 -1.02992341e-01\n",
      "  3.34161699e-01  3.57864857e-01 -5.24877720e-02 -4.34802473e-01\n",
      " -5.69789171e-01 -1.97696179e-01 -1.57526329e-01 -2.68113136e-01\n",
      "  3.63333702e-01  2.21667625e-02 -9.18771774e-02 -6.34207251e-03\n",
      " -8.97836611e-02 -9.21576992e-02  2.50588655e-01 -2.14478776e-01\n",
      " -2.94824272e-01  1.03834368e-01  3.12162321e-02 -3.00206393e-01\n",
      " -5.25012434e-01  2.02144817e-01  9.63341352e-03  2.74175435e-01\n",
      " -3.65722001e-01 -2.97793329e-01  2.60598838e-01 -3.19805592e-01\n",
      " -4.15078163e-01 -6.82330281e-02 -6.37890324e-02 -3.44764382e-01\n",
      " -3.99027109e-01  1.49476320e-01  4.14240658e-02  3.50192875e-01\n",
      "  1.83544517e-01 -5.80138564e-02 -2.09857702e-01 -3.62742573e-01\n",
      "  3.84716131e-02  5.45306876e-02]\n",
      "L4N0                    -> L5N64 = [ 5.84534444e-02  3.77759725e-01 -3.28505158e-01  9.19753835e-02\n",
      "  7.78697431e-02 -2.96066135e-01  3.75813514e-01 -2.38969535e-01\n",
      "  4.68577892e-01 -1.49916485e-01 -8.07880145e-03 -9.75754857e-02\n",
      "  9.89353508e-02  1.43157288e-01  1.27184749e-01 -4.45110679e-01\n",
      " -3.56836617e-01  8.66607279e-02  2.22597063e-01  2.13159397e-02\n",
      "  2.74745494e-01  4.93977927e-02  1.06814466e-01  1.05108179e-01\n",
      "  2.53444165e-01 -5.84639683e-02  2.57956713e-01 -1.65889248e-01\n",
      "  3.00499499e-01 -3.05232108e-01 -1.79813206e-01 -1.01195186e-01\n",
      "  4.94102016e-02  2.64584213e-01 -3.68988127e-01  2.84472108e-01\n",
      " -2.26480842e-01  7.79527947e-02 -3.13574433e-01  4.78100866e-01\n",
      " -6.18251711e-02  1.86966866e-01 -2.37966835e-01 -6.59945071e-01\n",
      " -2.01917201e-01 -3.20437729e-01 -4.80374247e-02 -1.76778823e-01\n",
      " -8.81075021e-03  1.94531798e-01 -7.16837943e-01 -7.30548501e-02\n",
      " -1.11668259e-01 -1.22954108e-01 -4.24797684e-01  5.67153795e-04\n",
      " -2.32538320e-02 -1.19168013e-01 -3.61320108e-01 -1.14312001e-01\n",
      " -5.46740778e-02 -1.62791893e-01  5.42641766e-02  7.49249458e-02\n",
      " -3.28905433e-01 -6.21026978e-02 -2.19804630e-01 -3.41529191e-01\n",
      " -3.56454492e-01  5.75491607e-01 -2.77175978e-02  4.95324023e-02\n",
      " -2.59420335e-01  1.06060244e-01 -2.13894665e-01 -1.88097164e-01\n",
      " -2.30927587e-01 -1.38266832e-01 -1.13438733e-01  1.12992069e-02\n",
      "  7.37843215e-02 -1.90065533e-01 -6.86783949e-03  4.19392288e-01\n",
      " -1.27194598e-01 -1.38271764e-01  5.24655953e-02  5.97464107e-02\n",
      "  2.21486554e-01 -1.49117336e-01 -3.36440027e-01 -2.24867195e-01\n",
      " -2.87369311e-01  5.56803644e-02 -1.38698429e-01 -3.07901382e-01\n",
      " -4.40109164e-01  5.79345375e-02 -1.29814938e-01  4.53274161e-01\n",
      "  3.38385344e-01  7.41176009e-02 -1.65414825e-01 -1.35857016e-01\n",
      " -2.54172742e-01  1.28157869e-01 -1.57585964e-01 -4.10757691e-01\n",
      "  1.25570893e-01 -7.45755583e-02  1.73765093e-01 -1.96302861e-01\n",
      "  3.62025499e-01 -2.77057052e-01 -1.65169209e-01 -1.71308488e-01\n",
      " -8.85777250e-02 -1.62205160e-01 -1.63895972e-02  1.25016198e-01\n",
      "  4.79102992e-02  1.50090400e-02 -3.61869548e-04  2.60301173e-01\n",
      "  5.94869033e-02 -4.30432707e-01  1.73938990e-01 -7.26602301e-02\n",
      " -2.49129117e-01 -4.96714823e-02 -7.91985393e-02 -1.23956837e-01\n",
      " -3.13702345e-01 -2.18706593e-01  1.11544102e-01 -4.05273110e-01\n",
      " -4.20420527e-01 -1.22589894e-01 -3.09655607e-01  1.63332760e-01\n",
      "  3.00731868e-01  1.64309219e-01 -7.73605928e-02  1.13275766e-01\n",
      " -2.85564065e-01  2.58098960e-01  1.42318979e-01 -2.69990534e-01\n",
      " -1.82591960e-01 -4.09531385e-01]\n",
      "L4N0                    -> L5N65 = [ 6.10508323e-02 -2.86281884e-01 -2.45328426e-01  1.69495605e-02\n",
      " -2.72329636e-02 -3.36835057e-01  2.78233528e-01  1.06733732e-01\n",
      "  9.02461335e-02 -9.81495604e-02  1.50897354e-01 -1.28345983e-02\n",
      "  2.73482710e-01 -1.03308642e-02 -1.56480506e-01  1.26847476e-01\n",
      " -4.19749528e-01 -5.38310587e-01 -1.05490886e-01  3.47730070e-02\n",
      " -2.30744421e-01  1.86344981e-01  1.86014518e-01  1.23989955e-01\n",
      " -2.98208594e-01 -1.20442845e-01  1.92541569e-01 -2.56725937e-01\n",
      "  3.41189623e-01 -2.71750718e-01  1.62382856e-01 -1.77625164e-01\n",
      "  4.82535660e-01  1.84606597e-01 -2.63100773e-01  2.42692471e-01\n",
      "  7.53626451e-02 -2.72697598e-01 -1.44933060e-01 -1.43758267e-01\n",
      "  3.16208482e-01 -2.75773220e-02 -2.65488327e-01  2.49879118e-02\n",
      " -3.13809276e-01  5.52649312e-02 -2.54445106e-01  2.95045137e-01\n",
      "  5.61492860e-01 -5.16045392e-01 -1.81821734e-01 -1.20576313e-02\n",
      "  5.97172007e-02 -1.75271794e-01 -2.08951086e-01 -2.81403899e-01\n",
      " -1.70518965e-01  3.71190339e-01 -1.12614810e-01 -1.28256112e-01\n",
      " -3.29560697e-01 -3.18841398e-01  4.01192039e-01 -3.68260771e-01\n",
      "  3.09660077e-01 -4.90325801e-02  2.67604947e-01 -2.01378271e-01\n",
      " -1.72297791e-01  2.59212494e-01  6.13242388e-02 -7.22875535e-01\n",
      " -5.22102654e-01 -1.21032633e-01  2.33532652e-01  1.32600022e-02\n",
      " -1.42496526e-01  1.05157778e-01 -4.83363807e-01 -8.85259658e-02\n",
      "  4.73985784e-02 -6.71655813e-04  3.36010069e-01  2.02752456e-01\n",
      " -1.59747764e-01 -2.00172096e-01  3.37016433e-01  1.67585045e-01\n",
      " -2.71881018e-02 -3.97824675e-01  2.20910817e-01 -3.24597985e-01\n",
      " -4.06544417e-01 -2.15695173e-01  4.09227312e-01  9.68614146e-02\n",
      " -1.66759435e-02  6.38099760e-03 -2.67851740e-01 -5.40545225e-01\n",
      "  6.30462356e-03 -8.81812572e-02  9.45785642e-02 -1.72448009e-01\n",
      " -5.33603966e-01  1.63467050e-01  3.83141637e-02 -3.46038453e-02\n",
      " -1.59653306e-01 -1.33555338e-01  2.39584848e-01  1.44400168e-02\n",
      "  3.44292432e-01 -2.72931069e-01 -1.63243353e-01 -1.53153613e-01\n",
      " -1.56404734e-01  7.45418966e-02 -4.01471443e-02 -1.79398924e-01\n",
      "  1.09127462e-01  2.24999458e-01 -2.74102032e-01  4.07311410e-01\n",
      " -1.79281443e-01 -1.44284600e-02 -5.83979860e-02 -2.00764947e-02\n",
      "  3.28779556e-02 -1.00616924e-03 -1.70631781e-01 -2.24863030e-02\n",
      " -3.11480463e-02 -1.74427442e-02  1.22283146e-01 -5.66708222e-02\n",
      " -1.67455643e-01  1.99059080e-02 -3.63103896e-01 -1.19053274e-01\n",
      " -8.03339258e-02 -2.49791980e-01  2.06635237e-01 -2.50792265e-01\n",
      " -1.59711003e-01  2.88668722e-02  2.18945205e-01 -1.91093996e-01\n",
      " -2.30278909e-01  3.12825173e-01]\n",
      "L4N0                    -> L5N66 = [-0.26910457 -0.0907955   0.10714838  0.13408388  0.34023398  0.02103547\n",
      " -0.06032469 -0.275153   -0.04749241  0.04447288  0.2382755  -0.36031377\n",
      " -0.05555845  0.14849596 -0.12860098 -0.04098069 -0.07055485 -0.62722945\n",
      "  0.2780297  -0.0437266   0.00196915 -0.18491319  0.07965793 -0.31762022\n",
      " -0.06269403 -0.16285105 -0.21170668  0.03943196  0.02847349  0.12872651\n",
      " -0.00498985 -0.1144496  -0.22696105 -0.24019717 -0.02631914  0.04276117\n",
      "  0.21561031  0.2690857   0.08756945 -0.30866662 -0.32754886  0.09714473\n",
      "  0.05517007 -0.32150894 -0.37099928  0.05232501  0.53428614 -0.00868956\n",
      "  0.10796515  0.12703963  0.17661957  0.41603544 -0.05553336  0.05951689\n",
      " -0.20527183 -0.14339273  0.26975656  0.1048675  -0.3149389   0.24949703\n",
      "  0.25543126  0.02881736  0.36087742  0.26569846 -0.15160449 -0.22987534\n",
      "  0.49779955 -0.21715212 -0.04756055 -0.29911655 -0.2310021   0.24061961\n",
      "  0.13035373 -0.32974094 -0.06497476  0.15910435 -0.04684658 -0.09970424\n",
      " -0.35140872 -0.08068517  0.19940615  0.07466551  0.30979246  0.16799645\n",
      " -0.1690609   0.08577263  0.08597738  0.06278569  0.10881323  0.0261099\n",
      " -0.14267968 -0.09140012  0.23307562 -0.26941904  0.08693212 -0.3110245\n",
      "  0.12419509  0.28819793 -0.23826894 -0.09097412  0.11334024 -0.27632695\n",
      " -0.24554914  0.39710525  0.11677061  0.21218698  0.05336389 -0.30441314\n",
      " -0.02877854 -0.11656662 -0.2959376  -0.26798967  0.11071474  0.045019\n",
      "  0.24454321  0.10519218  0.14529543 -0.11466045 -0.07860016 -0.13874005\n",
      " -0.1787075   0.04316185 -0.20113413 -0.24603194 -0.107029    0.2095326\n",
      " -0.01067962  0.08827794  0.21099326  0.09493978 -0.08992253  0.10592387\n",
      "  0.2506036  -0.06855253 -0.0818205  -0.23502658 -0.05205875 -0.5184981\n",
      "  0.11063623 -0.45498803 -0.14657599 -0.16569804  0.06919629 -0.04498805\n",
      " -0.1340847  -0.06006163  0.07941865  0.09729864 -0.36931378  0.35688013]\n",
      "L4N0                    -> L5N67 = [ 0.15084215  0.12342647  0.24282792 -0.39378023  0.12590805  0.14739537\n",
      "  0.12632065 -0.45164046  0.0581704  -0.03753095 -0.20742841  0.3133926\n",
      " -0.06951535 -0.01724014  0.04760198  0.07190873  0.13009253  0.08400083\n",
      " -0.38898286 -0.2833144   0.08767515 -0.32679585 -0.12334315  0.02888543\n",
      " -0.12358215 -0.2623837   0.14475729  0.03992695  0.09590631 -0.2709024\n",
      "  0.14503841 -0.04282127 -0.29387757  0.28075036 -0.3050234  -0.37422547\n",
      " -0.3006325  -0.1993444  -0.37146473 -0.0285632  -0.55040264  0.23682086\n",
      "  0.062241   -0.29607388  0.00284094  0.13109061 -0.51181686 -0.09031104\n",
      "  0.07075517 -0.67900217  0.17990199  0.12398635 -0.1807682  -0.2098167\n",
      " -0.24919704 -0.5467576   0.37258923  0.18754295  0.00662069 -0.01250129\n",
      "  0.07222495 -0.02732745 -0.26247045  0.20996284 -0.09868161  0.09200383\n",
      " -0.05030967 -0.69781935  0.372936   -0.60040367 -0.2664819  -0.607011\n",
      " -0.12429842 -0.02338029  0.24907428  0.10025246  0.01337385  0.06068541\n",
      " -0.1391267   0.26474714 -0.40581816  0.2205647  -0.4171799   0.01209631\n",
      " -0.02351306 -0.4115124   0.07235181  0.03473417 -0.27675074 -0.127375\n",
      "  0.1641832  -0.45116723  0.09373197 -0.29728442  0.28760484  0.34218755\n",
      "  0.01947043 -0.08331028 -0.14808014 -0.11804105  0.48476973 -0.8402175\n",
      "  0.01881575 -0.58503956 -0.5665649   0.12608944 -0.36918268  0.24712324\n",
      "  0.15763272 -0.03393666 -0.02357901 -0.19710195 -0.21611188  0.2634448\n",
      "  0.28228316  0.321558   -0.11263865  0.09499518 -0.00698508 -0.20293969\n",
      "  0.08793179 -0.08351643 -0.14934179 -0.298582   -0.5299292  -0.49062103\n",
      "  0.0629283   0.01080021  0.2451213  -0.23463126 -0.03935239  0.08623194\n",
      "  0.02373052  0.10096902 -0.03250339  0.3623996   0.32421556 -0.12979868\n",
      "  0.00307315 -0.6546398  -0.10982279 -0.7037847   0.00157257  0.01687139\n",
      "  0.04213762 -0.09348321 -0.39733928 -0.26989764 -0.0130039  -0.32721853]\n",
      "L4N0                    -> L5N68 = [ 0.06760076  0.00622326 -0.13488266 -0.20456126  0.07332631 -0.12697528\n",
      "  0.36779943  0.11781114  0.13670102 -0.01221687 -0.31625775  0.06043212\n",
      "  0.14307956 -0.29481918  0.00513209 -0.45217782 -0.22154982 -0.0721445\n",
      " -0.06200218  0.03164686 -0.41422114 -0.18845487 -0.11836406  0.00910456\n",
      " -0.16158806 -0.05998903 -0.18223119  0.2260507  -0.06184069  0.1171863\n",
      "  0.06548044 -0.04102235 -0.33857834  0.13519104  0.06628319 -0.05244965\n",
      "  0.31102827 -0.4431051   0.02473256  0.0280959  -0.27796134 -0.03595454\n",
      " -0.4120242  -0.38009405  0.07688754 -0.05553393 -0.13275824 -0.05076389\n",
      " -0.05530062  0.38107646 -0.16379319 -0.5105703   0.02735827 -0.07805021\n",
      "  0.12173634 -0.08417732 -0.00453593 -0.29152215 -0.34495935 -0.32220444\n",
      " -0.0763885  -0.35058397  0.06306248 -0.09093586 -0.1050446  -0.12195481\n",
      " -0.03231902  0.19340141  0.06819134  0.08418803  0.19066434  0.29364976\n",
      " -0.37474227  0.13428645  0.1040222  -0.27238843 -0.04507551 -0.09487598\n",
      " -0.29674983  0.06246729 -0.03742387 -0.33427045  0.50785255  0.06323551\n",
      "  0.25625062  0.24069156 -0.06187711  0.07649043  0.19685356  0.07425568\n",
      "  0.03221128  0.24871974 -0.01270657  0.35635015  0.19251755 -0.38947245\n",
      " -0.37095067  0.43443435  0.29096857  0.08365349  0.07046261 -0.08645186\n",
      " -0.2535581   0.14774679  0.00793447  0.33719108  0.17044362  0.18899174\n",
      " -0.2632931  -0.03831635 -0.09049156  0.18516669 -0.19255194  0.23561384\n",
      "  0.3196828  -0.17805721 -0.02358401 -0.21964452 -0.01126266 -0.18786941\n",
      "  0.05326824 -0.36433142 -0.22654916  0.12048092  0.2399264   0.34684184\n",
      " -0.18443333  0.08536588  0.01224724  0.21653734  0.12009826  0.2841739\n",
      " -0.32060042  0.02057508 -0.30249554  0.01727249 -0.12222418  0.4772856\n",
      "  0.17042218 -0.08192755  0.04652705  0.26789004 -0.1258611   0.3379052\n",
      " -0.10313671  0.28669393 -0.01804907 -0.17708117 -0.3627336  -0.20006245]\n",
      "L4N0                    -> L5N69 = [-0.1688085   0.09414374  0.059238    0.02986321  0.3039769   0.04808719\n",
      " -0.0823966   0.46430185  0.2302287   0.42177552  0.07796439  0.31168732\n",
      " -0.31721854  0.15531084 -0.11548221 -0.3802789  -0.4588289   0.39940798\n",
      " -0.50165695 -0.19797976  0.17072503 -0.40225148 -0.64055955  0.03874468\n",
      "  0.33283287 -0.2053133   0.31433868  0.01701716 -0.19687761  0.12211902\n",
      "  0.12536024 -0.555066   -0.45849162 -0.00459844 -0.2426229  -0.1459322\n",
      "  0.12610665  0.02297082 -0.10916223  0.02664088 -0.0721901   0.23991372\n",
      " -0.5159918  -0.3375233  -0.53329325 -0.05664667 -0.11655556 -0.04973055\n",
      " -0.02931902 -0.14259171 -0.06329969 -0.30757555 -0.6678073   0.0224324\n",
      "  0.11958559 -0.07092773 -0.15035155 -0.49621937 -0.21270864 -0.10635054\n",
      "  0.39012688 -0.1043671   0.0486531   0.49750853 -0.5048418   0.5489678\n",
      "  0.33741078 -0.4715809  -0.39092913  0.4090808  -0.3858299  -0.04312809\n",
      " -0.16733111 -0.14948471 -0.3984287  -0.37116268 -0.45607245 -0.32018712\n",
      " -0.19017473  0.37171784 -0.2518324  -0.2809153  -0.20806968  0.10149257\n",
      " -0.13687585 -0.03133164  0.23350099  0.4703979  -0.04499728  0.15698767\n",
      " -0.1873096   0.29904813 -0.13352805  0.08375558  0.04682054 -0.26005793\n",
      " -0.0313216  -0.48450908 -0.44714022 -0.43242475  0.21378689 -0.16052206\n",
      " -0.03902973  0.02533112 -0.02905319 -0.21529874  0.25436512 -0.18707667\n",
      "  0.3173449  -0.62270355 -0.06153109 -0.43315452 -0.2264251  -0.574877\n",
      " -0.73943263  0.05876048  0.03066323 -0.07120241  0.3297952   0.47590634\n",
      " -0.10683643 -0.2510464   0.1096719   0.03182605 -0.02253923 -0.2481254\n",
      "  0.14469585 -0.4028902   0.05148664 -0.06317932  0.1032853  -0.14336571\n",
      " -0.18579495 -0.30141196  0.3763674  -0.3570494  -0.3563964  -0.15911622\n",
      " -0.15411331 -0.17381595 -0.27630362  0.15437025  0.12738214 -0.03999925\n",
      " -0.24586184  0.36998516 -0.29633865 -0.17322762 -0.36389652  0.0573402 ]\n",
      "L4N0                    -> L5N70 = [-6.04004323e-01 -6.07627571e-01  4.77063730e-02 -1.04245223e-01\n",
      " -6.79770634e-02  1.26460478e-01 -1.95780653e-03 -2.87665039e-01\n",
      "  6.48214817e-02  1.61869571e-01  5.56637421e-02  2.12292656e-01\n",
      " -6.84091210e-01  2.95482427e-01 -5.79717815e-01 -1.13099456e-01\n",
      " -7.53371641e-02 -2.89223999e-01 -3.90329063e-01  5.80000468e-02\n",
      "  4.24877912e-01 -3.12834680e-01  1.51064411e-01 -1.43030211e-01\n",
      " -6.58079684e-02  1.12551652e-01 -5.36621129e-03  2.14679450e-01\n",
      "  2.05001622e-01  1.16544284e-01 -3.57753262e-02 -2.67580062e-01\n",
      " -6.85506761e-01  9.66486186e-02  1.89102545e-01 -4.08814758e-01\n",
      "  8.21036249e-02  1.17775820e-01 -1.61244318e-01 -3.33499372e-01\n",
      " -2.61185110e-01 -1.23305663e-01  1.79725900e-01  1.60533309e-01\n",
      " -3.88377905e-01  2.18804017e-01 -5.57946444e-01 -1.38259521e-02\n",
      " -3.73401865e-02 -1.67159453e-01  2.75701880e-01 -4.25150990e-02\n",
      "  4.42273282e-02 -3.87733221e-01 -9.31970682e-03 -1.94314808e-01\n",
      "  4.63962525e-01 -2.80766040e-01 -1.54603859e-02  9.77106318e-02\n",
      " -2.37561584e-01  8.29748213e-02  8.32750425e-02  1.08771563e-01\n",
      " -4.63662446e-01  5.67464866e-02 -2.46955171e-01  1.14130996e-01\n",
      " -1.42484546e-01 -5.04802048e-01 -1.22444339e-01 -1.29597858e-01\n",
      " -6.97329044e-02  1.27729595e-01  5.04680760e-02 -1.66988909e-01\n",
      " -2.44570634e-04 -1.90995857e-01  1.34277806e-01 -1.75249144e-01\n",
      " -3.50122482e-01 -1.02592064e-02  2.39694923e-01  4.25361171e-02\n",
      " -2.27362826e-01 -2.90092945e-01  1.30570885e-02 -2.10613944e-03\n",
      " -2.38791600e-01  2.65323132e-01  6.85288310e-02 -4.11260545e-01\n",
      "  2.15605855e-01  5.21765649e-02 -2.25229964e-01  3.43796581e-01\n",
      " -4.25556824e-02 -3.73428404e-01  1.18550748e-01  1.37669519e-01\n",
      "  7.68307373e-02 -2.27455154e-01  1.68617070e-01 -3.15267980e-01\n",
      " -4.49088454e-01  1.02723181e-01 -8.89831260e-02 -1.62227184e-01\n",
      "  9.55925137e-02  1.45808607e-01  5.52729070e-02  1.40610859e-01\n",
      "  8.37224945e-02  1.44518062e-01  2.99586952e-01 -1.92118883e-01\n",
      "  2.01351076e-01  5.58224693e-02 -1.24018431e-01  6.20392114e-02\n",
      "  1.05861664e-01 -2.27673277e-01 -1.81038715e-02 -3.07929248e-01\n",
      " -3.18157911e-01  9.01060458e-03 -2.29356036e-01 -1.56470779e-02\n",
      "  1.09146044e-01 -8.20431784e-02  2.42641389e-01  3.93457383e-01\n",
      " -1.47984311e-01  3.58351290e-01  1.51636884e-01  9.34582204e-02\n",
      " -2.62814552e-01  5.44532351e-02 -1.41107619e-01 -2.23604798e-01\n",
      " -2.72297412e-01 -6.29888654e-01 -4.61376965e-01 -2.47423515e-01\n",
      "  2.88265884e-01 -2.26788819e-01 -3.53133470e-01  2.31608935e-02\n",
      "  1.93744190e-02 -5.30683398e-01]\n",
      "L4N0                    -> L5N71 = [-0.13097943 -0.09929018  0.09702722 -0.32350293 -0.05445739 -0.1857703\n",
      " -0.18865724 -0.11113073  0.01014309  0.12289349 -0.1342559  -0.05171243\n",
      "  0.02909437 -0.05477916 -0.0096679   0.32397717 -0.02429598  0.04191815\n",
      " -0.09180208 -0.09504148  0.14770293 -0.24506435 -0.12172897 -0.24199413\n",
      " -0.22269647  0.03840489  0.22653328  0.03238985 -0.5189526  -0.3406445\n",
      "  0.2119933  -0.0388541  -0.28587246 -0.24964637 -0.26262972 -0.09804387\n",
      "  0.1272135  -0.22953862  0.10746057 -0.15162802  0.07357028  0.3716517\n",
      "  0.08345637 -0.14079736 -0.00856736 -0.14662132 -0.43995067 -0.23338391\n",
      " -0.1251075  -0.05072584 -0.22572063 -0.04872394 -0.14559612 -0.04861342\n",
      "  0.22705792  0.1442944   0.26095647  0.16275138 -0.1572734  -0.19369128\n",
      " -0.00644124 -0.02503883 -0.24212427  0.04509304 -0.17801812 -0.24091059\n",
      " -0.03130913 -0.43606573  0.25600347 -0.2661216   0.31030735 -0.34265175\n",
      "  0.3984908  -0.1818028  -0.18323301 -0.2567443  -0.11524758  0.09449426\n",
      "  0.06373706 -0.0462972  -0.01170297  0.06623243  0.00776626  0.12343609\n",
      "  0.3127191  -0.37310615  0.21999444  0.04858521 -0.14529397  0.3246335\n",
      "  0.36618295 -0.12210839  0.03670432 -0.2790848  -0.13384685  0.00999049\n",
      " -0.10621507 -0.29342803 -0.16382438  0.15214828  0.28988338 -0.56303465\n",
      "  0.42141947 -0.3803429  -0.13631137 -0.17418347 -0.33775574 -0.14452437\n",
      " -0.14288831  0.0334405   0.01031947  0.19576599 -0.12265982  0.15224093\n",
      "  0.17857818  0.00713786 -0.0945723   0.13261013 -0.11956188 -0.34491095\n",
      "  0.46526468  0.17782702 -0.04824721  0.10251699 -0.34171516 -0.25331968\n",
      " -0.01834494  0.07119831 -0.03859924  0.1553274   0.16122232  0.02089656\n",
      "  0.08254237  0.10498719  0.23841809  0.5090107   0.24817856  0.303777\n",
      "  0.32221103 -0.16362289 -0.17820723 -0.14012103 -0.06413655  0.30166194\n",
      "  0.13904722 -0.25440255  0.01454222 -0.174996    0.21737629 -0.24046697]\n",
      "L4N0                    -> L5N72 = [ 0.04278804  0.10606483  0.23641106  0.07446197 -0.07157303 -0.0650805\n",
      "  0.11269805 -0.12189052 -0.08928914 -0.31541157 -0.37262785 -0.35341585\n",
      " -0.09836178  0.11081932  0.30085924 -0.05338842 -0.4601105  -0.8652041\n",
      "  0.37962914 -0.14993127  0.11756931 -0.01230992  0.15025222  0.07136758\n",
      "  0.2259217  -0.41355672 -0.08467992  0.10709406 -0.01776549  0.15472302\n",
      " -0.53904355 -0.16794665  0.02607019 -0.03867105 -0.01968925  0.22626427\n",
      "  0.21856846 -0.08904798 -0.02251406  0.04650742 -0.18538935  0.0247946\n",
      " -0.2030395   0.13585901 -0.52835494 -0.52316743  0.19797356 -0.00436617\n",
      "  0.08478117 -0.10455111 -0.46137622 -0.11256739 -0.0845871  -0.30345932\n",
      "  0.13813196  0.09649058 -0.1921178   0.03039744 -0.41846633 -0.0881155\n",
      "  0.26654327 -0.08212934  0.23482788 -0.10804276 -0.30261552 -0.21315017\n",
      "  0.1353138  -0.32291844 -0.0746397  -0.24579369  0.20690466  0.18579437\n",
      " -0.12690689  0.02566088  0.13340555 -0.35451573 -0.2739506  -0.58905566\n",
      " -0.08827953 -0.4632125  -0.2056099   0.16029187  0.09904999  0.09874085\n",
      "  0.13116144 -0.06681105 -0.02097015 -0.66697097 -0.09768512 -0.04338167\n",
      "  0.32626802 -0.28748104 -0.1652239  -0.43809184  0.11340638  0.11775207\n",
      " -0.4340596   0.19341448 -0.04758588 -0.2968097  -0.07733551  0.04472478\n",
      " -0.12458459  0.03355697 -0.25909314 -0.03793003 -0.41573018  0.0583305\n",
      " -0.55553186 -0.36436668 -0.28635523 -0.01247701  0.0234354   0.04981743\n",
      "  0.06417044  0.10799731  0.22819006 -0.11706989 -0.5552288  -0.3735171\n",
      "  0.23801672  0.09605557 -0.19370976  0.07941953 -0.35898155 -0.03077086\n",
      " -0.5292425   0.4175429  -0.65669453 -0.0651949  -0.48010212 -0.28903133\n",
      " -0.6409949  -0.52007747 -0.23635614  0.1712884   0.09318715 -0.16090366\n",
      "  0.16152073 -0.02055954  0.51294583 -0.08726329  0.18368317 -0.14857325\n",
      " -0.519418   -0.04891174 -0.10700373 -0.22842833 -0.17268766  0.08687318]\n",
      "L4N0                    -> L5N73 = [ 0.31636646  0.34945947  0.42143548 -0.10135403  0.19054668  0.09160335\n",
      "  0.0480985  -0.16408294  0.10062863 -0.07054758  0.238094   -0.37070906\n",
      "  0.51919574  0.26478475 -0.443766   -0.03677016 -0.48134583 -0.2608815\n",
      "  0.08470415 -0.16671218  0.23927218  0.4145039  -0.24552916 -0.02147361\n",
      "  0.4140261  -0.38177654 -0.34864423  0.2202344   0.1331558  -0.3087327\n",
      " -0.3251987  -0.22290249 -0.09431405  0.45999306 -0.53407216 -0.2364096\n",
      "  0.31761888 -0.20540948 -0.09921663  0.48901543 -0.208156    0.13024229\n",
      " -0.35642022  0.11025505 -0.0679929   0.00614509  0.1286945  -0.05389281\n",
      " -0.09859265  0.16588558 -0.06255402  0.24721344 -0.19421016 -0.47065756\n",
      " -0.32214704 -0.12151846  0.11806213  0.2914812  -0.16382447 -0.22203845\n",
      "  0.1547157  -0.13129     0.39263648  0.39252844  0.08013829 -0.6100377\n",
      "  0.09049432 -0.20037295 -0.34927452  0.12404611  0.44352677 -0.01736649\n",
      " -0.09021922  0.04501565  0.14815503 -0.51246476 -0.14227402 -0.19062436\n",
      " -0.6857692  -0.25521606 -0.28449827  0.21961546 -0.57598454  0.31820306\n",
      "  0.16548863 -0.19834559 -0.00100799 -0.41093332 -0.1192471   0.18483606\n",
      "  0.00532639 -0.23663056  0.1269065  -0.20019849  0.32095608  0.07420459\n",
      " -0.14455865 -0.43964547 -0.38825893 -0.02388903  0.10735944 -0.5898874\n",
      "  0.2394903  -0.340813   -0.06181075 -0.2142729   0.11050048 -0.20846675\n",
      " -0.04080101 -0.08188167 -0.02981828 -0.0267981  -0.10576449  0.04785405\n",
      "  0.11457767  0.01125366 -0.02741474  0.00095066  0.06743473  0.12810703\n",
      "  0.06915262 -0.8001364  -0.21499728  0.3791871  -0.05206599 -0.38850972\n",
      "  0.1472962  -0.43238693 -0.1377133  -0.73864895  0.11427609 -0.39627895\n",
      " -0.22772416  0.14175442 -0.44963682  0.03716849  0.17540194  0.01824235\n",
      " -0.07599712 -0.25227153 -0.19719921 -0.16294968  0.29298088 -0.24068446\n",
      " -0.11931885 -0.21081997 -0.03384094  0.02015566 -0.39220592 -0.08366574]\n",
      "L4N0                    -> L5N74 = [ 0.00075018  0.11552727 -0.13475053 -0.03605676 -0.29831287 -0.01840849\n",
      "  0.13465841  0.15929054  0.20258339 -0.19537894 -0.0034741  -0.17005482\n",
      " -0.07890625  0.16403878 -0.17206725 -0.2930058  -0.3366481   0.23861875\n",
      "  0.52325034  0.06329971  0.18338753  0.02258092 -0.01627746  0.01119432\n",
      "  0.20179975 -0.17385273 -0.37792718  0.34756947 -0.45459107  0.03697186\n",
      "  0.09403151  0.2139315  -0.14094824  0.055421   -0.18910189 -0.0944603\n",
      " -0.04222071  0.60973275  0.377231    0.05179169  0.15578221 -0.05619285\n",
      " -0.14252114  0.15218808  0.0991402  -0.23557179 -0.11142425 -0.45850304\n",
      " -0.14817315  0.05281578  0.03167814 -0.23037091 -0.3685563   0.09007244\n",
      "  0.07197593  0.16404584 -0.36781284 -0.3468174   0.20039041  0.00795174\n",
      "  0.08624674  0.02626876 -0.13575317 -0.11756229 -0.03789072  0.14884464\n",
      "  0.0442468   0.00239369 -0.26855505 -0.03152249  0.234089   -0.02105651\n",
      " -0.6248107  -0.44037893  0.01608863  0.36235115  0.08352369 -0.35833102\n",
      "  0.0309356  -0.14916682 -0.00179154  0.26563036  0.16646832 -0.09412262\n",
      " -0.25581047  0.15816407 -0.09921116 -0.16010322 -0.04464153 -0.04334323\n",
      " -0.22043611  0.09757078  0.34282267  0.05569773  0.05060282 -0.13690978\n",
      " -0.23377651 -0.03529495  0.04475775  0.10371794 -0.09333364  0.02497011\n",
      " -0.23242186 -0.239905    0.04380316 -0.06722988  0.00633504  0.04435511\n",
      " -0.41122875 -0.00578118 -0.0223902   0.02841252 -0.10952684  0.10371149\n",
      "  0.17731307  0.1533344  -0.46478045 -0.4129578   0.09393971 -0.00072274\n",
      " -0.23643675  0.05318919 -0.35925534  0.1375291  -0.06071537 -0.06680809\n",
      "  0.16053362  0.07169333 -0.38571236  0.20029475  0.09791482  0.09459184\n",
      " -0.20999908 -0.28155053 -0.16564204 -0.07984137 -0.14370082  0.30237713\n",
      " -0.6056109  -0.20581205  0.16748095  0.07322222  0.02052195 -0.11210329\n",
      " -0.14243011  0.53767145  0.23295964 -0.17486587 -0.3548154   0.12939134]\n",
      "L4N0                    -> L5N75 = [-0.5065462   0.43147135  0.29772934  0.07619394 -0.14553683 -0.27023262\n",
      " -0.10069829  0.08292417  0.446454   -0.4593316  -0.03584634 -0.3671797\n",
      "  0.05934834 -0.04978985 -0.13032396  0.00189584 -0.22754295 -0.02196541\n",
      "  0.19205245  0.2422995   0.09971934 -0.01131379 -0.07718396 -0.33803394\n",
      " -0.4275842  -0.30036718 -0.22806689 -0.20228976 -0.10239906  0.09717446\n",
      " -0.26760438 -0.15213819  0.3657916   0.07347778 -0.26304787 -0.21051516\n",
      "  0.49881765 -0.1397892  -0.05658572  0.02643865 -0.08967572  0.042375\n",
      " -0.13410148  0.07221299 -0.0537921  -0.15481459  0.14919041 -0.3023922\n",
      " -0.16473976 -0.25332212 -0.06386765  0.2420557  -0.55198133  0.14216185\n",
      "  0.00209459 -0.21796846 -0.2789491   0.15276505 -0.03664837  0.00375983\n",
      "  0.16144918 -0.08540604 -0.30813053 -0.08278527 -0.22416255  0.02467845\n",
      "  0.63437325 -0.017998   -0.1163012   0.17452848 -0.07535954 -0.23311815\n",
      " -0.622952   -0.0431302   0.13740899 -0.16878384 -0.47662842 -0.17093441\n",
      " -0.1361428  -0.12776393 -0.00880155 -0.02383232  0.25479293 -0.10450301\n",
      " -0.12909263  0.09652835  0.14286016  0.2919503   0.08041894 -0.3021446\n",
      "  0.17561351 -0.13895054 -0.13327028  0.01360444 -0.30115956 -0.00847464\n",
      " -0.36963344 -0.06494402  0.00117279 -0.13559549 -0.21847305  0.2892615\n",
      " -0.1189573   0.07416704  0.02514403 -0.17905943  0.05382999 -0.18920109\n",
      " -0.24664655 -0.03509076 -0.30223224 -0.05575052 -0.3518608   0.04595907\n",
      "  0.14019811  0.12794952 -0.29668033 -0.45217434 -0.20262857 -0.2642694\n",
      "  0.23120818  0.14799766 -0.2583032  -0.31275934 -0.016137    0.22221375\n",
      "  0.02751521  0.18484595 -0.3082892   0.26714793 -0.6279694   0.18384822\n",
      " -0.3632044  -0.11966763  0.1339555   0.12535615 -0.08298064 -0.18206456\n",
      "  0.03010207 -0.22351135 -0.26332352 -0.19950554  0.04388593  0.33781084\n",
      " -0.2769643  -0.06156845 -0.09712189 -0.04771348 -0.36102703 -0.28202468]\n",
      "L4N0                    -> L5N76 = [ 4.77242731e-02  1.83336347e-01 -3.65865052e-01 -1.48746073e-01\n",
      "  2.53460318e-01  2.80827612e-01  2.09002152e-01  1.66411608e-01\n",
      "  1.31123904e-02  1.27994061e-01  9.84504670e-02  1.93408772e-01\n",
      "  2.46077925e-01  2.01026767e-01 -1.95904642e-01  1.65718496e-01\n",
      "  1.23418476e-02 -6.49242178e-02 -5.14344275e-02 -4.60965455e-01\n",
      "  2.23356813e-01 -2.76141584e-01  3.79987769e-02  3.87873995e-04\n",
      "  6.71099424e-02  5.79170883e-02 -1.62854761e-01 -3.03386539e-01\n",
      " -3.00491601e-02 -3.51005167e-01  1.16327098e-02  1.79758117e-01\n",
      "  2.56016135e-01  2.54765719e-01 -4.64895934e-01 -2.78545320e-01\n",
      "  5.82833588e-03  6.00512177e-02 -3.36594373e-01 -5.14386356e-01\n",
      " -1.72137711e-02  2.33207107e-01 -1.17481694e-01 -1.15883768e-01\n",
      "  5.98380491e-02 -5.14763035e-02 -5.63016236e-01 -2.12425694e-01\n",
      "  2.52328604e-01 -2.85539597e-01  1.12625740e-01 -4.46128175e-02\n",
      "  1.59777030e-01 -3.48475635e-01 -7.61121511e-02  1.40682891e-01\n",
      " -6.76701665e-02  2.27218896e-01 -5.34606799e-02 -1.01972669e-02\n",
      " -1.27932087e-01  7.42961168e-02  1.31644636e-01  5.33410370e-01\n",
      " -9.15889665e-02  2.14042887e-01 -1.57747462e-01 -3.13556582e-01\n",
      "  3.94972004e-02 -3.95675927e-01  2.99090832e-01 -1.67065158e-01\n",
      " -3.03979013e-02  8.78339335e-02  3.97472419e-02  4.93612327e-02\n",
      "  1.85674384e-01  1.67210370e-01  7.51681253e-02  3.74123365e-01\n",
      " -1.86593175e-01  8.65716264e-02  4.41440910e-01 -2.35199649e-02\n",
      " -2.12323099e-01 -4.18248475e-01  5.13483584e-01  3.30800086e-01\n",
      "  8.62872675e-02  1.12858951e-01  2.59590354e-02  1.28050745e-01\n",
      "  4.48971689e-02  1.38604343e-01 -5.50002754e-02  2.04128772e-01\n",
      " -2.84541816e-01 -5.79071343e-01 -4.26193401e-02 -4.31067273e-02\n",
      " -2.20627680e-01 -7.80945197e-02 -8.44140947e-02 -7.56333247e-02\n",
      " -2.85771430e-01 -1.51623696e-01  6.45784847e-03 -7.11844265e-02\n",
      "  2.13129390e-02  2.65937112e-02 -3.22819620e-01  1.85046047e-01\n",
      "  2.54847229e-01  1.82046935e-01 -1.30453438e-01 -1.69634596e-01\n",
      "  5.20283170e-02 -1.38957202e-01  4.28171940e-02 -1.35176763e-01\n",
      "  3.94377559e-01  4.06953543e-02 -8.97685811e-02  1.47732228e-01\n",
      " -5.16997799e-02  2.06923038e-01  1.42481625e-01 -1.92371681e-01\n",
      "  8.26698989e-02 -1.90815106e-01 -1.97263300e-01 -5.97645827e-02\n",
      "  1.28513768e-01  1.51185960e-01 -4.93096225e-02  3.14359963e-01\n",
      " -1.11784801e-01 -1.29206538e-01 -6.98486418e-02 -3.55060101e-01\n",
      "  1.68378696e-01 -2.26653919e-01 -1.44750983e-01 -2.35001460e-01\n",
      " -8.52296129e-02  3.59915011e-02 -3.56623441e-01  3.14554602e-01\n",
      "  1.04318954e-01 -2.72878200e-01]\n",
      "L4N0                    -> L5N77 = [-3.27695221e-01 -6.57095611e-02 -7.35630468e-02 -5.85854575e-02\n",
      "  1.19950049e-01  1.57542855e-01  2.31142640e-02 -1.55928880e-02\n",
      "  2.40364388e-01  8.52088332e-02  2.34718233e-01  1.75653011e-01\n",
      " -4.28179890e-04  1.15237750e-01  4.46099788e-02 -4.64617878e-01\n",
      " -2.09566250e-01  5.30425832e-02  5.36261834e-02  7.10154250e-02\n",
      "  2.73918267e-03 -4.48648557e-02  6.32362366e-02 -2.73268163e-01\n",
      "  2.32572228e-01  1.75299168e-01  2.95260400e-01 -1.62420198e-01\n",
      " -5.27502447e-02 -1.07778639e-01  6.00587926e-04 -1.69622198e-01\n",
      "  1.65077448e-01  6.22577295e-02 -2.88381994e-01 -9.29550231e-02\n",
      " -1.84858680e-01  4.96884510e-02  2.40660459e-01  2.24945158e-01\n",
      "  1.18820257e-01 -1.22571938e-01 -1.97047144e-01 -6.14251085e-02\n",
      "  2.52466723e-02 -8.19080397e-02 -2.81378627e-01 -1.05168097e-01\n",
      "  2.27686018e-01 -2.19519317e-01  2.30679467e-01  2.53594726e-01\n",
      " -3.69434506e-01 -2.81009883e-01 -2.31809080e-01  4.91201766e-02\n",
      "  2.76427507e-01  1.90699063e-02 -1.13970645e-01 -3.05991739e-01\n",
      "  1.81112409e-01  9.12872031e-02 -1.76587164e-01  1.31312922e-01\n",
      "  1.41116977e-01  1.23696581e-01 -3.08029115e-01  8.73858333e-02\n",
      " -4.54252921e-02 -1.77837163e-01 -2.23267466e-01 -1.50091350e-01\n",
      " -1.83300838e-01  6.08566046e-01 -8.45789611e-02  2.56725311e-01\n",
      " -7.34054819e-02 -1.42631158e-01  3.33788782e-01 -2.40234584e-01\n",
      "  5.12456372e-02  3.30431387e-03  3.45462501e-01  2.08687149e-02\n",
      "  2.50724759e-02  1.98647290e-01  2.15770882e-02 -1.21040426e-01\n",
      " -2.48904452e-01 -1.47353411e-01 -4.13739204e-01 -3.39618862e-01\n",
      " -2.32516617e-01  2.26035286e-02  2.45538846e-01  2.37684205e-01\n",
      " -1.70752764e-01  6.26298934e-02 -4.04533923e-01  3.27023193e-02\n",
      " -1.61183327e-01 -2.60977060e-01  6.77543432e-02 -3.44417483e-01\n",
      "  2.72405446e-01  1.60068795e-01 -1.63756073e-01 -1.70053691e-01\n",
      "  2.02903524e-01  2.52329767e-01  1.50178626e-01 -2.87466556e-01\n",
      "  1.89030603e-01  2.67266352e-02  1.56414267e-02 -1.87142454e-02\n",
      "  3.15623432e-01  2.48413116e-01  1.06179886e-01  2.51606613e-01\n",
      "  5.23845516e-02 -1.20353259e-01  2.15422794e-01 -2.58171447e-02\n",
      "  6.59513324e-02  2.69750327e-01 -1.49087414e-01  3.21357757e-01\n",
      " -2.08915904e-01 -6.37852550e-02 -8.02385658e-02 -3.78655717e-02\n",
      " -2.54888415e-01  3.13990772e-01  5.67799099e-02 -4.58918124e-01\n",
      "  8.64427686e-02  1.23486836e-02  7.54523054e-02 -2.99958587e-01\n",
      "  1.67798307e-02 -5.53456806e-02 -5.07424846e-02  5.65267168e-02\n",
      " -2.22814739e-01 -1.61655188e-01  3.98195870e-02  1.56822260e-02\n",
      "  2.64365226e-01  6.23586960e-03]\n",
      "L4N0                    -> L5N78 = [ 0.08828078  0.01248622  0.17247836  0.30043793  0.42902702  0.24538964\n",
      "  0.18424721  0.38603628 -0.24728462  0.05951706  0.34644872 -0.37442997\n",
      "  0.25818145  0.15885735 -0.08169939 -0.00145998  0.38655144  0.1618413\n",
      "  0.18833165 -0.04787332  0.21883343 -0.2611171  -0.00607507 -0.11792547\n",
      " -0.22298275  0.23067473  0.29556367  0.4137991   0.54002184  0.17725013\n",
      "  0.2665489   0.26954782  0.23753916  0.4713274   0.22770484 -0.12302123\n",
      "  0.23820847  0.29410818  0.42995417  0.09383859 -0.14890635  0.56451225\n",
      " -0.11491866  0.09240551 -0.14140694  0.28560442 -0.10192621 -0.11676077\n",
      " -0.04638058  0.02070185 -0.07939252  0.50318366 -0.09482967  0.21055873\n",
      "  0.11516099  0.2101079  -0.24138904  0.03245278  0.24080867  0.20621823\n",
      " -0.03554494 -0.01475315  0.23889992  0.08911365  0.01517122 -0.48527133\n",
      "  0.04872707  0.1950035  -0.32140002 -0.05079053 -0.0726179   0.0964565\n",
      "  0.11039321 -0.08908539  0.28120166 -0.16363613  0.15495451 -0.04978711\n",
      " -0.03626101  0.2980034   0.55007195 -0.04719055  0.32794046  0.20930354\n",
      " -0.07402148  0.09420624 -0.38817778  0.2539884   0.36895755  0.28008157\n",
      "  0.11698409  0.23070668  0.46373153 -0.08164909 -0.14470571  0.13106422\n",
      "  0.02510026 -0.0389863   0.33425805  0.4701045   0.02762361 -0.3728882\n",
      " -0.25609803 -0.04102837 -0.00241324  0.1226298   0.4018332   0.65938294\n",
      "  0.2023233  -0.0730286  -0.13231625  0.21281536  0.34540138  0.21837725\n",
      "  0.22446898  0.15507656 -0.05113937  0.07972268  0.26431748 -0.1565799\n",
      "  0.23667464  0.09794018 -0.00374557  0.35691008  0.17864269 -0.05074144\n",
      " -0.13529126 -0.09736781  0.40075845 -0.20730619  0.2647698   0.32887715\n",
      "  0.40809253  0.04583346  0.0623009   0.33384898  0.24978563 -0.08060298\n",
      "  0.17720634 -0.08005607  0.15532123 -0.21022925 -0.02570605 -0.15725291\n",
      "  0.2861773   0.01443598 -0.00688664  0.16749676 -0.10791042  0.02821005]\n",
      "L4N0                    -> L5N79 = [-0.58403224 -0.04999959  0.3280806  -0.21289709 -0.22862367 -0.40525076\n",
      " -0.34009513 -0.00964224  0.34102428 -0.5657363  -0.4720293   0.0371462\n",
      "  0.16416591  0.22555934  0.05070314  0.19517256  0.29258218 -0.02917698\n",
      "  0.06160402  0.2602781   0.06341324  0.27322412  0.26768342 -0.47236186\n",
      "  0.13753758 -0.53509    -0.44101164  0.1760845  -0.19705929 -0.0297509\n",
      " -0.26461828  0.00324497  0.14615144  0.05336548  0.13203728  0.01804779\n",
      " -0.04083767  0.2904727   0.2002118   0.23900601  0.1521146   0.0354781\n",
      "  0.07563901  0.23116668 -0.30764642 -0.57736444  0.30041623 -0.12305915\n",
      " -0.10592932  0.0115872  -0.56372    -0.5330068  -0.24877635  0.07375108\n",
      " -0.26031265  0.39277548 -0.052579    0.32718486 -0.35304412 -0.41079503\n",
      " -0.03842585 -0.52590686 -0.28694788  0.22543333 -0.49204013 -0.301329\n",
      "  0.15081146 -0.29252633 -0.0837562   0.09376126  0.01549832  0.22391146\n",
      "  0.16851684  0.00937744  0.23081478  0.14588954 -0.16222504 -0.21507484\n",
      " -0.03639474 -0.32167542 -0.18463549  0.20921811 -0.14727008 -0.41097283\n",
      "  0.28435415 -0.14030913  0.21050303 -0.4708963  -0.0126708  -0.14797728\n",
      " -0.1294954  -0.31045282  0.05910167 -0.7444826  -0.1247531   0.27432972\n",
      " -0.705563   -0.04267161 -0.12277502 -0.6253416   0.16458707  0.19391248\n",
      "  0.02377857  0.08091338  0.11160549  0.37332556 -0.7188915  -0.07733807\n",
      " -0.23441626 -0.02367313 -0.24903682 -0.06611381 -0.04897342  0.16850978\n",
      "  0.02320524  0.06712589  0.11398983  0.0619063  -0.7122487  -0.75600505\n",
      "  0.0952491   0.1942267   0.17712429  0.08018773 -0.5166717  -0.09178001\n",
      " -0.54786515 -0.00170467 -0.6012191   0.09915322 -0.34406438  0.10882299\n",
      " -0.56354177 -0.71994746 -0.00319483  0.26786867  0.2648181   0.20914212\n",
      "  0.11897168 -0.07102139 -0.45558125 -0.7663951  -0.35426056  0.35251912\n",
      " -0.61223245  0.09804628  0.17115721 -0.0015174  -0.39328733  0.20476627]\n",
      "L4N0                    -> L5N80 = [-1.30800605e-01 -7.69189000e-02  1.30918682e-01 -2.02029899e-01\n",
      "  3.26809287e-01  6.67266846e-02  6.55546486e-02 -8.59793350e-02\n",
      " -4.57727075e-01  3.03976983e-01  1.30370185e-01  5.01882732e-02\n",
      "  1.29651293e-01  9.19534042e-02 -2.30749249e-01  3.57896030e-01\n",
      " -1.56075239e-01 -1.97701409e-01  7.10899457e-02 -1.31580248e-01\n",
      "  5.11476636e-01 -3.74000996e-01 -4.23560943e-03 -5.11252463e-01\n",
      " -1.48573503e-01  4.50978100e-01  2.68420637e-01  2.33935937e-01\n",
      "  3.65048498e-01  1.55429393e-01  1.33615166e-01  3.51387411e-01\n",
      " -3.66728574e-01  1.31199062e-01  3.55271518e-01 -3.81335676e-01\n",
      " -4.04822677e-01 -1.34758860e-01 -9.03585926e-02 -1.00236513e-01\n",
      " -3.89615744e-02  2.64576405e-01 -1.02119856e-01 -3.65299918e-02\n",
      "  5.18331230e-02 -2.73164362e-01 -3.81998926e-01 -7.52506405e-02\n",
      " -1.91908672e-01  1.88390128e-02 -1.77205160e-01  1.78615853e-01\n",
      "  1.25025108e-01 -1.00579090e-01  8.58050063e-02 -2.32984543e-01\n",
      "  4.18981701e-01 -1.15606278e-01 -7.87089542e-02 -2.16463096e-02\n",
      " -1.39260113e-01  1.31570384e-01  3.28346521e-01  1.59041569e-01\n",
      " -2.27835894e-01  2.12234020e-01  7.98648745e-02 -7.70558640e-02\n",
      " -2.76766539e-01 -1.66674480e-01  1.93667218e-01 -1.83449015e-01\n",
      "  1.02103993e-01 -1.03168741e-01  4.07790869e-01 -1.53746437e-02\n",
      "  9.14702564e-02 -2.39619166e-01 -1.58583939e-01 -1.08280219e-01\n",
      " -1.07215524e-01  7.14234710e-02 -1.91831607e-02  1.28213182e-01\n",
      "  3.81425023e-02  1.38508677e-01 -5.09552062e-01 -1.00901886e-03\n",
      " -9.07953382e-02 -3.18930238e-01 -1.56875253e-02  2.47682109e-01\n",
      "  4.77399938e-02  6.95875809e-02 -2.90552882e-04  5.32776952e-01\n",
      "  1.71815664e-01 -8.22981521e-02 -6.13229536e-02  1.03391349e-01\n",
      "  2.78219700e-01 -3.07309955e-01 -1.68429390e-01 -2.71025062e-01\n",
      " -2.71160126e-01  1.46411791e-01 -7.70424753e-02  2.50044048e-01\n",
      " -2.25295842e-01 -3.25812101e-01  6.91015720e-02  2.34581009e-01\n",
      " -3.79895985e-01  3.14322650e-01  5.56730628e-01 -1.89078137e-01\n",
      "  1.93592891e-01 -1.30093321e-01 -5.07699959e-02  1.27326157e-02\n",
      "  3.23088497e-01 -1.78087205e-01  6.77441955e-02  2.23688200e-01\n",
      " -7.01733083e-02  1.23728719e-02 -3.92565280e-01 -1.52403221e-01\n",
      "  1.08597018e-01 -1.61113694e-01  3.09389114e-01  2.77956128e-01\n",
      "  6.86793029e-02  1.40373752e-01  4.77010868e-02  1.85456112e-01\n",
      "  4.66001719e-01 -1.15579907e-02 -3.44044417e-02 -1.45670116e-01\n",
      " -1.38859391e-01 -3.53055298e-01 -1.92131132e-01 -2.59158850e-01\n",
      "  1.50859550e-01  5.83299659e-02  2.26565581e-02 -6.05539531e-02\n",
      "  1.11253105e-01 -2.82407463e-01]\n",
      "L4N0                    -> L5N81 = [-0.1440818  -0.422502   -0.01103459 -0.18277758 -0.14125478 -0.32147893\n",
      "  0.2025949   0.14175549 -0.18603368 -0.05321592 -0.3718128  -0.09153648\n",
      " -0.10748687  0.08494441  0.36937517 -0.03232216 -0.06297801 -0.11320978\n",
      "  0.07292902 -0.10597322  0.04314763  0.06103102  0.12537444 -0.04490433\n",
      "  0.25459132 -0.5082136  -0.6198715  -0.6568823  -0.24609394  0.3843899\n",
      " -0.3216596   0.13659747  0.04515654  0.18782413  0.02545802 -0.09846491\n",
      "  0.22506776 -0.30061844  0.05975543 -0.23978959 -0.12458592 -0.0893947\n",
      " -0.22152855  0.5198682   0.07622255 -0.24676862  0.17788246 -0.43430236\n",
      " -0.08452112 -0.11903568 -0.1891315   0.15687057  0.02192924 -0.1299911\n",
      "  0.11546195 -0.16095598 -0.29653737 -0.13361467 -0.42376643 -0.36614543\n",
      "  0.10901209 -0.38537797  0.1313376   0.06204775 -0.16337329 -0.18405902\n",
      "  0.73480576 -0.17529444 -0.17088908  0.3168345   0.19919784  0.2169278\n",
      " -0.65418124  0.32113424 -0.0485925  -0.05675332 -0.01658993  0.00663301\n",
      "  0.04801698 -0.26407894 -0.35399637 -0.17656712  0.13362113  0.01196974\n",
      "  0.30698898  0.04675233  0.24098755 -0.19412546 -0.23466057  0.11299728\n",
      " -0.16304357  0.19349866 -0.11177381 -0.00937698  0.05432724 -0.03300423\n",
      " -0.22932865  0.01323826 -0.02325439 -0.12979944  0.03995849 -0.07262772\n",
      " -0.20500666 -0.07051634  0.17945956  0.34910434 -0.20069838  0.06795876\n",
      " -0.35356557 -0.19804391 -0.2396469   0.1204417   0.3507376   0.12801267\n",
      "  0.21157742  0.11456826 -0.18488738 -0.329912   -0.16245186  0.11550917\n",
      "  0.09755555  0.5938428  -0.19460845  0.23374529  0.16156466  0.25538242\n",
      "  0.04799737  0.22828142 -0.21421312 -0.05873999 -0.01732985 -0.19725043\n",
      " -0.43983158 -0.2705116  -0.110494    0.07933345 -0.07894594  0.18159524\n",
      " -0.21541604  0.03798277 -0.07715642  0.21497558  0.4263959  -0.11100253\n",
      " -0.16322748  0.04297896  0.12989533 -0.5341739  -0.1664584   0.12282582]\n",
      "L4N0                    -> L5N82 = [ 2.25326587e-02 -8.01222771e-02  9.46823955e-02  1.48655340e-01\n",
      " -3.39900851e-01  3.82926226e-01  3.77012193e-02 -5.63651212e-02\n",
      "  6.67432696e-02  1.52838185e-01  2.33901992e-01 -3.05649072e-01\n",
      " -1.43174618e-01 -1.53831825e-01 -1.89599112e-01  5.38395904e-02\n",
      " -6.90319315e-02  2.07891107e-01  7.19392598e-02  5.41569665e-02\n",
      "  3.30078229e-02  2.04480663e-01 -2.06059031e-02  1.12910502e-01\n",
      " -3.56598288e-01 -1.64081320e-01 -6.29807830e-01  1.35600194e-01\n",
      "  4.37581956e-01  2.15328425e-01  1.54004991e-01 -2.84249544e-01\n",
      "  1.96741745e-01  3.11896443e-01 -5.78901410e-01 -3.42994332e-01\n",
      " -3.34047347e-01 -3.05437366e-03  1.17784522e-01 -1.54701933e-01\n",
      " -9.36979055e-02 -1.25248760e-01 -4.25514281e-01 -1.65692493e-01\n",
      " -1.69057518e-01 -2.86639839e-01 -3.65371406e-01 -7.78449252e-02\n",
      " -7.97877312e-02  9.86960679e-02  3.07282992e-03  2.00199813e-01\n",
      " -6.47908986e-01  3.83720472e-02  7.32011423e-02  1.96184814e-01\n",
      "  4.99153510e-02  1.55929714e-01 -1.31612331e-01  3.24289501e-01\n",
      "  3.85336988e-02 -1.42056718e-01 -1.07688665e-01 -1.01931266e-01\n",
      " -7.25605860e-02 -5.75819552e-01 -1.78345844e-01 -2.55799353e-01\n",
      "  1.31756663e-01  3.43742929e-02  2.96605490e-02  2.95384943e-01\n",
      "  2.94559062e-01 -6.34738952e-02  2.72105988e-02 -4.73552234e-02\n",
      " -2.63484806e-01 -4.78437185e-01 -4.80318606e-01 -5.03347635e-01\n",
      " -3.12003456e-02  2.75143743e-01 -1.01165041e-01  2.51086168e-02\n",
      " -1.40399829e-01  3.54815334e-01 -3.45257878e-01 -3.49350721e-01\n",
      "  1.59367353e-01  4.39762175e-01  7.25973621e-02 -3.27149123e-01\n",
      " -1.14463633e-02 -1.71198860e-01 -4.19370756e-02  1.17011733e-01\n",
      " -6.28725141e-02  2.57749319e-01  2.11385667e-01  3.43887210e-01\n",
      " -3.22410546e-04  6.47132844e-02  3.63993615e-01  1.14220664e-01\n",
      "  1.63785458e-01  1.18004993e-01 -1.78745434e-01 -3.08608681e-01\n",
      " -1.44972175e-01  1.57040894e-01  1.00915439e-01  2.62941211e-01\n",
      " -9.53212082e-02 -1.15011267e-01 -3.28248627e-02  1.43882468e-01\n",
      " -3.64805490e-01  3.51023316e-01 -9.56095830e-02 -4.70364206e-02\n",
      "  3.16767961e-01 -3.01250309e-01 -5.11505306e-01 -1.73938468e-01\n",
      " -1.62534162e-01 -1.39762148e-01 -2.19861895e-01  1.10222951e-01\n",
      " -3.89584482e-01  7.31772184e-02 -4.35758568e-02 -1.25776187e-01\n",
      "  1.83897644e-01 -1.37797356e-01 -7.55488634e-01 -9.21242610e-02\n",
      "  4.24797907e-02  2.38571122e-01 -1.59262031e-01  1.72001243e-01\n",
      " -7.13941827e-02 -3.60639513e-01 -1.26504183e-01 -1.38085812e-01\n",
      " -2.39906654e-01 -1.78790882e-01  2.32240260e-01 -7.66120732e-01\n",
      " -2.89627910e-01  2.69457847e-01]\n",
      "L4N0                    -> L5N83 = [ 0.16441484 -0.20913678 -0.00250488 -0.0149796  -0.3029596  -0.04057973\n",
      "  0.2251042   0.2630821  -0.13944422 -0.125399   -0.1407599  -0.6675054\n",
      "  0.13669193  0.00697236  0.14713669  0.08852474  0.02004852 -0.17400536\n",
      " -0.15273307  0.00646386  0.32319716 -0.2694492  -0.2884298   0.05366192\n",
      "  0.0427007  -0.17431723 -0.10039201  0.07388996  0.03174816 -0.13984911\n",
      " -0.13779673 -0.13350013  0.13687548  0.26806125 -0.088599   -0.2685301\n",
      "  0.11827665  0.19135344  0.5412053   0.17862833  0.02819371  0.008782\n",
      " -0.2884174  -0.02400267  0.07268944 -0.28534532  0.12459804 -0.20362109\n",
      "  0.04699563 -0.08162151  0.09182577  0.0163103  -0.34219274 -0.01455402\n",
      " -0.17249519  0.19259794 -0.02189473  0.07575487 -0.03340554 -0.04475257\n",
      "  0.09103648 -0.18619137 -0.17126374  0.16770504  0.05673515 -0.054909\n",
      "  0.24671678  0.42959598  0.14897226  0.2029588  -0.2210647   0.16775617\n",
      " -0.41223246 -0.5596388   0.08101904 -0.07544701 -0.17364964 -0.2989831\n",
      " -0.12491378 -0.14890982  0.13316236 -0.27089018  0.01398382 -0.07931211\n",
      " -0.18862633  0.31077164 -0.3688335  -0.21876645  0.1147557  -0.00233857\n",
      " -0.01820788 -0.21654889  0.1623372  -0.05891046 -0.11736555 -0.03642425\n",
      "  0.04143475  0.32533193 -0.30190724 -0.15839954 -0.13428862 -0.4042864\n",
      " -0.29253432  0.06639965  0.1687056  -0.47579274  0.03096986 -0.41594222\n",
      " -0.41110662 -0.07030503 -0.15806085  0.11287726 -0.00924787 -0.09738888\n",
      "  0.16792399  0.2441114  -0.7444558  -0.01678733  0.07021356  0.10683814\n",
      " -0.14657405  0.22261532 -0.53343844  0.10220786  0.0552234   0.22218712\n",
      " -0.10576168  0.27529642 -0.3929705  -0.29158023 -0.19194876 -0.2438044\n",
      " -0.087602   -0.07229137 -0.09028038  0.10553499 -0.08514781 -0.20414837\n",
      "  0.13634105  0.02401215  0.03376066 -0.09391623  0.04889988 -0.02769214\n",
      " -0.29105964 -0.31573695 -0.15962815 -0.2150727  -0.5837311   0.17719685]\n",
      "L4N0                    -> L5N84 = [ 1.26056805e-01 -1.59764603e-01  2.50247836e-01 -1.95607403e-03\n",
      " -2.32536525e-01  7.57669657e-02  3.39187801e-01  2.09364891e-01\n",
      "  8.62931237e-02  4.93874460e-01 -9.38514248e-02 -3.79753739e-01\n",
      "  1.26839289e-02  8.62712711e-02  1.20720662e-01 -1.02413774e+00\n",
      " -1.83392391e-01  2.34224815e-02  7.88269490e-02 -3.26434076e-02\n",
      " -3.91479433e-01  8.74349847e-02 -1.02204263e+00 -6.98612779e-02\n",
      "  1.40540943e-01 -1.42529771e-01  4.73619550e-02  1.25879005e-01\n",
      " -1.20530955e-01  4.12163697e-02 -1.44907832e-02 -6.93712533e-01\n",
      "  1.62023678e-01  8.02553296e-02 -8.06677388e-04  2.53500134e-01\n",
      "  3.96423787e-02 -5.61136045e-02 -2.08193675e-01 -5.65464869e-02\n",
      " -2.14654300e-02 -6.65720999e-01 -4.94652748e-01  2.26841215e-02\n",
      "  1.01565480e-01 -8.40089545e-02 -2.45240360e-01 -2.56716684e-02\n",
      " -2.10823342e-01  1.93671465e-01 -3.64845768e-02 -3.03009182e-01\n",
      " -1.04382783e-01  2.79584765e-01  7.24133030e-02  1.92630924e-02\n",
      " -6.21444993e-02 -2.88103968e-01 -1.44598065e-02 -3.13410275e-02\n",
      " -1.34153679e-01 -2.56109424e-02  4.83546555e-01  1.94542751e-01\n",
      " -2.70016462e-01 -9.78092998e-02 -3.35593820e-02 -9.72323399e-03\n",
      "  6.21132143e-02  2.01837003e-01 -3.07495743e-02  2.55921602e-01\n",
      " -3.32207978e-01 -1.47129342e-01 -3.75938684e-01  1.64681122e-01\n",
      " -5.25396645e-01 -1.19832017e-01 -8.22259560e-02  9.80632082e-02\n",
      "  3.72810289e-02 -1.45941079e-02  1.64077859e-02 -1.40416175e-01\n",
      " -2.32680380e-01 -1.06860429e-01 -6.11645162e-01  7.45188892e-02\n",
      "  2.34657466e-01 -2.10397504e-02 -4.01051521e-01  4.50708568e-02\n",
      "  3.64436507e-02  3.30831230e-01  1.63811699e-01 -7.75075912e-01\n",
      "  8.30132663e-02 -3.07272561e-02  3.04187983e-01 -1.57454029e-01\n",
      " -4.15931433e-01  2.04817817e-01 -3.03619117e-01  9.58550051e-02\n",
      " -3.20114881e-01 -3.99354637e-01  7.12086335e-02 -6.67153120e-01\n",
      " -1.96092483e-02 -3.61099131e-02  2.31734812e-01 -3.17336142e-01\n",
      "  3.82310152e-01 -4.12026674e-01 -4.18341815e-01 -5.31809807e-01\n",
      " -5.63228607e-01 -3.77653420e-01  1.53834015e-01  1.50065515e-02\n",
      " -1.74354032e-01 -2.18844116e-01 -1.41290665e-01  1.68543249e-01\n",
      "  1.48345083e-01  3.46455485e-01 -7.09882304e-02 -6.59369454e-02\n",
      "  2.17925727e-01 -1.86783805e-01 -3.10164213e-01  4.32120919e-01\n",
      " -1.32910907e-01 -4.25774558e-03 -3.94192822e-02 -3.41038227e-01\n",
      " -6.61576152e-01 -3.19653451e-01  4.01820801e-03  6.06444739e-02\n",
      "  1.00984700e-01  1.07089840e-01 -1.25226662e-01 -9.81622934e-03\n",
      "  3.15693915e-02 -1.56388998e-01 -1.50894895e-01 -8.27133954e-02\n",
      " -4.16522957e-02  3.13495964e-01]\n",
      "L4N0                    -> L5N85 = [-0.18029179 -0.01959315  0.07241284 -0.25138196  0.38016224 -0.16812474\n",
      " -0.00569666 -0.13041124  0.1369617   0.1499136   0.0351494   0.11014406\n",
      " -0.31501344 -0.01288782 -0.08440761 -0.22594622  0.27460378 -0.02471336\n",
      " -0.1515492  -0.30594838  0.17775592  0.4469716   0.46360296 -0.29890105\n",
      "  0.28131604  0.15692283  0.07007118  0.00662021  0.22411236 -0.2416535\n",
      " -0.07178446 -0.3721909   0.02646133  0.06083831 -0.15439188 -0.22690181\n",
      " -0.2510488   0.04463126 -0.26613745 -0.2511319   0.41485733  0.09646126\n",
      "  0.27121726  0.12657914 -0.19131598  0.3232156  -0.27782267  0.03479129\n",
      "  0.11759593 -0.5758871   0.07869053 -0.358154    0.10805541 -0.23980948\n",
      "  0.09082338 -0.03270419 -0.07085323  0.35736924  0.05669339  0.02936091\n",
      " -0.04637604 -0.25199303 -0.0010887   0.31386977 -0.30698678  0.0607006\n",
      "  0.06692135 -0.16840842 -0.07683255 -0.7444665  -0.07959461 -0.06191132\n",
      " -0.09017824 -0.2952437   0.26110187 -0.32598552 -0.13260812 -0.11167722\n",
      " -0.26109466  0.18829833 -0.46693793  0.00313249 -0.03595948 -0.15660845\n",
      "  0.3279509  -0.3108832   0.36447087 -0.11586791  0.04605488  0.05606058\n",
      "  0.05258381 -0.3863742   0.14800297 -0.11640885 -0.20253599  0.33524907\n",
      " -0.08536074 -0.34123415 -0.0168757  -0.11969566  0.26722616 -0.4595368\n",
      "  0.3895921  -0.16331586 -0.02266133  0.02204318  0.1510039  -0.15654865\n",
      "  0.02778747 -0.08034649  0.0372159  -0.07831603  0.14017017 -0.32456633\n",
      " -0.2648431   0.03028043 -0.20605442  0.12999934 -0.00620804 -0.38218877\n",
      "  0.29064077  0.08357421 -0.08807527  0.11227649 -0.4683231  -0.17807251\n",
      " -0.27315584 -0.11034907  0.24770127  0.03938584 -0.03219145 -0.15652895\n",
      "  0.0879166   0.17549479  0.09731883  0.18703549  0.1611274  -0.08551165\n",
      "  0.5242562  -0.3853057  -0.05843041 -0.20977463 -0.18635973  0.28508782\n",
      "  0.01368758  0.00560999 -0.09017513  0.04452842 -0.19133748 -0.17825401]\n",
      "L4N0                    -> L5N86 = [ 0.24074732  0.31851086 -0.31823584 -0.01229864 -0.4343895   0.02831594\n",
      "  0.42053118  0.01742749 -0.1794689  -0.15113671  0.08938477 -0.48440307\n",
      " -0.03158213  0.20514278 -0.0884642  -0.02862678 -0.43158305 -0.30131122\n",
      " -0.0060025   0.18549816  0.20458879  0.24552797  0.1289709   0.41673547\n",
      "  0.13568568 -0.29251477 -0.30550975  0.27121207  0.22668032  0.09230208\n",
      " -0.38292533 -0.40261784  0.31088683 -0.0038745  -0.00573993  0.22764063\n",
      " -0.26507297 -0.06085636 -0.00405342  0.16426304 -0.01755332 -0.21861637\n",
      " -0.33168995  0.21350358 -0.24048053 -0.2670258  -0.28203663 -0.18870474\n",
      "  0.16977777  0.09144562  0.00547371 -0.3345665  -0.26797038 -0.45180807\n",
      "  0.22751096 -0.13032405 -0.17111112 -0.12378747 -0.35659817 -0.26750946\n",
      " -0.3690878  -0.11617413 -0.01837464 -0.15369381 -0.21492866 -0.07489768\n",
      "  0.27182755  0.25505024  0.06470609 -0.09827837  0.3098894   0.13488367\n",
      "  0.02535743  0.29590017  0.09471691 -0.22061129 -0.49301162 -0.4599071\n",
      " -0.16242465 -0.45875195 -0.17599271 -0.10679923 -0.07827754 -0.2561532\n",
      "  0.06904044 -0.24435925  0.30348834 -0.10007196  0.12229913  0.18372646\n",
      " -0.11162885 -0.08416198 -0.27082628 -0.1606546   0.15531537  0.1877173\n",
      " -0.24647726 -0.05648056  0.6332813   0.02679052 -0.27656445  0.01953502\n",
      " -0.16401951 -0.3528894  -0.18314038 -0.2150234   0.01412477 -0.28817618\n",
      " -0.2243591  -0.1689937   0.17195909  0.10196975  0.24117611 -0.22311726\n",
      "  0.04614045  0.02961306 -0.12715432 -0.24438196  0.1336076  -0.0216884\n",
      " -0.01542737 -0.08451043 -0.6224202   0.13404696 -0.11089617 -0.19883937\n",
      " -0.35949746 -0.35722673 -0.18088028  0.00851908 -0.42429507 -0.06320412\n",
      " -0.34530026 -0.04910095 -0.07376533  0.13343926  0.06328604  0.3842114\n",
      " -0.01338228  0.26392147  0.15554944  0.00469333 -0.02917561 -0.33824947\n",
      " -0.35732704 -0.10753682 -0.10899999 -0.4882981  -0.07079823 -0.55835336]\n",
      "L4N0                    -> L5N87 = [ 0.27015263  0.34724346 -0.10326553  0.05156067  0.09140128  0.1407867\n",
      "  0.15665911 -0.2310539  -0.1570744   0.02154377 -0.02487935 -0.19102983\n",
      " -0.02489654 -0.26765764  0.26578057  0.3322166   0.09490184 -0.06025083\n",
      " -0.16800661  0.00373876  0.15821737 -0.04096645 -0.35596195  0.26010674\n",
      " -0.23083693 -0.20784616 -0.22373518  0.10242775  0.37964445 -0.2052658\n",
      " -0.38499236 -0.08142164  0.40274552 -0.03609918 -0.18976359 -0.00783656\n",
      " -0.6223484  -0.03664266 -0.28983906 -0.1361998   0.3066428   0.49405172\n",
      "  0.2028222  -0.29187694 -0.4095079  -0.10705616 -0.28827575 -0.06607576\n",
      "  0.22991115 -0.37671903 -0.42801595  0.04329417  0.15099198 -0.5357192\n",
      "  0.12479043 -0.3161654   0.22286195 -0.16283599  0.00988758  0.07832529\n",
      " -0.4762187   0.10169858 -0.25879464  0.24533388 -0.36770746  0.07538926\n",
      " -0.3938741  -0.70166385 -0.35832807 -0.7139214   0.18015064  0.16633172\n",
      " -0.06432865  0.02211048  0.47168127 -0.42688933 -0.20299003 -0.26585615\n",
      " -0.0509187   0.3033529  -0.23615308 -0.1654909   0.23153655  0.14019713\n",
      " -0.2300069  -0.34120744  0.64857954 -0.0962038   0.25411627 -0.24977669\n",
      "  0.22053109 -0.5231592  -0.05028356 -0.4139688   0.1869886   0.43918514\n",
      " -0.35891902  0.11073439  0.03846746 -0.14259507  0.32502714 -0.13946076\n",
      " -0.00893692  0.18934949 -0.29850003 -0.19480579 -0.50724906 -0.2369886\n",
      "  0.00542456  0.00612863  0.40327772  0.23759638  0.09538953  0.11176612\n",
      " -0.03145341  0.00300439  0.13715303  0.2859163  -0.1836007  -0.3231285\n",
      "  0.06537822  0.20055379 -0.0176767  -0.05380433 -0.17476998 -0.19181168\n",
      " -0.07118392  0.11948792  0.09765948  0.20497806  0.18669757  0.14786497\n",
      "  0.21205778 -0.13538957 -0.11778188  0.11589193  0.36657864 -0.18670987\n",
      "  0.10018928  0.30969992  0.2644334  -0.27770838  0.18868168  0.05607751\n",
      " -0.10656741 -0.10401476 -0.07683951  0.2714283   0.0461344   0.31910643]\n",
      "L4N0                    -> L5N88 = [-3.51168722e-01 -1.27568990e-01 -9.93577912e-02 -6.27695262e-01\n",
      "  2.70935804e-01 -2.84775436e-01 -4.22844529e-01 -6.08358271e-02\n",
      "  8.54262114e-02 -2.57487506e-01 -2.06128359e-01  2.07303420e-01\n",
      " -1.73457921e-01 -2.64942069e-02 -2.71728456e-01  2.22958148e-01\n",
      "  8.70470554e-02  1.18891606e-02 -1.38659626e-01 -3.88270356e-02\n",
      "  2.29365662e-01  2.05736488e-01  1.81231406e-02 -2.71967649e-01\n",
      "  6.52370304e-02  1.32927775e-01  4.63143297e-05  2.65743345e-01\n",
      " -8.78385901e-02 -1.27763584e-01  2.57807374e-01  1.58884943e-01\n",
      "  6.29762635e-02  1.16242945e-01 -1.58122972e-01 -1.22264169e-01\n",
      " -2.72427388e-02 -8.35290998e-02  1.33343831e-01 -1.88720688e-01\n",
      " -4.42826539e-01 -5.02422079e-02  7.80204386e-02 -4.76850942e-02\n",
      "  1.80293575e-01  1.14250937e-02 -3.63732368e-01 -2.43129134e-01\n",
      " -1.77031547e-01 -1.32884815e-01 -1.65942073e-01 -1.59190267e-01\n",
      " -1.09131403e-01  9.02607217e-02 -5.76348379e-02 -5.89096658e-02\n",
      "  1.20188944e-01  1.78276837e-01 -1.60769030e-01  2.04456732e-01\n",
      "  5.60323112e-02  1.59766048e-01 -4.27888155e-01  3.09231579e-01\n",
      " -2.58641869e-01 -1.47873843e-02  1.06349967e-01 -4.94993746e-01\n",
      "  2.23551184e-01 -3.24526429e-01 -3.30422491e-01 -1.41697094e-01\n",
      "  5.51614761e-02 -1.54061064e-01 -2.06635237e-01  1.68386430e-01\n",
      "  3.22377011e-02  2.52087712e-01  4.88367602e-02  5.34229726e-02\n",
      "  2.17018098e-01  6.08382449e-02 -1.06179446e-01 -7.54696354e-02\n",
      "  4.53393944e-02 -6.70031011e-02  2.71951199e-01 -1.11843124e-01\n",
      "  1.77501179e-02  6.01687469e-02  2.49001548e-01 -4.26194966e-01\n",
      "  4.87529129e-01 -4.14719701e-01 -2.57787138e-01  1.77961320e-01\n",
      " -7.93367177e-02 -2.90997088e-01  5.23543432e-02  1.55939266e-01\n",
      "  1.84732154e-01 -4.88144487e-01 -4.06458378e-02 -1.04054250e-01\n",
      "  6.31390959e-02 -2.04994708e-01 -4.39635515e-01  1.96055397e-01\n",
      " -3.52130741e-01 -2.70009667e-01 -1.61973074e-01 -3.38733107e-01\n",
      "  2.64463246e-01 -1.67431608e-01 -6.98614749e-05 -7.86441714e-02\n",
      " -2.76355684e-01 -2.34114394e-01 -1.50604457e-01 -4.11828667e-01\n",
      " -5.25567420e-02 -9.57244411e-02  5.02686799e-02 -2.83048898e-01\n",
      " -5.52433729e-01 -6.60384446e-02 -2.95824200e-01  9.47529525e-02\n",
      " -7.28534982e-02 -2.26254821e-01 -2.71856755e-01 -1.09203406e-01\n",
      "  3.29389088e-02 -3.60717326e-01  3.01185697e-01 -4.69373241e-02\n",
      "  2.66933560e-01  2.87537634e-01  9.66493189e-02 -5.97368404e-02\n",
      " -2.56731778e-01 -2.01748416e-01 -1.88377947e-01  1.22995153e-01\n",
      " -4.38469887e-01  6.20300658e-02 -2.11680353e-01  1.26096085e-01\n",
      "  6.31749779e-02  4.47730049e-02]\n",
      "L4N0                    -> L5N89 = [-0.37701482 -0.5137203  -0.20569856 -0.44152775 -0.31458247  0.27964643\n",
      " -0.5424137   0.13966005 -0.04477403  0.57507986  0.31517726  0.21786153\n",
      " -0.41847605 -0.30204913 -0.16687351 -0.00654014 -0.18303199  0.6560883\n",
      " -0.47501358  0.09023157  0.02425241 -0.42124146  0.02384678 -0.13388716\n",
      "  0.08590421  0.19948883  0.3140107  -0.3332662  -0.45178998  0.32213324\n",
      "  0.28304842  0.41510698 -0.49825162 -0.2588926  -0.09316052 -0.45613858\n",
      " -0.05705779 -0.4355785   0.13087387 -0.4429894  -0.39505708  0.28915972\n",
      "  0.10461225 -0.18056437 -0.3276125   0.07701248 -0.22809425 -0.07660842\n",
      "  0.16945316 -0.36744234  0.34057876  0.0621469   0.28737205  0.05490525\n",
      "  0.17848925 -0.13203162  0.2700998  -0.12656206  0.01080329 -0.01028411\n",
      " -0.29088143  0.33740446 -0.0803763  -0.63038784  0.22869155 -0.29755095\n",
      " -0.25847405  0.23029388 -0.07647562 -0.08760414 -0.4286324  -0.38658252\n",
      "  0.08584457  0.05808334  0.32366788 -0.03292772  0.11928095 -0.08285516\n",
      " -0.19984962 -0.12889713 -0.23417008 -0.44461787 -0.3081536  -0.19092001\n",
      " -0.6079447  -0.266432    0.13732088  0.20473398 -0.07731754  0.11554251\n",
      "  0.33314297 -0.43519604 -0.58419967  0.26896274  0.11357943  0.06930026\n",
      "  0.25406054 -0.25236672  0.12355071  0.27124926  0.10302918  0.03093814\n",
      " -0.15737872 -0.11489291 -0.11434382  0.26290542  0.24968643 -0.30538282\n",
      "  0.2905446   0.7302971  -0.16086204  0.29235834 -0.09570371  0.51529294\n",
      "  0.21498346 -0.12933147  0.3390225   0.25849602  0.03661865 -0.1591421\n",
      "  0.24348286 -0.02905116 -0.00613027 -0.18551058 -0.36848086 -0.01051178\n",
      "  0.01667716 -0.3664075   0.22275206 -0.4047012   0.02011725  0.67498213\n",
      "  0.08711388  0.48258162 -0.37677607  0.1921824   0.15580025 -0.44454804\n",
      "  0.21509117 -0.3822562  -0.21484274 -0.25471103 -0.05176602 -0.36036354\n",
      "  0.13779344  0.13680683 -0.24004473  0.25131306  0.1987483  -0.2449599 ]\n",
      "L4N0                    -> L5N90 = [-2.54724294e-01 -4.19553310e-01 -1.56124711e-01 -2.02543139e-02\n",
      " -3.86953615e-02 -3.67704630e-01  1.37803927e-01  1.83380678e-01\n",
      "  1.16512038e-01 -9.12535116e-02  3.95642407e-02  2.15387434e-01\n",
      " -1.19348034e-01  7.84226656e-02 -5.67026615e-01 -1.30862072e-01\n",
      " -8.83157179e-02 -1.75638366e-02 -1.92636862e-01 -1.59668148e-01\n",
      "  3.48072171e-01  1.80732664e-02 -1.77965477e-01 -4.55924541e-01\n",
      " -3.14788446e-02 -6.56669512e-02 -9.55642313e-02 -1.94019020e-01\n",
      " -8.37748591e-03 -2.65691429e-01 -5.98980449e-02 -2.88630724e-01\n",
      "  9.57722366e-02  2.15492807e-02 -3.77994627e-01 -1.92603976e-01\n",
      "  4.70943637e-02  5.19943563e-03 -3.61269504e-01 -1.32602766e-01\n",
      "  1.35011245e-02 -8.73260349e-02  1.88589752e-01  1.14271142e-01\n",
      " -1.47288144e-01 -2.74852924e-02 -5.93314469e-01  2.14718029e-01\n",
      "  3.48009765e-01 -1.27395689e-01 -1.35215878e-01 -2.21501395e-01\n",
      " -5.77772968e-02 -4.65182036e-01 -3.07801068e-01 -1.04916677e-01\n",
      "  3.27011794e-02  3.65347527e-02  3.43059599e-01 -3.10314242e-02\n",
      " -1.91825017e-01 -5.25990091e-02 -1.18726015e-01 -1.29060090e-01\n",
      " -1.69493720e-01  3.44957024e-01  3.52936157e-04 -9.42436829e-02\n",
      " -5.97695112e-01 -3.49683523e-01  2.07282752e-01  1.12210102e-01\n",
      " -9.49012861e-02 -1.20410644e-01  3.08646202e-01  9.29864720e-02\n",
      " -8.02272707e-02  1.14347845e-01  1.30736321e-01  1.71877027e-01\n",
      " -4.95241225e-01  9.50763840e-03  3.01934063e-01  9.54053327e-02\n",
      " -2.44402543e-01 -3.79010797e-01 -5.88395372e-02 -4.40199748e-02\n",
      " -1.11363702e-01 -8.84164423e-02 -2.20835090e-01 -3.07671189e-01\n",
      "  1.61954433e-01  7.95572549e-02  1.71520874e-01 -1.36732295e-01\n",
      "  1.47982955e-01 -4.92348373e-01 -2.22155154e-01  2.51630098e-01\n",
      " -3.85898328e-03 -2.17582107e-01  1.46247104e-01 -3.74597490e-01\n",
      " -2.63645351e-01 -2.61506647e-01 -1.43259704e-01 -2.08441943e-01\n",
      "  6.86226562e-02 -1.28226429e-01  9.25220642e-03 -5.43437541e-01\n",
      "  6.74798787e-02 -9.89551023e-02 -2.16658786e-01 -1.87062591e-01\n",
      "  2.00958326e-02  1.21350922e-02 -3.40406299e-01  6.68470189e-02\n",
      " -3.14924687e-01  5.75044490e-02  7.02423826e-02  9.79726538e-02\n",
      " -3.29294086e-01 -9.13244858e-02 -2.41546631e-01  1.11593805e-01\n",
      " -1.19346038e-01 -1.37059549e-02 -1.50617138e-01 -1.44363686e-01\n",
      " -1.19352467e-01 -2.49486715e-01  3.98000062e-01  6.49918839e-02\n",
      " -2.85548747e-01 -2.82972932e-01 -1.05758771e-01  1.54965937e-01\n",
      " -2.69289553e-01 -1.51202261e-01 -2.54568011e-01  1.41554162e-01\n",
      "  7.83326998e-02 -2.22430855e-01 -2.98788488e-01  1.69278994e-01\n",
      "  2.39692539e-01 -2.43882284e-01]\n",
      "L4N0                    -> L5N91 = [-1.07375793e-01  1.09930612e-01 -1.26406461e-01  3.11464742e-02\n",
      "  1.64310440e-01 -2.90751249e-01  2.68662155e-01  1.19619861e-01\n",
      "  2.55913168e-01 -4.25876856e-01 -5.19328535e-01 -1.08475819e-01\n",
      "  2.21376806e-01  7.44910017e-02 -2.17460245e-01  1.28144309e-01\n",
      "  2.73911119e-01 -1.36674404e-01  1.43143550e-01 -1.64426655e-01\n",
      "  4.21636552e-01 -2.08281651e-01  1.55774066e-02  7.92972371e-02\n",
      " -8.73404145e-02  1.29142255e-01  7.38108084e-02  6.43054247e-02\n",
      "  7.55116791e-02  1.60539374e-01  5.04631288e-02  1.88118771e-01\n",
      "  3.23827654e-01 -1.97963595e-01  1.91432238e-01  6.72751619e-03\n",
      " -8.77514761e-03  7.65267089e-02  9.35201049e-02  1.20955128e-02\n",
      "  8.57137442e-02  2.26913258e-01  3.24608028e-01  3.03469002e-02\n",
      " -2.39757802e-02 -9.38157663e-02 -1.77211732e-01 -5.35724461e-01\n",
      "  3.37014049e-01  2.42945045e-01  7.16664596e-03  1.86837107e-01\n",
      "  1.99652269e-01 -7.20199570e-02 -1.07892957e-02  4.81059700e-02\n",
      " -2.62248665e-02  8.85147378e-02  3.40218782e-01 -3.47974747e-01\n",
      "  2.90196747e-01 -4.07165848e-02 -2.83116400e-01 -8.26088805e-03\n",
      "  6.56577349e-02  2.64114797e-01  1.18351422e-01 -1.88828893e-02\n",
      " -4.83750731e-01 -2.26579145e-01  1.70754075e-01 -1.32418975e-01\n",
      "  3.23908001e-01  4.18157279e-01 -2.43702501e-01 -1.55815095e-01\n",
      "  1.39507607e-01  5.81788272e-02  5.27641535e-01  1.10908829e-01\n",
      " -1.45652235e-01  3.09988201e-01  2.70919740e-01 -2.12186858e-01\n",
      "  6.52038902e-02  4.25496250e-02  7.94235792e-04  7.95307457e-02\n",
      "  4.67946865e-02 -2.66367823e-01  7.18990415e-02 -1.75416082e-01\n",
      "  2.50898331e-01  2.84994632e-01  3.04926485e-01  9.45645720e-02\n",
      " -2.28639588e-01  5.79297282e-02  1.07898146e-01 -1.14030298e-02\n",
      "  2.63854891e-01  3.71467084e-01 -3.93282712e-01  3.99064366e-03\n",
      " -1.85276747e-01  3.64694685e-01 -3.67351115e-01  2.59203643e-01\n",
      " -1.65732920e-01 -8.10271427e-02  4.43699390e-01  1.29792824e-01\n",
      "  2.08878890e-01  4.36911643e-01  1.53204158e-01 -3.91188785e-02\n",
      "  8.77914727e-02 -1.42207697e-01 -2.07893997e-01 -2.53741294e-01\n",
      "  1.97407097e-01  1.41581059e-01 -1.84991360e-01 -9.63573009e-02\n",
      " -1.00665621e-01 -5.18886559e-02 -3.41772214e-02  1.28398970e-01\n",
      " -2.90426284e-01  1.92486405e-01 -1.01696132e-04  2.14235038e-02\n",
      "  2.24133320e-02 -4.54112768e-01  2.10314840e-01  1.96319535e-01\n",
      "  6.87994510e-02  7.15165660e-02  1.61287963e-01  2.59781390e-01\n",
      "  1.33942127e-01 -7.11771771e-02 -1.48372799e-01  2.75179118e-01\n",
      " -1.14365436e-01  5.45983501e-02  5.77607229e-02 -3.38540792e-01\n",
      "  2.37897769e-01 -2.03329638e-01]\n",
      "L4N0                    -> L5N92 = [-0.05102982 -0.13723546  0.01846292 -0.22876291  0.37905547  0.01708173\n",
      "  0.08569746 -0.40034395 -0.2547616   0.13029431  0.34160832  0.08176067\n",
      " -0.0961251   0.15378247 -0.44577354 -0.31350845  0.15368319  0.06657254\n",
      "  0.19270991  0.07261112 -0.08605137  0.14808081 -0.40694103 -0.33158508\n",
      " -0.05329893  0.22563821 -0.00406276 -0.0196629  -0.1162573  -0.05837803\n",
      "  0.11757076 -0.44589242  0.13648029  0.09533247 -0.05239522 -0.40928635\n",
      " -0.22822192  0.05212066  0.30750218 -0.04641692 -0.06813211  0.13375865\n",
      " -0.44260794  0.26397723 -0.29730245  0.05260031 -0.23394138  0.38783243\n",
      " -0.41218847  0.26559597 -0.12914973  0.2109302  -0.4261696   0.27769697\n",
      " -0.14494255  0.1580721   0.07574124 -0.19184989 -0.1296793   0.19406223\n",
      "  0.45664617  0.03624067 -0.20091574  0.3985962   0.12209897  0.0061125\n",
      "  0.03826113 -0.23302415  0.10089067 -0.19942287 -0.20014541  0.19504148\n",
      " -0.16867559 -0.4557445  -0.1174758  -0.16301723 -0.47458285  0.0141433\n",
      " -0.30594236 -0.05226313  0.26015726  0.15019369  0.33353293 -0.17568034\n",
      "  0.12902075  0.21962443 -0.26431054  0.22443175  0.34618545  0.07318578\n",
      "  0.01240713 -0.06621762  0.43272522 -0.0818734  -0.10953142  0.01171708\n",
      "  0.09889285  0.107889   -0.1316677   0.14077684  0.22405298 -0.3526781\n",
      "  0.07732107  0.02477381  0.10481466 -0.1433138   0.19530907 -0.15883444\n",
      "  0.23853938 -0.11260483 -0.46302095 -0.17175174  0.09891196 -0.18047908\n",
      " -0.20588085 -0.2985446  -0.29931006 -0.25863022  0.09302665 -0.15204093\n",
      " -0.22098643  0.10416175 -0.28876603 -0.42991054 -0.29489353  0.0275505\n",
      " -0.34914392  0.18108061  0.03833096  0.11659482 -0.22689705  0.34762856\n",
      " -0.18519033  0.10360526 -0.0365679   0.1016505  -0.26504052  0.20459512\n",
      "  0.43102103 -0.12632178 -0.3898666  -0.2109659  -0.24478571 -0.12291993\n",
      "  0.39312294  0.32076326 -0.01386131  0.20739347 -0.25146395  0.04442984]\n",
      "L4N0                    -> L5N93 = [ 0.17553058  0.07994627 -0.1888731   0.06976797 -0.0358843  -0.22465993\n",
      " -0.07259524 -0.36078358 -0.17401841 -0.09469435  0.01980469  0.00451126\n",
      " -0.06911605 -0.08279169  0.10408674  0.02298434  0.3576491   0.3009018\n",
      " -0.01936921 -0.45690864  0.21854153  0.15397374  0.15860774  0.45994166\n",
      "  0.08937851 -0.07135715 -0.13626756 -0.4506325  -0.06516345  0.06274165\n",
      " -0.07210071  0.19386362  0.10471359 -0.32094994 -0.07469139  0.31156355\n",
      "  0.1372216   0.06477813 -0.04753334 -0.09656106 -0.16804291 -0.01105926\n",
      "  0.03273136  0.01208014  0.10962304  0.27416924  0.06342736  0.21932341\n",
      "  0.22722545 -0.20607515  0.12350712  0.09200406  0.0507443  -0.10424139\n",
      "  0.40293813  0.09016594 -0.1719711   0.36089882  0.23534016  0.0237754\n",
      " -0.16772126 -0.19700398 -0.04163968 -0.5033678   0.07519586  0.45531547\n",
      " -0.21968514 -0.01125253  0.05319708  0.268976    0.28938794  0.04513521\n",
      "  0.29738963  0.10255857 -0.24100941  0.01075999  0.10651248  0.0723647\n",
      "  0.21083517 -0.11290625  0.14900324 -0.6151264  -0.34893522 -0.00977048\n",
      " -0.3118652   0.20180738 -0.07482816 -0.07148748 -0.0905212  -0.14055333\n",
      "  0.2891159   0.1927065  -0.43541402  0.1458066   0.12620762  0.00477272\n",
      "  0.17757678  0.28208166  0.41826907 -0.18708749 -0.01466382 -0.18439627\n",
      "  0.02961131 -0.03406085 -0.6080989   0.04971811 -0.11332604  0.62160325\n",
      " -0.01292422 -0.45097762  0.37983942  0.22265638 -0.07108476  0.0624131\n",
      " -0.16567151 -0.0501339  -0.09914614 -0.16003253 -0.16249841  0.17744234\n",
      "  0.05482344  0.14880332 -0.09019655  0.07422837  0.30836436  0.06803522\n",
      "  0.18752383 -0.56236976 -0.3946898   0.13308914  0.13952461 -0.04139554\n",
      "  0.05733809 -0.18318065  0.20967028  0.10517875  0.4049449  -0.07995286\n",
      " -0.04036488 -0.15067266  0.19684209 -0.12338962  0.18765797  0.45386893\n",
      "  0.05906452  0.1296227   0.14849076 -0.03587563  0.13767695 -0.03261384]\n",
      "L4N0                    -> L5N94 = [-0.07092571 -0.2323925   0.09430619  0.04008726  0.06407524 -0.0645852\n",
      "  0.01960357 -0.26330608 -0.14449236 -0.00549683  0.01064658  0.00311793\n",
      "  0.06381887  0.24767178  0.16868912 -0.01700166 -0.21600695 -0.06690829\n",
      "  0.26683378  0.02598887 -0.13552687  0.05456281 -0.19623908  0.04796944\n",
      "  0.3103933  -0.10478867 -0.38241255  0.03442241  0.4393914  -0.36428657\n",
      "  0.0466689  -0.1986907   0.07050876 -0.21374172  0.10503995  0.1450374\n",
      "  0.37916127 -0.08262751 -0.21360837  0.09948491 -0.04142025  0.09678563\n",
      " -0.12718976 -0.05326134  0.00640703 -0.18649197  0.0549356  -0.11495075\n",
      "  0.32361203 -0.3820102  -0.03045378  0.47599143 -0.5226954  -0.1737815\n",
      " -0.1029681  -0.1083754  -0.4132281   0.14921725  0.23608436 -0.03437994\n",
      " -0.16655134 -0.11435258  0.1897916  -0.24194625  0.06793796 -0.29255447\n",
      "  0.5360036   0.1364455  -0.06900083  0.12731737 -0.03110698  0.07070032\n",
      " -0.03185898  0.28237188  0.08877192 -0.21473382 -0.336582   -0.55091494\n",
      " -0.20721714  0.04507147 -0.20696375 -0.01176294 -0.36243027  0.21057294\n",
      "  0.4584893  -0.12929544 -0.10962618  0.28806436 -0.3123264  -0.41337743\n",
      " -0.02803805 -0.18687841 -0.06046991  0.00383187  0.23712492  0.05379011\n",
      " -0.08114016  0.20725867 -0.26008037 -0.12613676  0.07094866 -0.00401269\n",
      " -0.424639   -0.13445485 -0.35657236  0.10020199  0.12723681  0.2572896\n",
      " -0.18683824 -0.36762857 -0.04929005 -0.15044664  0.3809119  -0.11739963\n",
      " -0.23250754  0.12406407 -0.1819938  -0.23546723  0.14813168  0.02313576\n",
      "  0.02799582  0.1262005  -0.03976861  0.01528869  0.00630485  0.11396372\n",
      " -0.4157887  -0.21407762 -0.20230685 -0.60266155 -0.10947485  0.21921866\n",
      "  0.03023099  0.15652736 -0.10729624 -0.05948716  0.11930686 -0.00435552\n",
      " -0.0868135   0.21742284  0.07229776 -0.04627735  0.28993833 -0.02642228\n",
      " -0.20660111  0.0928833   0.4387414   0.02790784 -0.09164312  0.11841145]\n",
      "L4N0                    -> L5N95 = [ 7.13004023e-02  1.42996535e-01  3.48878652e-01 -3.88434201e-01\n",
      "  1.25220194e-01  2.15637296e-01 -2.09882915e-01 -5.97586811e-01\n",
      "  3.58676374e-01  1.17073104e-01 -8.84468555e-02  3.06359679e-01\n",
      " -2.21713498e-01  2.59692013e-01  1.32833585e-01  1.48922697e-01\n",
      "  3.03853140e-03 -9.89919752e-02 -2.76475400e-01 -1.18393414e-01\n",
      "  3.55551764e-02 -2.13313531e-02  2.26693392e-01  5.05388916e-01\n",
      " -7.46517256e-02  2.70831227e-01 -1.59615353e-01  7.93330073e-02\n",
      "  1.31664738e-01 -3.68139207e-01 -2.12347448e-01  1.24227546e-01\n",
      " -5.46059432e-03  1.34975865e-01  4.08677638e-01  2.70040557e-02\n",
      " -4.38210458e-01 -3.55941862e-01  9.38733071e-02 -1.00174816e-02\n",
      " -2.65379667e-01  8.47643316e-02 -2.47637570e-01 -5.29938221e-01\n",
      " -1.21233746e-01  6.98694512e-02 -1.51371673e-01  1.22421384e-01\n",
      " -2.34483317e-01 -6.69711351e-01  5.01852017e-03 -1.35210961e-01\n",
      "  2.31834412e-01 -6.13821089e-01 -1.57067612e-01 -7.48907626e-02\n",
      "  6.01443350e-01 -2.10232913e-01 -5.94328828e-02  7.14249536e-02\n",
      "  1.37082011e-01  7.14057162e-02 -5.42234063e-01  2.68805683e-01\n",
      " -7.16574863e-02  1.98437586e-01 -6.39666393e-02 -3.21727604e-01\n",
      "  3.74575526e-01 -2.30253100e-01 -2.82086492e-01 -2.76292175e-01\n",
      "  2.30341971e-01  1.23816773e-01  1.85412407e-01  8.52512270e-02\n",
      " -1.23429313e-01 -9.84154642e-02 -3.11254144e-01  1.35253802e-01\n",
      " -1.58657044e-01  5.68336323e-02 -4.24458236e-01 -2.44425207e-01\n",
      "  1.28695071e-01 -4.23310459e-01  3.03715058e-02  4.52066399e-02\n",
      " -3.05357337e-01  2.28956118e-02  7.10116103e-02 -2.96791673e-01\n",
      "  4.13703881e-02 -3.71378332e-01 -9.38743725e-02  1.37559488e-01\n",
      "  2.31206268e-02  2.73149684e-02 -1.99544609e-01 -3.53577249e-02\n",
      "  1.32913440e-01 -5.44784546e-01  1.20294066e-02 -1.74952477e-01\n",
      " -2.97446012e-01 -1.08854063e-01  3.58916745e-02 -1.16050161e-01\n",
      "  2.10722938e-01  9.61950272e-02  5.97685352e-02  2.36653164e-02\n",
      " -3.36720884e-01 -1.19292088e-01  1.37299076e-01  2.53283143e-01\n",
      "  1.85453534e-01 -6.89937100e-02 -3.79251361e-01 -4.30355854e-02\n",
      "  2.82562464e-01 -2.10843310e-01  4.06767316e-02 -5.20739794e-01\n",
      " -4.22486186e-01 -1.22132376e-01  9.90851447e-02  1.52714372e-01\n",
      "  1.27152294e-01 -2.36913949e-01 -2.31465772e-02  2.96690971e-01\n",
      "  5.69188595e-02 -2.28698179e-02 -6.54037520e-02 -1.89814121e-01\n",
      " -1.54903904e-01  9.38415602e-02 -2.26677731e-01 -6.01627111e-01\n",
      " -1.04133651e-01  4.44654259e-04  1.11453883e-01 -8.98474678e-02\n",
      "  2.25162819e-01 -2.39215121e-01 -2.72673786e-01 -4.49143760e-02\n",
      "  3.34767044e-01  1.24589294e-01]\n",
      "L4N0                    -> L5N96 = [ 0.23520175 -0.30468515  0.22033545 -0.30461377  0.02031353  0.10625382\n",
      "  0.06882199 -0.12146864  0.05603509 -0.0131671  -0.22192529  0.18994094\n",
      "  0.1312779  -0.49884322 -0.12794529 -0.02815052 -0.03977387  0.01825279\n",
      "  0.2262514  -0.14228842 -0.1196218  -0.00589276  0.19378091 -0.30742946\n",
      "  0.30548173 -0.46215937 -0.0409471  -0.4145503  -0.427952    0.20185582\n",
      " -0.32197866  0.10035907 -0.21105276 -0.3024875   0.04574237  0.09400921\n",
      " -0.11328467  0.2806589   0.20114599 -0.01524482 -0.512871   -0.16922307\n",
      "  0.0171948   0.25043216  0.53734463  0.23282412 -0.14252545 -0.02677337\n",
      "  0.20731093 -0.14446147 -0.26098028 -0.07273393  0.08085984  0.29341084\n",
      " -0.16844536 -0.0209696   0.2888881   0.00845541 -0.4612033  -0.2816585\n",
      " -0.22725588 -0.35288453  0.28219125  0.27228233  0.6407303   0.36266956\n",
      "  0.13761199 -0.03126765  0.1034518   0.03998427  0.08934253  0.34572867\n",
      "  0.15519425 -0.27537686 -0.08354019  0.32810435 -0.05563236  0.14930904\n",
      "  0.12617792  0.2911422  -0.4615299  -0.45334798  0.0424355   0.01744592\n",
      " -0.14340702  0.04039522 -0.01344288  0.31679612 -0.44078878  0.37519732\n",
      "  0.2879137   0.0718782  -0.27963358  0.30157846 -0.1253873  -0.11642827\n",
      "  0.00662715  0.13275652 -0.22559959 -0.5235624   0.4046298  -0.07543191\n",
      "  0.20823808 -0.1751765   0.00597605 -0.04942803 -0.02078131  0.48181972\n",
      "  0.5832226   0.4581571  -0.12862492  0.12097257 -0.187863    0.12790816\n",
      "  0.46409383  0.3337293  -0.1396304  -0.02722865 -0.03191013  0.30671817\n",
      " -0.4515565  -0.11591827  0.02004021  0.00252512  0.23319216  0.15864111\n",
      "  0.15521024 -0.03267001 -0.00680053  0.35767496 -0.01985368  0.00257687\n",
      " -0.08992893  0.03320345 -0.41414008 -0.03611407  0.19836375 -0.01366295\n",
      " -0.08436625 -0.15773913 -0.09595618  0.23856375  0.26902413 -0.48702297\n",
      "  0.29710057  0.29187006 -0.14490925 -0.25645778  0.35985586 -0.26736146]\n",
      "L4N0                    -> L5N97 = [-0.36400256 -0.36154798 -0.52963734 -0.29051906  0.01601403  0.34288898\n",
      " -0.24207982  0.0533674  -0.26115918  0.05026639 -0.23558216  0.37344083\n",
      " -0.5740096  -0.34257287 -0.05374658  0.30800503  0.5258744   0.0549649\n",
      " -0.03891473  0.1899081   0.01442219 -0.5412088   0.00785225 -0.5891821\n",
      " -0.51528084  0.08865317  0.14095558 -0.10736477  0.323687   -0.15617299\n",
      " -0.16077213  0.38297147 -0.05271287 -0.22906774 -0.05817975 -0.38550663\n",
      "  0.05395947 -0.40737274 -0.16761588 -0.32804763 -0.01315898  0.5664873\n",
      "  0.27541044 -0.3593689  -0.09046884  0.13955148 -0.11830697  0.3235977\n",
      "  0.06801807 -0.0762706  -0.10378846 -0.17538558  0.03453717 -0.0158748\n",
      "  0.31422365 -0.37421343  0.35634896  0.15386543  0.08697296 -0.24321301\n",
      " -0.04428041 -0.102011    0.11757676  0.09463228 -0.07022582  0.349413\n",
      " -0.21984816  0.1713377  -0.28044748 -0.10208132 -0.3499556  -0.5649729\n",
      "  0.1311645  -0.17130853  0.10791023  0.18760946 -0.13118166  0.10327926\n",
      "  0.46171728  0.12751524 -0.14453194 -0.403294   -0.23335394 -0.2859579\n",
      " -0.30573598  0.07247142  0.3671538   0.5094488  -0.0240737  -0.04233068\n",
      "  0.38504615 -0.2759631  -0.29145867  0.0562403  -0.14849553  0.37739357\n",
      "  0.09105671 -0.07360492 -0.41385615 -0.049574    0.20802027 -0.20020185\n",
      "  0.2991583  -0.08721624 -0.19323088  0.32076973 -0.05598651  0.2661622\n",
      "  0.47759163 -0.04763204 -0.01811526  0.45305336 -0.17565058  0.20119481\n",
      " -0.16531412 -0.23880409  0.01986268  0.4462908   0.20135969 -0.31299835\n",
      "  0.62408346 -0.15298572  0.09022465 -0.4304206  -0.36003163  0.09984599\n",
      " -0.13725805 -0.14630076  0.01845178 -0.04195311  0.12597394  0.1183887\n",
      " -0.12088273  0.21375613  0.35920903  0.23865162  0.42454404 -0.68120694\n",
      "  0.55579203 -0.25673002 -0.4372326   0.20927149 -0.33150002  0.3174604\n",
      "  0.1652105  -0.23272625 -0.2883644  -0.10489205  0.41436931 -0.10744924]\n",
      "L4N0                    -> L5N98 = [ 0.21100637  0.57699734  0.09494616 -0.3011463  -0.436508   -0.04701299\n",
      "  0.32348007  0.27301207 -0.12257504  0.13063575 -0.17429279 -0.25881752\n",
      "  0.47159815 -0.08993683 -0.12775046 -0.2660698   0.08461406 -0.36717167\n",
      "  0.24050029 -0.10535036  0.00450304  0.14439285 -0.0141307   0.29856864\n",
      " -0.18289453 -0.21515122 -0.08215367  0.43926346 -0.3017878   0.15558226\n",
      " -0.23715977 -0.2123718  -0.27230465  0.10246081  0.04279384 -0.03355209\n",
      " -0.5338065   0.26511523  0.3219386   0.13239898 -0.17790887 -0.19505583\n",
      " -0.39031115 -0.25008997  0.28537425 -0.11099361 -0.20186315  0.10519382\n",
      "  0.09149134 -0.02791292  0.29759008  0.0439055  -0.17457615 -0.28320435\n",
      " -0.13272063  0.3427995  -0.2696325   0.09705631 -0.2040217  -0.5977591\n",
      " -0.26984683 -0.47408262 -0.10689951  0.22577778 -0.01155662 -0.22209878\n",
      " -0.16245945  0.19223332  0.10418943  0.0832172  -0.17498283  0.11799305\n",
      " -0.20866251 -0.12411337 -0.18000844  0.12859732 -0.4330096   0.0324067\n",
      " -0.01097179 -0.63374615  0.2855246   0.09073254  0.48786837  0.4193022\n",
      " -0.42571157 -0.20399259 -0.17472821  0.09418666  0.04065635 -0.02831226\n",
      " -0.07612241  0.28580958  0.1314801   0.34707418 -0.04363662 -0.17792004\n",
      " -0.01430514  0.1516926  -0.09854071 -0.10269117 -0.4507335  -0.01729788\n",
      " -0.43918493 -0.13069607  0.11992259  0.16557366 -0.00337556 -0.13174197\n",
      " -0.18383138  0.03169198 -0.10935482 -0.07173863  0.01086275 -0.20419861\n",
      " -0.03567706 -0.1176866  -0.36281046 -0.17672823  0.04268817  0.18385181\n",
      " -0.25725985  0.1178689  -0.56716424  0.05468766  0.24360608  0.21067284\n",
      " -0.13254897 -0.130934   -0.05489138 -0.22579041 -0.47234118  0.26371482\n",
      " -0.39357007 -0.04132687 -0.00807761 -0.08835281 -0.06851176  0.03293086\n",
      "  0.17774001 -0.286525    0.5145348  -0.03739047  0.55705345  0.49986434\n",
      " -0.3281825   0.48665586 -0.13270283 -0.4238701  -0.1432393   0.28950432]\n",
      "L4N0                    -> L5N99 = [ 2.07258359e-01 -1.85194120e-01  1.66046441e-01 -2.93455482e-01\n",
      " -3.67332518e-01 -2.56617907e-02 -2.75821120e-01  1.15770377e-01\n",
      "  2.31897365e-02 -6.80762678e-02 -3.59739244e-01 -2.00398326e-01\n",
      "  1.75530881e-01  7.47956857e-02  6.23670280e-01  1.15756355e-01\n",
      " -2.52879918e-01 -1.47434305e-02 -1.78557202e-01 -2.99863815e-01\n",
      "  2.35554919e-01  1.44598216e-01 -2.74796560e-02  3.35839838e-01\n",
      "  4.39731777e-01 -3.15270633e-01 -2.79708713e-01 -3.96926440e-02\n",
      "  1.36011153e-01  3.98715492e-03 -1.45059437e-01 -1.90557837e-02\n",
      "  1.07557923e-01  4.45214838e-01 -4.66148913e-01 -1.01322234e-01\n",
      " -2.28780285e-01  6.14356026e-02  3.59943300e-01  1.33966446e-01\n",
      "  5.74363209e-02  1.44760996e-01 -2.61765439e-02 -3.33958954e-01\n",
      " -1.21680751e-01 -3.96238804e-01  4.90175337e-02 -4.84780669e-01\n",
      " -1.14511691e-01  4.28766221e-01  2.11146086e-01 -1.05137803e-01\n",
      " -2.74355382e-01  2.22981349e-01  4.61089045e-01  2.07546055e-01\n",
      "  1.29121631e-01 -1.20832235e-01 -3.31578881e-01 -7.19338953e-02\n",
      "  7.81289022e-03 -4.10524726e-01 -1.77858740e-01  1.73847571e-01\n",
      " -2.10008875e-01 -2.12039858e-01  2.24631513e-04  1.05904229e-01\n",
      "  5.74907586e-02  2.09872723e-01  2.40468293e-01  3.27320904e-01\n",
      " -2.21095830e-01 -1.58806264e-01 -2.09134575e-02 -2.28467956e-01\n",
      " -1.97916806e-01 -2.33270124e-01 -1.76551729e-03 -5.48512638e-01\n",
      "  3.66313313e-03  3.27988505e-01  5.61471134e-02 -2.97223687e-01\n",
      " -2.77394503e-02  2.16679260e-01 -4.30543214e-01 -2.87760228e-01\n",
      "  2.73570627e-01 -1.55680170e-02 -8.95936936e-02  1.48305133e-01\n",
      "  4.99402508e-02 -2.17867494e-01  3.41361135e-01 -6.34167623e-03\n",
      " -2.39583269e-01 -3.50553840e-01  6.63864911e-02  3.40306871e-02\n",
      " -5.05539216e-02  1.91883564e-01 -5.05999103e-02  7.36200884e-02\n",
      "  1.71018004e-01 -3.12041104e-01 -6.96067363e-02 -2.64221784e-02\n",
      " -1.40092894e-01  3.25209573e-02 -8.27770010e-02  8.66575316e-02\n",
      " -1.92277879e-01 -1.72644574e-02  1.75652895e-02  1.36007726e-01\n",
      " -2.67217129e-01  1.39451429e-01 -9.05595198e-02  6.26996607e-02\n",
      "  1.50063321e-01 -4.82152343e-01 -3.50796193e-01  2.84133196e-01\n",
      "  7.22306892e-02 -8.15559775e-02  6.98700547e-02  2.21289054e-01\n",
      " -5.54153800e-01 -2.26848438e-01 -2.46546611e-01 -1.87440202e-01\n",
      " -2.70085245e-01 -3.49949449e-01 -1.10422358e-01  4.53246459e-02\n",
      "  7.46243745e-02  3.28202471e-02 -2.21239865e-01  1.60177261e-01\n",
      " -5.02801277e-02 -1.00000657e-01 -4.23186362e-01 -1.86920062e-01\n",
      " -4.78159606e-01 -4.61333007e-01 -5.78402951e-02 -7.62948275e-01\n",
      " -1.29841387e-01 -4.57986332e-02]\n",
      "L4N1                    -> L5N0 = -0.14822746813297272\n",
      "L4N1                    -> L5N1 = -0.009434619918465614\n",
      "L4N1                    -> L5N2 = -0.18039806187152863\n",
      "L4N1                    -> L5N3 = -0.18977195024490356\n",
      "L4N1                    -> L5N4 = -0.36160558462142944\n",
      "L4N1                    -> L5N5 = -0.11676635593175888\n",
      "L4N1                    -> L5N6 = -0.25702083110809326\n",
      "L4N1                    -> L5N7 = -0.2779483497142792\n",
      "L4N1                    -> L5N8 = 0.16115978360176086\n",
      "L4N1                    -> L5N9 = 0.024724287912249565\n",
      "L4N1                    -> L5N10 = -0.30443233251571655\n",
      "L4N1                    -> L5N11 = 0.13720948994159698\n",
      "L4N1                    -> L5N12 = -0.036727678030729294\n",
      "L4N1                    -> L5N13 = -0.0921606495976448\n",
      "L4N1                    -> L5N14 = 0.027176549658179283\n",
      "L4N1                    -> L5N15 = -0.07999435067176819\n",
      "L4N1                    -> L5N16 = -0.2894335091114044\n",
      "L4N1                    -> L5N17 = 0.0682385042309761\n",
      "L4N1                    -> L5N18 = -0.31468653678894043\n",
      "L4N1                    -> L5N19 = -0.20795021951198578\n",
      "L4N1                    -> L5N20 = -0.41146326065063477\n",
      "L4N1                    -> L5N21 = 0.209706112742424\n",
      "L4N1                    -> L5N22 = 0.12501388788223267\n",
      "L4N1                    -> L5N23 = 0.07935439795255661\n",
      "L4N1                    -> L5N24 = 0.014657665975391865\n",
      "L4N1                    -> L5N25 = -0.26659584045410156\n",
      "L4N1                    -> L5N26 = -0.16339224576950073\n",
      "L4N1                    -> L5N27 = -0.4391901195049286\n",
      "L4N1                    -> L5N28 = -0.35439959168434143\n",
      "L4N1                    -> L5N29 = -0.33273977041244507\n",
      "L4N1                    -> L5N30 = -0.2966555058956146\n",
      "L4N1                    -> L5N31 = -0.36348891258239746\n",
      "L4N1                    -> L5N32 = -0.13285231590270996\n",
      "L4N1                    -> L5N33 = -0.44843998551368713\n",
      "L4N1                    -> L5N34 = -0.045349378138780594\n",
      "L4N1                    -> L5N35 = -0.008312002755701542\n",
      "L4N1                    -> L5N36 = -0.039391033351421356\n",
      "L4N1                    -> L5N37 = -0.14161716401576996\n",
      "L4N1                    -> L5N38 = -0.2923390865325928\n",
      "L4N1                    -> L5N39 = 0.07846381515264511\n",
      "L4N1                    -> L5N40 = -0.11398028582334518\n",
      "L4N1                    -> L5N41 = -0.5766370296478271\n",
      "L4N1                    -> L5N42 = -0.01718687079846859\n",
      "L4N1                    -> L5N43 = -0.1392812579870224\n",
      "L4N1                    -> L5N44 = 0.05978134647011757\n",
      "L4N1                    -> L5N45 = -0.028412500396370888\n",
      "L4N1                    -> L5N46 = 0.015350723639130592\n",
      "L4N1                    -> L5N47 = 0.14436306059360504\n",
      "L4N1                    -> L5N48 = -0.0127730006352067\n",
      "L4N1                    -> L5N49 = -0.2155778557062149\n",
      "L4N1                    -> L5N50 = 0.1353914439678192\n",
      "L4N1                    -> L5N51 = -0.3329680263996124\n",
      "L4N1                    -> L5N52 = 0.025840217247605324\n",
      "L4N1                    -> L5N53 = -0.19573859870433807\n",
      "L4N1                    -> L5N54 = 0.07739795744419098\n",
      "L4N1                    -> L5N55 = -0.20712649822235107\n",
      "L4N1                    -> L5N56 = 0.3086127042770386\n",
      "L4N1                    -> L5N57 = -0.16915659606456757\n",
      "L4N1                    -> L5N58 = -0.16375869512557983\n",
      "L4N1                    -> L5N59 = -0.2170906811952591\n",
      "L4N1                    -> L5N60 = -0.019940201193094254\n",
      "L4N1                    -> L5N61 = -0.29044654965400696\n",
      "L4N1                    -> L5N62 = -0.2279009222984314\n",
      "L4N1                    -> L5N63 = 0.006114852149039507\n",
      "L4N1                    -> L5N64 = 0.038100406527519226\n",
      "L4N1                    -> L5N65 = 0.14383134245872498\n",
      "L4N1                    -> L5N66 = -0.021058570593595505\n",
      "L4N1                    -> L5N67 = -0.03881113603711128\n",
      "L4N1                    -> L5N68 = 0.308017373085022\n",
      "L4N1                    -> L5N69 = 0.09922566264867783\n",
      "L4N1                    -> L5N70 = 0.04183648154139519\n",
      "L4N1                    -> L5N71 = -0.11641905456781387\n",
      "L4N1                    -> L5N72 = -0.11848362535238266\n",
      "L4N1                    -> L5N73 = -0.10518833994865417\n",
      "L4N1                    -> L5N74 = -0.36921241879463196\n",
      "L4N1                    -> L5N75 = 0.16650211811065674\n",
      "L4N1                    -> L5N76 = -0.30294087529182434\n",
      "L4N1                    -> L5N77 = -2.5380964871146716e-05\n",
      "L4N1                    -> L5N78 = 0.07494578510522842\n",
      "L4N1                    -> L5N79 = -0.09773910790681839\n",
      "L4N1                    -> L5N80 = -0.21595004200935364\n",
      "L4N1                    -> L5N81 = 0.12913896143436432\n",
      "L4N1                    -> L5N82 = -0.2515276372432709\n",
      "L4N1                    -> L5N83 = -0.19976510107517242\n",
      "L4N1                    -> L5N84 = 0.10049151629209518\n",
      "L4N1                    -> L5N85 = -0.1093905121088028\n",
      "L4N1                    -> L5N86 = 0.1215008795261383\n",
      "L4N1                    -> L5N87 = -0.07957813888788223\n",
      "L4N1                    -> L5N88 = -0.2328016608953476\n",
      "L4N1                    -> L5N89 = 0.004336557351052761\n",
      "L4N1                    -> L5N90 = -0.12783436477184296\n",
      "L4N1                    -> L5N91 = -0.1399146169424057\n",
      "L4N1                    -> L5N92 = -0.29565009474754333\n",
      "L4N1                    -> L5N93 = 0.026112418621778488\n",
      "L4N1                    -> L5N94 = 0.024239834398031235\n",
      "L4N1                    -> L5N95 = -0.2064058482646942\n",
      "L4N1                    -> L5N96 = -0.05923643335700035\n",
      "L4N1                    -> L5N97 = -0.16158993542194366\n",
      "L4N1                    -> L5N98 = -0.2646169364452362\n",
      "L4N1                    -> L5N99 = -0.32279521226882935\n",
      "L4N1                    -> L5N100 = -0.3548525869846344\n",
      "L4N1                    -> L5N101 = 0.23526014387607574\n",
      "L4N1                    -> L5N102 = 0.07680501788854599\n",
      "L4N1                    -> L5N103 = -0.07446446269750595\n",
      "L4N1                    -> L5N104 = -0.11096402257680893\n",
      "L4N1                    -> L5N105 = -0.2002437263727188\n",
      "L4N1                    -> L5N106 = -0.22332154214382172\n",
      "L4N1                    -> L5N107 = -0.47144776582717896\n",
      "L4N1                    -> L5N108 = 0.052524834871292114\n",
      "L4N1                    -> L5N109 = 0.02759641595184803\n",
      "L4N1                    -> L5N110 = 0.1329074203968048\n",
      "L4N1                    -> L5N111 = -0.31792908906936646\n",
      "L4N1                    -> L5N112 = -0.14893339574337006\n",
      "L4N1                    -> L5N113 = -0.1846567988395691\n",
      "L4N1                    -> L5N114 = -0.4291285574436188\n",
      "L4N1                    -> L5N115 = -0.09785926342010498\n",
      "L4N1                    -> L5N116 = -0.04517662152647972\n",
      "L4N1                    -> L5N117 = -0.05973035469651222\n",
      "L4N1                    -> L5N118 = -0.11421167105436325\n",
      "L4N1                    -> L5N119 = 0.05522147938609123\n",
      "L4N1                    -> L5N120 = -0.4410717487335205\n",
      "L4N1                    -> L5N121 = -0.08430451899766922\n",
      "L4N1                    -> L5N122 = 0.047588642686605453\n",
      "L4N1                    -> L5N123 = -0.24550315737724304\n",
      "L4N1                    -> L5N124 = -0.0954010859131813\n",
      "L4N1                    -> L5N125 = 0.03644746169447899\n",
      "L4N1                    -> L5N126 = 0.14558696746826172\n",
      "L4N1                    -> L5N127 = 0.05232919007539749\n",
      "L4N1                    -> L5N128 = -0.26330840587615967\n",
      "L4N1                    -> L5N129 = 0.20233659446239471\n",
      "L4N1                    -> L5N130 = -0.16682514548301697\n",
      "L4N1                    -> L5N131 = -0.1310604065656662\n",
      "L4N1                    -> L5N132 = -0.17373831570148468\n",
      "L4N1                    -> L5N133 = -0.04701154679059982\n",
      "L4N1                    -> L5N134 = 0.02525079995393753\n",
      "L4N1                    -> L5N135 = -0.4459250867366791\n",
      "L4N1                    -> L5N136 = -0.43648433685302734\n",
      "L4N1                    -> L5N137 = 0.01387723721563816\n",
      "L4N1                    -> L5N138 = -0.1305662840604782\n",
      "L4N1                    -> L5N139 = -0.0321861132979393\n",
      "L4N1                    -> L5N140 = -0.048605676740407944\n",
      "L4N1                    -> L5N141 = 0.029677147045731544\n",
      "L4N1                    -> L5N142 = -0.023286277428269386\n",
      "L4N1                    -> L5N143 = 0.09132321178913116\n",
      "L4N1                    -> L5N144 = -0.28527194261550903\n",
      "L4N1                    -> L5N145 = -0.15480934083461761\n",
      "L4N1                    -> L5N146 = -0.09799007326364517\n",
      "L4N1                    -> L5N147 = -0.2286357879638672\n",
      "L4N1                    -> L5N148 = -0.01236031111329794\n",
      "L4N1                    -> L5N149 = 0.0908021330833435\n",
      "L6N0                    -> L7N0 = 0.3764417767524719\n",
      "L6N0                    -> L7N1 = 0.34463995695114136\n",
      "L6N0                    -> L7N2 = 0.4487587511539459\n",
      "L6N0                    -> L7N3 = 0.2566995918750763\n",
      "L6N0                    -> L7N4 = 0.5122014880180359\n",
      "L6N0                    -> L7N5 = 0.26414671540260315\n",
      "L6N0                    -> L7N6 = 0.362657755613327\n",
      "L6N0                    -> L7N7 = 0.2148313969373703\n",
      "L6N0                    -> L7N8 = -0.050341829657554626\n",
      "L6N0                    -> L7N9 = 0.39825472235679626\n",
      "L6N0                    -> L7N10 = 0.33107393980026245\n",
      "L6N0                    -> L7N11 = 0.3994218409061432\n",
      "L6N0                    -> L7N12 = 0.3998302221298218\n",
      "L6N0                    -> L7N13 = 0.267814964056015\n",
      "L6N0                    -> L7N14 = 0.4612034261226654\n",
      "L6N0                    -> L7N15 = 0.281032919883728\n",
      "L6N0                    -> L7N16 = 0.2744362950325012\n",
      "L6N0                    -> L7N17 = 0.312433660030365\n",
      "L6N0                    -> L7N18 = 0.3296854794025421\n",
      "L6N0                    -> L7N19 = 0.24946428835391998\n",
      "L6N0                    -> L7N20 = 0.5097899436950684\n",
      "L6N0                    -> L7N21 = 0.21190199255943298\n",
      "L6N0                    -> L7N22 = 0.3836192190647125\n",
      "L6N0                    -> L7N23 = 0.16255077719688416\n",
      "L6N0                    -> L7N24 = 0.1878184974193573\n",
      "L6N0                    -> L7N25 = 0.27076026797294617\n",
      "L6N0                    -> L7N26 = 0.23599743843078613\n",
      "L6N0                    -> L7N27 = 0.32015910744667053\n",
      "L6N0                    -> L7N28 = 0.23308178782463074\n",
      "L6N0                    -> L7N29 = 0.3208767771720886\n",
      "L6N0                    -> L7N30 = 0.34996479749679565\n",
      "L6N0                    -> L7N31 = 0.5520082712173462\n",
      "L6N0                    -> L7N32 = 0.32836946845054626\n",
      "L6N0                    -> L7N33 = 0.381237655878067\n",
      "L6N0                    -> L7N34 = 0.4248895049095154\n",
      "L6N0                    -> L7N35 = 0.25761985778808594\n",
      "L6N0                    -> L7N36 = 0.2784038484096527\n",
      "L6N0                    -> L7N37 = 0.3709227740764618\n",
      "L6N0                    -> L7N38 = 0.22025597095489502\n",
      "L6N0                    -> L7N39 = 0.2534427046775818\n",
      "L6N0                    -> L7N40 = 0.2581523358821869\n",
      "L6N0                    -> L7N41 = 0.3973478376865387\n",
      "L6N0                    -> L7N42 = 0.5599585771560669\n",
      "L6N0                    -> L7N43 = 0.28728389739990234\n",
      "L6N0                    -> L7N44 = 0.4998815953731537\n",
      "L6N0                    -> L7N45 = 0.5017467141151428\n",
      "L6N0                    -> L7N46 = 0.26443761587142944\n",
      "L6N0                    -> L7N47 = 0.30063992738723755\n",
      "L6N0                    -> L7N48 = 0.2217503786087036\n",
      "L6N0                    -> L7N49 = 0.3133295476436615\n",
      "L6N0                    -> L7N50 = 0.31004196405410767\n",
      "L6N0                    -> L7N51 = 0.3062693774700165\n",
      "L6N0                    -> L7N52 = 0.438821405172348\n",
      "L6N0                    -> L7N53 = 0.43543556332588196\n",
      "L6N0                    -> L7N54 = 0.26994648575782776\n",
      "L6N0                    -> L7N55 = 0.4851692318916321\n",
      "L6N0                    -> L7N56 = 0.3864712417125702\n",
      "L6N0                    -> L7N57 = 0.27616289258003235\n",
      "L6N0                    -> L7N58 = 0.2667367458343506\n",
      "L6N0                    -> L7N59 = 0.34202349185943604\n",
      "L6N0                    -> L7N60 = 0.34163370728492737\n",
      "L6N0                    -> L7N61 = 0.43863487243652344\n",
      "L6N0                    -> L7N62 = 0.33107858896255493\n",
      "L6N0                    -> L7N63 = 0.3611855208873749\n",
      "L6N0                    -> L7N64 = 0.5417124032974243\n",
      "L6N0                    -> L7N65 = 0.5692634582519531\n",
      "L6N0                    -> L7N66 = 0.5149282813072205\n",
      "L6N0                    -> L7N67 = 0.3298320174217224\n",
      "L6N0                    -> L7N68 = 0.27495551109313965\n",
      "L6N0                    -> L7N69 = 0.260269433259964\n",
      "L6N0                    -> L7N70 = 0.23746271431446075\n",
      "L6N0                    -> L7N71 = 0.3603307008743286\n",
      "L6N0                    -> L7N72 = 0.40340131521224976\n",
      "L6N0                    -> L7N73 = 0.1515396237373352\n",
      "L6N0                    -> L7N74 = 0.41224798560142517\n",
      "L6N0                    -> L7N75 = 0.23123379051685333\n",
      "L6N0                    -> L7N76 = 0.5310204029083252\n",
      "L6N0                    -> L7N77 = 0.5334232449531555\n",
      "L6N0                    -> L7N78 = 0.36273932456970215\n",
      "L6N0                    -> L7N79 = 0.3951030671596527\n",
      "L6N0                    -> L7N80 = 0.2977757155895233\n",
      "L6N0                    -> L7N81 = 0.32918089628219604\n",
      "L6N0                    -> L7N82 = 0.30974259972572327\n",
      "L6N0                    -> L7N83 = 0.16843722760677338\n",
      "L6N0                    -> L7N84 = 0.2891826331615448\n",
      "L6N0                    -> L7N85 = 0.35893911123275757\n",
      "L6N0                    -> L7N86 = 0.14635337889194489\n",
      "L6N0                    -> L7N87 = 0.4430637061595917\n",
      "L6N0                    -> L7N88 = 0.2258569449186325\n",
      "L6N0                    -> L7N89 = 0.30639219284057617\n",
      "L6N0                    -> L7N90 = 0.20372416079044342\n",
      "L6N0                    -> L7N91 = 0.5691666007041931\n",
      "L6N0                    -> L7N92 = 0.3360585868358612\n",
      "L6N0                    -> L7N93 = 0.42680788040161133\n",
      "L6N0                    -> L7N94 = 0.12354333698749542\n",
      "L6N0                    -> L7N95 = 0.4644293785095215\n",
      "L6N0                    -> L7N96 = 0.40855270624160767\n",
      "L6N0                    -> L7N97 = 0.5358288288116455\n",
      "L6N0                    -> L7N98 = 0.20390018820762634\n",
      "L6N0                    -> L7N99 = 0.27828454971313477\n",
      "L6N0                    -> L7N100 = 0.47014865279197693\n",
      "L6N0                    -> L7N101 = 0.30132025480270386\n",
      "L6N0                    -> L7N102 = 0.35687685012817383\n",
      "L6N0                    -> L7N103 = 0.39318859577178955\n",
      "L6N0                    -> L7N104 = 0.31025466322898865\n",
      "L6N0                    -> L7N105 = 0.23689469695091248\n",
      "L6N0                    -> L7N106 = 0.5458475351333618\n",
      "L6N0                    -> L7N107 = 0.4543515741825104\n",
      "L6N0                    -> L7N108 = 0.34846439957618713\n",
      "L6N0                    -> L7N109 = 0.2799617350101471\n",
      "L6N0                    -> L7N110 = 0.34086450934410095\n",
      "L6N0                    -> L7N111 = 0.5081543326377869\n",
      "L6N0                    -> L7N112 = 0.26671212911605835\n",
      "L6N0                    -> L7N113 = 0.3588905334472656\n",
      "L6N0                    -> L7N114 = 0.6957039833068848\n",
      "L6N0                    -> L7N115 = 0.4010286331176758\n",
      "L6N0                    -> L7N116 = 0.5882793068885803\n",
      "L6N0                    -> L7N117 = 0.24548518657684326\n",
      "L6N0                    -> L7N118 = 0.47787830233573914\n",
      "L6N0                    -> L7N119 = 0.4803926944732666\n",
      "L6N0                    -> L7N120 = 0.3856907784938812\n",
      "L6N0                    -> L7N121 = 0.32234740257263184\n",
      "L6N0                    -> L7N122 = 0.2968406677246094\n",
      "L6N0                    -> L7N123 = 0.4039972722530365\n",
      "L6N0                    -> L7N124 = 0.7166442275047302\n",
      "L6N0                    -> L7N125 = 0.4660656154155731\n",
      "L6N0                    -> L7N126 = 0.5135089159011841\n",
      "L6N0                    -> L7N127 = 0.25451749563217163\n",
      "L6N0                    -> L7N128 = 0.5365278720855713\n",
      "L6N0                    -> L7N129 = 0.08235248923301697\n",
      "L6N0                    -> L7N130 = 0.3923150897026062\n",
      "L6N0                    -> L7N131 = 0.3484777808189392\n",
      "L6N0                    -> L7N132 = 0.3441005349159241\n",
      "L6N0                    -> L7N133 = 0.5301947593688965\n",
      "L6N0                    -> L7N134 = 0.3801252543926239\n",
      "L6N0                    -> L7N135 = 0.5689937472343445\n",
      "L6N0                    -> L7N136 = 0.47091811895370483\n",
      "L6N0                    -> L7N137 = 0.4008813798427582\n",
      "L6N0                    -> L7N138 = 0.25130897760391235\n",
      "L6N0                    -> L7N139 = 0.3315292000770569\n",
      "L6N0                    -> L7N140 = 0.4403400421142578\n",
      "L6N0                    -> L7N141 = 0.4998912811279297\n",
      "L6N0                    -> L7N142 = 0.5726646780967712\n",
      "L6N0                    -> L7N143 = 0.22251422703266144\n",
      "L6N0                    -> L7N144 = 0.31171953678131104\n",
      "L6N0                    -> L7N145 = 0.22019381821155548\n",
      "L6N0                    -> L7N146 = 0.25656190514564514\n",
      "L6N0                    -> L7N147 = 0.4824180006980896\n",
      "L6N0                    -> L7N148 = 0.3373238742351532\n",
      "L6N0                    -> L7N149 = 0.2454591691493988\n",
      "L6N1                    -> L7N0 = 0.03419993445277214\n",
      "L6N1                    -> L7N1 = 0.23705905675888062\n",
      "L6N1                    -> L7N2 = 0.35189998149871826\n",
      "L6N1                    -> L7N3 = 0.09331603348255157\n",
      "L6N1                    -> L7N4 = 0.3583967685699463\n",
      "L6N1                    -> L7N5 = -0.1497218906879425\n",
      "L6N1                    -> L7N6 = 0.28898394107818604\n",
      "L6N1                    -> L7N7 = -0.09727823734283447\n",
      "L6N1                    -> L7N8 = -0.014211323112249374\n",
      "L6N1                    -> L7N9 = 0.17994652688503265\n",
      "L6N1                    -> L7N10 = 0.0769684687256813\n",
      "L6N1                    -> L7N11 = 0.21995681524276733\n",
      "L6N1                    -> L7N12 = 0.22375090420246124\n",
      "L6N1                    -> L7N13 = 0.41827592253685\n",
      "L6N1                    -> L7N14 = 0.2851306200027466\n",
      "L6N1                    -> L7N15 = 0.008321213535964489\n",
      "L6N1                    -> L7N16 = -0.2205059826374054\n",
      "L6N1                    -> L7N17 = 0.05674714595079422\n",
      "L6N1                    -> L7N18 = 0.09405562281608582\n",
      "L6N1                    -> L7N19 = -0.007836363278329372\n",
      "L6N1                    -> L7N20 = 0.29751700162887573\n",
      "L6N1                    -> L7N21 = -0.2649216651916504\n",
      "L6N1                    -> L7N22 = 0.0396435484290123\n",
      "L6N1                    -> L7N23 = 0.04392559453845024\n",
      "L6N1                    -> L7N24 = 0.11043506860733032\n",
      "L6N1                    -> L7N25 = 0.12855610251426697\n",
      "L6N1                    -> L7N26 = -0.02622157149016857\n",
      "L6N1                    -> L7N27 = 0.09834818542003632\n",
      "L6N1                    -> L7N28 = -0.0017388073028996587\n",
      "L6N1                    -> L7N29 = 0.15033097565174103\n",
      "L6N1                    -> L7N30 = -0.22953397035598755\n",
      "L6N1                    -> L7N31 = 0.2598627209663391\n",
      "L6N1                    -> L7N32 = 0.11915096640586853\n",
      "L6N1                    -> L7N33 = 0.2514774799346924\n",
      "L6N1                    -> L7N34 = 0.19843770563602448\n",
      "L6N1                    -> L7N35 = -0.02522941492497921\n",
      "L6N1                    -> L7N36 = -0.05544787272810936\n",
      "L6N1                    -> L7N37 = 0.2055179476737976\n",
      "L6N1                    -> L7N38 = 0.0366399772465229\n",
      "L6N1                    -> L7N39 = 0.2043694406747818\n",
      "L6N1                    -> L7N40 = -0.21808961033821106\n",
      "L6N1                    -> L7N41 = 0.06278138607740402\n",
      "L6N1                    -> L7N42 = 0.37435320019721985\n",
      "L6N1                    -> L7N43 = -0.05720866471529007\n",
      "L6N1                    -> L7N44 = 0.1395554095506668\n",
      "L6N1                    -> L7N45 = 0.2652030885219574\n",
      "L6N1                    -> L7N46 = 0.04980388283729553\n",
      "L6N1                    -> L7N47 = 0.08057583123445511\n",
      "L6N1                    -> L7N48 = -0.31918808817863464\n",
      "L6N1                    -> L7N49 = 0.08126845955848694\n",
      "L6N1                    -> L7N50 = -0.06604248285293579\n",
      "L6N1                    -> L7N51 = 0.004958543460816145\n",
      "L6N1                    -> L7N52 = 0.06417931616306305\n",
      "L6N1                    -> L7N53 = 0.3514699637889862\n",
      "L6N1                    -> L7N54 = 0.018130332231521606\n",
      "L6N1                    -> L7N55 = -0.3079996109008789\n",
      "L6N1                    -> L7N56 = 0.1911134123802185\n",
      "L6N1                    -> L7N57 = -0.22429761290550232\n",
      "L6N1                    -> L7N58 = 0.10452648252248764\n",
      "L6N1                    -> L7N59 = -0.5462192296981812\n",
      "L6N1                    -> L7N60 = 0.13554155826568604\n",
      "L6N1                    -> L7N61 = 0.2284538894891739\n",
      "L6N1                    -> L7N62 = -0.08615125715732574\n",
      "L6N1                    -> L7N63 = 0.17159907519817352\n",
      "L6N1                    -> L7N64 = 0.18564841151237488\n",
      "L6N1                    -> L7N65 = 0.28924840688705444\n",
      "L6N1                    -> L7N66 = 0.26636093854904175\n",
      "L6N1                    -> L7N67 = 0.1509876847267151\n",
      "L6N1                    -> L7N68 = -0.1473148912191391\n",
      "L6N1                    -> L7N69 = -0.15943126380443573\n",
      "L6N1                    -> L7N70 = 0.11107297241687775\n",
      "L6N1                    -> L7N71 = 0.41186192631721497\n",
      "L6N1                    -> L7N72 = -0.2420947104692459\n",
      "L6N1                    -> L7N73 = -0.25362536311149597\n",
      "L6N1                    -> L7N74 = 0.11903373897075653\n",
      "L6N1                    -> L7N75 = -0.011923258192837238\n",
      "L6N1                    -> L7N76 = 0.13100992143154144\n",
      "L6N1                    -> L7N77 = 0.35244032740592957\n",
      "L6N1                    -> L7N78 = 0.061384156346321106\n",
      "L6N1                    -> L7N79 = 0.21310649812221527\n",
      "L6N1                    -> L7N80 = -0.08660433441400528\n",
      "L6N1                    -> L7N81 = 0.054029691964387894\n",
      "L6N1                    -> L7N82 = 0.04053753986954689\n",
      "L6N1                    -> L7N83 = 0.06638794392347336\n",
      "L6N1                    -> L7N84 = -0.0194108784198761\n",
      "L6N1                    -> L7N85 = 0.14922046661376953\n",
      "L6N1                    -> L7N86 = -0.05023247376084328\n",
      "L6N1                    -> L7N87 = 0.04947010055184364\n",
      "L6N1                    -> L7N88 = 0.04377926513552666\n",
      "L6N1                    -> L7N89 = 0.005932774394750595\n",
      "L6N1                    -> L7N90 = 0.0661754459142685\n",
      "L6N1                    -> L7N91 = 0.3799712061882019\n",
      "L6N1                    -> L7N92 = 0.013114260509610176\n",
      "L6N1                    -> L7N93 = 0.24304133653640747\n",
      "L6N1                    -> L7N94 = 0.024450886994600296\n",
      "L6N1                    -> L7N95 = 0.09791228175163269\n",
      "L6N1                    -> L7N96 = 0.0828523114323616\n",
      "L6N1                    -> L7N97 = 0.48130905628204346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L6N1                    -> L7N98 = -0.13288263976573944\n",
      "L6N1                    -> L7N99 = 0.05586006119847298\n",
      "L6N1                    -> L7N100 = 0.3466978073120117\n",
      "L6N1                    -> L7N101 = 0.12465067952871323\n",
      "L6N1                    -> L7N102 = 0.0024611512199044228\n",
      "L6N1                    -> L7N103 = 0.06913211941719055\n",
      "L6N1                    -> L7N104 = -0.15844027698040009\n",
      "L6N1                    -> L7N105 = 0.09363208711147308\n",
      "L6N1                    -> L7N106 = 0.22627604007720947\n",
      "L6N1                    -> L7N107 = 0.12641803920269012\n",
      "L6N1                    -> L7N108 = 0.08365409076213837\n",
      "L6N1                    -> L7N109 = 0.07991782575845718\n",
      "L6N1                    -> L7N110 = -0.140188530087471\n",
      "L6N1                    -> L7N111 = 0.19684883952140808\n",
      "L6N1                    -> L7N112 = -0.049443479627370834\n",
      "L6N1                    -> L7N113 = 0.13944077491760254\n",
      "L6N1                    -> L7N114 = 0.6201757192611694\n",
      "L6N1                    -> L7N115 = 0.3319355845451355\n",
      "L6N1                    -> L7N116 = 0.28218013048171997\n",
      "L6N1                    -> L7N117 = -0.18745240569114685\n",
      "L6N1                    -> L7N118 = -0.03297680988907814\n",
      "L6N1                    -> L7N119 = 0.34068867564201355\n",
      "L6N1                    -> L7N120 = 0.07109582424163818\n",
      "L6N1                    -> L7N121 = 0.09614285826683044\n",
      "L6N1                    -> L7N122 = -0.20879197120666504\n",
      "L6N1                    -> L7N123 = 0.24775508046150208\n",
      "L6N1                    -> L7N124 = 0.5214992165565491\n",
      "L6N1                    -> L7N125 = 0.3667316138744354\n",
      "L6N1                    -> L7N126 = 0.3242529332637787\n",
      "L6N1                    -> L7N127 = -0.03206388279795647\n",
      "L6N1                    -> L7N128 = 0.20004592835903168\n",
      "L6N1                    -> L7N129 = -0.03912351280450821\n",
      "L6N1                    -> L7N130 = -0.008362017571926117\n",
      "L6N1                    -> L7N131 = 0.31173408031463623\n",
      "L6N1                    -> L7N132 = 0.12046795338392258\n",
      "L6N1                    -> L7N133 = 0.14899452030658722\n",
      "L6N1                    -> L7N134 = -0.16032260656356812\n",
      "L6N1                    -> L7N135 = 0.1800004243850708\n",
      "L6N1                    -> L7N136 = 0.20243923366069794\n",
      "L6N1                    -> L7N137 = 0.0444306954741478\n",
      "L6N1                    -> L7N138 = -0.1092088595032692\n",
      "L6N1                    -> L7N139 = 0.20025575160980225\n",
      "L6N1                    -> L7N140 = 0.2604212760925293\n",
      "L6N1                    -> L7N141 = 0.33156588673591614\n",
      "L6N1                    -> L7N142 = 0.5736175775527954\n",
      "L6N1                    -> L7N143 = 0.02088542841374874\n",
      "L6N1                    -> L7N144 = -0.08160033822059631\n",
      "L6N1                    -> L7N145 = 0.018115807324647903\n",
      "L6N1                    -> L7N146 = -0.0007386855431832373\n",
      "L6N1                    -> L7N147 = 0.24237044155597687\n",
      "L6N1                    -> L7N148 = -0.03293250873684883\n",
      "L6N1                    -> L7N149 = -0.2119753062725067\n",
      "L6N2                    -> L7N0 = 0.8834713697433472\n",
      "L6N2                    -> L7N1 = 0.7313218116760254\n",
      "L6N2                    -> L7N2 = 0.7544063329696655\n",
      "L6N2                    -> L7N3 = 0.9229706525802612\n",
      "L6N2                    -> L7N4 = 0.2664048671722412\n",
      "L6N2                    -> L7N5 = 0.2694760859012604\n",
      "L6N2                    -> L7N6 = 1.0454232692718506\n",
      "L6N2                    -> L7N7 = 0.6775694489479065\n",
      "L6N2                    -> L7N8 = 1.8556342124938965\n",
      "L6N2                    -> L7N9 = 1.1251640319824219\n",
      "L6N2                    -> L7N10 = 0.23661717772483826\n",
      "L6N2                    -> L7N11 = 0.8848548531532288\n",
      "L6N2                    -> L7N12 = 1.0562691688537598\n",
      "L6N2                    -> L7N13 = 0.5962586402893066\n",
      "L6N2                    -> L7N14 = 0.8975220322608948\n",
      "L6N2                    -> L7N15 = 0.9373270869255066\n",
      "L6N2                    -> L7N16 = 0.21863099932670593\n",
      "L6N2                    -> L7N17 = 0.772202730178833\n",
      "L6N2                    -> L7N18 = 0.2932669520378113\n",
      "L6N2                    -> L7N19 = 0.31823498010635376\n",
      "L6N2                    -> L7N20 = 0.716360867023468\n",
      "L6N2                    -> L7N21 = 2.064274549484253\n",
      "L6N2                    -> L7N22 = 1.292018175125122\n",
      "L6N2                    -> L7N23 = 1.4437910318374634\n",
      "L6N2                    -> L7N24 = 0.9473627209663391\n",
      "L6N2                    -> L7N25 = 0.24052320420742035\n",
      "L6N2                    -> L7N26 = 0.6199632883071899\n",
      "L6N2                    -> L7N27 = 0.21255995333194733\n",
      "L6N2                    -> L7N28 = 0.45761385560035706\n",
      "L6N2                    -> L7N29 = 0.3433285355567932\n",
      "L6N2                    -> L7N30 = 0.21971693634986877\n",
      "L6N2                    -> L7N31 = 0.3770661950111389\n",
      "L6N2                    -> L7N32 = 0.9651593565940857\n",
      "L6N2                    -> L7N33 = 0.3285452425479889\n",
      "L6N2                    -> L7N34 = 0.6650419235229492\n",
      "L6N2                    -> L7N35 = 1.0047240257263184\n",
      "L6N2                    -> L7N36 = 1.342049479484558\n",
      "L6N2                    -> L7N37 = 0.7292230129241943\n",
      "L6N2                    -> L7N38 = 0.6736773252487183\n",
      "L6N2                    -> L7N39 = 1.7226135730743408\n",
      "L6N2                    -> L7N40 = 0.7380756735801697\n",
      "L6N2                    -> L7N41 = 0.3809969425201416\n",
      "L6N2                    -> L7N42 = 0.7666099667549133\n",
      "L6N2                    -> L7N43 = 0.7480980753898621\n",
      "L6N2                    -> L7N44 = 1.4646295309066772\n",
      "L6N2                    -> L7N45 = 0.6974618434906006\n",
      "L6N2                    -> L7N46 = 1.3121085166931152\n",
      "L6N2                    -> L7N47 = 1.067752480506897\n",
      "L6N2                    -> L7N48 = 0.8477556109428406\n",
      "L6N2                    -> L7N49 = 0.8157873153686523\n",
      "L6N2                    -> L7N50 = 1.1185698509216309\n",
      "L6N2                    -> L7N51 = 0.4239288568496704\n",
      "L6N2                    -> L7N52 = 0.8395122289657593\n",
      "L6N2                    -> L7N53 = 0.7381753325462341\n",
      "L6N2                    -> L7N54 = 0.7608857750892639\n",
      "L6N2                    -> L7N55 = 0.6156201362609863\n",
      "L6N2                    -> L7N56 = 1.0782172679901123\n",
      "L6N2                    -> L7N57 = 0.43380558490753174\n",
      "L6N2                    -> L7N58 = 0.44244512915611267\n",
      "L6N2                    -> L7N59 = 0.3360191285610199\n",
      "L6N2                    -> L7N60 = 0.9808400273323059\n",
      "L6N2                    -> L7N61 = 0.3170907199382782\n",
      "L6N2                    -> L7N62 = 0.34413155913352966\n",
      "L6N2                    -> L7N63 = 0.615531325340271\n",
      "L6N2                    -> L7N64 = 1.2521661520004272\n",
      "L6N2                    -> L7N65 = 1.314585566520691\n",
      "L6N2                    -> L7N66 = 1.3024100065231323\n",
      "L6N2                    -> L7N67 = 0.906868577003479\n",
      "L6N2                    -> L7N68 = 1.8483681678771973\n",
      "L6N2                    -> L7N69 = 1.9419025182724\n",
      "L6N2                    -> L7N70 = 1.4452922344207764\n",
      "L6N2                    -> L7N71 = 1.0172594785690308\n",
      "L6N2                    -> L7N72 = 0.3650669455528259\n",
      "L6N2                    -> L7N73 = 0.4771985709667206\n",
      "L6N2                    -> L7N74 = 0.9129566550254822\n",
      "L6N2                    -> L7N75 = 1.212214469909668\n",
      "L6N2                    -> L7N76 = 0.24651287496089935\n",
      "L6N2                    -> L7N77 = 0.8636584281921387\n",
      "L6N2                    -> L7N78 = 1.0114171504974365\n",
      "L6N2                    -> L7N79 = 0.6661080718040466\n",
      "L6N2                    -> L7N80 = 0.4914554953575134\n",
      "L6N2                    -> L7N81 = 1.1250156164169312\n",
      "L6N2                    -> L7N82 = 0.26946699619293213\n",
      "L6N2                    -> L7N83 = 0.7510384321212769\n",
      "L6N2                    -> L7N84 = 1.3108553886413574\n",
      "L6N2                    -> L7N85 = 0.6685830950737\n",
      "L6N2                    -> L7N86 = 1.3822377920150757\n",
      "L6N2                    -> L7N87 = 1.0462299585342407\n",
      "L6N2                    -> L7N88 = 0.578303873538971\n",
      "L6N2                    -> L7N89 = 0.5948858261108398\n",
      "L6N2                    -> L7N90 = 0.534307062625885\n",
      "L6N2                    -> L7N91 = 1.0042773485183716\n",
      "L6N2                    -> L7N92 = 0.20149756968021393\n",
      "L6N2                    -> L7N93 = 1.5649352073669434\n",
      "L6N2                    -> L7N94 = 1.329850673675537\n",
      "L6N2                    -> L7N95 = 0.8453407287597656\n",
      "L6N2                    -> L7N96 = 0.7152230739593506\n",
      "L6N2                    -> L7N97 = 0.945189356803894\n",
      "L6N2                    -> L7N98 = 0.42432621121406555\n",
      "L6N2                    -> L7N99 = 0.2019965499639511\n",
      "L6N2                    -> L7N100 = 1.0393955707550049\n",
      "L6N2                    -> L7N101 = 2.2113559246063232\n",
      "L6N2                    -> L7N102 = 0.7076953649520874\n",
      "L6N2                    -> L7N103 = 0.48231473565101624\n",
      "L6N2                    -> L7N104 = 0.6028463244438171\n",
      "L6N2                    -> L7N105 = 0.3256416320800781\n",
      "L6N2                    -> L7N106 = 0.6937965750694275\n",
      "L6N2                    -> L7N107 = 0.29222097992897034\n",
      "L6N2                    -> L7N108 = 1.023909330368042\n",
      "L6N2                    -> L7N109 = 0.7625439167022705\n",
      "L6N2                    -> L7N110 = 1.3216166496276855\n",
      "L6N2                    -> L7N111 = 0.46364495158195496\n",
      "L6N2                    -> L7N112 = 0.7278436422348022\n",
      "L6N2                    -> L7N113 = 0.6218116283416748\n",
      "L6N2                    -> L7N114 = 0.6670646667480469\n",
      "L6N2                    -> L7N115 = 0.840329110622406\n",
      "L6N2                    -> L7N116 = 0.7000295519828796\n",
      "L6N2                    -> L7N117 = 0.24554847180843353\n",
      "L6N2                    -> L7N118 = 0.9517351388931274\n",
      "L6N2                    -> L7N119 = 1.4077855348587036\n",
      "L6N2                    -> L7N120 = 0.5211725234985352\n",
      "L6N2                    -> L7N121 = 0.6841226816177368\n",
      "L6N2                    -> L7N122 = 0.7978220582008362\n",
      "L6N2                    -> L7N123 = 0.5287854671478271\n",
      "L6N2                    -> L7N124 = 1.6208546161651611\n",
      "L6N2                    -> L7N125 = 1.1830586194992065\n",
      "L6N2                    -> L7N126 = 1.5997967720031738\n",
      "L6N2                    -> L7N127 = 1.2491791248321533\n",
      "L6N2                    -> L7N128 = 0.5172924995422363\n",
      "L6N2                    -> L7N129 = 1.6724120378494263\n",
      "L6N2                    -> L7N130 = 0.3805733919143677\n",
      "L6N2                    -> L7N131 = 0.6178109049797058\n",
      "L6N2                    -> L7N132 = 0.5942843556404114\n",
      "L6N2                    -> L7N133 = 0.7870858311653137\n",
      "L6N2                    -> L7N134 = 1.246848225593567\n",
      "L6N2                    -> L7N135 = 0.6839969754219055\n",
      "L6N2                    -> L7N136 = 0.3216903805732727\n",
      "L6N2                    -> L7N137 = 1.2389397621154785\n",
      "L6N2                    -> L7N138 = 0.3782886862754822\n",
      "L6N2                    -> L7N139 = 1.1132853031158447\n",
      "L6N2                    -> L7N140 = 1.0686670541763306\n",
      "L6N2                    -> L7N141 = 1.8072212934494019\n",
      "L6N2                    -> L7N142 = 1.394778847694397\n",
      "L6N2                    -> L7N143 = 0.8004665374755859\n",
      "L6N2                    -> L7N144 = 0.48056936264038086\n",
      "L6N2                    -> L7N145 = 0.5192189812660217\n",
      "L6N2                    -> L7N146 = 1.195385217666626\n",
      "L6N2                    -> L7N147 = 0.5700913667678833\n",
      "L6N2                    -> L7N148 = 0.6730033159255981\n",
      "L6N2                    -> L7N149 = 1.081947922706604\n",
      "L6N3                    -> L7N0 = 2.3876559734344482\n",
      "L6N3                    -> L7N1 = 2.0148544311523438\n",
      "L6N3                    -> L7N2 = 3.640754461288452\n",
      "L6N3                    -> L7N3 = 4.202728271484375\n",
      "L6N3                    -> L7N4 = 1.024713397026062\n",
      "L6N3                    -> L7N5 = 0.8055345416069031\n",
      "L6N3                    -> L7N6 = 5.69913911819458\n",
      "L6N3                    -> L7N7 = 1.6887991428375244\n",
      "L6N3                    -> L7N8 = 6.424335479736328\n",
      "L6N3                    -> L7N9 = 2.6482677459716797\n",
      "L6N3                    -> L7N10 = 0.591745138168335\n",
      "L6N3                    -> L7N11 = 4.479717254638672\n",
      "L6N3                    -> L7N12 = 2.7863433361053467\n",
      "L6N3                    -> L7N13 = 3.0702664852142334\n",
      "L6N3                    -> L7N14 = 2.22906494140625\n",
      "L6N3                    -> L7N15 = 6.691895008087158\n",
      "L6N3                    -> L7N16 = 0.7218000888824463\n",
      "L6N3                    -> L7N17 = 1.9742892980575562\n",
      "L6N3                    -> L7N18 = 1.1167693138122559\n",
      "L6N3                    -> L7N19 = 1.2436429262161255\n",
      "L6N3                    -> L7N20 = 6.783685207366943\n",
      "L6N3                    -> L7N21 = 6.127319812774658\n",
      "L6N3                    -> L7N22 = 5.558523178100586\n",
      "L6N3                    -> L7N23 = 5.195362567901611\n",
      "L6N3                    -> L7N24 = 4.262702941894531\n",
      "L6N3                    -> L7N25 = 0.47347915172576904\n",
      "L6N3                    -> L7N26 = 1.6097179651260376\n",
      "L6N3                    -> L7N27 = 0.7335890531539917\n",
      "L6N3                    -> L7N28 = 3.016974687576294\n",
      "L6N3                    -> L7N29 = 1.6210968494415283\n",
      "L6N3                    -> L7N30 = 0.3471626937389374\n",
      "L6N3                    -> L7N31 = 2.0376949310302734\n",
      "L6N3                    -> L7N32 = 2.7750933170318604\n",
      "L6N3                    -> L7N33 = 1.6053049564361572\n",
      "L6N3                    -> L7N34 = 2.137585163116455\n",
      "L6N3                    -> L7N35 = 2.6481966972351074\n",
      "L6N3                    -> L7N36 = 4.566408157348633\n",
      "L6N3                    -> L7N37 = 2.4952011108398438\n",
      "L6N3                    -> L7N38 = 3.588379144668579\n",
      "L6N3                    -> L7N39 = 6.10936164855957\n",
      "L6N3                    -> L7N40 = 1.7194150686264038\n",
      "L6N3                    -> L7N41 = 2.741489887237549\n",
      "L6N3                    -> L7N42 = 3.2960057258605957\n",
      "L6N3                    -> L7N43 = 2.3261075019836426\n",
      "L6N3                    -> L7N44 = 4.426432132720947\n",
      "L6N3                    -> L7N45 = 1.5182305574417114\n",
      "L6N3                    -> L7N46 = 3.7499566078186035\n",
      "L6N3                    -> L7N47 = 2.8978331089019775\n",
      "L6N3                    -> L7N48 = 4.3182878494262695\n",
      "L6N3                    -> L7N49 = 2.9657094478607178\n",
      "L6N3                    -> L7N50 = 2.393310546875\n",
      "L6N3                    -> L7N51 = 2.183593273162842\n",
      "L6N3                    -> L7N52 = 2.953338146209717\n",
      "L6N3                    -> L7N53 = 2.309783697128296\n",
      "L6N3                    -> L7N54 = 2.7439522743225098\n",
      "L6N3                    -> L7N55 = 1.2602678537368774\n",
      "L6N3                    -> L7N56 = 5.013768196105957\n",
      "L6N3                    -> L7N57 = 1.4132986068725586\n",
      "L6N3                    -> L7N58 = 1.2174293994903564\n",
      "L6N3                    -> L7N59 = 0.5547323226928711\n",
      "L6N3                    -> L7N60 = 4.416703701019287\n",
      "L6N3                    -> L7N61 = 0.6583158373832703\n",
      "L6N3                    -> L7N62 = 0.9600138068199158\n",
      "L6N3                    -> L7N63 = 3.3891186714172363\n",
      "L6N3                    -> L7N64 = 4.059841156005859\n",
      "L6N3                    -> L7N65 = 6.4311957359313965\n",
      "L6N3                    -> L7N66 = 6.771622180938721\n",
      "L6N3                    -> L7N67 = 2.474898099899292\n",
      "L6N3                    -> L7N68 = 3.984837293624878\n",
      "L6N3                    -> L7N69 = 5.184911251068115\n",
      "L6N3                    -> L7N70 = 5.4206953048706055\n",
      "L6N3                    -> L7N71 = 4.837072849273682\n",
      "L6N3                    -> L7N72 = 0.9355907440185547\n",
      "L6N3                    -> L7N73 = 1.509053111076355\n",
      "L6N3                    -> L7N74 = 9.957690238952637\n",
      "L6N3                    -> L7N75 = 3.1857082843780518\n",
      "L6N3                    -> L7N76 = 0.8208363652229309\n",
      "L6N3                    -> L7N77 = 1.901833176612854\n",
      "L6N3                    -> L7N78 = 4.079852104187012\n",
      "L6N3                    -> L7N79 = 2.3079192638397217\n",
      "L6N3                    -> L7N80 = 1.0278692245483398\n",
      "L6N3                    -> L7N81 = 4.522984504699707\n",
      "L6N3                    -> L7N82 = 0.695668637752533\n",
      "L6N3                    -> L7N83 = 2.5104167461395264\n",
      "L6N3                    -> L7N84 = 4.024455547332764\n",
      "L6N3                    -> L7N85 = 2.4751105308532715\n",
      "L6N3                    -> L7N86 = 7.885204315185547\n",
      "L6N3                    -> L7N87 = 3.4202301502227783\n",
      "L6N3                    -> L7N88 = 2.495769739151001\n",
      "L6N3                    -> L7N89 = 3.0280938148498535\n",
      "L6N3                    -> L7N90 = 2.4742610454559326\n",
      "L6N3                    -> L7N91 = 2.2561933994293213\n",
      "L6N3                    -> L7N92 = 0.8660796880722046\n",
      "L6N3                    -> L7N93 = 4.5191521644592285\n",
      "L6N3                    -> L7N94 = 5.239420413970947\n",
      "L6N3                    -> L7N95 = 8.284599304199219\n",
      "L6N3                    -> L7N96 = 1.2612292766571045\n",
      "L6N3                    -> L7N97 = 4.2854695320129395\n",
      "L6N3                    -> L7N98 = 1.5620521306991577\n",
      "L6N3                    -> L7N99 = 0.5414155125617981\n",
      "L6N3                    -> L7N100 = 9.42427921295166\n",
      "L6N3                    -> L7N101 = 7.352843284606934\n",
      "L6N3                    -> L7N102 = 2.7990992069244385\n",
      "L6N3                    -> L7N103 = 0.9475150108337402\n",
      "L6N3                    -> L7N104 = 2.1099913120269775\n",
      "L6N3                    -> L7N105 = 1.5476409196853638\n",
      "L6N3                    -> L7N106 = 1.2266006469726562\n",
      "L6N3                    -> L7N107 = 1.4659581184387207\n",
      "L6N3                    -> L7N108 = 2.7131826877593994\n",
      "L6N3                    -> L7N109 = 2.365156412124634\n",
      "L6N3                    -> L7N110 = 6.253142356872559\n",
      "L6N3                    -> L7N111 = 2.6640961170196533\n",
      "L6N3                    -> L7N112 = 2.7158150672912598\n",
      "L6N3                    -> L7N113 = 4.649893760681152\n",
      "L6N3                    -> L7N114 = 4.990725994110107\n",
      "L6N3                    -> L7N115 = 4.8676276206970215\n",
      "L6N3                    -> L7N116 = 4.001676082611084\n",
      "L6N3                    -> L7N117 = 0.547687292098999\n",
      "L6N3                    -> L7N118 = 1.886634111404419\n",
      "L6N3                    -> L7N119 = 3.222714424133301\n",
      "L6N3                    -> L7N120 = 3.6924753189086914\n",
      "L6N3                    -> L7N121 = 3.293278932571411\n",
      "L6N3                    -> L7N122 = 2.1064369678497314\n",
      "L6N3                    -> L7N123 = 1.1989506483078003\n",
      "L6N3                    -> L7N124 = 5.017277717590332\n",
      "L6N3                    -> L7N125 = 4.102904796600342\n",
      "L6N3                    -> L7N126 = 3.9891345500946045\n",
      "L6N3                    -> L7N127 = 5.386354923248291\n",
      "L6N3                    -> L7N128 = 0.9431989192962646\n",
      "L6N3                    -> L7N129 = 6.313505172729492\n",
      "L6N3                    -> L7N130 = 1.637890338897705\n",
      "L6N3                    -> L7N131 = 1.7467432022094727\n",
      "L6N3                    -> L7N132 = 1.5201338529586792\n",
      "L6N3                    -> L7N133 = 1.4765558242797852\n",
      "L6N3                    -> L7N134 = 5.6834716796875\n",
      "L6N3                    -> L7N135 = 5.238221168518066\n",
      "L6N3                    -> L7N136 = 2.00738525390625\n",
      "L6N3                    -> L7N137 = 4.242816925048828\n",
      "L6N3                    -> L7N138 = 1.3217812776565552\n",
      "L6N3                    -> L7N139 = 5.750111103057861\n",
      "L6N3                    -> L7N140 = 4.9265241622924805\n",
      "L6N3                    -> L7N141 = 4.529261112213135\n",
      "L6N3                    -> L7N142 = 6.231250762939453\n",
      "L6N3                    -> L7N143 = 2.3907687664031982\n",
      "L6N3                    -> L7N144 = 0.9259966611862183\n",
      "L6N3                    -> L7N145 = 1.9637125730514526\n",
      "L6N3                    -> L7N146 = 5.262547492980957\n",
      "L6N3                    -> L7N147 = 1.4066513776779175\n",
      "L6N3                    -> L7N148 = 1.7652558088302612\n",
      "L6N3                    -> L7N149 = 2.554274320602417\n",
      "L7N0                    -> L8N0 = [-0.1181074  -0.0345423   0.19010027 -0.20535181  0.28733715 -0.04172961\n",
      "  0.29174083 -0.12261454 -0.16460985 -0.05516915 -0.01665479  0.20437278\n",
      " -0.41821268 -0.10634191 -0.26656005 -0.12426138 -0.27339134 -0.12163187\n",
      " -0.10649923  0.02151512 -0.07401448  0.04079197 -0.05633542 -0.14162613\n",
      " -0.0738509   0.01475858 -0.20642953 -0.01566133 -0.18917483  0.03738407\n",
      "  0.18033478 -0.2639083  -0.01937201 -0.08454523 -0.01485632  0.01806618\n",
      " -0.06226902  0.09948201  0.32165793  0.04124538  0.01758958  0.17748289\n",
      "  0.08463933  0.2952355  -0.22265285  0.2302897  -0.30901223 -0.12525912\n",
      "  0.21814194  0.20627338 -0.18222734 -0.02148882  0.02276061  0.17451972\n",
      "  0.04315617 -0.17530973  0.02133028  0.22991388 -0.08022873 -0.03071974\n",
      "  0.16112687  0.2363066   0.23496279 -0.01841079 -0.48100847 -0.21426173\n",
      "  0.11715872 -0.30512157  0.08317423 -0.19718881 -0.01097292 -0.10917249\n",
      "  0.19188593 -0.12795566  0.16860767 -0.0705443   0.16204588 -0.2554712\n",
      " -0.1997831   0.08777767 -0.23718685 -0.1752968  -0.10873133  0.00704356\n",
      "  0.07848448  0.03890495 -0.32822922 -0.10527892 -0.17986389 -0.13294873\n",
      " -0.05380915  0.0438386  -0.13664532  0.38696834 -0.09969279  0.13935147\n",
      " -0.18678637 -0.23275757  0.10121925  0.16143663 -0.16851632  0.02166667\n",
      " -0.06340423 -0.16795583  0.06775495 -0.075657   -0.09884367 -0.08650257\n",
      "  0.22663322 -0.52948564  0.01891486  0.02594742  0.22841056  0.17005287\n",
      " -0.00489006  0.06552262  0.1546286  -0.33769602  0.02434986 -0.02989924\n",
      " -0.3655259   0.02730344 -0.07769582  0.1927484  -0.1787212   0.16668163\n",
      "  0.11630978  0.43601078  0.10830171  0.09055016  0.08765467  0.16540092\n",
      "  0.02388501  0.05315198 -0.01418353  0.07984636 -0.1436405   0.20453744\n",
      "  0.19470596  0.08493962  0.25650588 -0.05060232 -0.33878264 -0.07375047\n",
      " -0.41282195  0.06797601 -0.22006936  0.21901366 -0.01244282  0.15953083\n",
      " -0.03294548 -0.05686289 -0.01770692 -0.06081334 -0.21018122 -0.12739228\n",
      "  0.18706308  0.09138881  0.05481387 -0.15658014 -0.15107988 -0.11324742\n",
      " -0.18177104  0.0617978  -0.06122063  0.02223545 -0.0377207  -0.18090829\n",
      " -0.19963759 -0.23365335 -0.23651317 -0.1448507   0.26538143 -0.08538119\n",
      "  0.17091826 -0.00278724 -0.07216924 -0.18590875 -0.00620922 -0.31874818\n",
      "  0.07134598 -0.02243509 -0.02083036 -0.11576437 -0.14306812 -0.04257648\n",
      "  0.17122665 -0.295817    0.00589452 -0.00726039  0.12940845  0.24815136\n",
      " -0.22774228 -0.12681012 -0.22015402  0.08932783 -0.07893597 -0.0099519\n",
      "  0.03836915 -0.16527165]\n",
      "L7N0                    -> L8N1 = [ 0.1645478  -0.09929483  0.03825659 -0.16712071  0.01064166 -0.02888856\n",
      "  0.0810169  -0.219311   -0.15312727 -0.25601938 -0.22766243  0.12035455\n",
      "  0.0240691  -0.24400818 -0.06746002 -0.03849014  0.14850833  0.08368558\n",
      "  0.00869078 -0.25108886 -0.30690148 -0.18262096 -0.08826717 -0.11231374\n",
      " -0.106832   -0.31023258  0.03563991 -0.20261179 -0.13081121 -0.15839957\n",
      " -0.01416867  0.05072532 -0.1785422  -0.05171147 -0.1863562  -0.11880128\n",
      " -0.2888082  -0.23155236  0.1029321  -0.07138602 -0.36514747 -0.06315164\n",
      " -0.23480901 -0.18115172 -0.24075566 -0.37998688 -0.3022004   0.00859503\n",
      "  0.3321508   0.1744371  -0.1205285  -0.00736941 -0.2207339  -0.22141966\n",
      "  0.079091    0.05632344 -0.18723856  0.03585627 -0.13151063 -0.06453267\n",
      " -0.06551652 -0.1389222  -0.1623671   0.05807845 -0.05557474 -0.15866344\n",
      " -0.12900135  0.16607541 -0.20004874  0.03176906 -0.01844187 -0.18967076\n",
      "  0.03369177 -0.10430435 -0.2429278  -0.12340511 -0.25154954 -0.01136035\n",
      " -0.24775644  0.0100811  -0.3688853  -0.11836363 -0.08655689 -0.00246005\n",
      " -0.17407161 -0.2572833  -0.03856548 -0.2415462  -0.21369258  0.01959888\n",
      " -0.20239027 -0.05507057 -0.13106    -0.14185835 -0.17528781 -0.04923323\n",
      " -0.26533172 -0.03780423  0.08948327 -0.04276405 -0.3504841  -0.29304004\n",
      "  0.06587217 -0.28515244 -0.35138437 -0.02639849 -0.06403421 -0.0967795\n",
      "  0.14770015 -0.04105166 -0.20846544 -0.08408031  0.20310488  0.06594772\n",
      " -0.09040966  0.11558607 -0.16649425 -0.11099239  0.00865656  0.01444459\n",
      "  0.08774032 -0.02018797 -0.3085404  -0.05307974 -0.17883721 -0.02441696\n",
      " -0.11598827 -0.19650246  0.2192017   0.00512245 -0.05598943 -0.2488941\n",
      " -0.34954998 -0.10476388 -0.19224001 -0.2648304  -0.13619722 -0.0171106\n",
      "  0.09877924 -0.02969215  0.06207945 -0.2378115   0.01544584  0.05160634\n",
      " -0.18449862  0.2559398  -0.10308209  0.03669474  0.03019803 -0.34225947\n",
      " -0.0153082  -0.078679    0.16427782 -0.22094856 -0.14908817  0.05043839\n",
      "  0.01974224  0.06262924  0.15788516 -0.03555858 -0.10205974  0.15613236\n",
      "  0.19866009  0.02689573 -0.06146239 -0.133242    0.13647923 -0.1626789\n",
      " -0.18281218  0.00210056 -0.13038622 -0.04774821 -0.08472756  0.02807423\n",
      " -0.08397225 -0.16981496 -0.37494785 -0.24393855 -0.04085274 -0.2826036\n",
      " -0.13197654 -0.13411817 -0.02011409 -0.11470559  0.06207035 -0.15943412\n",
      " -0.06474858 -0.08963341 -0.12541063  0.04182842  0.03461083  0.01161357\n",
      " -0.24255475 -0.13036232 -0.2416044  -0.1433018  -0.0484532   0.25110555\n",
      " -0.08047157 -0.01238106]\n",
      "L7N0                    -> L8N2 = [-0.04368704 -0.01965346  0.14079988 -0.53564256  0.103476   -0.140333\n",
      " -0.39172536 -0.08392136 -0.21587187 -0.13227123  0.1929059  -0.0543599\n",
      "  0.13035926 -0.30353585  0.2770133   0.05345389 -0.23635863 -0.09992781\n",
      " -0.08211655 -0.02272376 -0.05054825 -0.32928127 -0.08103766 -0.05538565\n",
      " -0.24603666 -0.13510303 -0.17011218 -0.21085209 -0.19482946 -0.19819734\n",
      "  0.07076949 -0.30505466 -0.21098095 -0.26511928 -0.38885584  0.00693159\n",
      "  0.04137503 -0.14738816 -0.1932317  -0.35758534 -0.00947798  0.04506795\n",
      " -0.25540453 -0.04170506  0.08211342  0.04724309 -0.11871818 -0.33946255\n",
      "  0.07070691 -0.20008104 -0.20461404  0.03063662 -0.32486925 -0.26080662\n",
      " -0.13938989 -0.02437804 -0.20662689 -0.12763648 -0.05434396  0.12266462\n",
      " -0.15320331 -0.26338536 -0.2752526  -0.36587     0.04387293 -0.05927274\n",
      " -0.08644992  0.00871074 -0.32990292 -0.17149265 -0.02237839 -0.06341391\n",
      " -0.3226947  -0.11476436  0.06987803  0.02482921 -0.44629624  0.15887167\n",
      " -0.09214715  0.13148159 -0.10740121  0.13482274 -0.21172135 -0.28653473\n",
      " -0.28563935 -0.15835218  0.0371226  -0.19807884 -0.18749158 -0.02275001\n",
      " -0.07493284 -0.44068098 -0.18524192 -0.10317546  0.10593162 -0.063076\n",
      " -0.34036985 -0.18489026 -0.23584144 -0.16338217 -0.0615529  -0.15434577\n",
      " -0.10338423 -0.34883097 -0.34909666  0.09750118  0.16920267  0.17649445\n",
      " -0.13316225  0.12315566  0.08725964  0.08775161 -0.01193052 -0.06755733\n",
      " -0.24371314  0.04776498 -0.36202255 -0.28934237 -0.14269681 -0.27035955\n",
      "  0.03405252 -0.29803437 -0.09153477 -0.11024282 -0.04105539 -0.19858389\n",
      " -0.08910007  0.20089376 -0.06562621  0.06160611  0.0384188  -0.14224021\n",
      " -0.23616931 -0.19553651 -0.24625286 -0.19097361 -0.0900253  -0.17783503\n",
      " -0.38231924  0.07609407 -0.21895438  0.31115982  0.13880922 -0.10077392\n",
      "  0.03262295  0.13141398 -0.15885653 -0.10789328 -0.27852148 -0.2774504\n",
      "  0.19693328 -0.44052085  0.18978475 -0.21011162 -0.18740465 -0.21933396\n",
      " -0.14204317 -0.06358494 -0.02793544  0.04125562 -0.24426426 -0.22874221\n",
      "  0.0721634   0.09729016 -0.22975498 -0.30788207 -0.23110414 -0.08642455\n",
      "  0.07426843 -0.14355476 -0.156709    0.04018176 -0.22984274 -0.08290373\n",
      "  0.02800348 -0.13395503  0.02498777 -0.02787462 -0.15507995 -0.12571064\n",
      " -0.06917736 -0.2765809  -0.20272748 -0.11431681 -0.03727464 -0.21033415\n",
      "  0.04204864 -0.06696206  0.13318    -0.08613572 -0.05716016 -0.00498872\n",
      " -0.07840611 -0.32541585  0.03299807 -0.06662577 -0.3246535   0.10756042\n",
      " -0.18866229 -0.309106  ]\n",
      "L7N0                    -> L8N3 = [-2.74787426e-01 -8.18386376e-02  1.14497542e-01  9.09837545e-04\n",
      " -1.18499866e-03  1.79703891e-01  8.95188376e-02 -3.04052174e-01\n",
      " -1.33579001e-01  8.69878680e-02 -2.18680389e-02  1.16873592e-01\n",
      " -5.29946871e-02  2.22990550e-02 -1.67664111e-01  1.07232042e-01\n",
      " -9.67860222e-02  1.31974176e-01 -9.92092565e-02 -1.07954018e-01\n",
      " -9.41149443e-02  1.46657169e-01  1.17505074e-01 -1.13951251e-01\n",
      " -3.38378772e-02  1.36417802e-02 -4.56494391e-02 -1.19238101e-01\n",
      " -7.04807714e-02  4.33282480e-02  2.63095021e-01  2.05151010e-02\n",
      "  9.71626416e-02 -3.06019068e-01  1.67106092e-01 -5.92736453e-02\n",
      " -2.14561194e-01 -2.11452857e-01  1.64464146e-01  2.05042884e-01\n",
      " -1.30722553e-01 -3.35482478e-01  2.10162885e-02  1.55792795e-02\n",
      " -4.48387235e-01 -9.67498571e-02  5.51997349e-02  1.26649216e-02\n",
      "  4.89188619e-02  1.70597136e-02 -6.25156909e-02  3.12433660e-01\n",
      " -2.32375517e-01 -1.84003174e-01  5.89538850e-02 -2.71488696e-01\n",
      "  1.59538463e-01  9.49283764e-02  4.39941697e-02  5.03098592e-03\n",
      "  9.39409882e-02 -6.60956139e-03  2.11370364e-01 -1.38816582e-02\n",
      "  1.10562190e-01 -1.09733261e-01  2.25505763e-04  1.34807959e-01\n",
      " -6.27380908e-02  1.02037758e-01 -5.94757795e-02  2.23566517e-02\n",
      " -2.04466581e-01 -3.06355000e-01  1.99629083e-01 -9.08978842e-03\n",
      " -6.72796369e-02  1.25689387e-01  7.45373294e-02  1.07996240e-01\n",
      " -2.01114401e-01 -3.05035710e-01 -7.01930225e-02  3.83671582e-01\n",
      " -5.10181449e-02  1.33805379e-01 -3.82589012e-01 -1.61276922e-01\n",
      " -1.28137186e-01 -8.11746269e-02  2.53018707e-01 -5.96360266e-02\n",
      "  2.64660805e-01  6.18557818e-02  4.40338999e-02 -8.40408579e-02\n",
      " -1.13127947e-01 -2.75231693e-02  9.36202556e-02 -3.49791460e-02\n",
      " -1.91480622e-01 -4.77861576e-02 -2.77259588e-01 -4.98163313e-01\n",
      "  2.59080138e-02  3.08409750e-01  8.14355612e-02 -1.00483187e-01\n",
      "  2.92200059e-01 -5.09099998e-02  1.48185179e-01 -1.39892474e-01\n",
      "  1.31583899e-01  2.30360389e-01 -1.61425740e-01 -1.87754154e-01\n",
      " -2.51050323e-01  1.46203758e-02 -2.33031049e-01 -5.55831492e-02\n",
      " -1.53287739e-01  1.67907923e-02  1.04107164e-01  3.35826248e-01\n",
      "  1.47893643e-02 -4.15505804e-02  1.58303618e-01  2.91273575e-02\n",
      "  1.59244776e-01  1.65731162e-01  3.54750343e-02  8.53970870e-02\n",
      " -4.10998970e-01  2.19285786e-01  6.56279698e-02 -6.63912371e-02\n",
      " -1.23850338e-01 -3.46705653e-02  1.24694243e-01  1.23377733e-01\n",
      "  6.81476519e-02  8.29925537e-02  1.81005672e-01  3.36128116e-01\n",
      " -7.90209174e-02  1.46207884e-01 -3.81927580e-01  2.12285265e-01\n",
      "  1.38553649e-01 -8.15344229e-02  4.42910016e-01 -1.59725115e-01\n",
      "  1.82937264e-01 -1.17813267e-01  1.02145858e-01 -2.89876200e-02\n",
      " -2.71948427e-01 -4.72858846e-02 -2.27821693e-01  1.31406516e-01\n",
      " -1.06886074e-01 -2.09743634e-01  5.47231659e-02  1.28986850e-01\n",
      " -1.84331402e-01 -1.24613672e-01  7.73827918e-03 -2.47070000e-01\n",
      "  1.79552957e-02 -2.62612045e-01 -2.05443874e-01  1.61674805e-02\n",
      " -1.09107524e-01 -2.78886944e-01  1.00300707e-01  6.26313314e-02\n",
      " -1.16197936e-01 -1.07233495e-01 -2.51888838e-02 -2.35538095e-01\n",
      " -5.01101837e-02 -1.06974095e-01 -1.02505133e-01  1.75755754e-01\n",
      "  1.07149452e-01  1.68830436e-02  2.64433712e-01 -1.62086904e-01\n",
      "  5.56189492e-02 -1.23799413e-01  1.74212351e-01  1.78264186e-01\n",
      " -3.24475825e-01 -1.26108050e-01 -2.68838942e-01  1.92000180e-01\n",
      "  2.27603968e-02  5.37117273e-02 -6.60693869e-02 -3.83676320e-01]\n",
      "L7N0                    -> L8N4 = [-1.66371822e-01  1.01700619e-01 -1.52287468e-01 -3.00484091e-01\n",
      " -1.87466875e-01 -1.69897214e-01 -1.73463047e-01 -8.30432177e-02\n",
      "  1.01207614e-01  4.69596870e-02 -2.98265517e-01 -1.30084127e-01\n",
      " -1.57334283e-01  3.07212118e-02  9.03469250e-02 -1.72802527e-02\n",
      " -2.51259506e-01 -4.44017239e-02 -1.07586095e-02 -4.53397445e-02\n",
      "  1.77944750e-01 -8.37748423e-02 -7.95044843e-03 -2.54277050e-01\n",
      " -1.07357740e-01 -2.75022179e-01 -2.54396737e-01  5.57708740e-02\n",
      " -2.01024398e-01 -3.82748656e-02 -1.90410733e-01 -2.66241968e-01\n",
      " -1.84833899e-01  1.45986630e-02 -3.83522332e-01 -1.31936654e-01\n",
      " -4.09626931e-01 -4.75442261e-01 -4.59765503e-03 -2.77744889e-01\n",
      " -2.60853529e-01  1.70247629e-01 -2.24184468e-01  5.25627770e-02\n",
      "  1.44255877e-01 -5.25970683e-02 -1.12273701e-01 -9.05159265e-02\n",
      "  1.84397981e-01 -3.54140729e-01  7.07236454e-02  3.66408727e-04\n",
      " -2.57711530e-01 -3.93314272e-01 -2.72838026e-01  6.72988370e-02\n",
      " -1.04845434e-01 -1.98873401e-01 -8.79473537e-02 -1.95531502e-01\n",
      " -2.63690293e-01 -3.69348489e-02  3.99715565e-02 -3.94987725e-02\n",
      " -1.64706856e-01 -3.44454055e-03 -1.74795631e-02 -1.54593304e-01\n",
      " -3.78460735e-01 -4.25148457e-02 -3.83534282e-01  3.69475037e-03\n",
      "  1.82590149e-02  1.27530664e-01 -2.97677308e-01 -3.34688634e-01\n",
      " -3.46783221e-01 -1.94297507e-01 -5.40687628e-02 -8.09171349e-02\n",
      " -4.65458259e-02 -7.11813569e-02 -2.26365894e-01 -2.60738909e-01\n",
      " -2.66978651e-01  5.32923564e-02  1.58235803e-01  1.32351518e-01\n",
      " -1.65296659e-01 -9.43299085e-02 -2.49917042e-02 -1.89132765e-01\n",
      "  3.07451487e-01 -2.53752172e-01  1.74669147e-01 -1.77114055e-01\n",
      " -6.79181367e-02 -1.36822641e-01  4.96618042e-04  1.59541250e-03\n",
      " -6.28109882e-03 -2.18487427e-01 -3.40735465e-01  5.40966466e-02\n",
      " -7.81837180e-02 -3.09190512e-01 -1.67310759e-01 -2.51744650e-02\n",
      "  5.54736238e-03 -5.68769984e-02 -3.50768775e-01 -2.01293752e-01\n",
      " -2.50697702e-01 -1.63587511e-01 -8.98394212e-02 -2.00105682e-01\n",
      " -2.82125413e-01 -2.08705515e-01 -1.33052438e-01 -2.83501208e-01\n",
      " -1.24427699e-01 -2.87965268e-01 -7.60632977e-02 -5.52667566e-02\n",
      " -4.73673306e-02 -2.25196272e-01 -3.12838733e-01 -2.74604499e-01\n",
      " -1.85696676e-01  6.82166144e-02 -1.39628306e-01  1.02436207e-02\n",
      " -1.38169542e-01 -2.38532484e-01 -3.69606882e-01 -2.90625542e-01\n",
      " -1.38159394e-01  1.01108879e-01 -2.67219812e-01 -1.97648942e-01\n",
      " -3.94503832e-01 -4.25494835e-02  6.12208843e-02  5.62610663e-02\n",
      " -1.07592352e-01 -2.15481222e-01  1.42531648e-01 -1.13877170e-01\n",
      "  4.20657098e-02 -1.12614475e-01 -1.32137626e-01 -1.99105397e-01\n",
      "  1.05706699e-01 -1.55045837e-01 -2.50493318e-01 -1.01541962e-04\n",
      " -2.48473555e-01  1.25288472e-01 -2.34209999e-01 -2.48870149e-01\n",
      " -2.28033721e-01 -1.17741600e-01 -2.97611803e-01 -3.66702639e-02\n",
      " -1.99766040e-01 -5.86086735e-02 -4.17582281e-02  2.72151753e-02\n",
      " -5.84079176e-02 -4.34336752e-01 -8.09003934e-02 -6.70651048e-02\n",
      " -2.59070452e-02 -1.17542166e-02  1.01654343e-02 -2.77966429e-02\n",
      " -9.51210335e-02 -3.49395536e-02 -2.20626816e-01  4.50156033e-02\n",
      " -2.21144438e-01 -2.41796345e-01 -1.59314305e-01 -3.35694104e-02\n",
      "  2.44690124e-02 -1.35382354e-01 -1.35726944e-01  1.10495128e-01\n",
      "  5.32416888e-02 -9.25676078e-02 -1.20535910e-01 -1.50353059e-01\n",
      " -1.52808383e-01  8.14796146e-03  2.04024632e-02 -2.33567685e-01\n",
      "  4.58854325e-02 -1.38157323e-01 -6.47141859e-02  2.15462856e-02]\n",
      "L7N0                    -> L8N5 = [ 0.17054221  0.05308142  0.02489014 -0.2657008  -0.07181375  0.42432496\n",
      "  0.23064974 -0.06493801  0.20779273  0.10829245  0.13202219  0.04247548\n",
      "  0.10074206  0.01775826 -0.0206788  -0.17110957  0.04357144 -0.27358028\n",
      "  0.03805528  0.23526084  0.25151786  0.09964985  0.24608503  0.08079774\n",
      "  0.22697476 -0.14039436 -0.28618523 -0.16186556  0.07980692  0.29288742\n",
      "  0.27896574  0.15381235  0.22824001  0.14042349  0.14394048 -0.30420235\n",
      " -0.09012582 -0.11258715 -0.18626559 -0.05013714  0.14395502  0.00964008\n",
      " -0.05501407  0.17630981  0.02501327 -0.05967495 -0.05616516 -0.0380796\n",
      " -0.12007052  0.00735873 -0.03480909  0.01376201  0.1505364  -0.02574391\n",
      "  0.2692746  -0.15174562 -0.22804874  0.16401944 -0.02333716  0.03371089\n",
      "  0.23034139  0.09075443  0.26819897 -0.09970029 -0.02514783  0.13988686\n",
      "  0.1662607  -0.21499595  0.00897496  0.2855227   0.0074802  -0.06235816\n",
      "  0.18940301 -0.16453682  0.03252972  0.4350179  -0.10221482 -0.09181575\n",
      "  0.12478465 -0.01074959 -0.00403448  0.22749862  0.1571515   0.07000338\n",
      "  0.04340398  0.07280787 -0.10933482 -0.10536412  0.1329142  -0.09714001\n",
      " -0.1543146   0.28296918 -0.247465    0.16680197  0.07881395  0.07307313\n",
      "  0.04199328 -0.04700631  0.15565093 -0.12447368 -0.17179443 -0.12308063\n",
      " -0.06530482  0.16303687  0.07376313 -0.21006684 -0.19981608  0.06953822\n",
      " -0.11013775 -0.01484565 -0.30869213  0.17086469 -0.30212831  0.24579506\n",
      "  0.08723306 -0.0130484  -0.02304314 -0.14748925  0.1920411  -0.07003921\n",
      " -0.14929228  0.03400001  0.06361469  0.20594202 -0.17565939  0.17501278\n",
      "  0.11474764  0.02776426 -0.11956055  0.0048498   0.16396527  0.12411682\n",
      "  0.03148007  0.11726289  0.21258523 -0.07680839  0.15732275 -0.2039788\n",
      "  0.04874599  0.254627    0.2970617  -0.08952102 -0.19531949 -0.14262025\n",
      "  0.04051375 -0.17030227 -0.13875987  0.32744068  0.22167838  0.14239056\n",
      " -0.16342635 -0.03744628  0.01811548  0.14763173  0.2076127  -0.05360175\n",
      "  0.09956303 -0.0222022   0.20107944 -0.19430847 -0.04312135  0.03812563\n",
      " -0.02110732 -0.21235982 -0.05182983  0.16712417 -0.00469365 -0.03627094\n",
      " -0.04243328 -0.10626885  0.43848842 -0.12268219  0.11263255 -0.05193203\n",
      " -0.1255139   0.0298528   0.31556305  0.11018655 -0.03527857 -0.04246177\n",
      "  0.08705184 -0.25867394 -0.06210071 -0.02989111 -0.06474836  0.13533346\n",
      " -0.04464805 -0.0488058  -0.14101438 -0.07326485 -0.02615027 -0.01702782\n",
      " -0.07484224  0.27357107  0.03823167 -0.00854471  0.11788674 -0.12130172\n",
      "  0.15767588  0.1065608 ]\n",
      "L7N0                    -> L8N6 = [-6.80200234e-02 -3.15168023e-01  3.89755070e-02  1.16786428e-01\n",
      "  3.87195349e-02 -3.79732668e-01 -1.72070205e-01 -7.88447820e-03\n",
      " -1.73848540e-01 -7.58622959e-02 -1.71352386e-01  7.21702948e-02\n",
      "  1.32047534e-01 -2.12424129e-01 -2.79595643e-01 -1.67053685e-01\n",
      " -3.94590378e-01  3.16117294e-02 -1.50368080e-01 -4.98662479e-02\n",
      " -1.01390414e-01 -2.40896374e-01 -1.95476130e-01 -3.07526350e-01\n",
      " -6.31617606e-02 -1.86954901e-01  6.70000836e-02 -1.42447904e-01\n",
      " -1.34989932e-01  2.74087228e-02 -1.11049138e-01 -3.70526873e-02\n",
      " -1.66322365e-02 -9.69220325e-02 -4.66464879e-03 -7.43898898e-02\n",
      " -1.04995064e-01 -2.55918711e-01 -2.39608392e-01  1.25169978e-01\n",
      " -2.11059004e-01 -7.18189031e-02 -5.33568561e-01  1.32554382e-01\n",
      " -3.22151631e-01 -1.42357975e-01  1.46333098e-01  1.45214364e-01\n",
      "  7.99518153e-02 -1.13221474e-01  1.73970520e-01 -1.91447471e-05\n",
      " -2.20244944e-01 -2.23743498e-01 -7.86466375e-02 -3.91871184e-02\n",
      " -3.74412090e-01 -1.56787988e-02 -2.84042686e-01 -6.37226924e-02\n",
      " -1.73654497e-01  4.95112725e-02 -3.81655246e-02 -2.90799469e-01\n",
      "  1.19651809e-01 -2.20887095e-01 -2.36240983e-01 -8.61635208e-02\n",
      " -1.69054300e-01 -2.97955215e-01  4.19610664e-02  9.67656597e-02\n",
      " -2.06498832e-01 -4.29026783e-01 -3.59489590e-01 -1.41917303e-01\n",
      " -1.25114411e-01  1.08517863e-01 -2.49185592e-01 -2.25494653e-02\n",
      " -5.35103567e-02  1.29578605e-01  1.40200304e-02 -1.57418042e-01\n",
      " -2.62996525e-01 -2.05284402e-01 -2.83475786e-01 -2.68937111e-01\n",
      " -1.60080209e-01 -1.00455731e-01  1.47159994e-01  1.08749606e-01\n",
      " -2.97259778e-01  1.28017902e-01 -1.67263791e-01 -2.81227708e-01\n",
      " -1.12122469e-01 -8.39967933e-03 -1.70121472e-02 -2.10698873e-01\n",
      " -2.56737679e-01 -6.10215850e-02 -3.58075619e-01 -9.26864073e-02\n",
      " -1.14711545e-01 -8.81779492e-02  1.03143275e-01 -2.12299362e-01\n",
      "  9.36134830e-02  1.91900834e-01  1.27775565e-01 -3.33803445e-01\n",
      " -3.54429707e-02 -1.07590288e-01  1.38661796e-02  1.03258304e-01\n",
      " -2.08768412e-01 -4.64723051e-01 -1.81132972e-01  5.26449755e-02\n",
      " -3.75639424e-02 -4.18717042e-02 -2.83766717e-01 -1.19031807e-02\n",
      " -7.22288713e-02 -1.95591018e-01 -1.63943648e-01 -1.60491258e-01\n",
      "  9.55174118e-02 -1.47976011e-01  4.58783060e-02 -7.63445348e-02\n",
      " -3.28849077e-01 -3.13625783e-01  5.52588813e-02 -2.04601027e-02\n",
      "  6.57412335e-02 -1.32566184e-01 -3.56171310e-01  5.61622307e-02\n",
      " -3.90709102e-01 -1.50009885e-01  2.96218302e-02 -7.73844793e-02\n",
      " -6.17511012e-02  7.22717121e-02  2.63374038e-02  7.86514953e-02\n",
      "  1.45922810e-01 -2.71117359e-01  1.51029471e-02 -2.08593130e-01\n",
      " -6.05747290e-02  1.51674571e-02 -2.95427442e-01 -1.83749855e-01\n",
      " -3.71699959e-01 -1.45191640e-01 -3.26413989e-01 -6.12241626e-02\n",
      " -2.50442594e-01 -2.86207616e-01  1.29569694e-01 -7.77813494e-02\n",
      " -2.13553369e-01 -3.26181054e-01  1.59299046e-01 -1.90782443e-01\n",
      "  5.12891030e-03 -1.74195036e-01 -5.45913465e-02 -2.51549989e-01\n",
      "  4.36947122e-02 -1.38328239e-01 -2.93188602e-01 -9.36620086e-02\n",
      " -1.85787454e-02 -1.02473039e-03 -8.80076885e-02 -2.13101059e-01\n",
      "  1.34585589e-01 -3.22746187e-01  7.27781802e-02 -6.75695855e-03\n",
      "  2.41613667e-02 -3.06638964e-02  1.84544176e-01 -1.13206170e-01\n",
      "  1.74800783e-01 -1.57321170e-01  5.61055262e-03  2.92469144e-01\n",
      " -1.19457148e-01 -1.76651776e-01 -2.81450674e-02 -2.77418762e-01\n",
      " -9.93132368e-02  7.77484151e-03 -9.98231024e-02 -2.03295097e-01]\n",
      "L7N0                    -> L8N7 = [ 1.54150501e-02  3.85381803e-02 -4.53626039e-03 -2.01720923e-01\n",
      "  1.08081900e-01  1.15932927e-01  7.99634457e-02  1.31514460e-01\n",
      " -3.39582890e-01  3.90995890e-02  4.07816544e-02  1.27003506e-01\n",
      "  6.79724663e-03  8.11829977e-03 -1.80571660e-01 -4.15935069e-02\n",
      " -1.58192575e-01  1.96690843e-01  3.49321067e-02  1.15504764e-01\n",
      "  2.31952161e-01  1.74756318e-01 -6.17021956e-02  1.18514016e-01\n",
      "  1.68941841e-01  1.09272577e-01 -1.14551960e-02  1.44307405e-01\n",
      "  1.16325974e-01  3.97320092e-02  2.33525440e-01  1.80479005e-01\n",
      "  8.86633173e-02 -1.11454025e-01  1.26013130e-01  2.22959727e-01\n",
      "  4.20704670e-02  1.30488172e-01  2.76126385e-01  5.32070696e-02\n",
      " -5.54519594e-02 -7.87766352e-02  2.75258124e-01  1.98422633e-02\n",
      " -2.38143697e-01  8.91731754e-02  1.62525356e-01 -2.18812618e-02\n",
      "  3.75303961e-02  4.68488038e-02  2.87319183e-01  1.91892251e-01\n",
      "  2.59970665e-01  2.01895565e-01 -2.31634025e-02 -4.93096597e-02\n",
      "  2.08430797e-01  1.31100446e-01 -1.68315947e-01 -2.14356437e-01\n",
      " -3.42243873e-02 -3.55679244e-02 -9.99410450e-02  6.11193404e-02\n",
      "  2.48651147e-01  2.09053114e-01 -7.29460865e-02  2.87197647e-04\n",
      "  4.86392668e-03  3.01737003e-02 -1.00821033e-01 -2.92485300e-02\n",
      " -1.13814384e-01  1.10945618e-02 -1.19789713e-03  5.24673939e-01\n",
      "  7.32154623e-02  1.26876324e-01  3.44086103e-02  8.37745368e-02\n",
      " -1.82452917e-01 -9.35942754e-02 -1.48615554e-01 -2.23178305e-02\n",
      "  5.56471385e-02 -2.67993510e-01  3.03325485e-02 -1.09797314e-01\n",
      "  9.41259973e-03 -9.19013098e-02 -4.80351865e-01 -6.25678152e-02\n",
      "  2.34408408e-01  3.69303040e-02  7.69662019e-03 -5.19629046e-02\n",
      "  1.11182444e-02 -1.65422246e-01 -2.62601860e-02 -2.70191640e-01\n",
      " -1.25803109e-02  2.37678915e-01  5.93570285e-02 -2.97021363e-02\n",
      "  4.67359647e-02  2.16077060e-01  1.55794233e-01 -2.04776585e-01\n",
      "  2.84367532e-01  1.52386844e-01 -8.32352936e-02  4.62828502e-02\n",
      "  4.06613089e-02 -9.43213925e-02  1.91920117e-01 -1.13226801e-01\n",
      " -3.06458533e-01 -2.34891802e-01  2.83331126e-02 -1.35656968e-01\n",
      " -1.33271024e-01  5.61421784e-03  1.03656098e-01  9.54820141e-02\n",
      " -5.97767271e-02  1.17894262e-01  1.92352399e-01  1.10031128e-01\n",
      " -1.81134507e-01 -1.77958116e-01  2.04833433e-01  2.97545604e-02\n",
      " -1.57525644e-01  9.66803059e-02 -3.62033583e-02 -4.73495871e-02\n",
      " -1.56465173e-01 -1.05364710e-01  1.04819581e-01  1.02780260e-01\n",
      "  1.93157762e-01  1.26324207e-01 -1.01631016e-01  1.52460694e-01\n",
      " -1.38320565e-01  1.05377406e-01  1.48501649e-01 -2.46403024e-01\n",
      "  1.25789925e-01  1.75051659e-01 -4.06362936e-02 -9.59839150e-02\n",
      "  8.60802270e-03  2.38195330e-01  3.00441355e-01 -1.22733504e-01\n",
      " -1.07818380e-01  2.62974650e-01  2.93999940e-01  1.10660620e-01\n",
      "  1.54687092e-01  1.05902225e-01  1.86012477e-01 -6.57528713e-02\n",
      " -1.50493965e-01 -1.83493830e-02  1.10233031e-01 -1.52488902e-01\n",
      " -6.58960119e-02  2.72492051e-01 -3.27366590e-01 -4.63758148e-02\n",
      "  1.30445823e-01 -1.83592260e-01  2.90801048e-01 -2.24670932e-01\n",
      " -1.67716011e-01 -1.56789180e-02 -1.81624033e-02  1.22335821e-01\n",
      "  4.63334955e-02 -1.15834236e-01  5.71349636e-02 -5.21850586e-02\n",
      " -2.60717243e-01 -1.53107960e-02  5.50727546e-02  2.91030463e-02\n",
      " -3.32673304e-02 -1.62621021e-01 -2.11639002e-01  1.87793255e-01\n",
      " -1.89704165e-01 -7.52941146e-02  1.43495366e-01  2.06796706e-01\n",
      "  1.39904901e-01  1.80578098e-01  1.94243453e-02 -1.14558563e-01]\n",
      "L7N0                    -> L8N8 = [-0.25884822 -0.2118679   0.1096973  -0.15100107 -0.1279613  -0.05020073\n",
      " -0.03433453 -0.11367758  0.07216368  0.3778893   0.257468    0.10276874\n",
      " -0.21467075  0.07204154 -0.02615534 -0.13096537 -0.02437139 -0.00635396\n",
      "  0.15053204  0.1212604   0.06037499 -0.03997145 -0.1643148   0.03781799\n",
      " -0.09164022  0.01263458 -0.18222488  0.01129918 -0.03622553  0.04097377\n",
      "  0.00561327  0.12210195 -0.02144272  0.24733809  0.05791829  0.06954455\n",
      " -0.26463094  0.09259852 -0.07850996 -0.04359579 -0.13566974  0.10517991\n",
      "  0.20518574 -0.11178133  0.09526844 -0.14066358  0.02191832 -0.15791094\n",
      "  0.03296005 -0.15144603  0.06415804 -0.01573212  0.04274929 -0.01658413\n",
      " -0.12219188  0.05057062 -0.00637635 -0.032532   -0.06932365  0.13664658\n",
      "  0.20678204 -0.0876577  -0.00837297  0.21904169  0.07756345 -0.15484035\n",
      " -0.0372424  -0.02869339  0.04337363  0.09734739 -0.18671098  0.16061746\n",
      " -0.04383064  0.13759556 -0.03091085  0.00562371 -0.12330835 -0.15953434\n",
      " -0.0402027  -0.0814141   0.07346866 -0.05183133 -0.19921555 -0.02406079\n",
      " -0.13408686 -0.17413065  0.0409872   0.00893346 -0.20781301  0.08496629\n",
      " -0.06831755 -0.01347891  0.05845759 -0.05864741  0.02308698 -0.1681236\n",
      " -0.13312319 -0.18195248  0.21617916 -0.0858792  -0.05159999 -0.07031221\n",
      " -0.30567998  0.17331117 -0.1543185  -0.10854945 -0.03066878 -0.03876904\n",
      "  0.20197693 -0.10254924  0.01021048 -0.03354626  0.04836186  0.06895245\n",
      " -0.04431742  0.09216572 -0.10305484  0.02712108 -0.04702773 -0.0465128\n",
      "  0.23819856  0.01075055  0.07073011 -0.17658469  0.07950759 -0.10885087\n",
      "  0.01824806  0.05922941 -0.04251666 -0.15573771 -0.1967634  -0.0879098\n",
      "  0.17107666  0.38088378  0.08730222  0.13950655 -0.01102022 -0.03211039\n",
      "  0.06949988  0.08138207 -0.16810934 -0.1794956  -0.02950224  0.05813717\n",
      "  0.09622315 -0.09719623 -0.2527945   0.28077483  0.25801346 -0.18899609\n",
      " -0.15527353  0.05290081 -0.11455069 -0.18701583 -0.15013228 -0.12716924\n",
      "  0.13841929 -0.07701624 -0.11186691  0.0326491   0.23145896 -0.28058136\n",
      "  0.03055928  0.13628194 -0.11691938  0.12073584  0.04790272 -0.04188129\n",
      " -0.18670349  0.14970917  0.09300765  0.1324209  -0.22300895  0.06913217\n",
      "  0.03234805 -0.17083594  0.46212646  0.06376645  0.05922862 -0.01077611\n",
      " -0.10257369  0.00345818 -0.06234084 -0.06683313  0.02613434 -0.02820695\n",
      "  0.09634277 -0.1726895  -0.26220512  0.18645078 -0.05336052  0.10507932\n",
      "  0.19810073 -0.20073488 -0.03256914  0.08405206  0.05150306  0.08967574\n",
      "  0.06729347  0.15665586]\n",
      "L7N0                    -> L8N9 = [ 0.28746474  0.00351919  0.01712427  0.10041052 -0.02842639 -0.11751656\n",
      " -0.03708467  0.25514346  0.0533132  -0.02156498 -0.07413886 -0.34300485\n",
      "  0.05740552  0.02858398  0.01475312 -0.14884149 -0.24689955 -0.3750363\n",
      "  0.05150021  0.02115063 -0.07355095 -0.04751921 -0.13352059 -0.00197012\n",
      " -0.09034327 -0.1342664   0.08611412  0.09146446  0.01530024 -0.13628186\n",
      " -0.27275953  0.15043475 -0.03102644 -0.07447653 -0.19491506 -0.12487835\n",
      "  0.01725045  0.04122394  0.09277818  0.11675423  0.02755736  0.18074983\n",
      " -0.24351867 -0.04544846  0.1017679  -0.0476722   0.05959504 -0.03306466\n",
      " -0.21788085  0.0350497  -0.0936688  -0.1683557  -0.01654216 -0.01348337\n",
      " -0.05770752 -0.22147998 -0.00233573 -0.08568277  0.05334118  0.11180305\n",
      "  0.18504085  0.11308076 -0.4511382   0.08500154  0.11591042  0.03565938\n",
      "  0.14880072 -0.11543537 -0.10749137  0.07176324 -0.21119723  0.09595812\n",
      "  0.22751841  0.10683564  0.06584705  0.04858843 -0.04880448 -0.09174\n",
      " -0.09207832  0.08390021  0.06692549 -0.06958823 -0.01493802 -0.01289469\n",
      " -0.1110431   0.03793688  0.21406987 -0.00104732  0.12433414  0.00126531\n",
      " -0.39284417 -0.21459848  0.12873699  0.01045617 -0.05990639 -0.01070327\n",
      "  0.08656565  0.14410673  0.12815247  0.10871018 -0.11372814  0.30876637\n",
      " -0.00930277  0.22133583 -0.00722819 -0.21764685 -0.24785061  0.01425913\n",
      " -0.06029169 -0.08438371 -0.52553576 -0.03655384  0.04876248 -0.3281998\n",
      " -0.13163906 -0.0926428  -0.26077256  0.2520865   0.12579021 -0.2524565\n",
      " -0.10558932  0.04749463  0.11874142  0.10820892  0.10181879 -0.14826305\n",
      " -0.3733395   0.08361462 -0.5075585  -0.09916069 -0.08076175 -0.02442628\n",
      "  0.09556378 -0.0300744  -0.07898539 -0.03270314  0.10502601 -0.22598958\n",
      " -0.08086007  0.14238058 -0.02284522 -0.02704739 -0.24588133 -0.01382489\n",
      " -0.083514   -0.03161689 -0.1767911  -0.09501844 -0.15379278 -0.01287199\n",
      " -0.04508658  0.01703028 -0.07895447 -0.12195878 -0.15076539 -0.18653643\n",
      "  0.1730077  -0.0550165  -0.05028791  0.03296255  0.38859308  0.18794559\n",
      "  0.00439814 -0.09037775 -0.03951379  0.01247562 -0.2188975  -0.02465666\n",
      " -0.03161169 -0.21299817  0.01833802 -0.07880607 -0.15898067  0.18169698\n",
      "  0.1189419  -0.43172574 -0.11759211 -0.11936808  0.11036254  0.00738953\n",
      "  0.00526568  0.05075748  0.0960995   0.2921329  -0.09675211 -0.01894445\n",
      "  0.17605603 -0.48112956 -0.00604598  0.20128973 -0.19507776 -0.33418554\n",
      " -0.01163785 -0.0694961   0.14746957 -0.02393511  0.03202069 -0.23813453\n",
      "  0.02397573  0.03542496]\n",
      "L7N0                    -> L8N10 = [-0.09034544 -0.03176496  0.07608861 -0.08677483 -0.1825535   0.02099725\n",
      "  0.16163124  0.22684285  0.07132325 -0.01916086  0.21873719 -0.2806431\n",
      "  0.18227766 -0.0005553  -0.12881526 -0.16639641  0.14556317 -0.01971934\n",
      "  0.00832642 -0.03885372 -0.09770174 -0.02370715  0.27451867 -0.024444\n",
      " -0.12819417  0.01822532 -0.1946749   0.00729432 -0.19317238 -0.01351976\n",
      "  0.22083052 -0.07221181 -0.01897187  0.13156652  0.2071343   0.06330206\n",
      "  0.07575243  0.14977114 -0.17202315 -0.06069143  0.18393348  0.29149154\n",
      " -0.0584657   0.1894498   0.21729788 -0.14032081  0.10252413  0.05970439\n",
      " -0.15650244 -0.05421802 -0.22913098  0.00972093  0.08625063  0.11395547\n",
      " -0.05881818 -0.23716933 -0.04971357  0.07688981  0.0239544   0.10940804\n",
      " -0.10333145 -0.06404292  0.26167938 -0.14997093 -0.13227047  0.09862231\n",
      "  0.22201547 -0.06175736  0.14551508  0.1106514  -0.03107359 -0.19457799\n",
      "  0.21704486  0.09624909  0.03154664 -0.15290576 -0.07115922 -0.09422208\n",
      " -0.03022431 -0.01694896  0.16083807 -0.03372505 -0.04187614 -0.12223744\n",
      " -0.0355532   0.00429722 -0.02228188 -0.01499026 -0.04888326 -0.08880813\n",
      "  0.14561318 -0.1334926   0.08917569 -0.07471365  0.17202134  0.04389655\n",
      " -0.00385789 -0.11728482  0.0957875   0.00672536  0.03820563 -0.08148105\n",
      "  0.26018015 -0.16922113 -0.25820187 -0.10931895 -0.16769487 -0.08931488\n",
      "  0.06288145  0.2678618   0.05320191  0.21879876 -0.01300563  0.12475748\n",
      " -0.1034312  -0.24594103  0.06495     0.09259247 -0.05110567 -0.02035965\n",
      " -0.07542441  0.00316733 -0.02892544  0.28144416  0.1415872  -0.01855792\n",
      " -0.02081637 -0.01944002 -0.10954793 -0.02623236  0.01755546  0.06900303\n",
      "  0.1861146   0.10269622 -0.3295363  -0.1033506  -0.34120044 -0.13080662\n",
      " -0.01107475 -0.0269506  -0.13389286 -0.07242153 -0.31211275  0.06361667\n",
      "  0.18490554 -0.36965925 -0.24434832  0.14751826  0.12486761  0.10511498\n",
      " -0.0906831   0.15613069  0.06346865 -0.11661551 -0.14406742 -0.19901553\n",
      " -0.02424354 -0.26133463 -0.10183694 -0.11034667 -0.10823072  0.18767628\n",
      "  0.17274313 -0.14255299 -0.2160967   0.0300275  -0.18291603  0.07332021\n",
      " -0.20953909 -0.31443053 -0.28013828  0.17960174 -0.01996802 -0.04369713\n",
      "  0.01231787 -0.04776995 -0.2468624  -0.16377525  0.03565445  0.03106769\n",
      " -0.20719884 -0.07955863 -0.33320147  0.16919658 -0.16510645  0.02353338\n",
      " -0.13409352 -0.06638418 -0.16870826  0.04470083  0.22973564  0.3221266\n",
      "  0.30960572 -0.01231792  0.00887016  0.09353546 -0.02281302  0.03966367\n",
      "  0.01331956  0.02997965]\n",
      "L7N0                    -> L8N11 = [ 1.41312256e-01  1.68718770e-01  1.81847867e-02 -6.11433536e-02\n",
      " -1.79327145e-01 -3.83311093e-01 -9.73508358e-02  4.71081771e-02\n",
      "  9.52163828e-04 -1.30093634e-01 -1.02564283e-01 -1.11176871e-01\n",
      "  8.59426633e-02  5.57459332e-02  1.77738935e-01 -2.85212427e-01\n",
      " -2.23991811e-01 -1.30683109e-01 -1.40530705e-01 -8.03723484e-02\n",
      " -2.16390193e-02 -1.46926478e-01 -1.24038361e-01 -7.71555826e-02\n",
      "  5.78864478e-02 -2.02502772e-01 -3.81380357e-02 -1.13571241e-01\n",
      " -6.20003417e-02 -1.03967808e-01 -2.39725456e-01 -5.92527427e-02\n",
      " -3.78640480e-02  1.38815314e-01 -7.34959766e-02  8.28425735e-02\n",
      " -2.01758578e-01 -9.14872587e-02  1.07803151e-01 -2.78948456e-01\n",
      " -1.69366255e-01  1.68929771e-01 -6.90912083e-02 -7.19298935e-03\n",
      " -1.33373052e-01 -1.71935096e-01 -2.01718926e-01 -6.57657385e-02\n",
      " -1.24671616e-01 -1.87046584e-02 -5.86978793e-02 -2.14279860e-01\n",
      " -1.22615345e-01 -1.69412866e-01 -3.22247535e-01 -1.45810500e-01\n",
      " -1.31115802e-02  8.52301270e-02 -5.21827936e-02  1.58924982e-02\n",
      " -1.16944492e-01 -8.76381248e-02 -3.38308305e-01 -4.90928255e-02\n",
      " -1.37936428e-01  7.97036046e-05 -2.96872426e-02  6.37599640e-03\n",
      "  4.90502529e-02 -2.15837538e-01 -1.14660844e-01 -1.71707794e-01\n",
      "  5.03984168e-02 -4.82699983e-02 -3.64217311e-02 -9.13672671e-02\n",
      " -2.22753629e-01 -6.17297441e-02 -8.23250785e-02 -8.52338821e-02\n",
      "  4.93226685e-02 -8.37915167e-02 -9.25839692e-02 -4.80972707e-01\n",
      "  1.26849294e-01 -3.43332216e-02  1.05296053e-01  2.63316154e-01\n",
      " -2.29726762e-01 -1.46656498e-01 -2.82910049e-01 -8.27530921e-02\n",
      "  6.78981021e-02 -3.67367975e-02  6.01133555e-02 -1.28640667e-01\n",
      "  5.17430678e-02  3.21795158e-02 -3.98088396e-02 -2.61976957e-01\n",
      " -4.28453349e-02  1.51448243e-03 -2.68572181e-01 -4.74075675e-02\n",
      "  7.05593377e-02 -5.19200452e-02 -1.24073707e-01 -1.99721213e-02\n",
      " -2.70669043e-01 -4.97682430e-02 -1.45243257e-01 -2.09485635e-01\n",
      " -1.10889021e-02 -2.03021437e-01 -9.18327197e-02 -4.93982732e-02\n",
      " -1.10507078e-01 -3.33179146e-01 -8.48758966e-02 -1.04257444e-04\n",
      " -2.86831677e-01  2.01655179e-02 -1.76296785e-01  1.44889176e-01\n",
      "  1.55108254e-02 -9.67801660e-02 -1.27940431e-01 -4.39565107e-02\n",
      " -2.57560343e-01  4.00878266e-02 -2.69245327e-01 -2.66164124e-01\n",
      " -2.96923295e-02  3.04437578e-02 -1.52995795e-01 -1.53999448e-01\n",
      "  2.61819631e-01 -2.64712870e-01 -2.55942434e-01 -8.92310664e-02\n",
      "  4.66729403e-02 -1.62088260e-01 -2.85934687e-01 -6.75782785e-02\n",
      "  8.66628513e-02 -8.58052298e-02 -9.15581174e-03 -1.71053097e-01\n",
      " -3.91700342e-02 -5.79593666e-02 -4.76802111e-01 -1.42229199e-01\n",
      " -1.99835777e-01 -7.09120110e-02 -9.76484865e-02  3.34026776e-02\n",
      " -8.35390687e-02 -4.27451074e-01 -1.24237292e-01 -2.36239135e-02\n",
      " -2.82539427e-01 -2.91196525e-01 -6.04290962e-02 -2.15993166e-01\n",
      " -1.64748892e-01  2.20846869e-02 -5.25554359e-01  4.77749929e-02\n",
      " -7.82074034e-02 -2.70356953e-01 -6.50465563e-02 -2.08870336e-01\n",
      " -1.78838775e-01 -8.78250599e-02 -2.20680416e-01  1.36259124e-01\n",
      "  7.32836872e-02  1.46717697e-01  4.58466746e-02 -1.41321480e-01\n",
      " -1.33185551e-01 -3.50175053e-01  7.78071731e-02  2.22886056e-02\n",
      " -6.78793937e-02 -1.15440607e-01 -1.63412392e-01  2.25461144e-02\n",
      " -1.33749843e-01 -2.22848058e-02 -1.83813572e-02 -1.60879523e-01\n",
      "  3.50663476e-02  1.12589955e-01 -5.28753474e-02  3.74639295e-02\n",
      " -9.24939364e-02 -9.26720873e-02 -2.46070132e-01 -8.64628106e-02]\n",
      "L7N0                    -> L8N12 = [ 0.04037657  0.149723   -0.06106773 -0.2111885   0.06466918  0.07489733\n",
      " -0.20497894  0.12210204 -0.5306029  -0.21011837  0.12137291  0.2607005\n",
      "  0.00111436 -0.03241738 -0.32030547  0.05894565 -0.22088821 -0.04032403\n",
      " -0.10460074 -0.22855695 -0.5115642   0.02385755  0.09768367 -0.26182705\n",
      " -0.13756096 -0.15997651  0.05842083  0.05676013 -0.03414794 -0.11006434\n",
      "  0.07901672 -0.12201281 -0.06062723 -0.1681336  -0.09730386 -0.3134701\n",
      " -0.20209786 -0.09216694  0.20861779 -0.28263682 -0.09504708 -0.27937886\n",
      " -0.11050437 -0.10336939 -0.0246815   0.02571315 -0.28066954 -0.01298394\n",
      "  0.062005   -0.11489733 -0.074359    0.07389662 -0.02431902 -0.04773945\n",
      "  0.18685453 -0.17868343 -0.29080206 -0.08032859 -0.09923428  0.1898367\n",
      " -0.11636638 -0.1484036   0.21080445 -0.14559297  0.12848693 -0.04821333\n",
      " -0.11985189 -0.23493299 -0.13574173 -0.17460817 -0.0276179   0.00684803\n",
      " -0.07674941 -0.4206859  -0.2847872  -0.03798603  0.01863902 -0.1763266\n",
      " -0.19904053 -0.06780905 -0.33049384 -0.1370217   0.01269016  0.03066064\n",
      "  0.05253189 -0.2771156  -0.23460867 -0.4470303  -0.20507349 -0.14559574\n",
      "  0.08987821 -0.04143992 -0.22656468 -0.00989623 -0.04576182 -0.20844714\n",
      "  0.05838473 -0.06720366 -0.30007365 -0.07221166 -0.02970608 -0.19534287\n",
      " -0.06105909 -0.21250927 -0.15336479  0.05682245 -0.09264679 -0.30457622\n",
      " -0.1226307  -0.16208623  0.05892724 -0.11448942  0.15256488  0.1380728\n",
      " -0.00700102  0.16380851 -0.12894285 -0.06989994 -0.02244477 -0.12229615\n",
      " -0.3856677  -0.10137386  0.07552565  0.02655349 -0.48136958 -0.14981076\n",
      "  0.05042333 -0.12692137 -0.11174982 -0.39703003 -0.20374075 -0.15596218\n",
      "  0.08741131 -0.04283985 -0.2068918   0.00910592 -0.10359193 -0.03722434\n",
      " -0.06963759 -0.15772124  0.16598696 -0.02675983 -0.05068182 -0.05213173\n",
      " -0.15715317 -0.08377928 -0.32370907  0.1327145  -0.23728846 -0.12663582\n",
      "  0.0848893  -0.29891565  0.21793146 -0.17262243 -0.31093496  0.00329435\n",
      " -0.18321131  0.28580394  0.10568199  0.00668696  0.12812807  0.10795667\n",
      " -0.22440037  0.0284216   0.19856732 -0.09127964  0.03286067 -0.3527687\n",
      " -0.3107098  -0.17068554 -0.29039824 -0.3005428  -0.09900782 -0.21298139\n",
      "  0.16159965 -0.21127805 -0.09985189 -0.19503926  0.00207196  0.02026726\n",
      " -0.03065889 -0.27605152 -0.10344376 -0.08425711 -0.25308067 -0.24538362\n",
      " -0.21257241 -0.32992238 -0.05811878 -0.16903944  0.06920506  0.20091671\n",
      " -0.0943616   0.00223088  0.0707491  -0.20592487  0.10300706 -0.04692802\n",
      " -0.0783589  -0.09694353]\n",
      "L7N0                    -> L8N13 = [-3.30549292e-02 -1.58497497e-01 -1.36797443e-01  2.70138327e-02\n",
      " -1.42120523e-02 -2.52183676e-01 -8.46504495e-02 -1.16501532e-01\n",
      " -5.46535589e-02 -2.13790298e-01 -2.44688705e-01 -4.92288582e-02\n",
      "  9.86437500e-02 -2.19495416e-01  1.85668036e-01 -1.08023956e-01\n",
      " -1.42344400e-01  1.48215756e-01 -1.05100885e-01 -1.25715658e-01\n",
      " -9.64437947e-02 -3.88543278e-01  4.23223898e-02 -1.84138075e-01\n",
      " -4.49901938e-01 -8.07266757e-02 -6.10325187e-02 -3.60226274e-01\n",
      " -2.67756164e-01 -1.85195506e-01 -2.28970557e-01 -3.31901014e-01\n",
      " -1.35070324e-01 -1.44014820e-01 -3.32074344e-01 -1.32915139e-01\n",
      " -2.25066841e-01 -1.82790950e-01 -1.00218669e-01 -1.42701015e-01\n",
      " -1.59736082e-01 -6.27882313e-03 -1.99085310e-01  5.09287342e-02\n",
      " -8.35652798e-02  1.53702855e-01 -1.24343596e-01 -1.03050224e-01\n",
      " -1.24897934e-01 -1.02352060e-01 -1.27908841e-01 -2.73516793e-02\n",
      " -1.33564949e-01  1.22254930e-01 -1.84653789e-01 -1.78965271e-01\n",
      " -4.19753075e-01 -4.82339412e-02 -1.36816502e-01 -1.89577900e-02\n",
      " -1.22273698e-01 -3.57145190e-01  3.13800164e-02 -5.12686193e-01\n",
      " -2.00031865e-02 -1.54274970e-01 -5.29251397e-01  9.34358221e-03\n",
      " -1.08582482e-01 -2.07119331e-01 -8.75667855e-03 -1.82585359e-01\n",
      " -1.52391657e-01 -2.71145344e-01  2.00306857e-03  1.04796208e-01\n",
      " -1.01497158e-01 -1.41037837e-01 -3.07006210e-01 -2.43295386e-01\n",
      "  7.95261264e-02 -1.13595501e-01 -1.09613851e-01  1.23217985e-01\n",
      " -3.15595865e-01 -6.77039251e-02 -5.32022864e-02  8.13942030e-02\n",
      " -3.44351195e-02 -1.04256302e-01  1.00246616e-01 -1.49153888e-01\n",
      " -3.02401662e-01 -1.08466618e-01 -3.67800593e-01 -1.35538325e-01\n",
      " -2.42141590e-01 -2.52896827e-02 -3.10536355e-01 -1.18704341e-01\n",
      " -3.55144590e-02 -1.39091492e-01 -4.68864381e-01 -1.29258588e-01\n",
      " -8.29332769e-02 -4.03423570e-02 -7.34838992e-02 -3.20014238e-01\n",
      " -1.49760276e-01 -1.14567697e-01 -8.19010437e-02 -1.78871647e-01\n",
      "  1.55979261e-01 -3.91331106e-01  7.65364096e-02  1.74415275e-01\n",
      " -1.90505192e-01 -1.93990082e-01 -1.70988888e-01  7.73057193e-02\n",
      " -9.33617279e-02 -1.03805199e-01 -4.02575612e-01 -1.33750468e-01\n",
      "  7.95340687e-02 -4.12046798e-02 -2.78521746e-01 -3.20949964e-02\n",
      " -8.41296464e-02  1.10163152e-01 -2.46039405e-01 -1.06652481e-02\n",
      " -2.43124351e-01  1.15111455e-01 -4.07451987e-01 -9.50812921e-02\n",
      " -3.60649318e-01 -7.72514148e-03 -4.02993590e-01 -8.74783695e-02\n",
      " -2.79995263e-01  5.99416755e-02  2.41949074e-02 -2.36636862e-01\n",
      " -2.20265631e-02 -5.37626706e-02 -1.52999863e-01 -2.77413428e-01\n",
      " -2.03118131e-01 -4.92719471e-01 -2.20261142e-02 -2.92189538e-01\n",
      "  1.15423566e-02 -2.59641141e-01 -3.86568725e-01  3.75172645e-02\n",
      "  1.16407059e-01  1.07188553e-01 -2.96912938e-01  1.28301799e-01\n",
      " -8.77251476e-02 -1.19748190e-01 -2.26213336e-01 -1.59828067e-01\n",
      " -9.50482965e-04 -4.32151765e-01 -1.43268164e-02  3.90533097e-02\n",
      " -2.65980512e-01  1.21806547e-01  4.82004918e-02 -7.34677166e-02\n",
      " -1.32933468e-01  8.30013528e-02 -1.64639145e-01 -5.62443286e-02\n",
      "  1.18343338e-01  1.14207879e-01 -8.30692519e-03  4.35407758e-02\n",
      " -5.52430898e-02 -2.56836295e-01 -1.39562115e-01  5.90057708e-02\n",
      " -5.27270399e-02 -5.43541089e-02 -1.98196023e-04  4.67824601e-02\n",
      "  1.41724572e-01 -5.27113788e-02  4.87437937e-03  1.91310301e-01\n",
      "  5.49274795e-02  2.59560142e-02  6.19346090e-03 -1.15613423e-01\n",
      " -1.79860666e-01  9.33836401e-02 -1.44543946e-01  8.08287114e-02]\n",
      "L7N0                    -> L8N14 = [-0.07880612  0.1393806  -0.07265048 -0.11168843 -0.17079186 -0.01931619\n",
      " -0.19683243 -0.11140168 -0.24945305 -0.27701834 -0.27836072 -0.0433771\n",
      "  0.01243458 -0.06103845 -0.10298222  0.20462584 -0.28650466  0.16040489\n",
      "  0.18891953 -0.16480012 -0.33188257 -0.02658683 -0.0693514  -0.03115807\n",
      " -0.01172807 -0.10560816  0.06319598 -0.43651336 -0.0044528   0.06895076\n",
      "  0.00412955 -0.21241349  0.01348476 -0.3209595   0.14328626 -0.13679288\n",
      " -0.01125882  0.01180639  0.06678521 -0.07241032  0.08233345  0.03225534\n",
      " -0.14889316 -0.03527394 -0.09048465 -0.03347576 -0.2651815  -0.1948129\n",
      " -0.03047844 -0.04934035 -0.3850873  -0.37149125  0.05807775 -0.01224915\n",
      " -0.02533093 -0.03728703 -0.02768133 -0.07252208 -0.29809785  0.17579433\n",
      "  0.18550801 -0.3687369  -0.19317292 -0.11586075 -0.08889896 -0.49809462\n",
      " -0.15814129 -0.13565251  0.05781437 -0.07158727 -0.17215066 -0.05452844\n",
      " -0.12748069  0.05598246 -0.15150811 -0.16860823  0.03800864  0.04516984\n",
      " -0.0905607  -0.1168011  -0.20129044  0.13381624  0.00286351 -0.31861112\n",
      " -0.32457125  0.19774696 -0.26243415 -0.1436904   0.06367088 -0.43107808\n",
      "  0.01709916  0.10464293 -0.05913148 -0.24789944 -0.2384909   0.00071317\n",
      " -0.192409   -0.06574877 -0.2809489  -0.23767638 -0.42454648 -0.04875707\n",
      "  0.2204278  -0.5376945  -0.17218235  0.01232272 -0.05870903  0.19486612\n",
      " -0.07544661  0.00842987  0.00278343 -0.06997694  0.0518388   0.08061087\n",
      " -0.07381272 -0.13639602 -0.09235732 -0.14622788 -0.3340086  -0.24059772\n",
      " -0.18402372 -0.17784439 -0.11006741  0.05734594 -0.2213137  -0.16009195\n",
      " -0.09706247 -0.24053901  0.21720693 -0.1292429   0.0166186  -0.10665961\n",
      " -0.04230299 -0.18051815 -0.12621632 -0.12535061 -0.221779    0.0610873\n",
      " -0.06749766  0.05095001 -0.05117524 -0.32633185 -0.01133764 -0.21933727\n",
      " -0.13086213  0.16220464 -0.00816331  0.07036842  0.06032529 -0.02547236\n",
      " -0.06040641 -0.03260763  0.1789514   0.03300419 -0.09078959 -0.20914094\n",
      "  0.07901903 -0.1213043  -0.14821537  0.05424814 -0.19693235 -0.12645732\n",
      " -0.23568769 -0.10043739  0.00602362 -0.07367773  0.15464915 -0.00096727\n",
      " -0.22574979 -0.18905215 -0.20161481 -0.29988116 -0.25652465 -0.04931634\n",
      "  0.01364852 -0.10298096  0.0557673  -0.10838199 -0.34708402  0.1321263\n",
      " -0.08323931 -0.11836062 -0.06665496 -0.18780805 -0.3351611  -0.10855938\n",
      "  0.12166493  0.05694478  0.07261657 -0.36093825 -0.04196443  0.28608564\n",
      " -0.40669957 -0.32367286 -0.02525595 -0.16901876 -0.0996847   0.03349906\n",
      "  0.01163072 -0.12722236]\n",
      "L7N0                    -> L8N15 = [ 5.04308902e-02  5.34799173e-02  8.40901807e-02 -3.57980058e-02\n",
      " -2.86889337e-02  3.07342976e-01 -1.39087632e-01  1.63326994e-01\n",
      " -6.84340820e-02 -3.02522108e-02  1.45764470e-01 -2.67090257e-02\n",
      " -7.09239170e-02  8.77396092e-02  1.42224252e-01 -3.48438859e-01\n",
      " -1.27408355e-01 -1.97740123e-01 -5.81796691e-02 -1.92853987e-01\n",
      " -2.64545858e-01  3.93181220e-02 -1.24143593e-01 -5.00801159e-03\n",
      "  8.52779578e-03 -3.82438153e-02 -1.58846095e-01  5.55551536e-02\n",
      " -1.48740225e-02  2.35043883e-01  9.57208052e-02 -1.69321910e-01\n",
      "  1.18989922e-01 -1.43086389e-01  2.09750813e-02  5.01932353e-02\n",
      "  2.41581380e-01 -8.98492336e-02  1.56017736e-01 -1.54486746e-01\n",
      "  2.01456975e-02 -9.66665819e-02 -2.95120895e-01  2.74619341e-01\n",
      " -1.61875710e-01  2.47432608e-02 -1.23729266e-01 -2.17266977e-01\n",
      " -1.75442129e-01 -1.16726168e-01 -1.93847373e-01 -1.28211960e-01\n",
      "  3.89639437e-02 -1.43297175e-02 -1.13014340e-01 -1.27184197e-01\n",
      " -1.12779047e-02  9.85763520e-02 -2.75392026e-01  3.33516598e-02\n",
      " -8.72657001e-02 -6.31137043e-02  3.63685042e-02  2.09829640e-02\n",
      " -7.67471716e-02 -3.99689237e-03  2.39357054e-01 -1.06261536e-01\n",
      "  1.80111844e-02 -1.06569438e-04  1.16211765e-01 -5.44631183e-02\n",
      "  1.56975910e-01  1.04451507e-01 -5.36020547e-02 -4.88635004e-02\n",
      "  1.44299954e-01 -1.43331498e-01 -1.45840824e-01  6.95866346e-02\n",
      "  6.19662069e-02  5.86783476e-02 -1.27097834e-02  1.29742742e-01\n",
      " -1.63297594e-01  2.27669716e-01  1.03551522e-01  1.54061526e-01\n",
      " -3.40077698e-01 -8.89209658e-03 -1.12803355e-01  1.12468459e-01\n",
      " -6.37311637e-02  5.04777245e-02  8.42172652e-02 -2.88541634e-02\n",
      " -9.65759084e-02 -8.65154376e-04  9.08123776e-02 -2.13759646e-01\n",
      " -4.89938818e-03  2.46750358e-02 -1.02277763e-01 -1.95770469e-02\n",
      "  1.81974456e-01 -5.26988059e-02 -2.50011832e-01  1.29867941e-01\n",
      " -2.05210447e-01 -2.90925145e-01 -3.16759080e-01  1.81970522e-01\n",
      "  1.02866115e-02 -1.61227137e-01 -4.21655253e-02 -6.42136931e-02\n",
      " -1.67487711e-01 -6.07401989e-02  1.61193103e-01  5.43000735e-02\n",
      "  1.49098858e-01 -6.92962408e-02 -1.61197618e-01  1.29246250e-01\n",
      "  4.69712839e-02  9.16374624e-02 -9.78510305e-02 -1.60347973e-03\n",
      "  7.86344707e-02  7.38603175e-02  3.99212353e-02 -1.18251136e-02\n",
      "  1.01908088e-01  3.17084566e-02 -1.07781343e-01 -1.28754616e-01\n",
      " -4.27502632e-01 -4.16815430e-01  2.24654879e-02  2.80786693e-01\n",
      "  3.63978446e-01 -2.72370607e-01 -2.38752738e-01  2.81296782e-02\n",
      "  2.07599942e-02  2.99127656e-03  2.74435449e-02  1.47204980e-01\n",
      "  4.83244173e-02  1.46207169e-01 -3.24760079e-01 -2.26723831e-02\n",
      " -1.18800305e-01 -1.27371684e-01  9.58144516e-02 -2.63292760e-01\n",
      "  6.65454715e-02 -3.47866952e-01  9.74176526e-02 -2.43263885e-01\n",
      " -3.48989666e-02 -6.88388795e-02 -1.40547961e-01 -3.40725869e-01\n",
      " -1.17891114e-02  3.78832042e-01 -2.67980486e-01  1.95493028e-01\n",
      " -2.22097993e-01  4.77943309e-02  4.55863141e-02 -9.75799412e-02\n",
      " -2.53583461e-01  3.42346042e-01 -9.04816687e-02 -1.22090898e-01\n",
      " -8.67204741e-02  8.45916644e-02  2.14492176e-02 -1.92900911e-01\n",
      " -4.32688087e-01 -7.49016702e-02 -3.23235318e-02 -1.38766527e-01\n",
      " -2.17967004e-01 -5.27529977e-03 -3.11652869e-01 -2.59686578e-02\n",
      " -2.05701981e-02  1.02356561e-01 -2.64767138e-03 -2.32063606e-01\n",
      "  9.88773108e-02 -1.56861097e-01  7.40644755e-03 -1.08427525e-01\n",
      "  1.33273214e-01 -2.59392321e-01  1.52235165e-01  8.54640547e-03]\n",
      "L7N0                    -> L8N16 = [ 0.19747637  0.25985977  0.01935172 -0.17883205 -0.19567285  0.16599147\n",
      "  0.12897797  0.14714561 -0.0278019   0.12180899  0.02068226 -0.2599954\n",
      " -0.3094557   0.39402536  0.05418165 -0.025644    0.17312495  0.03891801\n",
      "  0.13501498  0.03222011  0.2504966  -0.00920406  0.27133062  0.1442599\n",
      "  0.10521933  0.17848639 -0.17696078 -0.00384629  0.06985944  0.22123215\n",
      " -0.1410852   0.16445906  0.06700652  0.15234864  0.17076665 -0.22557944\n",
      " -0.0803178   0.04745588  0.01049948  0.34331888  0.24883126 -0.1390477\n",
      "  0.04680044 -0.05168205  0.08476605  0.02489774 -0.13751648  0.11966024\n",
      " -0.31636715  0.14585884 -0.06416196 -0.01509525  0.01317023  0.10629769\n",
      " -0.35350427  0.00828658  0.00773969  0.00951855  0.02981688 -0.12424168\n",
      "  0.0914755   0.13999371 -0.00745515  0.00414083  0.18686774  0.04179114\n",
      "  0.17248176 -0.33959624  0.15100543  0.2042411   0.16847996 -0.08375733\n",
      " -0.01950938  0.22919849 -0.06411244 -0.07204153  0.15106103 -0.04045414\n",
      "  0.0077706   0.12788439 -0.205712    0.2676772   0.09566095  0.11379796\n",
      "  0.28062946  0.26226148  0.04322601 -0.11365686  0.11402729 -0.07047316\n",
      "  0.06227955  0.03862613  0.03851573  0.20345399 -0.1284916  -0.11107035\n",
      "  0.01955517 -0.11677122  0.11708802  0.06000637  0.11134241 -0.17466798\n",
      "  0.15228239  0.00086469 -0.04998331 -0.16912204 -0.01791358 -0.00623885\n",
      "  0.18878399  0.15119825  0.10867296 -0.04295278 -0.25438565  0.23567787\n",
      " -0.18242082 -0.00343383  0.15747948 -0.1384653   0.04052437 -0.14494723\n",
      " -0.0948841   0.08862457 -0.05515918  0.05761418  0.17015998  0.00510524\n",
      " -0.00084974 -0.09052641 -0.14394315 -0.0109862   0.14489046  0.14507717\n",
      "  0.05205345  0.19867605  0.10472648  0.06927504  0.25520548 -0.08775311\n",
      "  0.11790958  0.12666044  0.16907139 -0.02621622 -0.2563102   0.00104452\n",
      "  0.29296607 -0.03098135 -0.21552949  0.0742086   0.15494066  0.35088143\n",
      "  0.02744469 -0.1087959  -0.44128534  0.07351154  0.16680595 -0.08795718\n",
      "  0.49909043 -0.24658147  0.26201546 -0.29213434  0.3053105   0.08326942\n",
      "  0.04590132 -0.3178601   0.0922369   0.02093133 -0.11663109  0.02010435\n",
      " -0.09785192  0.10502488  0.25568736 -0.10721414  0.13955446  0.07902116\n",
      "  0.00320105  0.09957405  0.28068218 -0.02032255  0.15143271 -0.2035409\n",
      " -0.21844907  0.10201436  0.06138563  0.32411665  0.13872646  0.10197994\n",
      " -0.04283647 -0.00054575 -0.19679193  0.00603107  0.05585222  0.10484586\n",
      "  0.09579699 -0.04752877  0.11382619 -0.07963528 -0.02272995 -0.18077506\n",
      "  0.1070265  -0.07846104]\n",
      "L7N0                    -> L8N17 = [-3.05774622e-02  7.57036433e-02 -2.94012904e-01 -5.35721660e-01\n",
      " -4.96973731e-02 -2.09495932e-01  9.83532891e-02 -1.25446185e-01\n",
      " -1.23644806e-01 -6.40210733e-02 -5.68451136e-02 -1.24235339e-01\n",
      "  1.04619578e-01  8.72296169e-02 -3.17036435e-02 -3.01166624e-02\n",
      " -1.50294915e-01 -5.30603170e-01 -7.46250665e-03  6.16149455e-02\n",
      "  2.86925465e-01 -2.13961229e-02 -3.39651644e-01 -4.57629859e-02\n",
      "  1.10416390e-01 -1.17054461e-02 -1.72712713e-01 -9.85129401e-02\n",
      " -1.04558609e-01 -2.82699972e-01 -2.49614805e-01 -1.16231292e-01\n",
      "  1.15038238e-01 -1.12952240e-01  6.53778389e-02  2.14907333e-01\n",
      "  8.75935256e-02  7.04446211e-02 -1.39395371e-01 -8.57835189e-02\n",
      " -3.20651233e-01  9.40144882e-02  2.82289356e-01 -3.35752517e-01\n",
      "  6.32253215e-02  9.22592059e-02  1.27804115e-01  1.59848947e-02\n",
      " -2.50266314e-01 -3.17330956e-02  2.38338456e-01 -2.28379726e-01\n",
      "  1.90772235e-01  7.26627260e-02 -9.96833108e-03 -1.55870125e-01\n",
      "  1.49569079e-01 -3.96164879e-02  2.13668570e-01 -2.64918208e-01\n",
      " -1.80803105e-01  1.03229238e-02 -2.49990135e-01 -3.46478999e-01\n",
      " -5.95874563e-02  7.62111470e-02  1.39036432e-01  9.97226089e-02\n",
      " -1.94363490e-01 -1.68336779e-01 -1.01848245e-01  2.58913398e-01\n",
      " -1.32206216e-01 -3.87718752e-02 -5.06825984e-01 -3.13657016e-01\n",
      " -3.31041574e-01 -2.15571493e-01 -5.07906973e-02 -1.32665157e-01\n",
      "  2.48436276e-02 -1.70662239e-01  1.46465957e-01  1.20363943e-02\n",
      "  2.55292624e-01  3.14531773e-02  1.36080220e-01 -1.29378304e-01\n",
      "  1.26417711e-01  1.72596857e-01 -6.20137528e-02 -1.06130667e-01\n",
      " -9.89792794e-02 -2.31674343e-01  4.59590927e-02  7.17452094e-02\n",
      " -1.05431244e-01  2.79704612e-02 -2.83587903e-01 -1.11443684e-01\n",
      "  7.90630281e-02 -3.59540433e-01 -2.08842814e-01  1.28878593e-01\n",
      " -1.49743333e-01 -1.59860224e-01 -1.14066321e-02 -1.83708340e-01\n",
      " -7.05605075e-02  1.08615130e-01 -2.76166499e-01 -8.24676231e-02\n",
      " -3.93428773e-01 -9.52936858e-02  9.26520899e-02 -2.56282002e-01\n",
      "  2.65476834e-02  1.54874384e-01  1.37258125e-02 -1.16817005e-01\n",
      "  3.72822374e-01 -1.28506660e-01 -4.60598543e-02 -1.34037331e-01\n",
      " -2.31675748e-02  7.00048590e-03 -2.92808674e-02 -2.87692845e-01\n",
      " -7.61441886e-03  1.40455723e-01 -1.12444609e-01 -8.80399644e-02\n",
      " -7.52628520e-02 -3.71988229e-02 -2.11118355e-01 -2.11262852e-01\n",
      "  2.21878812e-01  1.96708456e-01  2.52528284e-02 -1.15653664e-01\n",
      "  5.82437404e-02  2.72075623e-01 -7.79397190e-02  2.90887862e-01\n",
      "  3.82473290e-01  8.16686675e-02  1.85162965e-02 -1.92986277e-04\n",
      " -2.37230100e-02  1.48447961e-01  9.97900665e-02  8.27915817e-02\n",
      "  1.25950098e-01 -1.69742852e-02  9.85775813e-02  1.33103758e-01\n",
      "  2.65782863e-01 -2.49728471e-01 -2.13846397e-02 -2.60679036e-01\n",
      " -4.40037623e-02 -4.77250554e-02  4.64235581e-02 -8.47505704e-02\n",
      " -2.98899990e-02 -1.59245521e-01 -5.49564809e-02 -1.20346218e-01\n",
      " -9.08144563e-03 -3.35570350e-02  6.04314245e-02  1.66354537e-01\n",
      " -2.81353951e-01  1.61409359e-02 -4.08196479e-01  1.73122913e-01\n",
      " -1.44809872e-01  1.16502203e-01  3.31190787e-02  6.23235926e-02\n",
      " -3.77766311e-01  2.41274133e-01 -6.93581551e-02  1.21302523e-01\n",
      "  4.28943485e-02  9.48015321e-03  1.10270783e-01 -2.54421771e-01\n",
      " -3.35474014e-01  1.04322068e-01 -3.99992734e-01 -2.88923293e-01\n",
      "  8.96242931e-02 -2.76455190e-02  5.34211732e-02 -1.81390002e-01\n",
      " -2.22381338e-01  9.22436193e-02  2.25199461e-02  6.27543926e-02]\n",
      "L7N0                    -> L8N18 = [-0.2522413  -0.18967384  0.0862962  -0.2507456   0.17811425 -0.09856242\n",
      "  0.0747477  -0.04580731  0.07717409  0.21107012 -0.16926157  0.13458662\n",
      "  0.02818472  0.10591607 -0.0915523   0.04392638 -0.11793401  0.04744194\n",
      " -0.22950482  0.21018988  0.25298792 -0.16210695 -0.38701177  0.09527292\n",
      " -0.08310096 -0.00466188 -0.02402099 -0.31980866 -0.16252235 -0.06595648\n",
      " -0.04921314 -0.08311643 -0.06324019 -0.20910324 -0.00596072  0.17533098\n",
      "  0.03148046 -0.02111435  0.07420287 -0.13599855  0.06416243 -0.0075987\n",
      "  0.08054908 -0.01382794 -0.00638559 -0.00520581  0.07410838 -0.0236218\n",
      "  0.21155629  0.06509759 -0.3131368   0.01518242  0.10031157 -0.11957203\n",
      " -0.03372918 -0.23034742 -0.23779336 -0.04408982  0.1807456   0.11570269\n",
      " -0.07753282  0.12987195  0.23071888  0.05501811  0.3102245  -0.20233677\n",
      "  0.18471253 -0.22058916 -0.07448641 -0.00731514 -0.07298464 -0.05482586\n",
      " -0.16696076  0.03449642  0.05626317  0.16567805 -0.12250248 -0.07298008\n",
      " -0.06811733 -0.10527173 -0.31531656 -0.21543197 -0.04199629 -0.11126804\n",
      " -0.17279118 -0.36164975 -0.10815018 -0.00834207 -0.16208681  0.17810832\n",
      "  0.04951433 -0.29464087  0.0530228  -0.09148071  0.00162305 -0.07991611\n",
      "  0.05908366 -0.30661044 -0.15697934 -0.07948565 -0.26776737 -0.00666976\n",
      "  0.03891581 -0.03387876 -0.21097033  0.13410139  0.2196395   0.26336583\n",
      " -0.15069424  0.2016039   0.07421952 -0.19122642 -0.07574992 -0.11611594\n",
      "  0.10631344  0.26017118 -0.07658159  0.22595549 -0.24908638 -0.08155433\n",
      "  0.10764658  0.04477703 -0.03292064  0.03761717 -0.25398585  0.03854944\n",
      " -0.01495693 -0.10463254 -0.01604664 -0.00899077 -0.06517227 -0.20319228\n",
      " -0.05698349 -0.03590978 -0.18404894 -0.306357   -0.07663138 -0.04841394\n",
      "  0.041099   -0.04726845 -0.03022754 -0.09706642 -0.04141043  0.21078612\n",
      "  0.14265352 -0.21124807 -0.04726305 -0.11614794  0.28281647 -0.03342888\n",
      " -0.12789041 -0.24698016 -0.12758791 -0.01970938 -0.04451067  0.16298148\n",
      " -0.01556905  0.21140058 -0.14344123 -0.0504039   0.03350327 -0.038179\n",
      " -0.09915475  0.09171636  0.12192443  0.0279823  -0.1178649  -0.12643468\n",
      " -0.10912689 -0.26760486  0.02722232 -0.08790364 -0.27107704 -0.1610254\n",
      " -0.05088741 -0.28945282 -0.17234199 -0.03377135  0.00191085 -0.08244724\n",
      "  0.23088528  0.10756871 -0.12447356 -0.24187209  0.1607254  -0.2685366\n",
      "  0.2472166  -0.20914963 -0.26127273 -0.23076603  0.07291123 -0.35611537\n",
      " -0.04729224  0.05192779 -0.15937622 -0.21105587 -0.13428979  0.09838194\n",
      "  0.07152449 -0.20884022]\n",
      "L7N0                    -> L8N19 = [ 1.08480956e-02  1.15068503e-01 -2.00906515e-01 -4.34257835e-02\n",
      "  1.03473559e-01  1.69994850e-02 -1.49860069e-01 -2.57501435e-02\n",
      " -4.54407126e-01 -1.42373040e-01  1.11358449e-01  8.38154927e-02\n",
      "  1.04168303e-01 -1.85945883e-01 -1.22795090e-01  2.41387282e-02\n",
      " -9.27775949e-02 -2.28435546e-01  1.16024986e-01 -5.49481288e-02\n",
      " -7.29178498e-03 -5.93332723e-02 -1.64226189e-01  5.91223836e-02\n",
      "  1.96294159e-01 -1.70305627e-03  1.67850554e-01 -5.88205718e-02\n",
      " -1.15395203e-01  2.32568353e-01  2.45666534e-01  1.06625706e-01\n",
      "  1.53363809e-01 -2.36285888e-02  9.00818035e-02  9.85095426e-02\n",
      " -1.47308901e-01  1.08984578e-02 -9.05620530e-02  3.22907448e-01\n",
      " -1.78530179e-02 -1.96164414e-01  3.72127518e-02  2.75832936e-02\n",
      "  4.90471795e-02  2.24038318e-01  5.58666475e-02  2.32626451e-03\n",
      "  1.05328359e-01 -3.22527587e-02  1.65268824e-01 -3.20070647e-02\n",
      "  1.27708688e-01  1.28530636e-01  1.22114554e-01  3.16387057e-01\n",
      "  5.08626997e-02 -4.04827967e-02 -2.72314459e-01 -2.86847860e-01\n",
      " -2.85568327e-01 -1.81416079e-01 -7.55228326e-02  1.67032667e-02\n",
      "  2.28774458e-01 -3.18701237e-01 -6.28095344e-02  7.49325305e-02\n",
      " -5.18930554e-02  2.96183173e-02 -5.28664663e-02  1.73238739e-01\n",
      " -1.43916517e-01 -7.33555183e-02  1.55206516e-01  1.41828552e-01\n",
      "  6.64573759e-02  1.91840246e-01 -2.46824902e-02 -5.71555234e-02\n",
      "  1.66565225e-01  1.82483226e-01 -3.99793051e-02 -4.91177998e-02\n",
      "  7.86124691e-02  3.30161780e-01 -4.99082416e-01  1.44091874e-01\n",
      "  1.12818368e-01  1.83869854e-01 -2.16433018e-01  6.33695573e-02\n",
      "  1.51394969e-02 -2.16558948e-01  9.19802464e-04 -9.15728956e-02\n",
      "  1.73147067e-01  1.78181425e-01  7.46645704e-02 -2.19205856e-01\n",
      " -1.63066819e-01  7.81133249e-02  1.01193845e-01 -1.27987698e-01\n",
      " -1.15985505e-01  7.87164345e-02  5.51009178e-02 -9.29597691e-02\n",
      "  6.60623237e-02 -5.53858876e-02  2.39788175e-01  1.27395079e-01\n",
      " -5.13911210e-02 -2.98604202e-02 -8.90403613e-03 -1.14886872e-02\n",
      "  2.50888169e-01  2.01264903e-01  3.05480473e-02 -1.23476721e-01\n",
      "  9.19841453e-02  8.36786628e-03 -3.54566306e-01  8.36295262e-02\n",
      "  2.00534880e-01  8.29050764e-02  2.29441170e-02 -1.39835536e-01\n",
      "  3.75276990e-02  2.52929442e-02 -3.84681411e-02 -5.97567298e-02\n",
      " -2.83939660e-01  1.14066005e-01  1.69681909e-03  9.47759207e-03\n",
      "  7.16280490e-02  5.59386285e-03 -5.31716421e-02 -1.70233190e-01\n",
      "  1.50750384e-01  1.08994737e-01  2.80761048e-02  1.79622918e-01\n",
      "  2.19284520e-01  1.25676155e-01  1.52983293e-01 -1.56223923e-01\n",
      " -7.58681819e-02 -1.18263923e-01  5.79963997e-02 -3.38149928e-02\n",
      " -8.88634324e-02 -1.23527154e-01  1.41134307e-01  1.95462689e-01\n",
      " -2.72893663e-02  8.19135159e-02  3.37030202e-01  1.46603301e-01\n",
      " -4.30783182e-02 -1.57467380e-01 -1.07714400e-01  1.29221335e-01\n",
      "  5.88079803e-02 -5.76855455e-05  2.29609191e-01  3.75447376e-03\n",
      "  3.40954542e-01  2.33926356e-01 -7.06236213e-02  5.28906472e-02\n",
      " -1.16597228e-02  3.21608543e-01 -2.05846682e-01  9.37059969e-02\n",
      "  1.03741504e-01  2.18916088e-01  1.22429505e-02  6.01909459e-02\n",
      " -3.32234055e-02 -6.39782920e-02  3.54974046e-02  2.73327947e-01\n",
      " -4.16041203e-02  1.32281706e-01  1.01536224e-02  4.84297276e-02\n",
      "  2.46853903e-01 -1.58911169e-01  2.21460201e-02  1.99965872e-02\n",
      "  1.69788167e-01  1.64261535e-01  2.69060656e-02 -3.13915536e-02\n",
      "  6.36795238e-02 -5.15306033e-02  1.47657290e-01  6.99645430e-02]\n",
      "L7N0                    -> L8N20 = [-2.86732048e-01 -2.07701832e-01 -1.61662623e-01  6.04933947e-02\n",
      " -2.77983069e-01  1.61064446e-01 -4.48557109e-01  1.91941425e-01\n",
      "  1.17330700e-01 -3.31787437e-01 -1.93203703e-01  8.47850740e-02\n",
      " -2.87655979e-01  4.54928614e-02 -3.74991819e-03 -1.72729775e-01\n",
      " -2.75982916e-01  1.22762479e-01 -2.77934283e-01  1.40230715e-01\n",
      " -3.00482213e-01  4.32769544e-02 -1.32485926e-01 -3.90176149e-03\n",
      "  6.11827374e-02  7.39768744e-02 -3.55830729e-01 -7.42373616e-02\n",
      " -1.47479564e-01 -1.77529976e-01 -2.24767089e-01 -1.72302216e-01\n",
      " -4.76080894e-01  1.04799367e-01 -6.36603683e-02 -1.84275601e-02\n",
      " -3.00304204e-01  5.38893277e-03 -1.90847889e-01  1.25934243e-01\n",
      " -1.03435203e-01  1.59218144e-02 -3.13240170e-01 -1.53396338e-01\n",
      "  1.67403787e-01 -1.99780881e-01 -4.33103263e-01 -2.24999189e-02\n",
      " -3.93203795e-01 -3.03483516e-01 -2.02517986e-01 -1.14133015e-01\n",
      " -1.44919483e-02 -2.27938771e-01  8.66009854e-03  2.65305564e-02\n",
      "  2.45835967e-02 -2.90308762e-02 -9.31375287e-03  6.36122376e-02\n",
      " -1.91499531e-01 -1.21047392e-01 -1.23877190e-01 -1.42419741e-01\n",
      " -2.37488270e-01 -8.86370614e-02 -5.68421818e-02 -4.44025360e-02\n",
      " -1.23674534e-01 -1.56129152e-01 -2.09433243e-01 -3.33668590e-02\n",
      " -1.88252442e-02  3.77888270e-02  1.51460385e-02 -2.87082553e-01\n",
      " -7.49409422e-02 -1.28874898e-01 -3.98770012e-02  1.98088754e-02\n",
      " -5.23793139e-02  2.28918433e-01 -2.29148224e-01 -8.23498741e-02\n",
      " -9.74977612e-02  4.35063839e-02 -5.51470779e-02  5.07742278e-02\n",
      " -1.26579776e-01 -4.61116657e-02 -3.48476946e-01 -1.98320761e-01\n",
      " -6.22390956e-02 -1.14722073e-01  2.60452251e-03 -2.62786865e-01\n",
      "  2.20336020e-02  9.23915133e-02 -5.82452454e-02  2.30200738e-02\n",
      " -1.60558522e-01 -3.30786347e-01 -1.84212983e-01  2.84022000e-02\n",
      " -1.88923270e-01 -4.05627117e-03 -1.01406947e-01 -1.61453888e-01\n",
      " -1.73088983e-01 -1.64977744e-01  5.92911765e-02  1.04925655e-01\n",
      " -2.54511535e-01 -2.80983895e-01 -2.95623988e-01  4.51747663e-02\n",
      "  7.82974064e-03 -2.93134302e-01 -3.79264474e-01 -3.49368304e-02\n",
      " -1.84923708e-01 -3.90838057e-01 -4.22724903e-01 -2.84293324e-01\n",
      "  2.35734731e-01 -1.99550554e-01 -2.91193854e-02 -1.57422334e-01\n",
      " -1.53425217e-01  8.77011791e-02 -3.65790546e-01 -3.33308399e-01\n",
      " -2.33921185e-02 -2.27565378e-01  1.76018830e-02 -3.95645976e-01\n",
      " -1.41743366e-02 -1.75079331e-01  1.08764783e-01 -2.08250940e-01\n",
      " -1.06565610e-01 -5.59450872e-02 -1.18876332e-02 -2.44113892e-01\n",
      " -1.29206717e-01 -4.80360771e-03  1.87615938e-02 -2.08666131e-01\n",
      " -1.26764163e-01 -1.82069674e-01 -3.06806147e-01 -1.12606026e-01\n",
      "  1.97961200e-02 -2.45865092e-01 -9.91025791e-02 -3.17677557e-02\n",
      "  2.40894049e-01 -2.81720180e-02 -1.62059873e-01 -3.31168473e-02\n",
      " -2.75057107e-01 -4.96844947e-01 -2.74043474e-02  5.90772890e-02\n",
      " -2.20414326e-01 -5.14718592e-02 -4.64387648e-02  1.11900084e-01\n",
      "  9.94129628e-02 -1.11293979e-01 -1.80595994e-01 -1.15130723e-01\n",
      " -3.75257403e-01  1.31092310e-01 -6.99240863e-02  6.58095032e-02\n",
      " -3.79091762e-02 -8.91338382e-03 -2.88103387e-04 -2.42723972e-01\n",
      " -3.49741220e-01  4.38541919e-02 -2.49397993e-01  2.37377062e-01\n",
      " -2.55238175e-01 -3.79453063e-01 -1.85787976e-01  7.46429414e-02\n",
      "  1.61190008e-04 -1.95012793e-01 -4.84612972e-01 -2.90955782e-01\n",
      "  3.49219106e-02  1.43825207e-02 -3.79901007e-03 -3.55705470e-01\n",
      " -5.71559146e-02 -2.71257877e-01 -2.70072192e-01  1.17299743e-02]\n",
      "L7N0                    -> L8N21 = [ 0.15906245 -0.02024328  0.07793345 -0.07611468 -0.04461869  0.12197745\n",
      "  0.06583924  0.12175618  0.00130308  0.04834979 -0.126089   -0.06800407\n",
      " -0.2106242   0.2228708  -0.14381696 -0.01467432 -0.0316176  -0.05314915\n",
      "  0.18315506  0.04492569 -0.01967671  0.3076728   0.33523723  0.28598505\n",
      "  0.11052832  0.16268225  0.04095807  0.23490486 -0.03774132  0.14222871\n",
      " -0.03438811  0.07679947  0.15317416 -0.39807793  0.12973703 -0.06076294\n",
      " -0.06002256  0.00894329  0.11944516  0.05380296  0.09233417  0.01571423\n",
      "  0.23085256  0.34733015 -0.01253221  0.2730547  -0.08298734  0.1304078\n",
      "  0.10002971  0.29576603 -0.03504858  0.12406269  0.17172651  0.23520133\n",
      "  0.31622738  0.00929838 -0.05794621  0.24734741 -0.13303597 -0.01336072\n",
      "  0.02033633  0.14634699  0.441814    0.248655    0.1142598   0.3093446\n",
      "  0.12687033  0.04091701  0.1367164   0.19073763  0.2385395   0.00355926\n",
      " -0.24209245  0.02144279 -0.16439754  0.19041283 -0.05994572  0.01268433\n",
      "  0.04965034  0.29072607 -0.28041166 -0.09278467 -0.07494591  0.16844419\n",
      "  0.24323025 -0.11838125 -0.29277274 -0.0915482  -0.26996553  0.18886635\n",
      "  0.07536463  0.04992468  0.05390841  0.09671146  0.08194627 -0.04894776\n",
      "  0.1898759  -0.37044042  0.15820482  0.17127396  0.12848175  0.22074376\n",
      "  0.19082928 -0.2221899   0.14168827  0.15473746 -0.01461614  0.20345971\n",
      "  0.15690418 -0.2318877   0.07841669  0.07087583  0.13612165  0.05309757\n",
      "  0.02374402  0.30099857  0.49606007  0.03672347 -0.18001159 -0.0427034\n",
      " -0.00913782  0.13090879  0.2068838   0.15556651 -0.38124883 -0.11614831\n",
      "  0.19606517  0.01632392 -0.11867804 -0.13400012  0.0950217   0.10375742\n",
      " -0.0887521   0.24321665  0.24817055  0.2974635  -0.20019832  0.01858194\n",
      "  0.413873    0.23961031  0.07060637  0.1684928  -0.22611266 -0.22459507\n",
      "  0.02261951  0.15254183 -0.05779479  0.02263956  0.16533282  0.45118833\n",
      " -0.01373739  0.13111474 -0.01872368 -0.00904056 -0.02134728  0.26167113\n",
      "  0.17589848 -0.04827302  0.12203476  0.0973094  -0.0428996  -0.1021555\n",
      "  0.04504137 -0.20190749  0.01634176 -0.08342811 -0.05226208 -0.19826554\n",
      " -0.05837509  0.11847365 -0.20355494 -0.04912916 -0.0128635  -0.10966336\n",
      "  0.16875593  0.46681327 -0.08542801 -0.23941207  0.08947933  0.05386738\n",
      " -0.01151629  0.10298719  0.07614835 -0.19671807  0.02031333  0.03772975\n",
      " -0.05384254 -0.14460246  0.20389615 -0.08521577  0.2159911   0.0944537\n",
      " -0.17094511  0.02757434  0.0465554   0.16913076  0.03710946 -0.04517813\n",
      "  0.21222727  0.01771433]\n",
      "L7N0                    -> L8N22 = [-0.09014439  0.29743668 -0.04052358 -0.01867477 -0.06146484  0.3118609\n",
      "  0.15163459 -0.14312042  0.24450123 -0.03589965  0.15077813  0.08897436\n",
      " -0.08475214  0.04586138  0.02930251  0.033301   -0.31161493 -0.059468\n",
      "  0.02177623 -0.14875892  0.11532331 -0.11412869  0.28757453 -0.07406901\n",
      " -0.01130375  0.01140529  0.2388909   0.14884384 -0.01422868 -0.27963597\n",
      "  0.02380494 -0.08638819 -0.02754703 -0.0623152   0.08356278 -0.15323503\n",
      "  0.01233158 -0.16189781 -0.09462508  0.09540971 -0.06077134  0.06084021\n",
      "  0.08695412  0.02759045  0.07165621 -0.1587518  -0.06516208 -0.06483054\n",
      "  0.10975792 -0.18837562 -0.12458982 -0.05834505  0.34118998  0.03079972\n",
      "  0.19013304  0.03011328  0.07710984 -0.07606366  0.07975478 -0.02737579\n",
      "  0.0609535   0.14159065  0.00896244 -0.16264886 -0.20139238 -0.12427568\n",
      "  0.05812068  0.20229988 -0.04591713  0.06353305 -0.00579523  0.31785917\n",
      " -0.25758237  0.23336643 -0.11837703 -0.2702934  -0.18156473 -0.41403976\n",
      " -0.26581073  0.14938867 -0.02650642  0.21625873  0.14657693  0.1190988\n",
      "  0.01544809 -0.04998522  0.1320728   0.12001833 -0.44917727 -0.10302816\n",
      "  0.05547655 -0.06467067  0.08278798 -0.09072647  0.00602899 -0.11590985\n",
      "  0.11465722 -0.51014477 -0.37480024  0.03273309  0.04400558  0.19744289\n",
      " -0.03349477  0.16581014  0.08443717 -0.13689233 -0.03684795 -0.22467797\n",
      "  0.02112454 -0.05160733 -0.30722147 -0.02283778 -0.00280082 -0.04057411\n",
      "  0.2651456   0.16493806 -0.15731546  0.03318491  0.04971894  0.00251334\n",
      " -0.2627957   0.06027332  0.16810815  0.0479449   0.20984031  0.04101241\n",
      "  0.04420735 -0.00062749 -0.18867649 -0.14193207 -0.28909057 -0.07648996\n",
      "  0.02192488 -0.05400997 -0.01695471  0.04373558  0.06130898 -0.00832671\n",
      " -0.25101277 -0.00398428  0.0504176   0.09284021 -0.26521933 -0.02107391\n",
      "  0.36550426 -0.09191431 -0.17065795  0.2013012  -0.01845334  0.05262737\n",
      " -0.1694551   0.06109264 -0.09062866  0.08867645 -0.22972946 -0.17979752\n",
      " -0.0207816  -0.1312049  -0.00712263 -0.18633594 -0.14611343 -0.20786308\n",
      "  0.05172361 -0.38021597  0.0850485  -0.08832864 -0.38961455 -0.0467719\n",
      " -0.02498616 -0.16001192 -0.13299467 -0.3509405   0.21245551  0.2991892\n",
      " -0.1287731  -0.22379994 -0.07019982 -0.07329236 -0.08177207 -0.17918716\n",
      " -0.30025727 -0.4816997   0.11162852 -0.13090979 -0.26893988 -0.0973677\n",
      " -0.40340453  0.22135139 -0.07886159 -0.02778674 -0.02059829 -0.11034337\n",
      " -0.15302184  0.22932631 -0.14650886  0.05942899  0.10263317 -0.10939433\n",
      " -0.11441954  0.05342678]\n",
      "L7N0                    -> L8N23 = [-0.23229662 -0.0164847   0.22233582  0.15076609 -0.12249737 -0.33503577\n",
      " -0.17466775  0.1637122   0.06267701 -0.3009729   0.1306938  -0.03145614\n",
      " -0.19678003 -0.21482137 -0.32216945 -0.11982167 -0.17119777 -0.00918054\n",
      " -0.24139866 -0.06374672  0.01221368 -0.11654136  0.09790434 -0.12765956\n",
      "  0.02326372 -0.03740975  0.26983666 -0.47264975 -0.00712219  0.02312766\n",
      "  0.10869966 -0.00176673  0.08783341  0.02054826 -0.09085555 -0.05235126\n",
      " -0.03481498  0.05314776 -0.09692787  0.03814639 -0.04476933 -0.15309937\n",
      " -0.01071041 -0.23004416 -0.07545467  0.15223846  0.0024382  -0.20824623\n",
      "  0.15139161  0.01226385 -0.18205717 -0.106435    0.2878485  -0.0366714\n",
      "  0.14642341  0.14016774 -0.07673471 -0.17156596 -0.06889907 -0.01118545\n",
      " -0.04287809  0.20824154  0.16562244 -0.03005463 -0.02757324 -0.21513891\n",
      " -0.03835366 -0.20767704 -0.04470243 -0.12978184 -0.13719472 -0.5217455\n",
      "  0.08821741 -0.05157077 -0.11486346  0.09154556 -0.20759328  0.14284259\n",
      " -0.24332033  0.08898868 -0.16213802  0.0838704  -0.11673892  0.00109541\n",
      " -0.22403806  0.14361316  0.03474542 -0.10705394 -0.3566139   0.05894576\n",
      "  0.03880308  0.06807601  0.07489201 -0.05582635 -0.05795138 -0.19578858\n",
      " -0.29425693 -0.15065897 -0.04158343  0.02413302 -0.05392375  0.11645781\n",
      " -0.3090411   0.3290468   0.05893392  0.1233343  -0.01761648 -0.04671497\n",
      " -0.00519703 -0.11020557  0.0771257  -0.21126431 -0.00225799  0.03842603\n",
      " -0.12490923  0.01132072  0.09945512 -0.21724805  0.06954845 -0.06262212\n",
      " -0.1459936   0.03333824  0.01022273 -0.09761099 -0.0303395  -0.10047712\n",
      " -0.2289956   0.00176774  0.28559813 -0.2008333   0.01508409 -0.26124287\n",
      "  0.15024698 -0.16424596 -0.14353871  0.10765215  0.11885262  0.05853182\n",
      "  0.04505263  0.05862     0.0811049  -0.41710582 -0.0480832  -0.136873\n",
      "  0.2550299  -0.01563473 -0.27864397  0.15741476  0.36195555  0.07749419\n",
      " -0.07443403 -0.01403972  0.12668176 -0.05301273 -0.3871379  -0.34775716\n",
      "  0.21147758  0.00301537 -0.11869416 -0.12332889 -0.16865878 -0.01905267\n",
      " -0.20606792  0.17352143 -0.05835461 -0.03531857 -0.05886163  0.03259965\n",
      " -0.06990183  0.05293319  0.17192253 -0.0198592  -0.10850096 -0.10970849\n",
      "  0.25423005  0.3620908  -0.18282998  0.06804657 -0.0673421  -0.31664425\n",
      "  0.13682865 -0.03979393  0.06916517  0.08615752 -0.35663426 -0.30357897\n",
      "  0.21795405  0.03354543 -0.14347629 -0.0492617   0.06304681  0.2199836\n",
      " -0.4472173  -0.34427828 -0.13138095 -0.11514023 -0.04310059 -0.05778632\n",
      " -0.04005791 -0.11941604]\n",
      "L7N0                    -> L8N24 = [-0.24715869 -0.14439751 -0.2758105  -0.03074796  0.0994891  -0.14859018\n",
      " -0.11493134 -0.09680735 -0.16443692  0.03289479 -0.04717306  0.18938728\n",
      " -0.09130245 -0.24446788  0.12730065 -0.08394188 -0.03015749  0.0384876\n",
      " -0.10964634 -0.29561973 -0.31069577 -0.1860827   0.18748482 -0.19835712\n",
      " -0.34842443 -0.06380662 -0.07463954 -0.04650669 -0.02608487 -0.18044956\n",
      " -0.08792173 -0.13731956 -0.28923574 -0.3200206  -0.20656592 -0.24653032\n",
      " -0.19934267 -0.1681713  -0.05475384 -0.02213758 -0.01135084 -0.0194695\n",
      "  0.01780811 -0.01182511 -0.02392402  0.07558417 -0.3066687  -0.17226829\n",
      " -0.2683053  -0.14205696 -0.06752495 -0.13915882 -0.10712448  0.0457303\n",
      " -0.23115194 -0.22386238 -0.16256449  0.00387977 -0.09367387  0.13343586\n",
      "  0.04074311 -0.01158024  0.03484092 -0.12019031 -0.03609419 -0.15426438\n",
      " -0.01512966  0.00057023 -0.10522056  0.07124201 -0.05853411 -0.25478482\n",
      "  0.13187322 -0.18285732  0.0469786  -0.07981685  0.09911887  0.10402389\n",
      " -0.09087455 -0.13726994 -0.35582155 -0.04127128 -0.00065281 -0.12867902\n",
      " -0.06899012  0.18592335 -0.16453135  0.04497773 -0.04666207 -0.29420745\n",
      " -0.22749029 -0.09401461 -0.39254332 -0.01032519  0.05485823 -0.09233043\n",
      " -0.02482275 -0.14102188 -0.3242293  -0.06458983 -0.09040924 -0.3534995\n",
      " -0.1722248  -0.02485286 -0.17717232  0.17729126 -0.04499196  0.11336552\n",
      " -0.11783677  0.03631323  0.16605091 -0.01100396 -0.02164219 -0.1456447\n",
      " -0.07859248 -0.0075509  -0.07999761 -0.3198554  -0.27339986 -0.08610041\n",
      " -0.159346   -0.24742092 -0.16924444 -0.33459458 -0.10441417 -0.14193907\n",
      " -0.28253946 -0.12618554 -0.06766652 -0.07320975 -0.05312117 -0.13621545\n",
      " -0.22419575 -0.0815917  -0.14347704 -0.02404311 -0.00868471 -0.10099173\n",
      " -0.17812726 -0.12863916 -0.20224553  0.16496986  0.05574527 -0.06801136\n",
      "  0.13711767  0.00996227  0.01678328 -0.12330695 -0.02925691 -0.32336488\n",
      "  0.16527678 -0.13901667 -0.02950176 -0.14580369 -0.36236873 -0.14748077\n",
      " -0.0549913   0.00147298  0.03557428  0.12838249 -0.04549067 -0.33571455\n",
      " -0.07236422  0.06304087  0.00546378  0.08240434 -0.15204774 -0.07423296\n",
      " -0.00887781 -0.24987404 -0.11137314 -0.29994032 -0.18147784 -0.08715017\n",
      "  0.16931699 -0.06773865  0.06298319 -0.02148904 -0.22872216  0.2949369\n",
      " -0.05303603 -0.3614816  -0.01490361 -0.14592665 -0.22905138 -0.00240384\n",
      "  0.0064548   0.02233337  0.1400419  -0.18873632  0.06128315 -0.13278067\n",
      " -0.12119004 -0.30170813 -0.08248322 -0.52633405 -0.07067285  0.00096398\n",
      " -0.24003315 -0.13430476]\n",
      "L7N0                    -> L8N25 = [-0.03090784 -0.15709065  0.02468976 -0.05153905  0.03354467 -0.16039376\n",
      " -0.06734885 -0.06184334  0.02496009 -0.2889514   0.0490511  -0.14362392\n",
      "  0.22365159 -0.05415444 -0.0643042   0.09505367 -0.08152743  0.19185431\n",
      " -0.21044403  0.05177145 -0.20849463  0.03507653  0.0358423  -0.14709412\n",
      " -0.08125804  0.08180933  0.2252166   0.1901115   0.01068518 -0.04953458\n",
      " -0.10989222 -0.01159847 -0.21594323  0.15881827  0.08452732 -0.02909382\n",
      " -0.03904402  0.03492347  0.17191327 -0.17387304  0.04879953  0.20737296\n",
      " -0.21443331 -0.09096031  0.3172456   0.14105296 -0.16293946 -0.33983177\n",
      " -0.00754579 -0.02473223 -0.23145042  0.1411309   0.01527959  0.00578529\n",
      " -0.07800583 -0.02842662 -0.10945231 -0.08409396 -0.22200969 -0.02993266\n",
      " -0.16358204 -0.34281823  0.11803356 -0.10876385  0.2248225  -0.0522625\n",
      "  0.10772598 -0.1120813  -0.05507752 -0.22458342 -0.18335561 -0.3694623\n",
      "  0.13219693  0.15619294 -0.17471711 -0.03294295 -0.2323925   0.08008156\n",
      " -0.0466734  -0.26958486  0.2689879   0.12485041 -0.11656284 -0.19129701\n",
      " -0.2756318   0.08230387 -0.01992898  0.17805141 -0.0525024  -0.08421127\n",
      "  0.18393917  0.00979653 -0.16834378 -0.05492096 -0.29661036 -0.14069812\n",
      " -0.04613581  0.26532674  0.02881389 -0.4505907  -0.0033912  -0.03358277\n",
      " -0.1875501   0.10894939 -0.04235067 -0.21659634  0.09686483 -0.00207169\n",
      "  0.138868    0.07404945  0.3529192  -0.30383068 -0.04779812  0.27819857\n",
      "  0.25590643 -0.13042547 -0.1479572  -0.24079984 -0.27606556 -0.02470016\n",
      " -0.13493465 -0.16832681 -0.00517506 -0.0163876   0.03271288 -0.06062642\n",
      " -0.18524745 -0.13623275  0.05126936  0.04320539  0.05449454 -0.00466992\n",
      " -0.03892909 -0.21729824 -0.37669373 -0.27542543  0.07040094 -0.07129823\n",
      "  0.05742938  0.0356619  -0.11269322 -0.06322937 -0.01840492  0.1039708\n",
      " -0.06402432 -0.18201773 -0.29764667  0.0353628  -0.23424271 -0.11487308\n",
      "  0.07472035  0.08346419 -0.05292146 -0.12627128 -0.04998571 -0.13054773\n",
      " -0.17126998 -0.05161033 -0.03934573 -0.11070902 -0.21030077  0.026076\n",
      " -0.09632922  0.05875975 -0.10175142 -0.00772765 -0.16755521  0.26643515\n",
      "  0.06788743 -0.1521552  -0.04936059 -0.14045037 -0.00474688  0.07181368\n",
      " -0.26241592  0.03446126  0.00876485  0.32686105 -0.3715199  -0.19934843\n",
      " -0.05968295  0.03124955  0.09223001 -0.00480052 -0.20304336  0.00405071\n",
      " -0.27981722  0.05447528 -0.08521611 -0.02027105 -0.0639127   0.11219428\n",
      " -0.0059977  -0.03975704  0.1819292  -0.1048268  -0.2175656  -0.01299741\n",
      " -0.24049765  0.09029533]\n",
      "L7N0                    -> L8N26 = [ 4.02883351e-01 -4.74877320e-02 -1.43608049e-01 -2.34316006e-01\n",
      " -1.87748358e-01  2.50414014e-01  4.33835089e-02 -2.96656102e-01\n",
      " -2.10227564e-01  2.92208552e-01 -2.05691487e-01 -4.53202993e-01\n",
      " -6.84321001e-02  1.02259569e-01  1.34630669e-02 -2.40205452e-01\n",
      "  4.45395559e-02 -2.83715636e-01 -5.28278723e-02 -6.45731539e-02\n",
      " -1.94759056e-01 -1.15767501e-01 -6.48602471e-02  4.83295806e-02\n",
      "  5.22194169e-02 -9.42274109e-02 -1.28374979e-01 -1.66474715e-01\n",
      "  1.93709247e-02  7.92768672e-02  3.36978696e-02 -1.43695876e-01\n",
      " -1.65539011e-02 -1.64671093e-01 -7.22990483e-02 -4.91416901e-02\n",
      "  6.43136725e-02 -1.01085834e-01  6.03214093e-03  1.35040224e-01\n",
      " -1.08682725e-03  1.31409734e-01  5.94454221e-02 -1.78443976e-02\n",
      " -4.55456525e-02 -1.60534710e-01 -1.99651822e-01  3.23272077e-04\n",
      " -1.86842024e-01 -7.76738152e-02 -7.01407045e-02 -1.02783628e-01\n",
      "  1.58160210e-01 -8.27285498e-02 -2.21048251e-01  2.40734875e-01\n",
      " -8.09893683e-02  4.78662476e-02 -3.36732790e-02 -8.35932046e-02\n",
      "  1.16976969e-01  8.54509175e-02 -7.89292455e-02  6.87430203e-02\n",
      " -6.52210414e-02 -1.81085810e-01  2.59963691e-01 -1.33409470e-01\n",
      "  4.39016521e-03 -2.52619646e-02  2.48499423e-01 -2.35782772e-01\n",
      " -2.31559165e-02  1.40739515e-01  2.60700379e-03  1.16189510e-01\n",
      " -5.37700392e-02 -1.42729715e-01  1.03096599e-02  6.42120093e-02\n",
      "  1.49046987e-01 -1.04759008e-01  5.62360473e-02 -5.82735017e-02\n",
      "  8.77860636e-02 -1.14770755e-02  1.18300207e-01  2.37276495e-01\n",
      " -2.41640314e-01 -2.33472988e-01  1.45222872e-01 -4.18119095e-02\n",
      " -1.39885187e-01  3.01760305e-02 -2.49157265e-01  1.48209315e-02\n",
      "  1.92423716e-01 -1.49500445e-01  1.66427627e-01 -1.76163897e-01\n",
      " -1.38807505e-01  1.30943403e-01 -1.14130169e-01  1.51431356e-02\n",
      "  2.07333595e-01 -2.08186105e-01 -1.13469034e-01 -8.64849165e-02\n",
      "  9.00818557e-02 -2.72748888e-01  3.37743685e-02 -9.85740498e-02\n",
      " -2.57995665e-01  2.12970808e-01 -2.28200614e-01 -4.41411346e-01\n",
      " -1.22082336e-02 -2.28751734e-01  1.90750480e-01  7.74455518e-02\n",
      " -4.67003360e-02  3.91813293e-02  4.31201681e-02 -2.16322780e-01\n",
      "  7.75992870e-02  1.14124790e-01  2.55188674e-01 -1.72004521e-01\n",
      "  1.12345263e-01  4.72320663e-03  1.13142073e-01  1.23763584e-01\n",
      "  1.80599660e-01  1.93551973e-01 -1.68820731e-02 -9.09381211e-02\n",
      "  1.43548623e-01 -7.75765404e-02 -2.58154403e-02  9.90902446e-03\n",
      " -8.40805247e-02 -1.03643969e-01 -1.96702376e-01 -1.25351176e-01\n",
      "  5.48172696e-03 -3.85913908e-01 -1.01657435e-02 -9.74834561e-02\n",
      "  4.01215488e-03 -7.64134675e-02 -1.47820273e-02  1.21202648e-01\n",
      " -1.64989874e-01 -3.71175557e-02  3.08677644e-01 -3.49781692e-01\n",
      "  2.03671977e-01 -2.02875867e-01  6.56916872e-02 -8.26891884e-02\n",
      "  1.03939220e-01 -8.72633532e-02 -7.71263242e-02 -2.84349616e-03\n",
      "  9.69124809e-02  2.04825312e-01 -4.21894453e-02  1.31332368e-01\n",
      " -3.03751260e-01  1.94951266e-01  1.14717431e-01 -4.29954417e-02\n",
      "  6.84389146e-04 -9.27605014e-03 -1.91060994e-02 -2.79771656e-01\n",
      "  4.31823748e-04 -5.30343130e-02 -4.28342633e-02 -2.54017144e-01\n",
      " -2.68042475e-01 -5.15341647e-02 -1.13248467e-01  2.32887100e-02\n",
      " -3.78081352e-01  2.25376487e-01 -1.85404107e-01  6.83093891e-02\n",
      " -2.00485483e-01  8.55042785e-02  1.16706185e-01  1.02786064e-01\n",
      "  8.77176151e-02  2.61568755e-01 -6.30713208e-03 -1.60258844e-01\n",
      "  3.76122743e-02 -3.14617828e-02  4.38636281e-02 -1.15149990e-01]\n",
      "L7N0                    -> L8N27 = [ 0.33701843 -0.02323791 -0.13482931 -0.19606607  0.08624604 -0.01076791\n",
      "  0.16146722 -0.26456663 -0.13186978  0.05967498  0.0794268  -0.35979265\n",
      " -0.01308893 -0.03865337 -0.02455018 -0.14024793  0.06021469 -0.13526893\n",
      " -0.04370403 -0.21832636 -0.23824002  0.11401882 -0.01868679 -0.09936833\n",
      " -0.12354394 -0.06537729 -0.14225839 -0.00366702 -0.09023395  0.01415345\n",
      " -0.04980735 -0.14876238  0.08155918 -0.08038787 -0.26116773  0.15885161\n",
      " -0.01838391 -0.07352393  0.0416969  -0.0060907  -0.11365584  0.09156124\n",
      " -0.17269173  0.02500888 -0.02539531 -0.03631581  0.04674114 -0.27398005\n",
      " -0.01537884 -0.15231173  0.23016502 -0.0126373  -0.09202045 -0.08235147\n",
      "  0.04127263  0.09106325 -0.35492507 -0.07441086 -0.19338806  0.136239\n",
      " -0.08943105 -0.09783377 -0.09922055 -0.20526758 -0.04338239 -0.24378738\n",
      " -0.04217911  0.02696771 -0.2575661  -0.12056749 -0.18792203  0.34117272\n",
      " -0.03514258 -0.09709579  0.07206067 -0.0520965  -0.15549783 -0.26748383\n",
      "  0.05616124 -0.14537366  0.05662171 -0.02124598 -0.2503671  -0.03500303\n",
      "  0.11800744  0.15680894 -0.19980769 -0.1054788  -0.06660827  0.01174986\n",
      "  0.11846314 -0.34745446  0.09864918  0.18618992  0.11186697 -0.04317001\n",
      "  0.07963575  0.13859093 -0.3419772  -0.15850045  0.04823997 -0.20346792\n",
      " -0.08223091 -0.2702824   0.06848585 -0.19387534  0.19178388 -0.02937106\n",
      "  0.0224349   0.0681304  -0.23397471 -0.14277133 -0.06083818 -0.13270721\n",
      " -0.07713389  0.0882009  -0.20570706  0.19786339  0.17842992  0.02782588\n",
      " -0.04924963  0.00501663  0.18415573 -0.13637516 -0.05093601 -0.22653086\n",
      "  0.04455112  0.05046983 -0.12623467 -0.13194564 -0.13094255  0.03013304\n",
      " -0.22683503 -0.4047128  -0.3312015  -0.31295046 -0.4153498   0.18950398\n",
      " -0.1707383  -0.09835138 -0.24219242  0.01743765 -0.27986595  0.41826892\n",
      " -0.08988851  0.1261348  -0.28493807 -0.3975187  -0.0462389   0.06892928\n",
      " -0.02356949 -0.10196645  0.18481487  0.03634542 -0.17798766  0.24668194\n",
      " -0.12827426  0.12473961  0.05718033 -0.12189341  0.14745913  0.11489109\n",
      " -0.00633162  0.16969469 -0.2701877   0.06910849 -0.0219658  -0.01540875\n",
      " -0.23634182 -0.00125626 -0.12020318  0.09181347 -0.14293085  0.01878142\n",
      " -0.2801969  -0.04572148  0.12187771 -0.13709186  0.11525334 -0.00784923\n",
      "  0.19308305 -0.18049262  0.1266758  -0.25050968 -0.06179035 -0.01766635\n",
      "  0.12868334 -0.10275754 -0.12283181  0.11537733 -0.48055777 -0.03858033\n",
      " -0.23809    -0.18760176 -0.21683921  0.0999887  -0.01269603 -0.12901787\n",
      " -0.07095366  0.18231308]\n",
      "L7N0                    -> L8N28 = [-0.18467492 -0.08166418  0.1800714   0.21211354 -0.11128727  0.10693178\n",
      "  0.08628954  0.00816723 -0.07068454 -0.2130414   0.18480837  0.2953609\n",
      " -0.17720057  0.1677409  -0.1335854  -0.293116    0.19717199  0.20178393\n",
      " -0.13240787 -0.01516776 -0.03414215  0.02973678  0.3614073  -0.03504729\n",
      " -0.01863769 -0.20174208 -0.06393586 -0.1118499  -0.01579236 -0.06732708\n",
      " -0.32518458 -0.1041012  -0.10711761  0.08381233 -0.03362817 -0.20217158\n",
      " -0.12647974 -0.1404232  -0.09908976 -0.14986676 -0.10749221 -0.00606247\n",
      " -0.2842248   0.3585471  -0.23554346 -0.38979664 -0.11613099  0.20600432\n",
      "  0.0238934   0.011397   -0.21942198 -0.29905662 -0.11584079  0.0046094\n",
      " -0.20844008 -0.00844627  0.20266801 -0.11147548 -0.01160595  0.5152047\n",
      " -0.21799463  0.01169269  0.12815861 -0.16352396 -0.0675509   0.15543938\n",
      " -0.08746397 -0.11810933 -0.02835324 -0.08594984  0.02315937 -0.50247335\n",
      "  0.11975423  0.2192675   0.08607667  0.15106635 -0.05695704  0.10256365\n",
      " -0.18249904  0.05134235 -0.12305943 -0.05304039  0.09877574 -0.04646181\n",
      " -0.05173253 -0.05790254  0.03870708 -0.12636867  0.08160682 -0.19613945\n",
      " -0.04195431 -0.03869707  0.12417206  0.00275106 -0.4330106   0.09503652\n",
      " -0.16132839  0.17215581 -0.21802689 -0.12891996 -0.06014091 -0.25588077\n",
      "  0.04621418  0.04587967  0.0451229   0.23939106 -0.06715439 -0.03057785\n",
      "  0.03841663 -0.21406165 -0.02621549 -0.02454441  0.11875951  0.16063789\n",
      " -0.09963752 -0.13014737 -0.19291145 -0.19213383 -0.17183337  0.08073793\n",
      " -0.04588079 -0.05479868  0.06861224  0.01400081  0.17607842  0.01870367\n",
      "  0.33696595 -0.08541555  0.16335942  0.06991349 -0.18240069  0.04480264\n",
      "  0.15976156  0.10247016  0.05008294 -0.02638571  0.12500972 -0.38039804\n",
      "  0.05709504 -0.10398018  0.06937402 -0.34038037 -0.0655506  -0.3030073\n",
      " -0.07949685 -0.09409273 -0.25709268  0.23067048 -0.03430469 -0.10763672\n",
      "  0.05773697  0.07169851 -0.17835815  0.04270271 -0.05806806 -0.26507148\n",
      " -0.02875796 -0.12751417 -0.05007729 -0.09006068 -0.04459473 -0.08393186\n",
      "  0.00877014  0.31817672 -0.02593376  0.16150483  0.02540362 -0.20441648\n",
      "  0.10219593  0.18413344  0.1344834  -0.21686792  0.06262752 -0.02210674\n",
      "  0.15951535 -0.03424064 -0.08792626  0.08712    -0.049328   -0.36661676\n",
      " -0.20293488 -0.01929427 -0.05053969  0.07509881 -0.11454231  0.17250001\n",
      " -0.05885894  0.03002598 -0.2761447   0.14801429  0.10764187  0.20706491\n",
      "  0.23791084 -0.04020189 -0.04159959  0.01678716  0.00875528 -0.03606779\n",
      "  0.04031968  0.04043701]\n",
      "L7N0                    -> L8N29 = [-0.06068502 -0.19162555 -0.1654395   0.18655585 -0.0444221  -0.16570622\n",
      "  0.09934306 -0.11270101  0.156949    0.07464719 -0.21419215 -0.22368148\n",
      "  0.08494159 -0.05969979 -0.03538563  0.18189068 -0.07474191  0.06328069\n",
      "  0.06035377 -0.1852255  -0.2204735  -0.13880771 -0.11756816 -0.2887895\n",
      "  0.08267889 -0.02236195 -0.15503885  0.04176151 -0.07304149  0.01468711\n",
      "  0.22848362 -0.13943806  0.10737868  0.07641793 -0.17602314  0.19235905\n",
      " -0.04795259 -0.14581122 -0.13542715 -0.0403582  -0.26615807 -0.07488373\n",
      " -0.11332037 -0.10997313  0.00698473 -0.17659402 -0.06642769 -0.07472023\n",
      " -0.04225316 -0.18182987  0.08430512 -0.06720633 -0.03290717  0.03853999\n",
      "  0.21421166 -0.0724773   0.07311958 -0.13443252 -0.03057423 -0.05533706\n",
      "  0.08346769 -0.18339682 -0.10734577  0.03652423  0.13619506 -0.12503232\n",
      " -0.05705578 -0.00708135 -0.10957275 -0.2829825  -0.22497573 -0.11605579\n",
      "  0.05293146 -0.00064119  0.21337    -0.13384306 -0.06845323 -0.17609943\n",
      " -0.24032043 -0.03771956  0.04334904 -0.04850762 -0.04570642  0.12495162\n",
      " -0.04933862  0.05558506  0.0931233   0.07380538 -0.28120026  0.2223854\n",
      " -0.15071909 -0.04687013  0.14530498  0.09699207  0.23388438  0.02775705\n",
      " -0.27301002  0.1622731  -0.00620436 -0.03402886 -0.26422846 -0.00235676\n",
      " -0.28765103  0.18135983 -0.125871    0.08888194  0.21672024 -0.32530132\n",
      "  0.02486884  0.28117508  0.2632088  -0.30999422  0.11027084 -0.10602664\n",
      "  0.06237026  0.17272846 -0.03715999  0.15114073 -0.2971739  -0.12642862\n",
      " -0.12230532 -0.07126454  0.00103959 -0.3453057  -0.12341739 -0.00375472\n",
      " -0.29800373 -0.00533333  0.03549524  0.07295023 -0.17625469  0.00376541\n",
      "  0.1242881  -0.20201257 -0.45834246 -0.09330733  0.08827643 -0.00636477\n",
      " -0.10388451 -0.03670097 -0.02380958  0.07130016  0.20967762  0.00254821\n",
      " -0.0266515  -0.2211643   0.3349466   0.05684924 -0.03289961  0.04977917\n",
      "  0.2591856  -0.14608455  0.12499484 -0.05051539  0.15836447  0.12598346\n",
      " -0.02797735  0.1749791  -0.10950948 -0.05379678  0.21915424  0.04283763\n",
      " -0.09508162 -0.05215148 -0.25948477 -0.13719371  0.06052639  0.25386286\n",
      " -0.20853895 -0.20883349 -0.12677094 -0.02159585 -0.10700518  0.16063732\n",
      " -0.3291183  -0.20361012  0.04863804  0.22957534 -0.30069438  0.13232207\n",
      " -0.07838933 -0.00725134  0.06149616 -0.04813334  0.0340483  -0.2277315\n",
      "  0.06412424 -0.16881265 -0.20306116  0.13935046 -0.31989393  0.01383297\n",
      " -0.12954338  0.04199746 -0.14392686 -0.19784808 -0.23235424  0.05537776\n",
      " -0.15722077  0.20749824]\n",
      "L7N0                    -> L8N30 = [ 1.01780733e-02 -5.81278875e-02 -5.02423123e-02 -3.41340184e-01\n",
      " -1.47119641e-01 -6.03442043e-02 -4.64963876e-02 -1.69939511e-02\n",
      "  1.16617098e-01  3.18766572e-02  1.84332635e-02 -8.09315145e-02\n",
      "  9.27530453e-02  4.04021936e-03  1.38272837e-01  7.74451718e-02\n",
      "  3.35377939e-02 -2.64027536e-01  8.18279758e-02  2.74189174e-01\n",
      "  2.10879892e-01  1.87924176e-01  9.39912274e-02  1.54591560e-01\n",
      "  2.55889535e-01  1.90185048e-02 -2.12072194e-01 -4.63615824e-03\n",
      " -3.57927456e-02 -3.30560058e-02  2.39028484e-02  2.69094437e-01\n",
      "  6.09526038e-03  1.89050570e-01  1.97061017e-01  5.37175238e-02\n",
      " -6.98425472e-02  3.76781970e-02 -5.79052046e-02  1.48238108e-01\n",
      "  2.85027593e-01 -1.50016785e-01  9.94603932e-02 -4.75091450e-02\n",
      "  1.21632501e-01  1.75886720e-01  2.02698022e-01  1.42073229e-01\n",
      "  1.02344215e-01  7.01068118e-02  1.18736774e-01 -1.44354373e-01\n",
      " -4.06428735e-04  1.15764700e-01 -1.57920226e-01 -1.40098318e-01\n",
      " -1.06078774e-01 -1.39068156e-01  2.10110154e-02 -1.21220529e-01\n",
      "  2.06721172e-01  9.78954807e-02 -7.87347034e-02 -1.35733828e-01\n",
      " -6.61514178e-02  4.56111729e-02 -1.27270609e-01  1.13684073e-01\n",
      "  8.47534910e-02  1.68069646e-01  2.51793593e-01  2.20714107e-01\n",
      " -9.87429395e-02  4.81328107e-02  6.57183155e-02  7.55445734e-02\n",
      " -2.78803483e-02 -9.22462791e-02 -1.13383494e-01 -6.47735074e-02\n",
      " -1.12225153e-02 -2.88894176e-01  9.80208591e-02  1.21713102e-01\n",
      "  1.45520434e-01 -1.72173426e-01  1.60944000e-01  1.70878664e-01\n",
      "  2.34021783e-01  1.13858968e-01  2.87428331e-02 -5.01363836e-02\n",
      "  1.54307589e-01  8.98946524e-02  3.47210109e-01  1.40629839e-02\n",
      "  1.34202734e-01 -1.03631198e-01  4.46423329e-02 -2.43349299e-02\n",
      " -2.65356041e-02  4.66060097e-04  2.28574216e-01 -3.99859138e-02\n",
      "  5.20395376e-02 -2.14207605e-01  8.95054936e-02  1.84303015e-01\n",
      " -5.59922233e-02  3.67183425e-02 -1.33483350e-01  3.08406726e-02\n",
      " -3.02983940e-01  4.00596783e-02 -2.99734503e-01 -2.97255874e-01\n",
      " -6.03824072e-02  4.17488009e-01  2.09182844e-01  1.09842233e-01\n",
      "  8.18310231e-02  1.75265402e-01 -6.87766746e-02  1.27666906e-01\n",
      "  1.54303342e-01  5.66106569e-03  1.60264954e-01  1.29222684e-02\n",
      "  3.76762114e-02  2.36352131e-01 -5.66786565e-02  1.45321205e-01\n",
      "  1.54883057e-01  1.35033771e-01  1.65953532e-01  2.17710406e-01\n",
      " -1.16261914e-01  2.63474494e-01  6.43283725e-02  3.11871078e-02\n",
      "  2.66792685e-01  1.79513484e-01  1.78629786e-01  3.16702098e-01\n",
      "  7.59230703e-02  2.51993388e-02  1.62936389e-01  7.11995224e-03\n",
      "  1.23339444e-01  2.97448367e-01 -5.98999113e-02  8.03812817e-02\n",
      " -1.12346165e-01  2.04079539e-01 -2.17531808e-02  2.64379501e-01\n",
      "  1.49501935e-01  1.70496050e-02  1.96441099e-01 -1.22284681e-01\n",
      " -1.74819995e-02 -4.23943959e-02 -1.83686463e-03  1.24469854e-01\n",
      "  1.74648445e-02 -6.83526471e-02 -5.51997386e-02 -3.25312205e-02\n",
      "  3.09817106e-01 -1.86423250e-02  1.47688150e-01  1.91526949e-01\n",
      " -1.88155562e-01 -9.79197025e-02  2.35622048e-01  2.79378980e-01\n",
      "  9.90964547e-02  9.57403556e-02  1.09398767e-01 -3.41130905e-02\n",
      "  5.60061075e-02 -8.85563940e-02  2.05473647e-01  1.68939203e-01\n",
      "  2.03049347e-01  2.90163070e-01  4.14605558e-01 -2.89330423e-01\n",
      " -6.97783679e-02 -2.04477042e-01 -1.99030980e-01 -2.13430375e-02\n",
      "  1.17380373e-01  3.84842247e-01  1.57981277e-01  6.73014000e-02\n",
      " -5.34177721e-02 -1.13408260e-01  8.99294838e-02 -3.07651050e-02]\n",
      "L7N0                    -> L8N31 = [-5.48381470e-02  9.51652080e-02  1.87157001e-02 -2.75364459e-01\n",
      " -7.02673048e-02 -1.90535352e-01 -1.61138967e-01 -1.65715724e-01\n",
      " -5.50468499e-03 -3.05108935e-01 -4.57932353e-02 -6.11659698e-02\n",
      " -8.03678110e-02 -2.50701308e-01 -1.08461985e-02  3.47135449e-03\n",
      " -1.25059694e-01 -4.41478081e-02 -1.07762396e-01 -1.20615900e-01\n",
      " -1.83255032e-01 -1.66874722e-01  4.05019848e-03  6.29415736e-02\n",
      " -1.99699208e-01 -1.32823912e-02 -2.56775558e-01  1.76391564e-02\n",
      "  7.43029118e-02 -1.91300675e-01  1.60807259e-02 -1.03437096e-01\n",
      " -2.96683133e-01 -5.43602072e-02 -2.12231010e-01 -3.35977487e-02\n",
      " -9.87165049e-02 -1.52855888e-01 -4.19415049e-02  1.93194866e-01\n",
      "  1.94054425e-01 -1.25756979e-01  2.78964460e-01 -3.49952906e-01\n",
      "  2.65685897e-02 -2.47403085e-01 -1.74786910e-01  7.66071631e-03\n",
      " -1.04012089e-02 -2.05504447e-01 -1.00540325e-01 -4.21750173e-02\n",
      " -3.53286825e-02 -1.68355390e-01  3.39584402e-03 -1.14121102e-01\n",
      " -7.09211826e-02 -2.59629250e-01 -4.63739363e-03 -2.07203150e-01\n",
      " -3.65719557e-01 -8.99936482e-02 -2.99050182e-01 -4.64751385e-02\n",
      " -8.18189010e-02  1.56096980e-01 -2.74375193e-02 -5.40847853e-02\n",
      " -1.44078359e-01 -1.33715913e-01 -3.02612275e-01 -2.66602546e-01\n",
      " -1.19345978e-01  1.94061130e-01  6.12789989e-02  7.73993284e-02\n",
      " -1.25878230e-01 -3.10862899e-01 -1.50173709e-01 -5.87379746e-02\n",
      " -4.31145094e-02 -1.81752846e-01 -2.66008705e-01  1.36240229e-01\n",
      " -6.63019344e-02 -4.82863374e-02  1.17678165e-01  1.94097489e-01\n",
      " -2.48527452e-01 -1.06528617e-01 -1.36929139e-01 -9.89390388e-02\n",
      "  5.88203669e-02 -1.01073556e-01  2.90023722e-02 -2.47588307e-01\n",
      "  1.55266821e-01 -1.60557538e-01 -3.41184676e-01 -5.02063632e-01\n",
      " -2.30620041e-01  5.51515184e-02 -1.22809783e-01 -1.01797491e-01\n",
      " -3.14521849e-01 -8.91770944e-02 -2.68731207e-01 -2.83072591e-01\n",
      " -1.00496508e-01 -1.34248719e-01 -2.56771326e-01 -1.23981439e-01\n",
      " -2.57295016e-02 -7.59439617e-02 -2.16628939e-01 -1.57934248e-01\n",
      "  5.46908416e-02 -2.67044455e-01 -2.65955210e-01 -2.30651587e-01\n",
      " -2.99500853e-01 -9.85207036e-02 -1.14626154e-01 -2.13404685e-01\n",
      "  1.58771589e-01  7.78194750e-03  2.35929936e-02 -3.52173001e-02\n",
      " -3.12394410e-01  5.20337150e-02 -1.14365473e-01 -4.12131637e-01\n",
      " -4.69727181e-02 -6.65814355e-02 -1.36793777e-01  1.05355278e-01\n",
      " -1.29388079e-01  1.63647830e-02 -4.16303948e-02  5.83554618e-02\n",
      " -1.70165449e-01 -1.08793139e-01 -1.45666495e-01 -3.34009618e-01\n",
      " -2.12504908e-01 -1.80119544e-01 -2.91646987e-01 -2.05560643e-02\n",
      " -1.61520109e-01  1.50458336e-01 -1.37837589e-01  4.76709455e-02\n",
      "  3.04441322e-02 -4.17542160e-01 -6.41559623e-03 -3.28523330e-02\n",
      "  5.12545817e-02 -2.20489070e-01 -1.20084248e-01 -1.38058007e-01\n",
      " -2.35767871e-01 -1.86676309e-01 -2.64791697e-01 -1.77850291e-01\n",
      " -1.42813325e-01 -1.01864696e-01 -9.22563151e-02  1.18511356e-01\n",
      "  1.48730859e-01 -6.80184439e-02  1.02270562e-02 -3.94674003e-01\n",
      " -6.86287507e-02 -4.81695123e-02 -2.53916800e-01 -1.29209816e-01\n",
      "  1.43246382e-01  1.53970540e-01 -2.45590627e-01 -8.86053145e-02\n",
      " -1.62140384e-01 -5.34290485e-02 -2.52059042e-01  8.05490538e-02\n",
      " -2.38950416e-01 -4.34240550e-01 -1.70150325e-01  1.47154613e-04\n",
      " -1.22283667e-01  2.66102292e-02 -2.91444659e-01 -3.39466631e-01\n",
      "  7.77991042e-02  3.42842907e-01  5.48255071e-02 -3.46641913e-02\n",
      " -1.11934416e-01  1.23704188e-01 -9.74877104e-02  1.72904179e-01]\n",
      "L7N0                    -> L8N32 = [-3.51550043e-01 -1.57240391e-01  2.53528684e-01  1.41779497e-01\n",
      "  4.49851304e-02 -6.79569766e-02 -2.12971106e-01 -1.57062858e-01\n",
      " -1.79815412e-01 -2.47137830e-01  2.27914661e-01 -6.88631535e-02\n",
      "  5.44574633e-02 -8.47740658e-03 -2.37761229e-01 -2.19251141e-02\n",
      " -2.16375533e-02  1.10149950e-01 -1.32285848e-01 -8.58689472e-02\n",
      " -1.57283530e-01 -1.08300641e-01 -2.32772194e-02 -2.73000710e-02\n",
      "  1.14319557e-02  1.88369267e-02 -1.41669586e-01 -1.18149266e-01\n",
      " -1.11750960e-01 -1.40276074e-01  6.08358644e-02  1.89513303e-02\n",
      " -3.54675710e-01 -3.06792140e-01  9.42451507e-02  1.40101746e-01\n",
      " -1.21669382e-01  1.70446426e-01 -1.27598539e-01 -1.23819664e-01\n",
      " -2.82153845e-01 -5.33568151e-02 -3.21953475e-01 -5.29983230e-02\n",
      " -3.20726812e-01  1.34901330e-01  3.15094233e-01  8.15609470e-03\n",
      "  1.35319591e-01  1.60174280e-01  5.58647066e-02  8.51164609e-02\n",
      " -1.99238881e-01 -2.20288426e-01  9.00081396e-02 -3.37106466e-01\n",
      " -2.53740996e-01  1.81462225e-02 -1.54438317e-01  2.03177035e-02\n",
      "  6.90255240e-02 -1.62748441e-01  7.65403137e-02  1.96792901e-01\n",
      "  1.02055572e-01  3.30302902e-02  1.00443386e-01  3.88347954e-02\n",
      "  7.65043274e-02  2.60352939e-02  7.43192136e-02  3.87764163e-02\n",
      " -3.43589336e-01  5.44577325e-03 -1.84808642e-01 -2.72922637e-03\n",
      " -2.55739421e-01 -3.62191088e-02 -9.72498357e-02 -2.28873923e-01\n",
      " -1.88623339e-01 -1.25080198e-01 -5.07864915e-02 -3.15220892e-01\n",
      " -1.82360739e-01 -4.47235592e-02 -1.54361308e-01  1.12534463e-01\n",
      " -1.20963208e-01 -2.59029448e-01 -1.49447367e-01 -4.56196293e-02\n",
      "  4.95642386e-02  2.18291700e-01 -3.72902542e-01 -1.35348588e-01\n",
      " -3.46286505e-01 -1.00966059e-01  6.19897023e-02 -8.20740610e-02\n",
      " -2.95616031e-01 -7.93386251e-02  2.58188173e-02 -4.66453254e-01\n",
      " -1.85188428e-02  1.45300165e-01  1.05562031e-01  2.62224704e-01\n",
      "  3.52207184e-01 -2.06550695e-02  2.27526665e-01 -1.78920086e-02\n",
      "  9.99621674e-02 -9.63083468e-03  2.56550878e-01  1.74972817e-01\n",
      " -2.35891849e-01  1.31030113e-01 -1.10661291e-01 -1.35441467e-01\n",
      " -2.42673174e-01 -2.83325613e-01  1.35558126e-02  2.32046694e-01\n",
      " -3.67675163e-02 -1.22171238e-01 -5.58728725e-02 -2.58843571e-01\n",
      "  1.40202343e-01  1.08452730e-01 -1.02504589e-01  8.23815092e-02\n",
      " -3.21266800e-02 -8.35648850e-02 -1.82717696e-01 -3.51026565e-01\n",
      " -5.42239130e-01  9.10817683e-02  1.13265239e-01  9.14803967e-02\n",
      " -5.33451848e-02 -3.31711210e-02 -1.63607612e-01 -7.00240731e-02\n",
      "  3.42514995e-03  1.03719808e-01  1.97181359e-01  1.70155182e-01\n",
      " -2.37169459e-01  2.15152167e-02 -1.07397005e-01  4.20700526e-03\n",
      "  1.17856376e-01  6.05899207e-02 -1.22038171e-01 -4.70618866e-02\n",
      " -4.50916849e-02 -6.04707748e-02 -2.52505932e-02 -8.49307403e-02\n",
      " -1.49084747e-01  4.88798171e-02  2.28049073e-04 -1.48078948e-01\n",
      " -2.53169000e-01 -3.58706340e-02 -8.05677101e-02 -1.27858818e-01\n",
      "  5.83399832e-02  7.19912574e-02 -3.48404735e-01  1.90896057e-02\n",
      "  6.39529154e-02 -4.25766945e-01 -9.98354256e-02 -3.67636204e-01\n",
      " -2.46296361e-01 -6.16550855e-02 -1.97724268e-01 -7.48229548e-02\n",
      "  1.99072212e-01 -1.14379540e-01  2.05047075e-02 -4.60462183e-01\n",
      "  8.13990757e-02 -3.13407667e-02 -1.69571140e-03 -2.62738228e-01\n",
      " -7.63754398e-02 -8.03671256e-02  1.38551995e-01  3.79449502e-02\n",
      " -3.35951030e-01 -1.32496834e-01 -2.67831624e-01 -1.87029261e-02\n",
      " -1.44777656e-01  4.65995399e-03 -2.50015110e-02 -3.89390349e-01]\n",
      "L7N0                    -> L8N33 = [-0.3123132  -0.17323732 -0.02333174 -0.16980961 -0.15657252  0.14314255\n",
      "  0.01799198 -0.19517705 -0.12134722 -0.11074747  0.0062712   0.09070828\n",
      " -0.13191752  0.0118157  -0.23824184 -0.07540502 -0.03568133 -0.15666854\n",
      " -0.07013695 -0.19961888 -0.17702365 -0.07339822 -0.18321872 -0.26918375\n",
      " -0.11492465 -0.12235425  0.16034606 -0.38863185 -0.1227361  -0.00967112\n",
      " -0.07273978  0.13303846 -0.32790673 -0.24021827  0.01827139  0.26632386\n",
      " -0.01579962 -0.3603994   0.04722078 -0.29330972  0.03144747  0.07083049\n",
      " -0.1748377  -0.17310975 -0.28891152 -0.06515736  0.15622629  0.1408285\n",
      "  0.03452792 -0.18635498  0.09453209  0.0333645  -0.2260518  -0.09147798\n",
      "  0.15676755 -0.30915776 -0.15786962  0.0252276   0.0771139  -0.03453777\n",
      " -0.13881211 -0.06130384  0.12351323 -0.27812117  0.01207392 -0.12235483\n",
      " -0.22015004 -0.01743395 -0.03517413 -0.12684628 -0.18672572 -0.14014886\n",
      "  0.06660954 -0.39357162  0.28424585  0.24179775 -0.21440181 -0.24899995\n",
      " -0.18455862 -0.017713    0.03337702 -0.33768448  0.00406512 -0.210321\n",
      " -0.22753078  0.10957879 -0.2564019  -0.14244504 -0.04391377 -0.01239886\n",
      " -0.08552176 -0.15801008 -0.3395242  -0.09715186  0.04969564 -0.01451239\n",
      " -0.269849   -0.01955356 -0.05849044 -0.26436237  0.17631993 -0.1934786\n",
      " -0.34959328  0.08598123  0.07249315  0.08690196  0.00787973 -0.18622382\n",
      " -0.21331485 -0.12276728 -0.18693045  0.22790195 -0.08955771 -0.06630564\n",
      " -0.17550232 -0.03971282 -0.13965075  0.10645911 -0.11751883 -0.2614898\n",
      " -0.06277093  0.02574486 -0.2598774  -0.39322817 -0.1734576  -0.1115353\n",
      " -0.2519736   0.1294921  -0.07944728  0.1058294  -0.11394276 -0.06316087\n",
      " -0.02092278 -0.34797597 -0.16938153 -0.12390867 -0.16120574  0.10967614\n",
      " -0.21545735  0.06138231 -0.10286856  0.04285868 -0.13952553 -0.05020953\n",
      " -0.27969602 -0.05584129 -0.2050308  -0.09957869 -0.5157135  -0.11973812\n",
      "  0.05757942 -0.18189086 -0.00077928 -0.03666126 -0.39133638  0.13561173\n",
      " -0.2270997   0.02594174  0.00994652  0.01684637 -0.02182808 -0.30193385\n",
      " -0.26884624  0.04985407  0.02693322 -0.22585116 -0.20166606 -0.260966\n",
      " -0.02572181 -0.15161656  0.22763447  0.01808567  0.00940874 -0.06746587\n",
      " -0.02062641 -0.22894017 -0.68506503 -0.07172074 -0.05072316  0.060425\n",
      "  0.11725879 -0.09037331 -0.26749653 -0.14381765  0.2551812  -0.253451\n",
      " -0.05456206 -0.40613994  0.15376244 -0.04512316 -0.13770376  0.05225605\n",
      " -0.0833056  -0.05902376 -0.01634111 -0.13766763 -0.26681012 -0.05908547\n",
      " -0.08349288  0.05439705]\n",
      "L7N0                    -> L8N34 = [ 0.24213389  0.03418631  0.00555718 -0.06652246 -0.22356421 -0.17627643\n",
      " -0.05975132  0.0436873   0.03106552 -0.05898613  0.34908217 -0.03893675\n",
      "  0.0694785  -0.16121474  0.09979336  0.11288003 -0.16731451 -0.22156146\n",
      "  0.01639602 -0.16253881 -0.17687942  0.18937261 -0.42134678 -0.2265542\n",
      " -0.02222901 -0.20084442 -0.1075526   0.00850624 -0.30072588 -0.15482476\n",
      " -0.22732273  0.12376041 -0.32567403  0.00692763 -0.2332041  -0.04778367\n",
      " -0.02050607 -0.0218057   0.22338587 -0.00357316 -0.33611754 -0.10521914\n",
      " -0.38302907 -0.16025656  0.02217236  0.06288322 -0.18707418 -0.14395142\n",
      " -0.31292975  0.06081929  0.22891495  0.00063051  0.078784   -0.01899919\n",
      " -0.14671214  0.13056177 -0.04352625 -0.06755321 -0.04210091 -0.35578817\n",
      " -0.23612611 -0.38041294 -0.00456947  0.11020407 -0.2409029   0.04158928\n",
      "  0.21302621 -0.20441522  0.01832899 -0.24900885 -0.4214586  -0.21763287\n",
      "  0.10587107  0.07065129 -0.20873885 -0.19625567 -0.09986244 -0.26183447\n",
      " -0.1556862   0.02244012  0.02957328  0.02598193 -0.26910976  0.14386582\n",
      "  0.122534   -0.0059032  -0.23516828 -0.01175174 -0.05408646 -0.19911885\n",
      " -0.28401837 -0.19814093  0.13141534 -0.12917992  0.04232542 -0.21789293\n",
      " -0.0607433  -0.05151845  0.11799327 -0.00842552 -0.40834755 -0.01815901\n",
      " -0.23063357  0.04907596  0.00203823  0.02124821 -0.11286118 -0.12928887\n",
      " -0.33600783 -0.03895875  0.10180441 -0.19282082 -0.15359116 -0.5161537\n",
      " -0.1631727  -0.17839703  0.02067055  0.1438493  -0.00634432 -0.1273511\n",
      " -0.18342349 -0.05419548 -0.03417321 -0.0518796   0.21051592  0.03931955\n",
      " -0.20242257  0.06707177 -0.11627056  0.10168831 -0.01445895 -0.2922249\n",
      "  0.03958292 -0.18776019 -0.04457144  0.06002263  0.10526142  0.1934772\n",
      " -0.0777196  -0.10704991  0.03929037  0.18753864 -0.3380334   0.03528706\n",
      "  0.14418544 -0.12457614 -0.3083384  -0.1721311   0.09973545 -0.37668326\n",
      " -0.3874948   0.0292519  -0.21022922 -0.00659996  0.09076791 -0.32371354\n",
      "  0.15747222 -0.330191   -0.18958049 -0.1298634   0.09098929 -0.05469457\n",
      " -0.11326703 -0.24678779 -0.48080587 -0.15306473 -0.03969087 -0.22101967\n",
      " -0.06222998  0.10569032  0.23290956  0.13505033 -0.01367236 -0.0586891\n",
      "  0.01997378 -0.05768127  0.05162626 -0.16873027 -0.0472252   0.00110864\n",
      " -0.2341202   0.24126108 -0.20467468  0.14764865  0.09043761 -0.21747157\n",
      "  0.20683798 -0.02490518  0.04086601  0.06884944 -0.23997657 -0.2108479\n",
      " -0.02599455 -0.05409537  0.1212423  -0.17611489 -0.0202477  -0.27235916\n",
      " -0.146188   -0.00290197]\n",
      "L7N0                    -> L8N35 = [-0.03754596 -0.05821601  0.19866562  0.2506877   0.14557996  0.19603334\n",
      "  0.24987467  0.00346333 -0.24900489  0.04928255 -0.107653    0.33928952\n",
      "  0.05137142  0.14810571  0.07317301 -0.12187593 -0.17909044 -0.21622325\n",
      "  0.0917884   0.09719068 -0.03287309  0.12627499  0.04251442  0.21168783\n",
      "  0.07410815  0.15616359  0.12419543 -0.1655274   0.03632108 -0.02994785\n",
      "  0.16744576  0.06226218  0.00927113  0.00609114 -0.00059339 -0.38150966\n",
      " -0.04950533  0.09614081 -0.09581992  0.12815934 -0.07667111 -0.09133747\n",
      "  0.33895433  0.10884897 -0.31893694 -0.00991757 -0.11111259  0.15525568\n",
      " -0.14156146  0.08810062 -0.28256133  0.1625417   0.22281748 -0.07734166\n",
      "  0.2791611  -0.14390303  0.10433911 -0.08826507  0.05197071 -0.06600226\n",
      "  0.01015175  0.08044279 -0.03695741 -0.13844088  0.04496981 -0.12559424\n",
      "  0.2168858  -0.01604527 -0.02521731  0.11178448 -0.0483756  -0.14089826\n",
      " -0.28048488 -0.17236781 -0.25325036 -0.13443126  0.22486588  0.05886355\n",
      " -0.0149849  -0.04031716 -0.06476856  0.00649775  0.17758805  0.17985633\n",
      "  0.2025349   0.02889589 -0.20227584 -0.38775748 -0.08365186 -0.21020335\n",
      "  0.07873505  0.31606457  0.18234302  0.05500489  0.08114073 -0.08098976\n",
      " -0.19035344 -0.01347473 -0.12541907  0.25376344  0.13006894  0.2683725\n",
      "  0.14980969  0.0199827   0.07792041 -0.1421783   0.15024531  0.01854677\n",
      "  0.11653318 -0.1474103   0.18655187  0.10755129 -0.09486651  0.03252208\n",
      " -0.00626004 -0.1778443  -0.03280903 -0.40049675  0.05692871 -0.08826908\n",
      " -0.06876482 -0.00124555  0.1094371   0.31590983 -0.04046911  0.10287859\n",
      " -0.00628222  0.06504149  0.09704717 -0.12396901 -0.09051554  0.18530941\n",
      " -0.16508938  0.07210395  0.01236887  0.03365435  0.03380353 -0.00628577\n",
      " -0.01011137  0.04128476  0.33910736 -0.26580125 -0.19347675  0.28921115\n",
      " -0.17043331  0.05856989 -0.07860197  0.26072893  0.08186736  0.11471675\n",
      "  0.15805583 -0.04195908  0.11978418 -0.05379443  0.14884867 -0.14574891\n",
      " -0.05050404 -0.00228172  0.30280137  0.27558786  0.0998865   0.04067285\n",
      "  0.2970125  -0.00980301  0.05182109  0.10196608  0.20885204  0.03285161\n",
      " -0.14602579  0.0760181  -0.08986203 -0.12711146  0.19988094 -0.265295\n",
      " -0.02671005  0.11802815 -0.15623106 -0.25344867 -0.02954406 -0.05566777\n",
      "  0.0694875   0.18070664  0.04190232  0.10065614 -0.38960806  0.0900904\n",
      "  0.05196809  0.05014917  0.27287826 -0.26053548 -0.05075263 -0.0695245\n",
      "  0.03013696 -0.24170783 -0.09583353  0.03511573  0.23465931 -0.04154556\n",
      "  0.11496366 -0.04319701]\n",
      "L7N0                    -> L8N36 = [ 0.15224954 -0.11058746 -0.04590541 -0.04604623 -0.02559226 -0.09326011\n",
      " -0.03139205  0.0697602   0.03725465 -0.01087314  0.25779015  0.2067623\n",
      " -0.06505033  0.00303604  0.03106205  0.11710985  0.06610097  0.05774254\n",
      " -0.1136883  -0.09372494  0.08226663  0.00468668  0.02910736  0.08638991\n",
      "  0.04209872  0.07582299 -0.11598861 -0.18958628 -0.09995067  0.03253231\n",
      "  0.16626455  0.16396303  0.0235086  -0.12300442 -0.08589803 -0.0441484\n",
      "  0.10914905  0.09584588 -0.14181894  0.02213354 -0.07166906  0.02622527\n",
      "  0.10400783  0.13735004  0.04085733  0.01199312 -0.2138634   0.11524338\n",
      "  0.1465689   0.19841157 -0.20538118  0.09249391 -0.08359589 -0.04821579\n",
      " -0.37680063 -0.05854966  0.01435397  0.05663462  0.03388589  0.04162451\n",
      "  0.18365681  0.11166006  0.18158388  0.09281509 -0.20765816 -0.06095769\n",
      " -0.08843876  0.05894086  0.05276457  0.24655455  0.07094423 -0.5423666\n",
      " -0.06427319 -0.10557687  0.06593045  0.40540454 -0.10065009  0.181156\n",
      "  0.07090845 -0.01524171 -0.03916017 -0.09857711  0.06716977  0.08224465\n",
      "  0.41111583 -0.03089736  0.08741903 -0.20983982 -0.1857207  -0.49715707\n",
      "  0.10998388  0.05003697  0.10005775  0.1661284  -0.04583276  0.22754496\n",
      " -0.0136923   0.18967754  0.09681315  0.06241801  0.13672608 -0.15377079\n",
      "  0.00367964 -0.06190775 -0.02638926  0.21763423 -0.02650574  0.14854062\n",
      " -0.05321805 -0.02651285 -0.12715378  0.00429077  0.17448096  0.1241469\n",
      "  0.16123834  0.35600424  0.02603308 -0.46158522  0.1123655  -0.07954319\n",
      " -0.23679999  0.05232959  0.00827623  0.02906604 -0.04060322  0.01380358\n",
      "  0.162303    0.18338199 -0.0496117  -0.16796182 -0.15774181  0.02569325\n",
      " -0.00652999  0.33361942 -0.07948529  0.03208171 -0.11478692 -0.15279524\n",
      "  0.20974995  0.16201743  0.05893243  0.40121767 -0.04298927  0.01850081\n",
      " -0.08771171  0.03810433 -0.12771109  0.0593558   0.15515079  0.27065155\n",
      "  0.3540343   0.08578871 -0.14304517  0.08682246  0.10471329 -0.0064203\n",
      "  0.08064999  0.13017842  0.22210804 -0.01408042  0.05276261  0.0708549\n",
      "  0.22742757 -0.05802263  0.22224733  0.16102217  0.316466   -0.09015216\n",
      " -0.00401512 -0.10149832 -0.05546295 -0.34302598  0.00741957  0.07987785\n",
      "  0.38986087  0.2108245  -0.04278517 -0.09519481  0.2726506  -0.21077996\n",
      "  0.24298282 -0.00557356  0.05544965 -0.24218093 -0.05731994  0.27538824\n",
      " -0.276716   -0.38340613  0.07771306 -0.07189333  0.03900191 -0.12451217\n",
      "  0.12644452 -0.3544472  -0.2897884   0.10302553  0.14779286 -0.14117435\n",
      "  0.01909733 -0.08501109]\n",
      "L7N0                    -> L8N37 = [ 3.76017205e-02 -3.13465983e-01 -1.83316752e-01  1.73980132e-01\n",
      "  2.51599073e-01 -1.16453193e-01 -9.69262794e-02 -3.85907322e-01\n",
      "  9.39157382e-02 -2.40681902e-01 -6.55700117e-02  6.96035624e-02\n",
      "  9.81321633e-02  3.07356007e-03 -1.37069970e-01 -1.09283961e-01\n",
      "  8.39091092e-02 -1.15905598e-01 -3.93573605e-02 -6.08919114e-02\n",
      "  2.32022014e-02 -1.62760779e-01 -5.76428510e-02 -3.50466460e-01\n",
      " -9.69891325e-02 -1.79574028e-01 -2.06129085e-02 -1.09198615e-02\n",
      " -2.96900366e-02 -8.09093118e-02  9.03152078e-02  1.01679161e-01\n",
      " -1.55624719e-02 -9.97806862e-02 -1.53784573e-01 -9.20525566e-02\n",
      " -1.94956869e-01 -2.65320063e-01  9.81970578e-02  6.28161505e-02\n",
      " -1.91854075e-01 -6.21797517e-02 -3.01221251e-01 -1.66944936e-01\n",
      "  2.88001634e-02  2.59869069e-01 -5.55604436e-02 -5.75146601e-02\n",
      "  3.41376662e-02 -2.31338009e-01 -3.65375578e-02 -1.49769038e-01\n",
      " -4.26053157e-04  1.75351538e-02  2.36769199e-01 -3.44391704e-01\n",
      " -1.84264421e-01  5.21183759e-03 -2.56793061e-03 -3.30872461e-02\n",
      " -2.29920641e-01 -1.25487685e-01 -4.57685068e-03  8.89475495e-02\n",
      " -1.08918160e-01 -2.16604978e-01 -2.89872825e-01 -1.33129716e-01\n",
      " -2.84972399e-01 -7.34572411e-02 -2.37935498e-01  3.63860861e-03\n",
      " -1.57626197e-01 -2.80124638e-02 -3.80633809e-02 -1.75246924e-01\n",
      " -4.16670181e-02 -3.34694743e-01  6.98869005e-02 -1.43684164e-01\n",
      " -2.72577882e-01 -3.83606732e-01  6.33192733e-02  8.67213681e-02\n",
      " -1.77527264e-01 -5.38091242e-01  2.23107748e-02 -1.87708944e-01\n",
      " -2.65324563e-01 -1.62806764e-01  5.85090704e-02  2.83919603e-01\n",
      " -1.74687877e-01 -9.08463746e-02 -1.29725682e-02 -1.52478665e-01\n",
      " -9.79373753e-02 -2.40907427e-02 -3.43012847e-02 -1.62091821e-01\n",
      "  8.10967535e-02 -1.85852244e-01  8.79414529e-02 -2.02089757e-01\n",
      "  9.06474132e-04  1.17447890e-01  9.45966411e-03  1.54347357e-03\n",
      " -2.40735799e-01  2.85905525e-02 -1.44219682e-01 -2.34822899e-01\n",
      "  2.56849919e-02 -1.01040669e-01  3.32294464e-01  2.97382995e-02\n",
      " -1.56354994e-01  2.13551790e-01  2.03659445e-01  3.86902466e-02\n",
      " -9.37905982e-02  1.31063327e-01 -2.64624860e-02 -1.25436842e-01\n",
      " -1.97349578e-01 -1.08874343e-01 -2.00741574e-01  1.56110615e-01\n",
      "  3.14737819e-02 -1.54034853e-01 -3.73877883e-02 -2.21943572e-01\n",
      " -4.57568988e-02 -8.45329240e-02  1.21391430e-01 -2.74379700e-01\n",
      " -1.76460072e-01  6.27474766e-03 -6.01977594e-02 -2.20720768e-01\n",
      " -1.89000458e-01  7.02851936e-02 -1.69830397e-01  2.40725681e-01\n",
      " -5.62472641e-02  1.61347277e-02 -1.39771923e-01 -2.96781361e-01\n",
      " -1.94108024e-01  1.91043705e-01  7.02943013e-04 -2.18698993e-01\n",
      "  6.79492056e-02 -1.50520742e-01 -1.38891131e-01  4.87649441e-02\n",
      " -1.42586336e-01  1.49614766e-01 -4.07294333e-02  9.98648405e-02\n",
      " -2.72628535e-02 -2.47572839e-01 -1.50753096e-01  2.30384544e-01\n",
      "  1.44864008e-01 -1.24797687e-01 -1.26131728e-01 -1.66916355e-01\n",
      " -4.27586250e-02 -4.70253546e-03 -1.26001105e-01  1.96343422e-01\n",
      " -2.95187503e-01 -3.08458507e-01  3.80497123e-03 -1.35301396e-01\n",
      " -6.05063848e-02 -9.25142504e-03 -1.84868678e-01  2.37539988e-02\n",
      "  8.34768340e-02 -1.21082775e-01  3.89413647e-02 -4.44086157e-02\n",
      " -1.10677786e-01 -5.70902973e-02  2.70009458e-01 -2.61758715e-01\n",
      "  1.70580178e-01 -9.38632637e-02 -1.46634609e-01 -3.20311725e-01\n",
      "  1.43932030e-02 -8.61801058e-02  8.65760669e-02  7.84246698e-02\n",
      "  5.09030558e-02 -1.15006000e-01 -9.87502635e-02 -2.54442543e-01]\n",
      "L7N0                    -> L8N38 = [ 2.43309021e-01 -6.98484704e-02 -4.20421548e-02 -2.99075186e-01\n",
      " -4.50485051e-02  9.81428027e-02  3.25415246e-02  8.15019533e-02\n",
      "  1.88877515e-03 -1.02561280e-01 -5.39961047e-02  2.90941773e-03\n",
      "  3.68536301e-02 -6.72149956e-02  4.94878972e-03  1.63013816e-01\n",
      " -1.55929744e-01 -1.02719314e-01 -4.41547669e-02  8.37187096e-02\n",
      " -4.61795889e-02  2.01538637e-01 -6.16627038e-01  1.45661414e-01\n",
      "  1.65385216e-01 -1.36942849e-01  1.88796207e-01 -3.63986820e-01\n",
      " -1.80015013e-01  3.16805951e-02  3.22876215e-01  3.58933538e-01\n",
      " -1.10761955e-01 -4.08305526e-01 -4.74124700e-02  3.32864851e-01\n",
      " -9.41337347e-02 -1.70597240e-01 -4.03733402e-02  1.71911925e-01\n",
      "  7.98667129e-03 -4.18927446e-02  6.43177181e-02 -1.13954969e-01\n",
      "  3.08920583e-03 -5.71869984e-02 -2.76453733e-01  1.43292665e-01\n",
      "  4.10120934e-02 -8.92504230e-02  2.11342424e-02 -1.72414824e-01\n",
      " -7.72878975e-02 -2.55230237e-02 -2.08265707e-03 -6.45426509e-04\n",
      " -2.82223225e-01 -1.32882342e-01  2.54348963e-01 -1.87381059e-01\n",
      " -5.46519570e-02  9.87733230e-02 -1.13525428e-01 -2.73788162e-02\n",
      " -1.36648156e-02  4.14547697e-02 -2.46359810e-01 -1.26840189e-01\n",
      "  5.19376993e-02 -1.81042165e-01 -1.28048331e-01  9.41525176e-02\n",
      " -2.92784303e-01  1.89491719e-01 -1.28914583e-02  2.31265694e-01\n",
      " -2.82129705e-01  8.79233852e-02  1.24916069e-01 -2.60487292e-02\n",
      " -1.29798383e-01  6.90418109e-02 -5.33884652e-02 -6.12485744e-02\n",
      "  1.61628380e-01 -1.44084051e-01  1.64657369e-01  5.99508530e-06\n",
      "  1.06375538e-01  9.29025188e-02 -2.87583768e-01 -2.21795231e-01\n",
      " -1.04656249e-01 -1.28731534e-01  3.54941517e-01 -1.81413487e-01\n",
      "  1.74791723e-01 -2.87832189e-02  4.78951074e-02 -8.72533768e-02\n",
      " -1.11438014e-01 -2.59636715e-02  4.75412868e-02 -1.37400448e-01\n",
      " -1.08289167e-01  1.85530186e-01  1.35519698e-01  1.54423332e-02\n",
      " -1.24492623e-01  4.56729755e-02 -1.08523980e-01 -8.31607431e-02\n",
      " -5.13954051e-02 -1.93119030e-02  8.57468247e-02  2.23598722e-02\n",
      "  1.48430437e-01 -2.93140441e-01 -5.23165278e-02 -7.81922266e-02\n",
      "  1.12056069e-01 -1.93888694e-01  4.54314202e-02 -2.01749384e-01\n",
      " -2.77787610e-03  3.86094823e-02  2.40760557e-02  1.76665664e-01\n",
      "  8.52220953e-02 -2.93817502e-02  1.07617922e-01  1.89004511e-01\n",
      " -1.36477336e-01 -1.21293068e-01  7.36839473e-02 -2.36048743e-01\n",
      " -1.41851351e-01  2.35286117e-01  6.03408404e-02 -1.69162154e-01\n",
      "  1.90559968e-01 -9.09890831e-02  1.39283434e-01  6.07430153e-02\n",
      " -1.46770719e-02  4.28068191e-02  2.37920180e-01 -5.68813324e-01\n",
      "  7.93730244e-02  4.03172910e-01 -4.25005518e-03  1.05326235e-01\n",
      " -1.52246088e-01 -1.23046383e-01  1.97752076e-03 -1.45293877e-01\n",
      " -5.92628047e-02  1.31968826e-01 -1.06777199e-01 -2.76948400e-02\n",
      "  3.73392738e-02 -1.01948768e-01 -2.69150566e-02  3.54999304e-02\n",
      " -1.68252006e-01 -3.76791358e-02  7.27047399e-02 -1.73505962e-01\n",
      "  6.40853122e-02  1.35535363e-03 -4.30083461e-02  2.24505797e-01\n",
      "  3.42631489e-02  1.65482223e-01 -2.42746510e-02  1.30404204e-01\n",
      " -8.16249624e-02  2.80457616e-01 -2.37003163e-01 -2.22155407e-01\n",
      "  2.54719734e-01 -3.35220188e-01  1.03228666e-01 -2.35824600e-01\n",
      "  2.62814224e-01 -9.04573426e-02  2.79687382e-02 -2.11126283e-01\n",
      "  1.81506664e-01 -1.89949393e-01 -2.29876533e-01 -7.27106333e-02\n",
      " -7.60004967e-02  6.77300692e-02 -1.52219310e-01  2.87526213e-02\n",
      " -9.35801193e-02  1.50075421e-01 -1.42941952e-01 -1.27580762e-01]\n",
      "L7N0                    -> L8N39 = [-1.38720274e-01 -9.76580977e-02 -1.18764170e-01 -2.09735949e-02\n",
      "  7.07660802e-03  4.30033691e-02  1.30188800e-02 -9.76581592e-03\n",
      " -1.51212677e-01 -2.78584421e-01  5.36910817e-02  1.20069630e-01\n",
      "  1.01747140e-01 -1.03596270e-01 -2.95349985e-01  3.88704650e-02\n",
      " -1.40175730e-01  3.33072059e-02 -1.85725227e-01 -7.07476810e-02\n",
      " -1.80392802e-01 -1.69674255e-04 -1.47704974e-01 -3.32999796e-01\n",
      " -1.42122433e-01 -1.85950801e-01  3.45665850e-02 -1.92327574e-01\n",
      " -1.12301014e-01 -2.31238484e-01  2.67178118e-01 -6.37595728e-02\n",
      " -1.60691723e-01 -5.66075481e-02  2.25809384e-02 -1.59942135e-01\n",
      " -2.62391716e-01 -7.52287135e-02  1.03546092e-02 -3.76900345e-01\n",
      "  1.42107069e-01 -1.98153764e-01 -1.42516881e-01 -1.44977868e-01\n",
      "  1.62834048e-01  1.21392950e-01  5.39411418e-02 -3.11809272e-01\n",
      "  1.29648671e-01 -1.83597460e-01 -1.36849791e-01 -1.09299220e-01\n",
      " -1.20277300e-01 -7.50713795e-02 -1.38426006e-01 -1.51006743e-01\n",
      " -1.81067586e-01 -2.30188906e-01 -1.83413506e-01  1.56631410e-01\n",
      " -4.94410574e-01 -2.74266582e-02  1.81560308e-01  4.90673073e-02\n",
      "  4.64512222e-03 -2.29956418e-01 -3.13287646e-01  7.11106211e-02\n",
      " -2.92966545e-01 -1.53945416e-01 -2.33151436e-01  1.07019320e-01\n",
      " -1.45686790e-01 -2.40993053e-01  5.31070530e-02 -7.58475298e-03\n",
      " -1.36612147e-01  1.94982160e-02 -2.00545460e-01 -5.82105294e-02\n",
      " -1.44459829e-01 -2.21612781e-01  5.41863255e-02 -1.57938659e-01\n",
      " -2.40652531e-01 -1.92691743e-01 -2.95373406e-02 -2.37579122e-01\n",
      " -1.12241141e-01 -6.90088719e-02  2.09854454e-01 -4.37368661e-01\n",
      " -9.78435725e-02 -8.61193016e-02 -7.35215321e-02 -8.94447342e-02\n",
      " -9.29229856e-02 -1.38552040e-01 -3.88521731e-01 -1.99408263e-01\n",
      "  4.77855057e-02 -2.64632672e-01  6.77757710e-03 -2.03082249e-01\n",
      " -2.94982404e-01  9.45780650e-02  2.60762334e-01  1.30496114e-01\n",
      "  1.30633503e-01 -7.34735429e-02  3.00965756e-02 -2.53629629e-02\n",
      "  2.61751860e-01  1.12845719e-01  8.90532061e-02 -9.68083590e-02\n",
      " -1.08271405e-01 -3.13559324e-02 -4.04933579e-02  9.54705626e-02\n",
      " -1.52887583e-01  7.88803175e-02  4.16561998e-02  4.14256603e-02\n",
      " -7.88525939e-02 -1.23214260e-01 -2.23942585e-02  8.67988318e-02\n",
      "  9.48642492e-02 -7.91058838e-02 -1.28282040e-01 -3.37009251e-01\n",
      "  5.81858419e-02 -1.62760124e-01 -9.58478451e-02 -9.54289287e-02\n",
      " -1.89704478e-01  4.14781906e-02 -2.21413478e-01 -2.60739535e-01\n",
      "  7.45156333e-02 -2.23442182e-01 -1.16082905e-02 -2.59381700e-02\n",
      " -2.85699256e-02 -2.34127089e-01 -4.45592105e-01 -1.65179178e-01\n",
      "  5.74990967e-03 -4.67386693e-02 -4.38363403e-02 -1.89491391e-01\n",
      " -2.55796790e-01  1.33924540e-02 -2.44254693e-01  1.52513146e-01\n",
      " -1.59356967e-01  4.50556539e-02 -6.88631609e-02 -2.88087502e-02\n",
      " -1.20504141e-01 -1.03828181e-02  1.90905496e-01  1.58781394e-01\n",
      " -3.02478611e-01 -1.86167508e-01 -1.17267873e-02 -1.47226527e-01\n",
      " -1.90734774e-01  1.62748754e-01 -1.22598812e-01 -3.80386673e-02\n",
      " -8.06485191e-02 -1.51160598e-01  1.36046097e-01 -3.71596098e-01\n",
      "  3.01103711e-01 -5.87640926e-02 -3.13785046e-01  1.20151080e-01\n",
      " -1.80642635e-01 -2.56454617e-01  1.69211462e-01 -6.65245503e-02\n",
      "  1.39786556e-01 -2.77283899e-02  1.20240346e-01 -3.03134859e-01\n",
      " -3.73178609e-02 -1.90988109e-01  1.13484329e-02  2.06163973e-01\n",
      " -3.44601236e-02 -2.99851209e-01 -7.64837489e-02 -1.67534664e-01\n",
      "  1.18642393e-02  1.97650075e-01 -1.03426985e-01 -2.47553125e-01]\n",
      "L7N0                    -> L8N40 = [-0.14532177  0.03822751 -0.18803313  0.08793069 -0.06632569  0.02088339\n",
      " -0.01407234 -0.01267671 -0.03729422  0.4011055   0.20567538 -0.07355387\n",
      " -0.26877925  0.1625475  -0.44885305 -0.08424408 -0.12018908  0.21904482\n",
      "  0.02889584  0.0601267   0.149573   -0.06898069  0.05578788  0.23728095\n",
      "  0.30097848  0.03728241  0.2198477   0.07821807 -0.04150074  0.01934674\n",
      "  0.05617357  0.24676189  0.19424647 -0.14732336  0.04170749 -0.1011344\n",
      "  0.27965087  0.07769123  0.09196088 -0.09284134  0.03018501 -0.4152791\n",
      "  0.23526748  0.08121888  0.07038967  0.32447     0.06015977  0.01375923\n",
      "  0.10798103 -0.12265585  0.03075353 -0.09310652  0.23226807  0.25850096\n",
      "  0.09740262  0.16789544 -0.07463783 -0.01219199 -0.2520302  -0.0737181\n",
      "  0.04893857 -0.04140127  0.22215976 -0.02951787 -0.0022455   0.0824923\n",
      "  0.01512751 -0.33452737  0.06928793  0.00116401 -0.05592414  0.21217683\n",
      " -0.11571781  0.00066425  0.1057877   0.12242168  0.23839146 -0.1986304\n",
      "  0.13209344  0.07518694 -0.16159126 -0.01582928  0.06338987 -0.34543705\n",
      "  0.15121695 -0.32007298 -0.00257604 -0.1708502  -0.0528935   0.17935538\n",
      " -0.04553952  0.00898014  0.05223534  0.16483544 -0.23252898  0.09226593\n",
      " -0.00213189  0.13460399  0.40113288  0.08278278  0.0715755   0.03975458\n",
      "  0.14013118 -0.10077791  0.03796376 -0.03634911 -0.13448521  0.01547103\n",
      "  0.1951466  -0.06525335 -0.06619146 -0.08358288 -0.09548393  0.1421744\n",
      " -0.03018771  0.08275043  0.18745054  0.04155365  0.04377881  0.16722676\n",
      "  0.14414234  0.03938257 -0.02782376  0.40959635  0.0116093   0.04653814\n",
      "  0.25199476  0.01659116  0.10996015 -0.37947822  0.15100355  0.1870893\n",
      "  0.14976212 -0.00619714 -0.09117632 -0.04308809 -0.09152966  0.11440282\n",
      "  0.02434435  0.05168454  0.13251047 -0.04689239 -0.07399308 -0.02895544\n",
      " -0.0786885   0.16230124 -0.03664071  0.3184946  -0.02482994 -0.01313756\n",
      "  0.03343661 -0.00461953  0.08881334  0.14374378  0.3486076  -0.11972222\n",
      "  0.03285484  0.19469571  0.22258598  0.2502721   0.03509603 -0.15722397\n",
      " -0.03405711  0.00532783 -0.1088481   0.05630068  0.09831426 -0.21033745\n",
      " -0.17059691  0.11896705  0.07501366 -0.08020657  0.18155447 -0.1030407\n",
      " -0.08397729  0.0494992   0.19473144  0.00364308 -0.19802871 -0.13518554\n",
      "  0.12188341  0.13207006 -0.04474773 -0.04842039 -0.08265869 -0.04646437\n",
      " -0.40583143 -0.13774942  0.10811202  0.15537043  0.06148206  0.09388229\n",
      " -0.12847264  0.10080041 -0.23712955  0.18842994  0.11600624  0.09783031\n",
      "  0.02176591  0.06436264]\n",
      "L7N0                    -> L8N41 = [ 0.05265543  0.01886914 -0.01346304  0.0147635   0.01541734  0.22597517\n",
      " -0.18103349 -0.04648307  0.01320491  0.02806984  0.11750329 -0.3216629\n",
      " -0.43129158 -0.10992057 -0.16126087  0.03676206 -0.11775036  0.07768434\n",
      " -0.20183913 -0.11462848  0.07757979 -0.01328404 -0.07235859  0.11050285\n",
      "  0.00995419 -0.08855831 -0.39042777 -0.16884997  0.0259638   0.18295017\n",
      " -0.13261442 -0.10179759 -0.04328339  0.38351798 -0.26114762  0.08997411\n",
      " -0.1660182   0.08094378 -0.0508053   0.25631523  0.13076115  0.15313749\n",
      "  0.11057898 -0.21085158 -0.0997435  -0.14318195 -0.01603984 -0.06041291\n",
      " -0.3667357   0.00765628 -0.25620604 -0.21861443  0.1321727  -0.0359273\n",
      " -0.0599751  -0.14372367  0.0005847   0.09907163 -0.17107797  0.019493\n",
      " -0.05040578 -0.44378847 -0.13893007  0.00211701 -0.3888833  -0.0229505\n",
      "  0.08388928 -0.12058821  0.00562427 -0.0647511  -0.2501663  -0.02558356\n",
      "  0.24144784  0.1661897  -0.18466638  0.0170419  -0.07194008 -0.33086675\n",
      "  0.02817256  0.16202137  0.2389336  -0.03221616 -0.13672249  0.06630208\n",
      " -0.18826066 -0.09639611  0.10547497 -0.03237498 -0.11379435  0.18025975\n",
      " -0.11946058 -0.20252909  0.10304382  0.20676678  0.01157785 -0.03212889\n",
      "  0.11410837  0.07010505 -0.1019872  -0.2773093   0.03959468  0.04692465\n",
      " -0.27444467  0.28208214 -0.01323766 -0.22372805 -0.17000672  0.01152607\n",
      "  0.09574744 -0.14399713 -0.24103159  0.27641475 -0.09801671  0.11416773\n",
      " -0.14400187  0.05924406 -0.03527553  0.01122008  0.01821904 -0.06050218\n",
      "  0.05746372 -0.07912563 -0.1762283  -0.05383384 -0.19974996  0.016298\n",
      "  0.0088867  -0.1597986  -0.24484783 -0.05300613 -0.15730444 -0.16713963\n",
      "  0.01170584 -0.09873553 -0.06012775 -0.314387    0.24183236 -0.20537353\n",
      "  0.16888927 -0.202218    0.01055987 -0.16272222 -0.04086018 -0.30990267\n",
      "  0.07962143  0.12034355  0.25401032 -0.05443629 -0.18579556 -0.39038306\n",
      " -0.5246234   0.11599306 -0.03451559 -0.24032319  0.04734332 -0.0384719\n",
      " -0.03114507 -0.1946032  -0.06463404  0.01293229 -0.24600905 -0.13380754\n",
      " -0.1543168  -0.2939507  -0.19516228 -0.00478696 -0.31046548 -0.21998969\n",
      "  0.13230649 -0.15763342  0.17726909 -0.23489168 -0.10281386  0.01456443\n",
      " -0.11160285  0.0154194   0.21840419 -0.02378216  0.06006843 -0.15279602\n",
      " -0.5065062  -0.14433713 -0.19236976  0.0093431  -0.09960645  0.02042508\n",
      " -0.00748819  0.15226872  0.13208607 -0.2627075  -0.11865705 -0.22563551\n",
      " -0.19251888 -0.2009797   0.23416561 -0.03093736 -0.03178861 -0.28079027\n",
      "  0.16776699 -0.05932181]\n",
      "L7N0                    -> L8N42 = [-0.12048484 -0.08959827 -0.04039279 -0.12525132 -0.04280248 -0.08673628\n",
      " -0.20282167  0.00227379 -0.04604182 -0.02443746 -0.45541114  0.01444376\n",
      " -0.11930514 -0.15552     0.10870723 -0.02368482 -0.22435936 -0.12595369\n",
      " -0.24123834  0.00851975  0.02101564  0.029515   -0.31971902 -0.2508387\n",
      " -0.3498825  -0.03645135  0.00091091  0.08781537 -0.3123586  -0.28188533\n",
      " -0.20285441 -0.05543249 -0.30861485  0.03417567 -0.2811437  -0.14003299\n",
      " -0.2201187  -0.2372298  -0.28705513 -0.12665464 -0.16111197  0.17936173\n",
      " -0.2071047  -0.2896945   0.12632366 -0.09494124  0.10112166 -0.25360274\n",
      "  0.13477086 -0.16278297 -0.22943382 -0.1586652   0.08193465 -0.3132017\n",
      "  0.06996562  0.02454788 -0.06284085 -0.23204312 -0.03310569 -0.14808992\n",
      " -0.42084804 -0.23355941 -0.07946819 -0.10723571 -0.18064316 -0.00500498\n",
      " -0.16400349 -0.04569167 -0.18781018 -0.37022457 -0.4607289   0.06225386\n",
      "  0.09348421 -0.04850573 -0.3725953  -0.14564335 -0.29613894 -0.14450048\n",
      " -0.05651475 -0.23594049 -0.01067025  0.24876651 -0.22979808 -0.42548314\n",
      " -0.04689103  0.03398029 -0.15461431  0.29272848 -0.02012268 -0.15719652\n",
      " -0.03427526 -0.21332584 -0.09815072 -0.16907336  0.03241173 -0.09300321\n",
      " -0.07940631 -0.25182295 -0.31087    -0.30976167 -0.2808909  -0.19012468\n",
      " -0.09902146  0.11056247 -0.13405725 -0.18472867 -0.14640051 -0.2640743\n",
      " -0.16870071  0.09230226 -0.32765052  0.01938519 -0.29828644 -0.26988328\n",
      " -0.14337865 -0.05228218 -0.27266258 -0.07117029 -0.27239728 -0.22326337\n",
      " -0.25335464 -0.12953484 -0.0909337  -0.12781285  0.12690215 -0.1859877\n",
      " -0.08100031  0.21500783 -0.19636583  0.17099287 -0.13177177 -0.43023673\n",
      "  0.23957027 -0.43257704 -0.16004823 -0.18239601 -0.18831044 -0.15928648\n",
      "  0.06219514 -0.012936   -0.21361274 -0.05866941  0.00419007 -0.21383987\n",
      " -0.01652584 -0.12564069 -0.19806533 -0.30885205 -0.08471548  0.12228891\n",
      " -0.15965076 -0.15732297  0.11887883 -0.07181514  0.13707899 -0.12094541\n",
      "  0.07880174 -0.21445432 -0.09872243 -0.21089731 -0.2995369   0.02102201\n",
      " -0.22401829 -0.12046786 -0.13749309 -0.30534595 -0.15470248 -0.00230188\n",
      " -0.07280613 -0.12202111  0.03148795 -0.18110612 -0.28918862  0.08183338\n",
      " -0.18686543  0.15258586 -0.04139886  0.19297631 -0.13600264 -0.14340757\n",
      "  0.0350713  -0.25294605  0.07556119  0.12270726  0.07784602 -0.24815245\n",
      " -0.19291797 -0.09857764 -0.2509416  -0.04119181 -0.09731115 -0.04986431\n",
      "  0.04153598 -0.10361317 -0.00625638 -0.22733036 -0.37755355  0.0308797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.04313998  0.0311463 ]\n",
      "L7N0                    -> L8N43 = [ 1.40367672e-01  1.15162665e-02  7.63168046e-03  1.88547924e-01\n",
      "  1.94799781e-01  1.34798050e-01  8.74677766e-03 -2.32181624e-01\n",
      "  4.93675051e-03  2.13096291e-01  1.87954783e-01 -9.14969295e-02\n",
      "  6.23084605e-03 -3.06709521e-02 -1.08632371e-01  8.02671444e-03\n",
      " -2.16699362e-01  1.63172230e-01 -2.71713227e-01  4.00958098e-02\n",
      " -1.54489785e-01  8.97291768e-03  4.09076698e-02 -3.11393682e-02\n",
      "  2.64575124e-01  1.95540618e-02  1.23812042e-01  8.25474635e-02\n",
      " -1.06718808e-01  4.98216040e-03  1.43687218e-01 -3.02925166e-02\n",
      " -2.03178786e-02 -2.02172816e-01 -8.84251378e-04  4.36076671e-02\n",
      " -2.53424376e-01 -9.49836746e-02  2.43584126e-01  1.68471914e-02\n",
      " -8.84789899e-02  8.87565222e-03  1.53474137e-01  2.71613628e-01\n",
      "  5.80940917e-02 -5.49997054e-02 -2.24683374e-01  1.44364521e-01\n",
      " -1.76557258e-01  5.56222349e-02 -2.69587487e-01  4.31532934e-02\n",
      "  1.78418979e-01 -1.90787553e-03  1.59677044e-01 -4.84438613e-02\n",
      "  4.02671359e-02  5.95404441e-03 -7.96611980e-02  6.68211281e-02\n",
      " -1.62361022e-02  2.12758854e-01  7.48357996e-02 -1.19539067e-01\n",
      "  1.32782191e-01 -1.93241626e-01 -8.34889263e-02  3.72942276e-02\n",
      "  1.73507586e-01 -9.39727873e-02 -1.12360299e-01 -2.51034260e-01\n",
      " -2.44116589e-01 -1.40633836e-01  1.53517097e-01  8.46679229e-03\n",
      "  1.05752133e-01 -2.67818216e-02  2.21769631e-01  4.63867672e-02\n",
      " -2.38786653e-01 -1.53713554e-01  1.59664184e-01 -1.53669836e-02\n",
      " -1.35604013e-02 -1.69050395e-01 -8.78164098e-02 -6.32729381e-02\n",
      " -3.77723784e-03 -9.60298032e-02  1.37110372e-04  6.79717287e-02\n",
      "  3.60583072e-03  3.93603705e-02  5.30620031e-02 -2.22171292e-01\n",
      "  6.14149496e-02  1.82939947e-01  1.71554402e-01  3.97204995e-01\n",
      "  6.95299208e-02  9.80246440e-02  9.33931544e-02 -1.33357584e-01\n",
      "  7.26123154e-02 -3.29574049e-02  1.78535059e-01 -1.28520578e-01\n",
      "  1.12973429e-01  8.11648220e-02 -1.67787001e-01 -1.33651674e-01\n",
      " -3.11027095e-02  4.10234958e-01  7.20874965e-02  9.67244059e-02\n",
      "  2.40966454e-01 -9.13137347e-02 -9.58376378e-02 -1.68173566e-01\n",
      "  1.93710595e-01  2.53408074e-01  2.47953489e-01  2.74618510e-02\n",
      " -2.06083030e-01  1.46263301e-01  2.43339896e-01 -1.88965902e-01\n",
      " -1.34810552e-01 -2.98598021e-01 -6.55005947e-02  1.58473360e-03\n",
      "  1.40101045e-01  2.00098708e-01  1.51068196e-01 -2.55900979e-01\n",
      " -1.46697551e-01  2.31235340e-01  4.71978113e-02  6.88240230e-02\n",
      "  1.56311899e-01  2.74606124e-02  1.09663121e-02 -2.79070169e-01\n",
      " -2.78740793e-01  2.97893316e-01  1.96137547e-01  2.84667850e-01\n",
      "  1.55664608e-02  1.47286579e-01 -3.60324346e-02 -9.60755721e-02\n",
      " -1.17858179e-01  1.42204911e-01  1.70787022e-01 -3.70540135e-02\n",
      "  4.00169380e-02  6.28068373e-02 -2.21239671e-01  8.21969882e-02\n",
      " -1.13987453e-01 -5.52838333e-02 -7.48918056e-02 -1.03403330e-01\n",
      " -4.19426225e-02  1.93665493e-02  7.75125101e-02 -1.41390428e-01\n",
      " -2.76449293e-01  1.32046685e-01 -1.30846143e-01 -3.38293850e-01\n",
      "  2.60623395e-01 -8.29986706e-02  3.77139896e-01 -7.18135610e-02\n",
      " -3.12523037e-01 -4.14505787e-02  1.13169223e-01 -2.38995738e-02\n",
      " -1.37536332e-01 -2.85195019e-02 -3.80151451e-01 -3.54327440e-01\n",
      "  1.65224239e-01  1.09149739e-01 -1.83886468e-01 -8.03672969e-02\n",
      " -3.39007825e-02 -1.90443732e-02  2.66425014e-01  2.82196701e-02\n",
      " -1.69010386e-01 -2.41401643e-01 -1.05483666e-01  1.45402476e-01\n",
      "  1.90329000e-01  1.07692838e-01 -1.16215825e-01 -1.69596538e-01]\n",
      "L7N0                    -> L8N44 = [-0.07543035 -0.17919227 -0.1235426  -0.25266257  0.03296345  0.20626415\n",
      " -0.06080276 -0.47385624  0.07757264  0.11168018  0.10235836  0.03252652\n",
      " -0.19429043  0.08515741 -0.05529482 -0.21956736 -0.10158391 -0.22458054\n",
      "  0.05273389  0.20189461 -0.09091075 -0.21946122 -0.23464797  0.1042089\n",
      "  0.14756137  0.03516059  0.11670211  0.27569997  0.04426474  0.19880116\n",
      " -0.07872632  0.03231576 -0.05030311 -0.3045368   0.28588858  0.18047166\n",
      " -0.07869925 -0.21986812  0.40287244 -0.21201423  0.2732845   0.2109212\n",
      " -0.26689267 -0.16174853 -0.20603393 -0.02421672  0.03913902 -0.06012319\n",
      "  0.00152121  0.15322703 -0.13218491 -0.17333338  0.05976596  0.22151646\n",
      " -0.04385747 -0.17729458 -0.04457343  0.03550946 -0.05433349  0.21618949\n",
      "  0.2198796   0.21509804 -0.4123549  -0.17746513  0.03467291 -0.02533941\n",
      " -0.3029699   0.00147302  0.10643718  0.02872399 -0.09074268  0.21391678\n",
      " -0.18312117  0.00163714 -0.22351448 -0.17833783 -0.12074742 -0.23262906\n",
      "  0.09155107  0.19043605  0.06814232  0.22900473  0.0810594   0.07328673\n",
      " -0.01559277  0.03672371 -0.1105857   0.05129478 -0.0605528   0.3028517\n",
      " -0.6819017   0.08328509  0.1878872  -0.02625746  0.04446795 -0.10852688\n",
      " -0.18184198 -0.15443337 -0.17238119  0.18510439  0.01448441 -0.18310207\n",
      " -0.01519497  0.00377673  0.12930931 -0.40402424 -0.10072224 -0.25484616\n",
      "  0.00117069 -0.06176457 -0.5705614   0.134691    0.09012708  0.13739598\n",
      " -0.11467012 -0.2159304   0.22276282 -0.04471984  0.20991378 -0.13562912\n",
      " -0.13589272  0.16584304  0.13095078 -0.14155945  0.06011365  0.07861541\n",
      " -0.15903068  0.0823094  -0.25051084  0.10557298  0.10705671  0.39001325\n",
      " -0.18478833  0.1645625   0.03397984  0.00675276  0.09702221 -0.27608675\n",
      "  0.17416754  0.21844089 -0.00393461  0.0131112  -0.09970057 -0.02022894\n",
      "  0.16204374 -0.0890777   0.05291089 -0.05281031 -0.0177368   0.07663587\n",
      " -0.47196782  0.16740261 -0.09609965 -0.11405462 -0.00485183 -0.19828902\n",
      " -0.15550722  0.21246588  0.15814392  0.16572896  0.01364214  0.02166807\n",
      "  0.0361512  -0.48256755 -0.11933529  0.17751463 -0.2886134   0.03085238\n",
      " -0.00249378 -0.03037192 -0.29460692  0.04002629  0.07385166  0.2995026\n",
      "  0.19318944 -0.03606918 -0.17236358  0.05581901  0.03388442 -0.2054998\n",
      " -0.14545038  0.05793051 -0.32215294 -0.10839923  0.0548837   0.06430586\n",
      " -0.02992673 -0.11212496 -0.19755018 -0.12225847 -0.08048821 -0.27142987\n",
      "  0.0393444   0.09618115  0.37881747 -0.01254837 -0.03591206 -0.10086855\n",
      " -0.15941322  0.04862292]\n",
      "L7N0                    -> L8N45 = [-2.09362045e-01 -3.56420875e-01 -3.90012860e-01 -2.45781124e-01\n",
      " -1.22863106e-01  1.71185896e-01 -1.63853496e-01 -3.22347283e-02\n",
      "  2.10772038e-01 -1.37810279e-02  2.05526188e-01 -2.08972678e-01\n",
      " -2.02218950e-01  1.61631450e-01  5.75706214e-02 -1.66263476e-01\n",
      " -2.59236749e-02 -2.59631515e-01  4.23896052e-02  1.81435511e-01\n",
      "  5.18997423e-02 -1.65736973e-01 -4.01342958e-01 -3.28280330e-01\n",
      " -1.36924043e-01 -1.47283927e-01 -1.51316583e-01 -3.71383220e-01\n",
      " -2.50991076e-01 -1.02733783e-01 -6.43165633e-02 -5.32629825e-02\n",
      " -1.58371747e-01  8.58370066e-02 -3.96912597e-04 -2.13879213e-01\n",
      " -5.75223789e-02  6.54406380e-03  1.48092240e-01 -1.90189019e-01\n",
      "  7.66575485e-02  1.41405210e-01 -1.35104448e-01 -2.16765702e-01\n",
      "  9.98694897e-02 -2.60322094e-01 -4.40970302e-01 -2.14225322e-01\n",
      " -1.57620385e-01 -1.49791434e-01 -2.32767180e-01 -1.22494981e-01\n",
      "  7.37482607e-02 -9.66304764e-02 -3.31969447e-02  9.58694518e-02\n",
      " -7.94209242e-02 -2.51700789e-01  1.15128793e-01 -1.18066810e-01\n",
      " -1.19388953e-01 -2.95324504e-01 -2.09174126e-01 -3.14788938e-01\n",
      " -7.00853243e-02 -1.36432648e-01  3.58053967e-02 -2.20934674e-01\n",
      "  2.30278894e-02 -1.13264821e-01 -2.09455490e-01 -1.00088313e-01\n",
      "  8.78788903e-02  5.16814590e-02 -1.27026692e-01 -1.58013105e-01\n",
      " -3.21572959e-01  1.43095911e-01 -1.02189399e-01 -4.52311859e-02\n",
      "  1.38130248e-01 -5.57138622e-02 -1.52283579e-01  3.62339779e-03\n",
      "  1.39665917e-01 -6.98627084e-02  1.78093180e-01 -6.87630400e-02\n",
      " -1.46268383e-01 -1.12944849e-01 -3.04989576e-01 -2.18666777e-01\n",
      " -1.07117228e-01 -2.62954026e-01 -1.84944972e-01 -1.12798929e-01\n",
      "  4.51691628e-01 -1.38089955e-01 -2.67523885e-01  3.15822624e-02\n",
      "  4.61842082e-02 -1.35096043e-01 -4.07710932e-02 -2.68413574e-02\n",
      " -6.51020631e-02 -1.36645898e-01 -1.04444571e-01  1.67785808e-01\n",
      " -1.46514595e-01 -1.28726676e-01 -2.81434327e-01 -2.20254809e-01\n",
      " -1.97181135e-01 -2.27370739e-01 -2.36576468e-01 -1.58512481e-02\n",
      " -1.85389012e-01 -1.46678582e-01  3.96911800e-02 -8.16387981e-02\n",
      " -1.42664209e-01 -1.37880528e-02 -1.23593770e-02 -1.18677415e-01\n",
      "  2.05541313e-01 -1.00070223e-01  1.68687671e-01 -8.28939974e-02\n",
      " -2.59910256e-01  1.46210179e-01 -1.61951646e-01 -8.40875581e-02\n",
      " -2.32057367e-02  1.20666504e-01  3.47553901e-02 -3.34542334e-01\n",
      "  7.15495944e-02 -5.20808958e-02  6.24558628e-02  1.93463806e-02\n",
      "  1.06636263e-01  5.38493022e-02  1.53542072e-01 -2.17517436e-01\n",
      "  2.29996070e-01 -1.59374043e-01 -1.40458107e-01  1.32516608e-01\n",
      " -7.93877915e-02  6.37556091e-02 -1.42393798e-01  5.16734533e-02\n",
      " -2.49357209e-01 -2.09610686e-01  1.34224117e-01 -3.94015193e-01\n",
      " -2.48911098e-01 -1.12249032e-01 -1.69306785e-01 -2.38502145e-01\n",
      " -1.57857180e-01 -1.10428341e-01 -1.03303485e-01 -9.07289088e-02\n",
      " -1.87846079e-01  1.04404524e-01 -2.00435100e-03  2.07667768e-01\n",
      " -1.36868149e-01 -1.68470174e-01 -2.29455814e-01 -7.75874853e-02\n",
      "  1.68093145e-01 -1.21072941e-01 -7.64211267e-03  5.78899160e-02\n",
      " -1.49947420e-01 -2.55200118e-01  6.17386587e-02 -1.95448488e-01\n",
      " -2.95838743e-01 -1.16394937e-01 -2.70198792e-01 -1.11924291e-01\n",
      " -2.57714659e-01 -1.21939257e-01 -7.92367086e-02  9.67319682e-02\n",
      "  3.24168503e-02 -4.47219834e-02 -6.11391924e-02 -2.09149614e-01\n",
      "  3.96578275e-02  4.10625376e-02 -1.97303638e-01  9.71740931e-02\n",
      " -2.41605565e-01 -1.95301160e-01 -3.11997771e-01  9.38305706e-02]\n",
      "L7N0                    -> L8N46 = [ 8.83111581e-02 -5.02059646e-02 -7.39290267e-02  1.49591237e-01\n",
      "  1.05733976e-01  7.01286197e-02 -2.63929099e-01 -8.46393630e-02\n",
      "  2.43182257e-02 -9.32767317e-02 -7.03860298e-02  1.49168313e-01\n",
      "  1.56409830e-01 -4.36593108e-02  1.38870543e-02  2.53137469e-01\n",
      " -1.33988589e-01  4.54796031e-02  4.38115895e-02  4.29514460e-02\n",
      " -1.24841169e-01  1.33811817e-01  1.50792956e-01  8.04609805e-02\n",
      " -8.15583691e-02 -3.80240530e-02  3.56014743e-02 -2.30133459e-01\n",
      "  1.19417943e-01 -1.78781629e-01  1.91428527e-01 -2.18808144e-01\n",
      "  1.68866329e-02 -5.01099490e-02 -1.39454976e-01  1.83709309e-01\n",
      "  7.57028237e-02  3.10595185e-02  1.31862864e-01  1.90249696e-01\n",
      "  1.56680241e-01 -1.29683331e-01  2.14724213e-01  2.51190066e-02\n",
      " -3.20729107e-01  2.73769468e-01  6.94667175e-02  2.93056685e-02\n",
      "  1.53304964e-01  2.05087632e-01 -5.94770499e-02 -2.44599909e-01\n",
      "  9.31785256e-03  6.50051087e-02 -1.32035911e-01 -2.43895203e-01\n",
      "  1.34154856e-01  2.28822827e-01  1.34280190e-01 -2.78442085e-01\n",
      " -1.52803868e-01  4.58986163e-02 -1.20562024e-01  8.61947164e-02\n",
      "  2.87287254e-02  7.32088685e-02 -2.24522892e-02  2.23926932e-01\n",
      "  3.06922793e-02 -5.22970036e-02 -1.30938023e-01 -1.99752167e-01\n",
      " -1.60948411e-01  1.04211822e-01 -1.46352559e-01  2.01111749e-01\n",
      "  2.88752206e-02  2.61215568e-01  6.69657439e-02  3.53810579e-01\n",
      "  6.62026703e-02 -3.45729925e-02  6.83226064e-02 -3.61718871e-02\n",
      "  9.13976356e-02 -4.32429835e-02 -2.09552124e-01  1.13209635e-02\n",
      "  9.32887476e-03 -1.11003697e-01 -2.85906196e-01 -1.59681857e-01\n",
      " -4.33369130e-02 -2.12383084e-02  3.67662311e-01  2.79126260e-02\n",
      " -1.47266820e-01 -9.62383449e-02 -6.27682507e-02 -1.13456666e-01\n",
      " -1.70970067e-01 -1.75889358e-01  4.30417284e-02 -2.92939574e-01\n",
      " -2.59246211e-02 -2.63392329e-02  3.18739146e-01  2.44949043e-01\n",
      " -1.09427303e-01  1.17896259e-01 -9.84703377e-02 -1.53152913e-01\n",
      " -1.40297279e-01  3.53037864e-02 -2.75329262e-01  1.23877391e-01\n",
      "  1.98625505e-01 -2.15508401e-01  7.70714693e-03 -6.07919395e-02\n",
      " -6.32093698e-02  9.10315886e-02 -1.01559259e-01 -1.54926434e-01\n",
      " -1.38545573e-01  5.98911382e-02  4.71462822e-03 -1.08501248e-01\n",
      "  1.98772743e-01  2.17977446e-02 -1.63176253e-01  4.27792333e-02\n",
      " -1.91386014e-01  5.20151556e-02  1.53377326e-03  2.76136369e-01\n",
      " -4.01724100e-01 -3.03013086e-01  1.71505615e-01 -6.84217662e-02\n",
      " -4.77885827e-02  1.46979019e-01  2.52570435e-02 -1.03591997e-02\n",
      " -1.78384095e-01  1.26623865e-02  8.26481581e-02 -2.51915842e-01\n",
      "  1.23871490e-01  1.85920849e-01  1.48966745e-01 -1.52642712e-01\n",
      "  2.39810511e-01 -4.26361151e-02  3.37550491e-02  1.13209561e-01\n",
      " -7.56807486e-03 -1.59095585e-01  4.25473340e-02  3.89538109e-02\n",
      "  6.01763390e-02  1.87619671e-01  5.81341796e-02 -2.90311184e-02\n",
      " -6.45080879e-02  1.35041133e-01 -1.62735179e-01 -1.04491130e-01\n",
      "  1.40472740e-01 -3.90477973e-04 -1.12354949e-01 -2.55081177e-01\n",
      " -1.90162569e-01 -1.02852732e-01  7.83371404e-02  1.13509275e-01\n",
      " -1.38038456e-01 -1.16918646e-01  1.43965021e-01 -9.45681855e-02\n",
      " -2.96036929e-01  1.43221632e-01  1.29907370e-01 -1.00023419e-01\n",
      " -2.74384141e-01 -7.69850984e-03 -1.80707611e-02 -2.07306698e-01\n",
      "  9.70302746e-02 -4.06901807e-01 -1.89885065e-01  2.60630995e-01\n",
      " -1.18907727e-01 -1.18174322e-01 -4.69673604e-01 -1.91345718e-02\n",
      " -7.38907531e-02  2.52331495e-01 -7.60108754e-02 -1.79253265e-01]\n",
      "L7N0                    -> L8N47 = [ 9.00281500e-03 -1.95863530e-01  7.09250793e-02 -1.65958881e-01\n",
      " -2.42839798e-01 -2.72218734e-01  1.13259241e-01  2.40083113e-01\n",
      "  3.71350437e-01  2.59083845e-02 -2.41498157e-01 -7.26867095e-02\n",
      "  1.23252207e-02  7.74585530e-02 -7.33213350e-02 -1.16964437e-01\n",
      " -2.76556432e-01 -5.16347960e-02 -2.24541977e-01  1.07940502e-01\n",
      " -1.15125291e-01  6.16211481e-02  2.29942381e-01 -5.13800010e-02\n",
      " -8.32635537e-02  2.33001798e-01 -3.40993479e-02  1.86140426e-02\n",
      " -4.26901728e-02 -1.03642009e-01  6.67345524e-02 -2.70045459e-01\n",
      "  9.49476659e-03  3.12510878e-01  1.55931398e-01  2.51020432e-01\n",
      "  3.25740092e-02  4.39076126e-03 -3.22892457e-01  5.18577620e-02\n",
      " -9.21729356e-02 -9.53003913e-02 -2.77069986e-01  7.16305971e-02\n",
      "  1.71120867e-01 -1.89844459e-01 -3.03934794e-02 -2.98801541e-01\n",
      " -1.85135394e-01  2.26039290e-01  2.46014684e-01  1.82616994e-01\n",
      "  6.06305003e-02 -3.45136784e-02 -1.19538918e-01  1.51653960e-01\n",
      " -7.95090497e-02 -9.34694614e-03 -2.93114576e-02 -7.40928873e-02\n",
      "  3.19214575e-02 -2.28323683e-01  2.50421464e-01  1.92343533e-01\n",
      " -1.06684834e-01 -1.60223022e-01 -5.80502935e-02  1.19710445e-01\n",
      " -2.65241086e-01  7.55735040e-02  1.55107960e-01 -7.80351833e-02\n",
      "  9.84399617e-02  5.03071509e-02  3.98311093e-02  2.66502369e-02\n",
      " -1.71817511e-01 -3.58614713e-01 -8.93129185e-02 -1.18049264e-01\n",
      " -1.35923281e-01  1.30762115e-01  1.00367039e-01 -3.41719478e-01\n",
      "  9.88932699e-02  2.54000109e-02 -2.04007298e-01  1.01548117e-02\n",
      " -2.04633027e-01 -1.33572504e-01  1.81688011e-01 -9.60403904e-02\n",
      "  9.84786749e-02  2.03599036e-01 -1.67301334e-02  7.63799548e-02\n",
      "  1.94496542e-01 -1.16625592e-01  1.57476112e-01  1.12716720e-01\n",
      " -2.12958738e-01 -2.46631637e-01 -3.85382026e-02  1.97153702e-01\n",
      " -2.36620322e-01 -1.65333554e-01 -5.61939888e-02  1.37366414e-01\n",
      "  3.56516272e-01  2.85688858e-03 -2.50220113e-02 -2.51614135e-02\n",
      " -1.67188093e-01  2.78677166e-01 -3.07881474e-01  1.15508577e-02\n",
      " -6.99166581e-02 -2.71294769e-02  5.43063171e-02  4.98623699e-02\n",
      "  3.27641666e-01  3.15337330e-02 -4.58860099e-02  1.94479525e-01\n",
      "  1.92437127e-01 -2.10892335e-01  2.06518233e-01  1.18353302e-02\n",
      "  1.14702195e-01  9.14530084e-02  5.60314655e-02 -1.73434973e-01\n",
      " -1.57123432e-02 -3.46049480e-02  1.58454909e-03  3.31046060e-02\n",
      " -6.78146854e-02 -1.44293040e-01  1.47762612e-01 -1.39088839e-01\n",
      "  4.30476367e-01  2.73386687e-02 -2.59827614e-01  1.33680612e-01\n",
      "  3.36917527e-02 -2.67798364e-01 -1.24574751e-01  1.01798456e-02\n",
      " -1.43015265e-01 -5.32314517e-02 -2.13947818e-01  3.37526575e-02\n",
      " -1.32907331e-02 -2.95733078e-03 -1.57661796e-01  2.58461237e-01\n",
      "  3.72875124e-01 -7.62118995e-02  1.57680165e-03 -3.18105280e-01\n",
      " -5.71565591e-02  2.82344263e-04  1.29415199e-01 -1.15803862e-03\n",
      " -3.14572543e-01 -7.07313418e-02 -4.83557545e-02 -6.74274713e-02\n",
      " -4.21654657e-02  1.57543063e-01  4.10463884e-02 -2.23781884e-01\n",
      "  2.58432716e-01  2.33380526e-01 -2.91745901e-01  1.74768642e-01\n",
      " -5.34258150e-02 -4.41679843e-02  2.29670852e-01 -1.65521830e-01\n",
      " -1.83681154e-03 -5.53108752e-02  1.49292693e-01  1.79867700e-01\n",
      " -1.23054028e-01  4.69462946e-02 -1.21561751e-01  2.42166501e-02\n",
      "  5.81250712e-02 -7.24030882e-02  2.87541449e-01 -2.16733515e-02\n",
      " -1.05988637e-01  6.00359179e-02 -1.66223720e-01 -1.44313589e-01\n",
      " -5.34090549e-02 -4.80416775e-01 -3.19292024e-02 -2.57237218e-02]\n",
      "L7N0                    -> L8N48 = [ 0.28722423  0.07930699 -0.00270188  0.33869797  0.09276322  0.22476676\n",
      "  0.20051536  0.08014277 -0.00070408  0.16384389 -0.07729465  0.19795968\n",
      " -0.20159663 -0.01893624  0.08606512 -0.12411424  0.18092959 -0.07067549\n",
      "  0.09140635  0.01118512  0.16213691  0.1077347   0.1326046   0.34408954\n",
      "  0.06507728  0.10169713  0.13282111 -0.03330461  0.01209743 -0.04622318\n",
      "  0.06453533  0.07256798  0.0931005   0.02357117  0.08566356 -0.27113312\n",
      "  0.10307597 -0.13080263 -0.06787641 -0.01313123 -0.18334638  0.07421048\n",
      "  0.06087315  0.14604996  0.01606034 -0.19195275  0.02927156  0.21931353\n",
      "  0.11894579  0.3075132  -0.04401361  0.06858581 -0.02195744  0.02727067\n",
      "  0.45899907  0.12969746  0.03814314  0.07001682  0.09269711  0.14631498\n",
      " -0.06923793 -0.00691244  0.22537228 -0.01549693  0.00504016  0.06896012\n",
      "  0.10138105 -0.24355696  0.112282    0.2599629   0.04117568 -0.22020514\n",
      " -0.01360605  0.08902729  0.06109418  0.32397252  0.15486701  0.23574062\n",
      "  0.02351879  0.07242218  0.13349569  0.19205238  0.25571087  0.11609251\n",
      " -0.03159253  0.07336108  0.21360537  0.03014543  0.10336623 -0.11436474\n",
      "  0.09688689  0.07256824  0.17286035  0.29738826 -0.10613864  0.09410889\n",
      " -0.05162602  0.14926293  0.13198683 -0.03596917  0.33387858  0.20867714\n",
      "  0.00686562  0.2389301   0.2065813  -0.09190109 -0.0452965  -0.07128585\n",
      "  0.29381236 -0.1608625   0.07503627  0.01316575 -0.22069822  0.17809103\n",
      " -0.09259605  0.0347399   0.2594144  -0.27950326 -0.04023096  0.17953324\n",
      " -0.07695069  0.06552704  0.12613945  0.19078098 -0.15474974 -0.0016456\n",
      "  0.00984169  0.04399911  0.1111988   0.04296974  0.02844224  0.06549851\n",
      "  0.19822766  0.11683197 -0.08417048  0.04692416 -0.3043405  -0.24845171\n",
      "  0.09361198 -0.07779107  0.08934718 -0.06975588 -0.21077101 -0.01741523\n",
      "  0.23851176 -0.13038254 -0.15179454  0.2067629   0.1316489   0.30048317\n",
      "  0.04650752  0.03668498 -0.08595217  0.04766256  0.06561536 -0.15999171\n",
      "  0.02855966 -0.01822418  0.10619976 -0.23610131  0.07225319 -0.04626026\n",
      " -0.00640807 -0.06817291  0.38721374 -0.02712931  0.2997679  -0.08562192\n",
      " -0.35256603  0.17492212  0.2793704   0.19650503  0.13737093  0.03310601\n",
      "  0.10475157  0.18046913 -0.1414294  -0.003361    0.2309552  -0.1101426\n",
      " -0.06160973  0.06940106 -0.20073411  0.04926773 -0.10944094  0.03299023\n",
      " -0.07912184  0.23967002 -0.05423581  0.18498646 -0.01816664  0.2671924\n",
      " -0.0758742   0.14605783  0.127571    0.10170228  0.03361764 -0.01356579\n",
      " -0.09076187  0.12444007]\n",
      "L7N0                    -> L8N49 = [-3.54202360e-01  3.41455899e-02 -4.16767411e-02 -1.29495040e-01\n",
      "  1.01366052e-02  2.18738467e-01 -2.03918785e-01  5.81563935e-02\n",
      " -2.48351227e-02  1.23437494e-01 -1.54683366e-01 -1.06252946e-01\n",
      "  1.55180320e-01  3.60738933e-02 -1.45490274e-01  1.34978756e-01\n",
      " -5.14898486e-02 -1.76261082e-01 -2.81435788e-01 -2.54455884e-03\n",
      " -1.71206340e-01  2.95384116e-02 -1.39770240e-01  9.66537073e-02\n",
      "  1.59930378e-01 -7.00883940e-02  2.31991485e-01  6.91127330e-02\n",
      " -7.20968023e-02  5.17592058e-02  2.47679889e-01  1.18098959e-01\n",
      "  4.19204086e-02  2.16520622e-01 -1.87149301e-01 -7.14335069e-02\n",
      " -1.72831416e-01  5.63715771e-02 -2.87506014e-01  2.15386614e-01\n",
      "  7.16632009e-02 -1.12407178e-01 -8.97522047e-02 -1.34303063e-01\n",
      " -3.60275298e-01  3.26407313e-01  1.14298597e-01  3.38661335e-02\n",
      "  3.49502444e-01 -2.78520495e-01  3.99018675e-02 -1.56072855e-01\n",
      "  5.26218489e-03 -2.77547926e-01 -2.67071217e-01 -1.78731918e-01\n",
      "  5.52158989e-02 -3.09456568e-02 -1.28006592e-01  2.02531368e-01\n",
      " -4.09696979e-04 -1.53840527e-01 -4.76748466e-01 -1.59326777e-01\n",
      "  3.32972199e-01  1.16388854e-02  1.48952037e-01 -7.38421232e-02\n",
      " -5.15207946e-02  1.58593029e-01 -1.49449661e-01  9.23093483e-02\n",
      " -1.41098559e-01  2.82913744e-02  4.74708229e-02  1.90116808e-01\n",
      " -2.81711459e-01  1.29346579e-01 -4.77482751e-02 -1.17233068e-01\n",
      "  2.80227363e-02  1.57993324e-02 -1.45073399e-01  5.83123975e-02\n",
      "  1.65935010e-01 -1.73258930e-01 -1.84708402e-01 -1.26463799e-02\n",
      "  8.19656923e-02 -2.42307827e-01  8.03785324e-02 -6.64652511e-02\n",
      " -7.09699020e-02 -2.70472169e-01 -6.03188900e-03 -1.34669125e-01\n",
      " -1.26403391e-01  3.00496906e-01  5.83505705e-02 -2.47026384e-01\n",
      " -1.46683887e-01  1.10244192e-01 -3.94490696e-02 -2.36227572e-01\n",
      " -1.62695106e-02 -2.55278014e-02 -1.49693519e-01 -3.54974478e-01\n",
      " -1.51044026e-01 -1.15057200e-01 -1.29194051e-01  4.66455072e-02\n",
      "  1.66464016e-01  8.18614960e-02  5.09570241e-02 -2.66939372e-01\n",
      "  1.99539438e-01 -5.43619227e-03 -6.29402027e-02 -1.55776337e-01\n",
      "  1.01842590e-01 -1.72562510e-01  1.67090118e-01  9.66171827e-03\n",
      "  4.37299088e-02 -1.03399932e-01  6.32555783e-02  9.61080492e-02\n",
      "  1.68404728e-02 -3.23426098e-01 -3.29108723e-02 -1.96034715e-01\n",
      " -3.32752526e-01  7.02108908e-03 -1.10708876e-03 -2.29392663e-01\n",
      "  3.54732007e-01  1.13292776e-01  1.82221293e-01 -2.93886840e-01\n",
      "  3.30312252e-01 -5.53540736e-02  7.58878067e-02  2.10004747e-01\n",
      "  5.23186699e-02  1.46691158e-01  8.52318555e-02 -2.49170169e-01\n",
      "  6.88649565e-02  5.60807958e-02 -1.08165421e-01  1.27899498e-01\n",
      " -2.05530182e-01 -6.81452034e-03 -8.45780671e-02  1.62351459e-01\n",
      " -1.90989777e-01 -4.92700748e-02 -1.90404594e-01  9.44363046e-03\n",
      " -1.67710409e-01  1.33429274e-01 -2.12163389e-01 -6.89497963e-02\n",
      " -8.42037871e-02 -1.39905483e-01 -2.61881799e-01 -3.35296750e-01\n",
      "  1.44529179e-01 -2.20120549e-01  4.83896919e-02  3.73542428e-01\n",
      " -9.17053968e-02 -4.40272018e-02  2.59572566e-01 -1.16794668e-01\n",
      " -1.31467506e-01 -3.27834547e-01 -1.22613132e-01 -1.09678566e-01\n",
      "  2.83026725e-01  2.01179869e-02 -5.48906289e-02  7.39125907e-02\n",
      "  4.88081336e-01 -1.11045711e-01 -2.13595644e-01 -2.42212489e-01\n",
      " -1.21945560e-01 -1.24578401e-01 -2.23871216e-01 -1.96334541e-01\n",
      " -9.62037668e-02 -2.04674602e-01 -2.04035491e-01 -8.15263465e-02\n",
      "  9.77775455e-03  8.63410234e-02  1.32149905e-01 -4.47010338e-01]\n",
      "L7N0                    -> L8N50 = [ 0.35159564 -0.26013082 -0.17618412  0.11772481 -0.22152336 -0.05597929\n",
      "  0.2296663  -0.2239367  -0.11013638 -0.19754444 -0.06355522 -0.149096\n",
      " -0.32471535  0.07294514  0.22707641 -0.3132646  -0.02299359  0.07387997\n",
      "  0.24427183  0.09974457  0.02463408 -0.16688716  0.07217549  0.22745366\n",
      " -0.18289037  0.10191917 -0.01096914  0.14305098  0.13680151 -0.10638063\n",
      "  0.1450442   0.07574077  0.02301602  0.24146347  0.3135978  -0.14070483\n",
      "  0.08759569  0.14274241  0.52829653 -0.07403678  0.19690518  0.14072517\n",
      "  0.07027177 -0.16014561  0.02636594 -0.1366193  -0.10872419 -0.1416435\n",
      "  0.11893132  0.00374198 -0.15369405 -0.01705541  0.25909147  0.19832894\n",
      " -0.2177493   0.39347184  0.15368143 -0.00694708  0.13651805  0.21377592\n",
      "  0.20914257  0.08706105  0.24206088  0.23588684 -0.18832147 -0.09441246\n",
      "  0.3243117  -0.40214023 -0.01732294  0.30461898  0.12776817  0.0542801\n",
      "  0.20693839 -0.365882    0.08532319 -0.06988008  0.00845932 -0.09386867\n",
      " -0.04288452  0.20577168  0.0337526   0.17131068  0.41735947  0.26488528\n",
      "  0.46629575  0.20490006  0.06417929 -0.01002619 -0.05797599 -0.00184135\n",
      "  0.03579657  0.05231418 -0.16720152  0.20209418 -0.04938356 -0.05751065\n",
      "  0.4856601   0.03006314  0.10287815 -0.05252124  0.05050271  0.24224283\n",
      "  0.00504899  0.27754867 -0.01913208 -0.0751168  -0.23684518 -0.15134893\n",
      " -0.1330878  -0.05926092 -0.3360428   0.1192795   0.01292161  0.09017748\n",
      "  0.09827837 -0.2512528   0.03729469 -0.06590137  0.18576328  0.02803317\n",
      " -0.23588806  0.12637202  0.04561612  0.13252768 -0.01257964  0.14379469\n",
      " -0.10234187 -0.24568512 -0.05256524 -0.07186758 -0.10209826  0.02179328\n",
      "  0.1796911   0.26215696  0.05278975 -0.02845403 -0.03968447 -0.41677597\n",
      "  0.3253213   0.01552064  0.19140857 -0.01319523 -0.46379262 -0.2201391\n",
      " -0.08970241  0.12244226 -0.03297029 -0.2500544   0.03540488  0.48902977\n",
      " -0.06433994  0.04727396 -0.10550047 -0.03528964  0.45911247 -0.10970249\n",
      "  0.22565077  0.13835424  0.11952583 -0.13733155  0.23826979  0.10936835\n",
      " -0.03183023  0.00176117 -0.02859877  0.02641597 -0.3111859  -0.04140645\n",
      " -0.22984762 -0.1017013  -0.01090618 -0.04688069 -0.21993178  0.22531521\n",
      "  0.12340081  0.06461089 -0.09630701 -0.15886454 -0.00205196  0.07155661\n",
      " -0.04240929 -0.26974368 -0.35500714  0.00232394  0.0095139   0.00875106\n",
      "  0.00276624 -0.24474996 -0.18850781  0.1192788  -0.01853875 -0.32402045\n",
      " -0.31911695 -0.01409994  0.05259889  0.00856197  0.03371983 -0.29465356\n",
      "  0.14206165  0.09774845]\n",
      "L7N0                    -> L8N51 = [ 0.14210041 -0.11018462  0.26016238 -0.20238604 -0.0659748  -0.16808616\n",
      "  0.10498253 -0.10874519 -0.11623724  0.14858943 -0.00141903  0.00130694\n",
      "  0.00502917  0.05840008 -0.21285018  0.15820868 -0.27815393  0.02085064\n",
      "  0.07106739  0.1712213   0.1082396   0.11088394  0.22817236 -0.07475609\n",
      "  0.04476707 -0.15726931 -0.10367429 -0.06965356 -0.01043158 -0.258123\n",
      " -0.17372976 -0.09126593  0.1000098  -0.02758294 -0.06563029 -0.09634229\n",
      "  0.02454735  0.0926739   0.43541217 -0.08815503 -0.11666975  0.03016656\n",
      "  0.12022551 -0.0631565  -0.0754476  -0.15168466  0.12124354  0.08085339\n",
      "  0.10076524  0.10923978 -0.09345455 -0.15051885  0.23753163 -0.19192877\n",
      " -0.16265784 -0.12673287 -0.02002617 -0.03940812 -0.10382226 -0.07398639\n",
      "  0.08041052  0.11264057 -0.03621849 -0.13148946 -0.01188132  0.18303628\n",
      " -0.03979601  0.27291927 -0.12655434 -0.25994942 -0.03967925 -0.5119139\n",
      " -0.14041634 -0.03558334 -0.04485924  0.01055094  0.13071777  0.08119325\n",
      "  0.24281801  0.20952985 -0.19659442  0.01043057  0.12279525  0.12451144\n",
      "  0.02674883 -0.20749894 -0.06177353 -0.05640342 -0.063127   -0.18379757\n",
      "  0.20338927 -0.18191896  0.04304028  0.1252605   0.13759601  0.14407894\n",
      "  0.05392086  0.5159768   0.02060182 -0.03625182 -0.09337182  0.18076822\n",
      " -0.07154241 -0.19546777  0.14487332 -0.24786475  0.15883791  0.09302836\n",
      "  0.12143496 -0.1159833  -0.0721582  -0.11400048 -0.18910474  0.27523148\n",
      "  0.132236    0.00179411  0.03856746  0.22420627 -0.08099815 -0.24859497\n",
      " -0.26934165 -0.01450704 -0.08038678 -0.05816772 -0.5129059   0.00874748\n",
      "  0.21284619  0.31529063  0.09438136 -0.13134941 -0.00741882 -0.12147332\n",
      "  0.06318222  0.18077594  0.1470234   0.09479723  0.1442257  -0.1785812\n",
      " -0.07354325  0.01940216  0.28028348  0.2997246   0.2194006   0.06954187\n",
      " -0.15826018  0.0124035  -0.28350377  0.04691487  0.05495976  0.01318158\n",
      "  0.09281442  0.04188862  0.05190257 -0.02878537 -0.01330307  0.11178031\n",
      "  0.18554033 -0.05640142  0.1119073  -0.35633984  0.220158    0.17437987\n",
      " -0.00885583  0.19509013  0.13485393  0.04467379  0.02349455  0.05207648\n",
      " -0.3127853  -0.03231573 -0.39989457 -0.01011442  0.15759933 -0.14198405\n",
      "  0.24051613  0.25698042 -0.00268582  0.173379    0.04481962 -0.2103503\n",
      "  0.2627706  -0.03689125 -0.17286627  0.12294367  0.2173635   0.17428552\n",
      "  0.04275785 -0.3187886   0.0156646   0.17128311  0.30713516  0.04140419\n",
      " -0.16783631 -0.03539714 -0.21881202 -0.05638368 -0.02464401  0.127192\n",
      "  0.06526735 -0.06775738]\n",
      "L7N0                    -> L8N52 = [-0.03987562  0.05883346 -0.12425542 -0.32528356  0.00304162  0.05030094\n",
      "  0.07035977  0.14602734 -0.08025304 -0.24560344 -0.19623174 -0.02367758\n",
      " -0.3379272   0.05871923 -0.25361562 -0.02919219  0.02598592 -0.52417576\n",
      "  0.0564759   0.12082534  0.32596982  0.04908645  0.19787778 -0.00114332\n",
      " -0.0356598  -0.18725467 -0.13605054 -0.32980233 -0.09178711  0.09204485\n",
      " -0.06224154 -0.01005951 -0.02450468  0.14774725  0.12579677 -0.20329566\n",
      "  0.03326653  0.15467711 -0.1276554  -0.10647438  0.10910204 -0.01097253\n",
      "  0.3363095   0.164302   -0.03390555 -0.06555547 -0.20923305  0.02730817\n",
      " -0.24688476  0.07001328 -0.37226406 -0.01860135 -0.02557735  0.15997706\n",
      "  0.05685585 -0.07261319 -0.12236673  0.0769689  -0.13929175 -0.27065077\n",
      " -0.0078043   0.23223786 -0.14741941 -0.25307176 -0.05175341 -0.01023872\n",
      "  0.34249675 -0.23402578 -0.09378521 -0.02987901  0.0173023  -0.18711458\n",
      " -0.06970858  0.06896774  0.00795402 -0.00750993  0.03379567 -0.42238632\n",
      "  0.07265059  0.05952514  0.1993156  -0.17079344 -0.00752473 -0.09127418\n",
      " -0.08539761 -0.03883856 -0.209445    0.20040224 -0.14105421 -0.18650204\n",
      "  0.09040885 -0.23475413  0.01912373 -0.00764673  0.10526866 -0.07739507\n",
      "  0.08686101 -0.22276406  0.04743212  0.1291666  -0.04075399  0.01754937\n",
      "  0.08210637 -0.09212068 -0.01292287 -0.24754651 -0.36066335 -0.23822978\n",
      "  0.15189098 -0.15239088 -0.41002965  0.04168131 -0.132171    0.23896086\n",
      " -0.45011532 -0.11040629  0.18093255 -0.32445118  0.1677309   0.1321939\n",
      "  0.07492332  0.1815665   0.09051614  0.01394531 -0.02734649  0.11548141\n",
      "  0.05497438 -0.10209747 -0.25678825 -0.03871561  0.16595428 -0.11138567\n",
      "  0.01140715  0.24246629  0.21161896 -0.23166957  0.09465996 -0.23599792\n",
      " -0.08359266 -0.13723879  0.3781913  -0.0835411  -0.20631275 -0.20530899\n",
      "  0.15492769 -0.32580552 -0.20649424  0.0998157  -0.04688118 -0.13243157\n",
      " -0.25341237 -0.13509946 -0.34677678 -0.16203386  0.26656967 -0.20814227\n",
      "  0.13071738 -0.09623897 -0.01675423 -0.24084315 -0.1378622  -0.10772432\n",
      "  0.26304206 -0.4049794  -0.19580536  0.01142564 -0.3272446   0.1860759\n",
      "  0.15170313  0.2542653   0.2317234  -0.1455314  -0.00693211 -0.07459266\n",
      " -0.2994118  -0.01713334  0.28632113  0.22411022 -0.03778213 -0.2504778\n",
      " -0.16722098  0.13801222 -0.17743571  0.0866641  -0.0392382  -0.15978985\n",
      " -0.24621864  0.44752708 -0.36166695  0.02225236  0.00973095 -0.16091189\n",
      "  0.02383873  0.01966556  0.1346831   0.0791131   0.02888765 -0.21255666\n",
      " -0.01334963  0.2749588 ]\n",
      "L7N0                    -> L8N53 = [-1.65274665e-01  3.14192921e-01  2.83973869e-02 -4.51421708e-01\n",
      "  1.53960899e-01 -2.06249282e-01 -1.35882860e-02 -1.53425872e-01\n",
      "  5.93533367e-02 -1.49106771e-01 -6.24744408e-02 -2.41443813e-01\n",
      "  1.40928239e-01 -2.15900511e-01 -2.04398273e-03  1.87664613e-01\n",
      " -2.35652879e-01 -1.57655001e-01 -1.37019968e-02 -8.31778571e-02\n",
      " -1.33244410e-01 -9.86909494e-02  2.02082053e-01  7.11899400e-02\n",
      " -2.67348289e-01 -3.35178643e-01  1.33211538e-01 -2.69401312e-01\n",
      " -4.88723814e-02 -9.78020951e-02 -1.17434964e-01 -3.51214081e-01\n",
      " -7.06275478e-02  1.35269776e-01 -1.91745818e-01  1.68514267e-01\n",
      "  4.05396335e-04 -3.15851480e-01 -1.98620856e-01  2.99002618e-01\n",
      "  1.59835726e-01 -1.91541091e-01 -1.35224357e-01 -2.81581795e-03\n",
      " -1.07290752e-01  1.81201622e-01 -4.77638515e-03  1.83516927e-02\n",
      " -2.82893460e-02  2.61408389e-02  3.25574666e-01 -2.81445473e-01\n",
      " -1.40134618e-01 -2.54667044e-01 -1.88969001e-02  1.21452928e-01\n",
      " -1.19664267e-01 -1.68131456e-01 -6.17282242e-02 -2.03809991e-01\n",
      " -4.34151858e-01 -9.95380059e-02  7.40317330e-02 -2.96241701e-01\n",
      " -2.61858046e-01 -2.48893678e-01 -1.87959269e-01 -7.96111673e-02\n",
      " -1.06836878e-01 -1.73507005e-01 -1.55197442e-01  1.05952486e-01\n",
      " -2.40301304e-02 -2.91493207e-01 -3.38378370e-01  2.56806880e-01\n",
      "  8.31559524e-02 -2.67569542e-01 -2.38778964e-01 -2.87110023e-02\n",
      "  2.78387181e-02  1.47879096e-02 -5.91020212e-02 -3.65823686e-01\n",
      " -8.35831836e-02  1.81761965e-01 -1.60930783e-01 -9.03505459e-02\n",
      "  2.84569748e-02  1.89704254e-01 -9.01157036e-02 -1.73732564e-01\n",
      " -2.96527922e-01 -1.27850667e-01  3.27408463e-02 -1.45874575e-01\n",
      "  4.59259003e-02  1.49751350e-01 -1.92740381e-01 -3.56575280e-01\n",
      " -1.58603743e-01 -2.27985784e-01 -2.11222649e-01 -2.49440805e-03\n",
      " -9.37656388e-02 -2.35573500e-01  1.15678176e-01 -1.37787804e-01\n",
      " -1.02487452e-01  2.39345700e-01 -5.49929496e-03 -7.47822523e-02\n",
      " -7.62495026e-02 -6.02044240e-02  6.37464831e-03 -1.09022081e-01\n",
      " -2.27292761e-01  9.31662545e-02 -1.36473835e-01 -3.81133437e-01\n",
      "  4.22008708e-02 -1.70288801e-01 -7.76481926e-02 -3.72704744e-01\n",
      "  5.47334133e-03 -2.74686068e-01 -2.53800273e-01 -4.96935472e-02\n",
      "  1.19268103e-02 -6.03533015e-02 -2.76002228e-01 -6.83487728e-02\n",
      " -1.87477484e-01 -1.91238433e-01 -3.04696143e-01 -3.42586972e-02\n",
      " -1.08770050e-01  7.04979002e-02 -2.68850267e-01  6.58866912e-02\n",
      " -1.55724779e-01  9.76780728e-02  1.66898314e-02  6.76851794e-02\n",
      " -6.14821259e-03  7.62876403e-03  3.12156212e-02 -1.21421851e-01\n",
      "  1.73275899e-02 -2.91949928e-01  3.80152613e-02 -9.87389982e-02\n",
      "  8.46659914e-02 -2.57810771e-01 -1.21147096e-01 -1.80222079e-01\n",
      " -1.58513322e-01  1.28445318e-02 -4.43529747e-02  1.85581539e-02\n",
      "  4.91600111e-02 -1.37788504e-01  6.60250112e-02 -3.03151682e-02\n",
      " -6.99690282e-02  1.60055775e-02 -6.89522848e-02  1.45651817e-01\n",
      "  1.24195449e-01 -3.12113881e-01 -1.83304437e-02  7.38498122e-02\n",
      " -4.21561390e-01 -4.32438180e-02 -2.13489369e-01 -3.61092687e-02\n",
      " -1.00983210e-01  1.63560674e-01 -9.34746861e-02  1.33636400e-01\n",
      " -1.18632384e-01  1.61980093e-01 -1.58539906e-01 -5.21785133e-02\n",
      "  1.57104924e-01 -2.50317343e-02 -4.50829536e-01  4.54002656e-02\n",
      " -8.47868547e-02 -3.62105519e-01 -2.57368505e-01 -1.63376167e-01\n",
      "  1.51138574e-01 -4.25619781e-01 -8.84910375e-02 -2.84032702e-01\n",
      "  1.42602265e-01 -7.68040419e-02 -2.85927113e-03  9.23988000e-02]\n",
      "L7N0                    -> L8N54 = [-2.63528153e-02  7.03518018e-02 -1.74185291e-01 -4.70349491e-02\n",
      " -5.94657883e-02 -1.53058887e-01  2.37705885e-03 -5.63310273e-02\n",
      "  1.70022547e-01 -1.64229780e-01  1.01311602e-01  6.05549961e-02\n",
      " -2.40685806e-01 -1.19106591e-01  3.73786911e-02 -1.95746616e-01\n",
      " -3.83563824e-02 -8.42234716e-02 -1.13137715e-01  1.42488241e-01\n",
      " -1.27528936e-01 -1.02444492e-01  1.13936082e-01  1.60730560e-03\n",
      " -7.46898120e-04  6.57680109e-02 -2.15835292e-02  2.08440438e-01\n",
      " -1.35922790e-01 -4.16024029e-03  3.78039271e-01  3.18459049e-02\n",
      " -4.68616933e-02 -4.03535068e-02  3.88398580e-02 -4.19036448e-01\n",
      " -7.82740582e-03  1.46070281e-02  1.64975822e-01 -9.36126336e-03\n",
      "  7.78499842e-02  3.64373531e-03  9.34403017e-02  1.32689103e-01\n",
      "  2.18091071e-01  1.89635023e-01 -3.81209403e-01 -1.41638741e-01\n",
      "  7.29860961e-02 -8.58042687e-02 -5.61224639e-01  4.37832214e-02\n",
      " -3.67405079e-02 -2.20146254e-01 -8.03125724e-02 -2.11813375e-02\n",
      "  1.42252883e-02 -2.67834365e-01 -1.67342871e-01  1.28847450e-01\n",
      " -8.84889662e-02  4.69441526e-02 -2.88617462e-02  1.42817423e-01\n",
      " -1.79128900e-01 -1.09542660e-01  1.07660286e-01 -2.51140982e-01\n",
      "  1.53565481e-01 -3.12452048e-01 -1.49305984e-01 -4.85714287e-01\n",
      "  2.45980933e-01  8.94253254e-02  2.41712630e-01  4.52051125e-02\n",
      "  1.70977920e-01  5.20719923e-02  5.79595454e-02 -1.16227672e-03\n",
      " -1.75533041e-01  2.88811535e-01 -2.14538444e-02  1.51297837e-01\n",
      "  4.87063937e-02  2.13221550e-01 -4.69988659e-02  1.79227084e-01\n",
      " -5.25732934e-02 -3.61271381e-01  2.05988944e-01 -1.64507538e-01\n",
      "  2.45253786e-01  1.43482074e-01 -4.20963317e-02 -1.04258098e-01\n",
      " -2.12081358e-01 -1.86357975e-01  2.41672277e-01 -1.80655159e-02\n",
      "  9.38793570e-02 -1.46645606e-01  2.16453075e-02  1.39504015e-01\n",
      " -1.06537431e-01  4.05910425e-03 -1.28734678e-01 -4.91899341e-01\n",
      "  2.43832171e-01 -2.76783288e-01  2.20947340e-02  2.05505013e-01\n",
      " -1.58697978e-01  2.85423100e-01 -2.98998803e-01 -1.87689811e-01\n",
      " -7.76293054e-02 -1.44768178e-01  1.40409160e-04 -8.18727687e-02\n",
      " -2.53894269e-01 -8.02073032e-02  1.40613467e-01  3.11224461e-01\n",
      " -3.00963461e-01 -1.46930724e-01 -9.52078775e-02 -9.87451524e-02\n",
      "  1.55536205e-01 -1.41470224e-01 -1.31184548e-01  3.48123312e-02\n",
      "  1.65335491e-01 -1.08769894e-01  5.70168486e-03 -3.03393919e-02\n",
      "  1.07717507e-01 -1.81629390e-01  1.21149831e-01 -1.62893124e-02\n",
      "  2.75370479e-01 -3.25723290e-01 -4.98724699e-01 -6.73096254e-02\n",
      "  6.45327419e-02  9.94831920e-02 -1.99943945e-01  5.27452290e-01\n",
      "  2.23768991e-03 -5.04377708e-02  7.06196502e-02  8.05501044e-02\n",
      " -3.10532808e-01  1.70030639e-01 -9.01316255e-02 -4.27102238e-01\n",
      "  1.76917344e-01 -1.62272856e-01  3.04753110e-02 -1.87950432e-02\n",
      " -1.02831349e-04 -5.07372394e-02 -2.98275724e-02 -1.40029527e-02\n",
      "  4.13092263e-02  1.41660258e-01 -2.41586536e-01 -9.84899700e-03\n",
      "  3.57377119e-02 -1.59456562e-02  1.69576854e-01 -6.71155080e-02\n",
      " -4.00365517e-02  4.33003038e-01  1.42643213e-01  7.47717246e-02\n",
      " -1.73563570e-01  2.25111023e-01 -1.00740239e-01 -1.47232682e-01\n",
      "  1.23889022e-01  1.99304789e-01 -1.99203998e-01  1.18446713e-02\n",
      " -2.80200481e-01  1.72594830e-01 -1.37118667e-01  5.69675788e-02\n",
      "  3.35924000e-01 -1.04735345e-01  1.08211793e-01 -9.38138515e-02\n",
      "  4.49616313e-02 -5.44647966e-03  1.64457038e-01  2.00824589e-01\n",
      "  1.83126628e-01 -1.08955555e-01  7.10232109e-02  1.39021516e-01]\n",
      "L7N0                    -> L8N55 = [ 2.00129241e-01  4.54401877e-03 -2.11094260e-01 -3.45879018e-01\n",
      "  2.20667511e-01  3.32661301e-01  1.25953123e-01  4.86312285e-02\n",
      " -2.28341203e-02  1.16420321e-01  2.76534647e-01 -6.45496696e-02\n",
      "  3.10789626e-02  1.03910737e-01 -2.70701766e-01 -1.82179362e-01\n",
      "  1.96672440e-01 -1.01018295e-01  9.73037928e-02  1.04278401e-02\n",
      "  1.72286808e-01  1.18043520e-01 -1.93089485e-01  2.82376260e-01\n",
      "  3.63131523e-01  1.25776172e-01  1.25153840e-01 -7.95703232e-02\n",
      "  1.66332960e-01  8.70083421e-02  1.17907912e-01  4.95651476e-02\n",
      " -2.94314474e-02 -1.47257864e-01  1.75703451e-01  1.34790465e-01\n",
      "  1.90928429e-01  3.33939552e-01 -2.03749556e-02 -3.09397001e-02\n",
      "  1.66402683e-01 -1.27646536e-01  9.46865231e-03  3.06115765e-02\n",
      " -1.89556211e-01  2.44444698e-01  7.31572136e-02  2.58780748e-01\n",
      " -4.76421192e-02  1.20588660e-01  5.31205945e-02 -2.88630417e-03\n",
      "  2.19636187e-01  2.22142771e-01  1.93393454e-01 -8.21104869e-02\n",
      "  2.49729276e-01  2.00169310e-01 -1.65890217e-01  2.49193728e-01\n",
      "  2.34017938e-01  2.45087951e-01 -3.72154057e-01  2.07671344e-01\n",
      "  3.18425715e-01  3.83455306e-03  8.44280720e-02  2.53087608e-03\n",
      "  6.39621615e-02  1.84808239e-01  3.23469311e-01  8.38567242e-02\n",
      " -2.32648492e-01 -1.74361676e-01 -6.93423077e-02  1.78142965e-01\n",
      "  3.02530348e-01  2.22121626e-02  3.68497986e-03  2.87774891e-01\n",
      " -1.24768883e-01 -1.66446984e-01  3.48207533e-01  3.51981431e-01\n",
      "  1.78334624e-01 -1.59651473e-01 -1.71953529e-01 -4.43518721e-02\n",
      " -4.05006669e-02 -9.22738835e-02 -8.16429779e-02  3.96872647e-02\n",
      "  2.29409307e-01 -1.33225042e-02  3.39497477e-01 -1.34601826e-02\n",
      "  1.69587150e-01 -2.55356252e-01 -4.12971294e-03  4.02700230e-02\n",
      " -9.33725983e-02  3.71233225e-02  1.61983609e-01 -6.49454445e-02\n",
      "  3.89903896e-02  1.49248108e-01  1.09746315e-01  6.33417889e-02\n",
      " -1.69545233e-01 -5.68367483e-04 -2.63618201e-01  9.59083810e-02\n",
      "  2.61072129e-01  3.83886620e-02 -6.45492272e-03 -1.30950222e-02\n",
      "  1.51337653e-01 -1.99420229e-01  2.57051289e-01  3.66986603e-01\n",
      " -4.75835912e-02 -6.17206544e-02 -3.88991050e-02 -8.89475495e-02\n",
      " -3.40481512e-02 -2.55752262e-03  2.55749017e-01  2.01984629e-01\n",
      "  2.13819340e-01 -2.46927053e-01  3.10402066e-01  2.02389464e-01\n",
      " -1.34684548e-01  2.32814446e-01  3.30766916e-01  1.39170796e-01\n",
      "  1.05308346e-01  1.60074249e-01  3.78972977e-01  1.16624117e-01\n",
      "  2.20462054e-01 -1.50843859e-01 -1.74774706e-01 -2.60800291e-02\n",
      " -2.71514118e-01  3.16946775e-01  1.34069160e-01  7.56827965e-02\n",
      " -5.29259071e-03  1.78486705e-01 -2.04690516e-01 -8.08097795e-03\n",
      "  1.29418179e-01  3.69071215e-02  3.01110148e-01 -2.28213504e-01\n",
      "  1.64685920e-01 -2.13864401e-01  1.19922176e-01  2.60568768e-01\n",
      "  2.03346506e-01  2.25256532e-01  1.91160738e-01 -6.38749078e-02\n",
      "  1.65396240e-02  1.32735416e-01 -1.81886956e-01 -3.22169691e-01\n",
      " -2.69760847e-01  1.68771729e-01  1.29996553e-01  9.60283354e-02\n",
      "  2.75158823e-01  4.32169363e-02 -1.38673499e-01  1.47325143e-01\n",
      "  7.41631985e-02 -1.14108659e-01  1.40060052e-01 -2.86928918e-02\n",
      " -7.27635920e-02 -9.36699659e-02 -2.48113200e-01 -2.09857643e-01\n",
      " -1.05116293e-02  7.87103996e-02 -1.62516966e-01  1.22712748e-02\n",
      "  1.04989797e-01 -1.14535145e-01 -2.35810932e-02 -2.30931729e-01\n",
      " -3.59940976e-01  3.12952470e-04 -3.30847986e-02  8.22819918e-02\n",
      " -2.97417156e-02 -1.50335506e-02  2.20856369e-01 -2.50012338e-01]\n",
      "L7N0                    -> L8N56 = [-0.01510383 -0.2633783  -0.05455329 -0.04905772 -0.18639259 -0.2824677\n",
      " -0.1881827  -0.10913853  0.02293009 -0.22438122  0.20918617 -0.04770324\n",
      " -0.03144664 -0.23930252 -0.10726754 -0.20814234 -0.05226626  0.01866048\n",
      " -0.11642266 -0.05224238  0.04008619 -0.12196228 -0.39507222 -0.108605\n",
      "  0.00608805 -0.05446506 -0.16474949 -0.0591612  -0.18304256 -0.10426003\n",
      " -0.38737756 -0.33078876 -0.23164222 -0.04091801 -0.08530488  0.10249262\n",
      " -0.15964225 -0.09231571 -0.35466722  0.03969276  0.09362289 -0.05629551\n",
      " -0.0209921  -0.37101063 -0.02661871 -0.05600847 -0.27328342 -0.10977391\n",
      "  0.00314196 -0.00720918 -0.16158897 -0.23712268 -0.18001801 -0.2516971\n",
      " -0.30272967 -0.02595803  0.01322715 -0.28119928 -0.13879463 -0.01117502\n",
      " -0.29531124 -0.07957833 -0.20030996 -0.20760638 -0.22693826 -0.05662894\n",
      " -0.04572196 -0.23735176 -0.22958864  0.08198611 -0.19597639 -0.18014057\n",
      "  0.06585898 -0.0633961   0.06491115 -0.27353963 -0.19915473 -0.15161467\n",
      " -0.06445877 -0.2682688  -0.08061383 -0.22159137 -0.31608877 -0.11879929\n",
      "  0.19022056 -0.14965476 -0.03871769 -0.0296087  -0.09340729 -0.21025908\n",
      " -0.00081419 -0.12964785  0.02541319 -0.20868987 -0.05060412 -0.05805081\n",
      " -0.18041234 -0.11511941 -0.21752203 -0.1715004  -0.19593585 -0.07536929\n",
      " -0.02657896  0.02880658 -0.24139385 -0.21572891 -0.22821428 -0.17142062\n",
      "  0.06966139  0.10172226 -0.10062305 -0.17809589 -0.05386337 -0.18841775\n",
      " -0.19403535  0.03290982 -0.06280595 -0.07906078 -0.12854432 -0.03450472\n",
      " -0.16153798  0.00528834 -0.20270054 -0.02040219 -0.05400366 -0.11836535\n",
      " -0.2612658   0.10924967 -0.13881649  0.05015898 -0.13448839 -0.04203082\n",
      "  0.06279438 -0.3000508  -0.26281735 -0.15267637  0.15179583 -0.45077783\n",
      " -0.172021   -0.13317733 -0.43000537 -0.16052788 -0.28378072 -0.07331383\n",
      "  0.10775231 -0.02353109 -0.07290128 -0.19832858 -0.2175162  -0.21339189\n",
      " -0.07152946  0.01425239 -0.07879911 -0.2637419  -0.0511953  -0.15418491\n",
      " -0.05443514 -0.30369085  0.11281199 -0.18366703 -0.09799777 -0.3381989\n",
      " -0.08406148 -0.26233903 -0.10858899 -0.3439558  -0.24848677 -0.00468329\n",
      " -0.14536023 -0.01094311  0.2376799  -0.1655421  -0.3108945  -0.00807161\n",
      " -0.23401105 -0.18714896  0.08177009 -0.02122255  0.06250176 -0.20088778\n",
      " -0.10599625 -0.2577384  -0.17959912  0.17996044 -0.05559337  0.04501146\n",
      " -0.23268823 -0.10615417 -0.10591989  0.07816549 -0.23195991 -0.1587748\n",
      "  0.02793058  0.17154714  0.10174805  0.00677953 -0.14738397 -0.3370616\n",
      " -0.04632089  0.120318  ]\n",
      "L7N0                    -> L8N57 = [ 0.18517019 -0.03272007  0.12371279  0.07450941 -0.03008558  0.24481267\n",
      "  0.26698038  0.0592883  -0.08432744  0.26155     0.29391855  0.06219261\n",
      " -0.14445584  0.3544086   0.04610426 -0.36167446  0.06262577 -0.01562098\n",
      "  0.02838223  0.00327309  0.20876332 -0.06292121  0.44580522  0.38525257\n",
      "  0.01676116  0.13911137 -0.07548765 -0.03912435  0.13839327  0.02227153\n",
      " -0.09914403  0.15941958  0.09198819  0.06519625 -0.02299325 -0.03088039\n",
      "  0.14516263  0.103542    0.12331604  0.266224    0.04784179  0.07718521\n",
      "  0.09646895  0.13090673  0.10227507 -0.1093943  -0.00453551 -0.0765349\n",
      "  0.0827718  -0.12302721 -0.10215469  0.28287724  0.02635291  0.02529209\n",
      "  0.42525205  0.32244503  0.15155545 -0.1365496   0.12105617  0.15164521\n",
      "  0.04355587  0.10498348  0.35924104 -0.05750059 -0.28421813  0.29779437\n",
      "  0.2031788  -0.25073457 -0.01032913  0.24079627  0.19702576  0.01927171\n",
      " -0.26310563  0.12071395 -0.23051459  0.2152948   0.04861516 -0.1791351\n",
      " -0.06075001  0.19996747 -0.09145961  0.23387642  0.08079034  0.06724038\n",
      " -0.0026281  -0.06195905  0.02807848 -0.06306583 -0.07646679 -0.2209696\n",
      "  0.4112158  -0.0410172   0.27211586  0.28887066 -0.31347343 -0.01194579\n",
      "  0.11656507 -0.16902432  0.23291554  0.00928267  0.09375411  0.02210118\n",
      "  0.10228576 -0.1937725   0.03065486 -0.07090859  0.0255714  -0.4016859\n",
      "  0.20256059 -0.20062955 -0.08509646  0.2581343   0.09878748  0.23239005\n",
      " -0.3274562   0.16317305  0.08792031 -0.20103678  0.15944912  0.16725214\n",
      "  0.13543613  0.08196422  0.09324239  0.39832157 -0.21853258  0.06281645\n",
      "  0.43342376 -0.2595956  -0.04372379  0.1541636  -0.02053386  0.02349439\n",
      "  0.22219932  0.10946869  0.05105402  0.01783012 -0.10178838 -0.22609776\n",
      "  0.07215579  0.15128027  0.15746854 -0.15224342  0.02234675 -0.11730497\n",
      " -0.1869355  -0.02858535  0.10837459  0.24502587  0.2118933   0.12310719\n",
      "  0.12500565 -0.09553283 -0.16338284  0.04750084  0.02350688  0.03483891\n",
      "  0.2519084   0.13695036  0.18715152  0.0163404   0.23105194  0.11438154\n",
      "  0.14353119 -0.2308419  -0.00304193  0.26923025  0.22531228 -0.02485749\n",
      " -0.15965955  0.30482113  0.13908692 -0.20345712  0.07642371  0.48799634\n",
      "  0.06202022  0.2604235   0.0770234   0.05717108  0.07774387 -0.11801033\n",
      " -0.17569362 -0.16156237 -0.10038866  0.10775151 -0.0161736   0.18275449\n",
      " -0.2518964   0.12376901 -0.00953196  0.03973933  0.29939196  0.25518623\n",
      "  0.11636049  0.03304126  0.1704196   0.2111933  -0.02152464  0.03534662\n",
      "  0.156198   -0.00823835]\n",
      "L7N0                    -> L8N58 = [ 0.13943334  0.13425809 -0.15528107 -0.00178683  0.11889667 -0.1068559\n",
      " -0.05632894 -0.08250932  0.16861175  0.12503175  0.02085179  0.15889952\n",
      "  0.02831369 -0.18679896  0.05869642 -0.24579214 -0.00129255 -0.22934176\n",
      " -0.13389236  0.03254657  0.30000266  0.05994819 -0.13510945  0.02164117\n",
      " -0.2655842  -0.10125909 -0.33186707 -0.24866079 -0.05417185  0.11925872\n",
      " -0.20515923  0.00315764 -0.08670208 -0.00590326  0.07131542 -0.16319099\n",
      "  0.10362963 -0.25282308  0.08789374  0.00700466  0.06514405  0.24578367\n",
      " -0.22021563 -0.13604943  0.01201724 -0.03030835 -0.1261257  -0.10048051\n",
      " -0.12469082  0.00143071 -0.04610093 -0.22091182  0.05281233 -0.0018635\n",
      " -0.1195802  -0.04798344 -0.09772304 -0.06230487 -0.2870704  -0.19074668\n",
      "  0.08064588 -0.0784794  -0.30175406 -0.3609678  -0.00475009 -0.05025882\n",
      " -0.19056885 -0.26177403 -0.15448263  0.15205011 -0.23082839 -0.3032184\n",
      " -0.08017094 -0.19998409  0.09255679  0.00041965 -0.14711954  0.04378222\n",
      " -0.26160207 -0.08656139  0.07187607 -0.05311431 -0.03862153 -0.3467987\n",
      " -0.05503291  0.06411516  0.2604171  -0.06326605  0.17843537 -0.35140893\n",
      "  0.03798389 -0.02222162  0.09814095 -0.00193264 -0.2407695  -0.03883103\n",
      "  0.00206555 -0.04181153 -0.00344945 -0.04333504 -0.18720017 -0.15272334\n",
      "  0.07060274  0.02992132  0.0399877  -0.19273587  0.14195225 -0.25754687\n",
      " -0.14804919 -0.10889535 -0.16282676  0.09789514  0.02491517 -0.34343976\n",
      " -0.04284771  0.06146782 -0.16723648  0.13713929 -0.05525184  0.01669052\n",
      "  0.07119185 -0.21443361 -0.05123902 -0.10480174 -0.05627896  0.00832103\n",
      " -0.06344728  0.18576217 -0.02024778  0.11905304 -0.03009909  0.17067583\n",
      "  0.17017157 -0.04563041 -0.10477094 -0.13199478 -0.15854564 -0.04925404\n",
      " -0.02234906 -0.11149477 -0.13620283 -0.10599475 -0.1963621   0.01008768\n",
      "  0.06870487 -0.24391146 -0.08571079 -0.16376048 -0.0818278   0.324642\n",
      " -0.1652179  -0.1140615  -0.19305035  0.02434717  0.12497383 -0.21905017\n",
      "  0.21334265  0.00437088 -0.02694957 -0.25328654 -0.07501459 -0.08645714\n",
      " -0.02809805 -0.06735821 -0.18152954 -0.26486745  0.02967605  0.07642958\n",
      "  0.01873035  0.14183615  0.15104891 -0.16843392  0.0394211   0.10417939\n",
      " -0.00788582  0.18505915  0.02413717  0.09905514 -0.0016113  -0.04392117\n",
      "  0.22896287  0.11996038 -0.0422952  -0.01677714  0.06832205 -0.1578979\n",
      " -0.19182818 -0.2346862  -0.14464639 -0.17468919 -0.05911549 -0.15028866\n",
      "  0.00526933  0.28206196  0.02728053  0.07649922 -0.01713967 -0.00171682\n",
      "  0.04057337  0.04123486]\n",
      "L7N0                    -> L8N59 = [ 0.4586573  -0.33652166 -0.22386889 -0.1373275  -0.24901196  0.22293496\n",
      "  0.28916702  0.28343865  0.10147852  0.03377706  0.18923274  0.10940374\n",
      "  0.03535901 -0.09366865  0.0560945   0.0108413   0.14105822 -0.05355799\n",
      "  0.07557128  0.41571626 -0.15025568  0.09354483  0.16292192  0.23694706\n",
      "  0.22978759 -0.10119914 -0.01480954  0.16939504  0.05933508  0.28524292\n",
      "  0.16835573  0.21325782  0.06868098  0.13028467  0.32745183  0.10573189\n",
      "  0.1542669   0.10661676  0.1072319   0.32368296  0.21707392  0.27492857\n",
      "  0.14976747 -0.04396399 -0.19222702  0.05255078  0.18917587  0.12372504\n",
      " -0.02730346 -0.02486956  0.21568565  0.08208422  0.37866196  0.16595532\n",
      "  0.04959128 -0.1596668   0.26578468  0.23216668  0.37348008 -0.17978503\n",
      "  0.13940932  0.1694562   0.06133606  0.2969561   0.09035035  0.04253475\n",
      "  0.48526287  0.02345734  0.13612658  0.44184023  0.14248037  0.2742643\n",
      "  0.00160432 -0.03644792 -0.09147105  0.23077379  0.07550436 -0.1577648\n",
      "  0.08911958  0.11666711  0.12973854 -0.1296808   0.19641994  0.03909266\n",
      "  0.36298272  0.09702999  0.05762831  0.03737841 -0.00311798  0.26945904\n",
      " -0.16344261  0.05791669 -0.06807714 -0.14592259 -0.12365714  0.13752435\n",
      "  0.13518882  0.16671957  0.40342784  0.24541582  0.28268746  0.1443753\n",
      "  0.15123431  0.24946429  0.09035379 -0.04766371 -0.03125096  0.1749953\n",
      "  0.01429708  0.1553534   0.02822516  0.4872443  -0.17408058 -0.05465816\n",
      " -0.09654331 -0.0417582   0.32996765  0.29593116  0.14084134  0.3064607\n",
      "  0.00541219  0.2064499   0.12649891  0.10070892  0.08116159  0.02705178\n",
      "  0.18463387 -0.13885176 -0.30115354  0.10480135  0.13687919  0.2301431\n",
      "  0.15671338  0.4279975   0.20931622  0.28636417  0.01498176  0.07146887\n",
      "  0.22902758  0.14213786 -0.00250197  0.1700835   0.1537102   0.06003382\n",
      "  0.09695063 -0.10285307 -0.01879139  0.07126404  0.13410635  0.08402166\n",
      " -0.14515038  0.12277027  0.02789266 -0.01411211  0.1533299   0.13602729\n",
      "  0.04699904 -0.16068366 -0.1708598  -0.08993202  0.11151227  0.30020225\n",
      " -0.04892367  0.03184298  0.24355945  0.27636895 -0.12403379  0.02511075\n",
      "  0.0147002   0.12925598  0.207107    0.16491507  0.0340817   0.0276386\n",
      " -0.16515751  0.39983648 -0.1595634   0.08841372  0.13759196 -0.02576173\n",
      " -0.05270277  0.12470813  0.26389277  0.04942849  0.3006773   0.30767986\n",
      " -0.02052766 -0.1827599  -0.21900536  0.14605556  0.12738411 -0.15295796\n",
      "  0.10760525  0.15168865  0.11976691  0.30295226  0.18304624 -0.22710444\n",
      "  0.128734   -0.00966776]\n",
      "L7N0                    -> L8N60 = [-0.20602529 -0.15033591  0.11854198 -0.32381207  0.00964841 -0.11184941\n",
      "  0.08636242 -0.13510177 -0.33378163 -0.11076949 -0.0682748  -0.03975722\n",
      "  0.05597111 -0.00603327 -0.09819584  0.15064645 -0.35999018  0.15128492\n",
      " -0.12919332 -0.171107   -0.28234485 -0.10562874 -0.03048312  0.0697612\n",
      "  0.0523525  -0.06195734  0.01954912  0.05871695 -0.13848995 -0.16758633\n",
      "  0.07941971 -0.23782262 -0.23260695 -0.07884932  0.04558839 -0.08053876\n",
      "  0.02675951 -0.06604984 -0.0893564   0.0728083   0.11971503 -0.2736395\n",
      " -0.03184647 -0.12697712  0.14632714  0.09448129  0.11947586 -0.44709966\n",
      " -0.00698791  0.1714289   0.04921792 -0.02510668  0.0034047  -0.01153692\n",
      " -0.2637777  -0.11331035  0.06958396 -0.05965248  0.04298493 -0.3517877\n",
      "  0.07248316 -0.34591237  0.03430109 -0.3179777   0.12968111  0.02752162\n",
      " -0.13107589  0.13745838 -0.07321072 -0.23393303 -0.07410648  0.16727304\n",
      " -0.06077018 -0.02091471 -0.33422452  0.02835776 -0.48668432 -0.06070779\n",
      " -0.19117706 -0.24873859 -0.1692044  -0.08117976  0.14686121  0.1235175\n",
      "  0.02613354 -0.3557587  -0.18433224 -0.5211255  -0.03011801 -0.08098119\n",
      " -0.34923664 -0.1009969   0.0664479  -0.01182374  0.05851739  0.00390409\n",
      "  0.04796284  0.15913638 -0.10876238 -0.0688903  -0.17398006  0.29483977\n",
      " -0.33350658 -0.29623586 -0.067185   -0.02348207  0.00610649 -0.23737839\n",
      "  0.06242352 -0.10878994 -0.21719615  0.07485395 -0.04017399 -0.0635313\n",
      " -0.20020178 -0.26448616 -0.04880248 -0.08930703 -0.18959555 -0.08607247\n",
      " -0.00303338 -0.18790478 -0.17488681 -0.13490883 -0.1476863  -0.09776242\n",
      " -0.01811435  0.18865371 -0.03977692 -0.23558922  0.03984418 -0.00130299\n",
      " -0.18632735 -0.21444322 -0.11312353 -0.09462287 -0.3293219   0.12412087\n",
      "  0.07485292 -0.00721408 -0.02316581  0.09924278  0.01607618 -0.0799474\n",
      "  0.07067358 -0.08992598  0.03631673 -0.34551385  0.17037664 -0.08740539\n",
      "  0.09883848 -0.17068112 -0.19239715 -0.14638089 -0.09433903  0.1962756\n",
      "  0.21971256 -0.11940458 -0.25115436  0.13476227 -0.18373443 -0.09821044\n",
      " -0.0607346  -0.10862175 -0.1535077  -0.30535576 -0.04716163 -0.1842005\n",
      " -0.2902325  -0.07645729 -0.14238907  0.17617875 -0.05560302  0.08247118\n",
      "  0.2547056   0.08617744 -0.2553015  -0.07901527 -0.05160017  0.0111296\n",
      " -0.02949822 -0.01449365 -0.09627745 -0.25409207  0.17039175 -0.34488758\n",
      " -0.08661237 -0.04412368  0.26659882 -0.3743839  -0.23931146  0.12948471\n",
      " -0.45527923  0.21828406  0.06185808 -0.1368803  -0.17688921 -0.07461514\n",
      "  0.01408654 -0.17475276]\n",
      "L7N0                    -> L8N61 = [-0.04642768  0.15263115 -0.17270781 -0.10462958 -0.07323392  0.0767529\n",
      " -0.14769496 -0.0144363   0.08716137 -0.16992019  0.05553904 -0.1534137\n",
      "  0.09675645 -0.07953557  0.07500803  0.01624853 -0.33622238 -0.06157268\n",
      " -0.17588885 -0.16118145  0.09564688 -0.14707267 -0.12512341 -0.0709608\n",
      " -0.19140346 -0.11013481  0.07717211  0.06494983 -0.02825814  0.0060323\n",
      " -0.40164638 -0.19350076 -0.01192995 -0.01443308 -0.07508628 -0.18097445\n",
      " -0.09423365  0.0819267  -0.2881623   0.09772533 -0.00655174  0.18368241\n",
      " -0.15384105 -0.29381865 -0.01797775 -0.18263792 -0.2750069   0.15308462\n",
      " -0.10941533 -0.16034277  0.01855104 -0.17791158  0.0334668  -0.05145667\n",
      " -0.11353935 -0.07893629  0.00210358  0.12621194  0.11871783 -0.28118435\n",
      " -0.24162759 -0.1643424  -0.12803073 -0.23226808 -0.19017561 -0.33413553\n",
      " -0.4261663   0.10297742 -0.08106759 -0.16751483 -0.09376486 -0.31463987\n",
      "  0.10270414 -0.13720575 -0.06980845 -0.30721086 -0.06976861 -0.11014759\n",
      " -0.1453369  -0.03241552  0.13186386  0.06888246 -0.27398598 -0.33343992\n",
      " -0.18759383  0.09718708  0.24266636 -0.02898058 -0.43216792 -0.301425\n",
      " -0.16754803 -0.14630282  0.07500419 -0.09434525 -0.07447639  0.01546959\n",
      "  0.00259154 -0.14729805 -0.17888412 -0.04685212 -0.04150751 -0.04942259\n",
      "  0.00426527  0.00687884 -0.06353536 -0.00173347  0.03474192 -0.2581306\n",
      " -0.22545739 -0.19066301 -0.03007231  0.10305174 -0.11361863 -0.15144284\n",
      "  0.06357139 -0.09283546 -0.06320684 -0.01992752 -0.11838567 -0.18802668\n",
      " -0.07855432 -0.02270883 -0.15410306 -0.0452434   0.15303333 -0.1294816\n",
      " -0.04414402 -0.00868954 -0.03848233  0.25896162 -0.18504056 -0.20108888\n",
      " -0.18427664 -0.30596268 -0.11361479 -0.22013304 -0.03356223 -0.017159\n",
      "  0.21166    -0.17946346 -0.20803337  0.0748928   0.18111753 -0.06310014\n",
      "  0.09526959 -0.275366   -0.18066944 -0.06924235 -0.13243249 -0.30294287\n",
      "  0.17303155  0.00752001 -0.01376825 -0.09954787  0.05399194 -0.05255155\n",
      " -0.02434212 -0.1846034   0.14925787  0.06412423 -0.1995082   0.07283577\n",
      " -0.15362339 -0.094941   -0.29317623  0.00347862 -0.04915361  0.28751752\n",
      "  0.07826862 -0.07597812  0.10008021 -0.39934993  0.09101004 -0.11093352\n",
      " -0.06375201 -0.04339183 -0.21379586  0.04217459 -0.03596021  0.2809913\n",
      " -0.13204393  0.0069666  -0.07522859  0.07565229 -0.05621986 -0.22022542\n",
      " -0.25775743 -0.19478309 -0.130869    0.24647768 -0.17305098 -0.21683165\n",
      "  0.00629195  0.00898176  0.10099754  0.19436397 -0.16594762 -0.07273258\n",
      " -0.20120336  0.09509109]\n",
      "L7N0                    -> L8N62 = [-0.13858083 -0.27468857  0.13132975 -0.09865106 -0.01371996  0.2653865\n",
      "  0.30040497  0.03136682 -0.23410341  0.0788294   0.15628234  0.07737082\n",
      " -0.20508033 -0.10734488  0.31791005 -0.198357   -0.19966781 -0.06608747\n",
      " -0.08507419 -0.14302701 -0.10321815  0.03529839  0.3294792   0.27475506\n",
      "  0.2192954  -0.03635635 -0.19480217  0.0929077   0.01555485  0.10199603\n",
      "  0.15039673  0.12520762 -0.00218128 -0.12969851  0.155893    0.09900148\n",
      "  0.07014751  0.10329432 -0.05447306  0.08969501 -0.10474478  0.12487207\n",
      "  0.02879244  0.17058066 -0.21972786 -0.21798861  0.07453023  0.12743314\n",
      "  0.08983943  0.09165024 -0.13231243  0.04408132  0.23647979  0.07291187\n",
      "  0.26254988 -0.18443379  0.23612843  0.04730652  0.05559542  0.16407144\n",
      " -0.08092693  0.05713406  0.3220002   0.14508551 -0.09740192  0.0543212\n",
      " -0.13728161 -0.3379583   0.02410795 -0.01510637 -0.1087808  -0.12905473\n",
      " -0.14052299  0.02778272  0.26152855  0.20528512 -0.01394432  0.215186\n",
      "  0.26229596 -0.14922796 -0.12867881 -0.25164732  0.04544272  0.2784909\n",
      " -0.04735547 -0.19032632  0.1541652  -0.16835381 -0.03138744 -0.17800951\n",
      "  0.09539123  0.00590181 -0.00750118  0.14705049  0.08778391 -0.03078577\n",
      "  0.05349284  0.03607163  0.03681908 -0.12671885  0.17686108 -0.07540508\n",
      "  0.17170033  0.42671013  0.1450238  -0.00510413  0.10062346 -0.08535543\n",
      "  0.12678707 -0.14163613 -0.23325862 -0.11254799  0.00964276  0.24913836\n",
      " -0.46484378 -0.24563295  0.1264523  -0.21460125  0.11889639  0.03481943\n",
      " -0.09015798  0.08344341  0.09741104 -0.13271146 -0.15342066 -0.04463332\n",
      "  0.21893996  0.36594483 -0.3704047  -0.10352251  0.06027509  0.09153815\n",
      " -0.2601655   0.19926219  0.1761274   0.0856414  -0.09744009 -0.17445873\n",
      " -0.02814388  0.0037438   0.4496386  -0.2526639   0.05998803 -0.17359899\n",
      " -0.2237142  -0.19313584 -0.11774116  0.16645372  0.03569847 -0.04771354\n",
      "  0.09795824  0.03889741 -0.11088323 -0.14773548  0.23230317 -0.10765834\n",
      " -0.26823112  0.10480527  0.12307272  0.11791209  0.2543758   0.07366213\n",
      "  0.02075343 -0.51791006 -0.01106082 -0.08791754  0.3049323  -0.03498915\n",
      "  0.04413917  0.07842879 -0.07100714 -0.06286441 -0.02035528 -0.31722966\n",
      "  0.08338064 -0.01362268 -0.15346768 -0.22169997  0.28324583  0.01569753\n",
      "  0.05857765 -0.19246206 -0.15202978 -0.21146184 -0.18414646  0.19679567\n",
      "  0.08331805 -0.00284024  0.15218323  0.06922486 -0.14361171  0.38431197\n",
      "  0.06993929 -0.03932336 -0.2741538   0.13242011  0.0649712  -0.12952942\n",
      " -0.04995952 -0.19845042]\n",
      "L7N0                    -> L8N63 = [ 1.53009012e-01  8.72662589e-02 -2.92584389e-01 -2.47600656e-02\n",
      " -2.10179109e-02 -1.58827543e-01 -1.48725972e-01 -6.08470440e-02\n",
      "  1.08887330e-01  3.21137756e-02  7.88217559e-02 -1.06572062e-01\n",
      " -2.32826397e-01  9.30618122e-02 -3.21971267e-01 -1.15265220e-01\n",
      " -5.39696850e-02  2.60508675e-02  1.09468764e-02 -1.24136090e-01\n",
      " -6.97657019e-02 -1.81723669e-01 -2.33871862e-01 -3.36817801e-01\n",
      " -1.52108908e-01 -2.60892510e-01  5.61702903e-03 -9.08872187e-02\n",
      " -2.42727622e-01 -7.73556530e-02 -2.14655563e-01 -2.94371665e-01\n",
      " -1.84630811e-01 -2.20138431e-01 -2.44052246e-01 -5.86435758e-02\n",
      " -3.99029553e-01 -2.71130800e-01 -1.90475866e-01 -3.54482234e-03\n",
      "  1.65818572e-01 -1.44270346e-01 -1.77571356e-01 -1.42541707e-01\n",
      " -8.53092372e-02  1.00628346e-01 -1.05419114e-01 -1.27831995e-01\n",
      "  3.77242640e-02 -7.68550336e-02 -1.39933601e-01  3.54429558e-02\n",
      " -5.68859912e-02 -1.46611005e-01  3.81403267e-02 -1.85569748e-01\n",
      " -1.59548402e-01 -3.17847669e-01 -1.71110421e-01 -1.67770796e-02\n",
      " -1.72912508e-01 -2.72863299e-01  9.19907913e-03 -1.50806740e-01\n",
      "  9.01226178e-02  1.04358360e-01  1.71228915e-01 -1.11649379e-01\n",
      " -2.31500983e-01 -4.30693954e-01 -2.54393578e-01 -1.35029582e-02\n",
      " -1.92156047e-01  2.38699809e-01  1.08304575e-01 -4.95465696e-02\n",
      " -1.43099084e-01 -3.50905627e-01 -1.20357968e-01 -4.14056897e-01\n",
      " -1.13497145e-01  1.42542273e-01 -2.68097758e-01 -1.11855343e-01\n",
      "  1.72597095e-02 -1.17553465e-01 -2.25738585e-01 -9.30727124e-02\n",
      "  3.71360369e-02 -4.49965112e-02 -2.65841842e-01 -6.69087749e-03\n",
      " -2.63310462e-01  1.34293690e-01  3.51934470e-02  1.48471650e-02\n",
      "  7.63634965e-02 -1.50789926e-02  3.47135141e-02  4.93703559e-02\n",
      " -1.63098752e-01 -1.61642924e-01 -4.27606106e-01  1.05279341e-01\n",
      " -1.55389696e-01 -1.01709872e-01 -3.53161246e-02 -1.45742461e-01\n",
      " -3.32178414e-01  1.35241255e-01 -1.24966413e-01  2.46223107e-01\n",
      " -1.01182468e-01  2.54804883e-02 -1.06382184e-01  6.69038743e-02\n",
      " -7.70726651e-02 -1.94905326e-01 -1.53309986e-01 -8.55581462e-02\n",
      " -9.57087241e-03 -3.18097770e-01 -1.72619462e-01 -1.41069070e-01\n",
      " -9.95151233e-04 -2.31321380e-01 -2.70961136e-01 -1.16224810e-01\n",
      " -5.42236149e-01 -9.78945568e-02 -1.68255478e-01 -1.51418135e-01\n",
      "  3.22091997e-01 -7.16553107e-02 -2.12702051e-01 -1.94071889e-01\n",
      "  1.50146291e-01 -1.50105273e-02 -2.52083480e-01 -2.65100867e-01\n",
      "  9.63507891e-02 -1.87601388e-01  6.49895370e-02 -3.41845572e-01\n",
      "  1.08654857e-01  1.29323259e-01  6.26850054e-02 -1.27086699e-01\n",
      " -1.24014460e-01 -1.38216447e-02 -2.47690361e-02 -8.09262693e-02\n",
      " -2.40856726e-02 -2.34458178e-01 -1.00461476e-01 -8.06949288e-02\n",
      "  8.10524002e-02  1.21208183e-01 -2.82426421e-02  6.34437874e-02\n",
      " -3.42430584e-02 -6.60134107e-02  1.30174547e-01 -2.49314830e-01\n",
      "  1.34462506e-01 -1.78300753e-01 -8.21549445e-02  1.28319085e-01\n",
      " -2.87999600e-01  2.47152336e-02  1.55552685e-01 -4.60822433e-02\n",
      " -1.53225332e-01 -2.93940574e-01  2.87283331e-01 -1.84231356e-01\n",
      "  2.49957278e-01  1.31730989e-01 -2.26119459e-01  8.80484879e-02\n",
      " -2.77873158e-01  3.67843750e-04  6.54144660e-02  1.32289246e-01\n",
      " -4.18814570e-01 -6.01450168e-02  5.52727953e-02  9.84802321e-02\n",
      " -1.96127415e-01  5.59897386e-02 -8.59329328e-02 -1.04307562e-01\n",
      " -3.41865957e-01 -1.28289074e-01  2.47531012e-02  5.55426069e-02\n",
      "  9.32938457e-02 -6.62586465e-02 -6.27290756e-02  5.84267825e-02]\n",
      "L7N0                    -> L8N64 = [-2.97736585e-01  2.38539860e-01 -2.32388809e-01 -6.97180629e-02\n",
      "  1.05082998e-02  1.54208615e-01 -1.35358989e-01 -1.02783740e-01\n",
      " -3.28972414e-02  9.59942490e-02 -1.49477944e-01 -2.50334233e-01\n",
      " -2.36031357e-02 -7.28970617e-02 -5.28548099e-02 -5.58035970e-02\n",
      " -1.75556064e-01 -2.33125716e-01  5.15936464e-02  1.41317338e-01\n",
      "  5.60902059e-02  5.10675907e-02  1.71226367e-01  9.38948169e-02\n",
      " -1.78218454e-01  9.11521614e-02 -7.43566528e-02 -2.75114458e-02\n",
      " -1.43353781e-02 -1.90492459e-02 -3.65388751e-01  3.46622393e-02\n",
      " -5.64748831e-02 -9.49654579e-02  1.64991409e-01  6.28433153e-02\n",
      " -6.11552130e-03 -8.82594809e-02  2.98737556e-01 -7.91686252e-02\n",
      " -1.70535058e-01 -2.07461476e-01 -2.54809558e-01  1.27914563e-01\n",
      "  8.99958163e-02 -7.60410056e-02  2.04314180e-02  7.93688968e-02\n",
      " -4.68830109e-01 -1.16710082e-01 -1.49247691e-01 -3.10289979e-01\n",
      "  2.06703246e-01  7.79067948e-02 -6.46426827e-02 -3.46582830e-01\n",
      " -1.12633966e-01 -1.85675512e-03 -6.15528114e-02 -1.29328534e-01\n",
      "  8.84345770e-02 -9.51420739e-02  1.06788754e-01 -4.13502008e-02\n",
      " -2.92778760e-01  1.11662067e-01  2.60582030e-01 -3.11110049e-01\n",
      "  1.82536498e-01 -4.38854061e-02  4.14560636e-04 -2.91383952e-01\n",
      " -5.19842617e-02  2.93735769e-02  6.36850744e-02 -6.77955225e-02\n",
      " -1.68995261e-01 -4.49894331e-02 -2.64197811e-02  8.25477019e-02\n",
      " -2.22141370e-01  5.20880967e-02  1.77993819e-01  6.64808601e-02\n",
      " -4.02145088e-03 -3.30033451e-02 -1.13941684e-01 -9.64312330e-02\n",
      " -1.00629218e-01  1.97938591e-01 -3.66296232e-01  7.87250698e-02\n",
      "  1.54995425e-02 -9.54627693e-02 -7.55451694e-02  1.79061040e-01\n",
      " -3.62692475e-01 -1.67239159e-01 -6.55447766e-02 -1.45963505e-01\n",
      "  2.45175764e-01 -2.18999058e-01 -3.04855667e-02  4.50475700e-02\n",
      "  1.73665434e-01 -1.17419779e-01 -3.48912716e-01 -2.94416342e-02\n",
      "  9.05724019e-02 -1.32712811e-01 -4.75953281e-01  1.77500844e-01\n",
      "  3.01823895e-02  1.71994060e-01  8.90165567e-02 -1.78949714e-01\n",
      " -1.05864882e-01 -1.63031109e-02  1.03540875e-01 -1.46843970e-01\n",
      "  1.67585164e-01  5.55030778e-02 -2.56828703e-02 -1.91279352e-02\n",
      " -1.86216578e-01 -4.92848866e-02 -1.23496808e-01  1.37722552e-01\n",
      " -2.08912089e-01 -5.16002886e-02  1.21519536e-01  1.35226073e-02\n",
      " -1.98186666e-01  1.35773597e-02 -2.84385741e-01 -1.85692515e-02\n",
      " -4.75756116e-02 -4.92953122e-01  1.18646868e-01  2.36224998e-02\n",
      "  6.12252112e-03 -2.02776104e-01 -2.99820185e-01  1.13362810e-02\n",
      "  3.92902568e-02 -1.26253217e-01  2.23016083e-01 -1.28236011e-01\n",
      " -2.26075854e-03 -5.69429323e-02 -8.53693336e-02 -1.62647702e-02\n",
      " -1.74621537e-01 -2.41429120e-01  9.64673311e-02  2.36576825e-01\n",
      " -3.07476610e-01  2.41034791e-01  3.06549799e-02 -3.60976189e-01\n",
      " -5.19706830e-02 -2.77908891e-01 -3.04443669e-02 -2.44558111e-01\n",
      " -1.35140538e-01 -2.18281504e-02  1.86544657e-02  8.05467814e-02\n",
      " -1.52032375e-01  5.73943974e-03 -3.07456613e-01 -1.87517226e-01\n",
      " -1.79466799e-01 -2.59067208e-01 -1.62133686e-02 -2.67617673e-01\n",
      " -3.28920960e-01 -9.13854241e-02  4.76144031e-02  3.83338705e-02\n",
      " -5.35441637e-02  1.20745517e-01 -1.81565404e-01  1.62033692e-01\n",
      " -1.15549222e-01  6.71571195e-02  9.88550931e-02 -1.75354332e-01\n",
      "  8.81905034e-02  3.03165596e-02 -1.66989073e-01 -3.20065081e-01\n",
      "  1.46474391e-01 -7.17360973e-02  2.28656530e-02 -4.00693342e-02\n",
      " -1.94851272e-02 -1.42084926e-01  2.44626086e-02 -1.34380227e-02]\n",
      "L7N0                    -> L8N65 = [-7.65426159e-02 -2.80696787e-02 -2.07250327e-01 -2.31137723e-01\n",
      " -3.22204441e-01 -3.00427973e-01 -3.35652739e-01  5.89593649e-02\n",
      "  2.54943006e-04 -2.62087077e-01 -7.44191781e-02 -6.21968322e-02\n",
      " -4.92753498e-02 -2.15768650e-01  1.92075089e-01 -5.49535528e-02\n",
      "  1.90074593e-02 -4.28108484e-01 -1.92281634e-01 -1.87761560e-02\n",
      "  5.46905547e-02  2.37150807e-02 -4.00432438e-01  4.21763100e-02\n",
      "  1.41264722e-01  6.30622031e-03 -9.96854976e-02 -2.23935489e-02\n",
      " -1.94096263e-03 -3.12028944e-01 -3.14180404e-01  2.64629751e-01\n",
      "  6.68004826e-02  8.64642039e-02 -1.91767246e-01  6.54504746e-02\n",
      " -1.25066992e-02 -9.02286321e-02  6.30638972e-02 -9.61552560e-03\n",
      "  2.35817228e-02  5.35808410e-03 -1.36874810e-01 -2.10831091e-01\n",
      "  5.04016913e-02  5.55339865e-02 -1.82423145e-01 -1.33455709e-01\n",
      " -2.52705604e-01 -6.68989271e-02  8.05759504e-02  4.40998469e-03\n",
      " -7.25494102e-02 -1.16646208e-01 -6.29324391e-02  1.18114211e-01\n",
      " -1.57021239e-01 -1.10305902e-02 -1.13097697e-01 -2.44879261e-01\n",
      "  5.44502996e-02 -1.28960878e-01 -3.49000506e-02 -4.36879933e-01\n",
      " -1.14749379e-01 -1.00935429e-01  6.85374439e-02 -8.79286230e-03\n",
      "  5.03175135e-04  2.88962312e-02 -3.32282633e-01  4.76035699e-02\n",
      "  5.06814867e-02  3.93064655e-02 -3.13054472e-02 -1.33265078e-01\n",
      "  7.83303529e-02  2.78623160e-02 -7.24504292e-02 -4.87033993e-01\n",
      " -1.52329519e-01 -2.71313416e-04 -2.71994621e-01 -1.31560504e-01\n",
      "  1.62517533e-01 -1.73838094e-01 -1.10110581e-01  4.14609984e-02\n",
      " -1.23986760e-02  1.80359166e-02 -3.52362573e-01 -1.01978660e-01\n",
      " -3.03409159e-01 -2.31641576e-01 -1.32494166e-01 -1.17586441e-01\n",
      " -6.42584860e-02  2.32944228e-02 -8.86911303e-02 -1.70093358e-01\n",
      "  8.31121057e-02 -7.02759251e-02 -1.08749904e-01 -2.09713012e-01\n",
      " -2.84447193e-01 -3.21536720e-01 -2.31398702e-01 -1.75727352e-01\n",
      " -8.87116715e-02 -1.84526015e-02 -9.73912552e-02 -1.40276968e-01\n",
      " -1.24179892e-01 -3.48867983e-01 -2.73626924e-01 -3.03433001e-01\n",
      " -9.48356912e-02 -3.69417280e-01 -2.54224837e-01 -3.30669880e-01\n",
      "  8.02361444e-02 -2.07063168e-01 -1.24814115e-01 -8.06743652e-02\n",
      " -6.97288886e-02 -2.34568164e-01 -1.42803505e-01 -2.33214423e-01\n",
      " -1.35021701e-01  3.04663628e-02 -1.69935167e-01 -2.30606794e-01\n",
      "  1.06709324e-01 -1.12509549e-01 -7.08790915e-03 -4.37054299e-02\n",
      " -2.90699393e-01 -7.24699795e-02 -3.37672085e-02 -1.77800760e-01\n",
      " -1.22292086e-01 -5.78300050e-03 -4.60531982e-03 -1.15785832e-02\n",
      " -5.81038147e-02 -2.34353289e-01 -9.20334905e-02 -2.08742544e-01\n",
      "  1.78474225e-02 -2.41802260e-02 -9.87417251e-02 -1.55302837e-01\n",
      " -1.47237808e-01 -3.05870563e-01 -8.52913558e-02 -1.30177006e-01\n",
      "  1.57331079e-01 -5.84985986e-02  2.74905562e-02 -1.37265369e-01\n",
      " -3.55763268e-03  8.47118534e-03 -3.54909897e-01 -3.27164941e-02\n",
      "  1.15723710e-03 -7.82370940e-02 -1.81603897e-02  7.10884482e-02\n",
      " -1.04866348e-01 -4.98471446e-02  1.80257797e-01 -1.27240166e-01\n",
      " -1.50315285e-01  1.01176910e-01 -2.84306943e-01  1.61434799e-01\n",
      " -3.28250498e-01 -4.21889983e-02 -8.61495733e-02  1.41272545e-01\n",
      " -1.68164503e-02  2.49799103e-01 -6.39920905e-02  7.89013579e-02\n",
      " -3.34233269e-02 -2.74498433e-01 -3.60948771e-01  4.46994975e-02\n",
      " -1.69825908e-02  1.55485392e-01 -2.10649401e-01 -6.83909878e-02\n",
      "  6.48707151e-02 -4.15132195e-02  2.00882941e-01 -3.59420091e-01\n",
      " -6.98114112e-02 -3.34057599e-01 -4.14296146e-03  1.50513560e-01]\n",
      "L7N0                    -> L8N66 = [ 1.61284670e-01 -6.27853647e-02 -1.26570657e-01  5.09114228e-02\n",
      "  1.10469677e-01 -1.62450671e-01 -1.11315399e-01 -2.32259080e-01\n",
      " -3.20132598e-02 -5.26309013e-02  3.41406092e-02  1.40964508e-01\n",
      " -8.53269361e-03 -2.40246113e-02 -8.23172927e-02 -1.27981916e-01\n",
      " -9.67083499e-02  1.21592380e-01 -1.93275306e-02 -1.79141313e-01\n",
      " -8.12485889e-02  4.03724872e-02  1.73894763e-01  5.06311134e-02\n",
      " -2.23851398e-01  8.03594291e-03  1.45252958e-01 -1.55599713e-01\n",
      "  3.17135528e-02 -2.35562492e-02 -1.14038521e-02 -2.64690459e-01\n",
      "  3.37061509e-02  2.97846552e-02 -1.32035920e-02  1.92639336e-01\n",
      "  4.68476526e-02 -3.35400760e-01 -6.46144971e-02 -4.35213931e-03\n",
      " -3.08676921e-02 -2.48661250e-01 -1.99052200e-01 -6.30520508e-02\n",
      " -2.17752275e-03  7.16541801e-03 -7.32316896e-02 -1.64212450e-01\n",
      " -1.53766304e-01 -1.10155374e-01 -7.20542520e-02 -1.82804093e-01\n",
      "  1.68027952e-01 -2.33912859e-02 -3.72270495e-02  8.24178532e-02\n",
      " -6.36249036e-02 -7.24929795e-02 -2.37849921e-01  1.19594336e-01\n",
      "  1.06410034e-01 -1.59154981e-01 -3.06215212e-02 -2.48889029e-02\n",
      "  2.48642433e-02  8.08407664e-02 -1.61318496e-01  1.25154778e-01\n",
      " -6.57459572e-02 -3.12465597e-02 -2.48187959e-01 -4.75336194e-01\n",
      " -4.45188582e-01 -5.94472438e-02 -7.68431500e-02  8.68186131e-02\n",
      "  1.37337074e-01 -2.60979950e-01 -1.41017288e-01  1.54000983e-01\n",
      " -3.48765075e-01 -3.21023911e-01  3.01024760e-04  1.70003057e-01\n",
      "  1.64629370e-02 -5.92960596e-01 -3.44971865e-02 -1.90033540e-01\n",
      " -2.62389570e-01 -1.11789718e-01 -1.20247781e-01 -5.32156050e-01\n",
      "  2.04157665e-01  9.05883536e-02  2.71828063e-02 -9.98029858e-03\n",
      "  2.16430113e-01  2.16590017e-01 -2.19510794e-01 -1.75236966e-02\n",
      " -1.86845243e-01 -2.93027520e-01 -2.48038657e-02 -2.08275095e-01\n",
      " -1.44840702e-01  1.20803811e-01 -1.11625597e-01 -3.28477025e-01\n",
      " -2.17557892e-01 -2.50679433e-01 -1.05384566e-01 -3.90110351e-02\n",
      "  2.18027338e-01 -3.97342801e-01 -6.21343479e-02 -1.30644783e-01\n",
      " -2.35635817e-01 -9.41461548e-02 -2.69824326e-01 -1.00847371e-01\n",
      " -8.97551700e-02 -1.71104103e-01 -9.87443030e-02 -7.29837120e-02\n",
      " -8.68644789e-02 -7.48734102e-02 -2.10659683e-01 -1.39764771e-01\n",
      "  5.53518422e-02 -4.24115449e-01 -1.32440627e-01  8.16427357e-03\n",
      "  2.10318446e-01 -1.63340718e-01 -3.69301975e-01  3.47350389e-02\n",
      " -1.29598826e-01 -1.29430324e-01  3.42076980e-02  1.62453670e-02\n",
      "  2.34848727e-03  1.43920735e-01  1.39741659e-01 -1.39707953e-01\n",
      " -2.10611358e-01 -1.91917568e-01 -2.09199548e-01 -8.95126630e-03\n",
      " -8.48413557e-02  1.08580075e-01  2.37645656e-01 -1.28955901e-01\n",
      "  1.39975715e-02  9.88962278e-02 -1.46833584e-01 -1.70756593e-01\n",
      " -2.14766096e-02  5.45190647e-02 -3.15097630e-01  3.94947864e-02\n",
      " -1.78093821e-01 -2.95041531e-01 -4.56948355e-02 -2.34177977e-01\n",
      " -1.89760908e-01 -1.85573995e-01  6.82235882e-02 -1.47021934e-01\n",
      " -1.64018854e-01 -6.46710694e-02  9.61176530e-02 -1.71974421e-01\n",
      " -2.22017780e-01 -1.47613674e-01 -5.01481444e-02  2.28632838e-01\n",
      "  1.62315462e-02  1.17654748e-01 -1.22570217e-01 -8.80508348e-02\n",
      "  2.18459234e-01 -1.20462645e-02 -2.16518760e-01 -2.32568219e-01\n",
      " -4.53943945e-03  1.50708100e-02  1.80018708e-01 -8.21460411e-02\n",
      "  3.37842070e-02 -3.07864100e-01  3.77438590e-02  1.74867123e-01\n",
      " -4.66143727e-01  7.73269087e-02  2.41233613e-02 -2.57678982e-03\n",
      " -1.49236277e-01 -1.04215302e-01  2.07063090e-02 -8.29042643e-02]\n",
      "L7N0                    -> L8N67 = [-0.14800006 -0.09342291  0.00982813 -0.07138299  0.0983867  -0.16960724\n",
      " -0.02062782 -0.06208221 -0.46880293 -0.03258489  0.00233161 -0.22382331\n",
      " -0.24829167 -0.02199527 -0.1777791  -0.32865924 -0.0501311  -0.16908482\n",
      " -0.14229214 -0.31907466 -0.32159367  0.02739076 -0.01184679 -0.117682\n",
      "  0.08299753  0.04694407  0.07192169 -0.09572407 -0.15581204 -0.04567088\n",
      "  0.10668977 -0.27843145 -0.06782057  0.14690962  0.10264111 -0.15565784\n",
      "  0.08015857 -0.0812      0.11529083 -0.08662915  0.07906845 -0.32647312\n",
      " -0.1484611  -0.01725151 -0.22102115  0.02198833 -0.20491835 -0.09786299\n",
      "  0.07869026 -0.18761829  0.21938425 -0.03769261 -0.02866878 -0.24075864\n",
      " -0.1470878  -0.18801773  0.18529634 -0.24805012 -0.05688223  0.10547114\n",
      "  0.05298188 -0.14337637  0.16806021  0.07417861 -0.10998498 -0.17380461\n",
      " -0.02572531 -0.24891132  0.05796571 -0.0750392   0.00741685 -0.01134493\n",
      " -0.02950057 -0.1235479  -0.12236451  0.12190273  0.15092559 -0.3036021\n",
      " -0.11371935  0.10930614 -0.0731601  -0.06460554 -0.12211596 -0.37413967\n",
      "  0.04489926  0.00402031 -0.29282853 -0.40514994 -0.445936   -0.20408893\n",
      "  0.24686465 -0.20076181 -0.10144968  0.11927462  0.30566156 -0.13402055\n",
      " -0.21036305 -0.13142435  0.0627057  -0.05108658  0.26604208  0.32678857\n",
      " -0.18597285 -0.08164763 -0.18823978  0.10807649 -0.01601634 -0.29879123\n",
      "  0.10009748  0.07097843 -0.20063236  0.04238104 -0.08604979  0.14821516\n",
      "  0.12733634  0.08873545  0.07130875  0.25131053 -0.21677178  0.01623296\n",
      " -0.15213855 -0.10258935 -0.05463339  0.16054817 -0.01725689 -0.17025894\n",
      "  0.02672137  0.00747556 -0.3700962  -0.12799528 -0.20705634 -0.17981878\n",
      " -0.33849102  0.14027084  0.09265321  0.00182553  0.23351288 -0.21388184\n",
      " -0.26928654 -0.19261248  0.17660448 -0.38080952 -0.3461453   0.01438355\n",
      " -0.15682615 -0.03578791 -0.09412174 -0.01902974 -0.37035    -0.07402318\n",
      " -0.11636548  0.00169207 -0.10722216 -0.05825116  0.08876508 -0.17220224\n",
      "  0.09120145  0.23019241  0.06514641  0.04287313 -0.10485457 -0.02394157\n",
      "  0.11406698 -0.04715142 -0.10449597 -0.05304551 -0.07571043 -0.00913421\n",
      " -0.02412269 -0.2751418  -0.1439683  -0.02831802 -0.23518787  0.020137\n",
      "  0.04024696  0.00494373 -0.21147627 -0.28688762 -0.16411422 -0.22038524\n",
      "  0.02733166  0.2018203   0.04750934 -0.12954082 -0.00584098  0.060683\n",
      "  0.29863292 -0.15389167  0.21939722 -0.46101695 -0.1545464  -0.11248048\n",
      " -0.2529608  -0.3607709  -0.10208058  0.09794733 -0.14143331 -0.05609575\n",
      " -0.10629012 -0.06292019]\n",
      "L7N0                    -> L8N68 = [-2.19948683e-02 -7.32368976e-02  1.00683913e-01 -2.42885649e-01\n",
      " -1.35160461e-01 -1.62942298e-02  1.60093546e-01  7.67563954e-02\n",
      "  2.01411843e-01  1.08514868e-01  4.69842315e-01 -2.08036795e-01\n",
      " -1.78449824e-01  1.16485111e-01 -1.67360067e-01 -3.79825421e-02\n",
      "  9.77526754e-02 -8.49867910e-02 -1.07933275e-01 -1.64159939e-01\n",
      " -2.38352358e-01  1.90487623e-01 -2.56233275e-01  2.70464957e-01\n",
      "  1.66988403e-01  4.15837765e-02  1.35534313e-02  3.45307678e-01\n",
      "  1.82662487e-01  1.31272584e-01 -2.34603316e-01  7.56429508e-02\n",
      "  1.13339759e-01 -2.35769093e-01  1.21879764e-01  7.80311553e-03\n",
      "  5.44532202e-02  2.59035259e-01 -1.74301229e-02  1.10117786e-01\n",
      " -3.41889620e-01  6.14614822e-02 -2.62997955e-01  4.56149839e-02\n",
      " -1.56958178e-01  2.98087727e-02  2.42636144e-01  2.25341007e-01\n",
      " -9.88470111e-03  1.58886105e-01  3.99353921e-01  4.68280576e-02\n",
      "  2.73212522e-01  1.69222385e-01 -2.59081900e-01 -3.17365974e-01\n",
      "  1.77994326e-01  4.96335439e-02 -7.75205642e-02 -2.50144958e-01\n",
      "  9.97212902e-02  6.11369982e-02  5.82248755e-02  1.22428410e-01\n",
      "  2.64288764e-02  4.60819192e-02  1.15345344e-01 -1.00410208e-01\n",
      "  1.41037822e-01  1.59764320e-01  5.44577800e-02  3.38697284e-01\n",
      "  1.15356289e-01 -3.31080407e-01  8.27798396e-02  1.15964256e-01\n",
      "  9.38302428e-02 -3.26189101e-01  1.15231968e-01 -8.35001245e-02\n",
      " -7.07469461e-03  8.05010721e-02  2.56075412e-01  3.41638774e-02\n",
      " -6.73161894e-02 -1.84894130e-01 -1.07969828e-01  9.96611547e-03\n",
      "  9.66371521e-02  1.45830691e-01 -2.17552885e-01 -3.62608545e-02\n",
      "  1.54496938e-01 -1.58722267e-01  5.72857633e-02  1.41124856e-02\n",
      " -1.98402390e-01 -4.02786136e-02  9.02534798e-02  1.18619107e-01\n",
      "  3.40787251e-03  6.57193586e-02  2.52111554e-01 -2.16970235e-01\n",
      "  7.06741661e-02 -1.69367343e-01 -5.92683852e-02  7.13358447e-02\n",
      "  6.30632415e-02  4.15666848e-02 -2.46743307e-01  5.42816043e-01\n",
      " -8.08829963e-02 -1.45408884e-01 -2.95623332e-01 -4.21503305e-01\n",
      "  1.98178992e-01  3.31823111e-01 -4.95172106e-02  2.42653415e-01\n",
      "  1.31940156e-01  1.61977649e-01  4.06129844e-02  1.38605580e-01\n",
      "  3.05924006e-02 -7.77912214e-02  2.60080576e-01  1.29713133e-01\n",
      " -2.05866739e-01  2.24407744e-02  2.33160947e-02  1.66975915e-01\n",
      " -2.04373002e-01  2.01729417e-01 -5.96228242e-02 -4.79423063e-04\n",
      "  1.03950880e-01  1.14146598e-01  1.46754175e-01  1.31531671e-01\n",
      "  2.09250942e-01 -1.58992819e-02 -2.83366770e-01  4.42381084e-01\n",
      " -1.30429059e-01 -1.17366284e-01 -8.09616758e-04 -1.85261235e-01\n",
      "  2.84704089e-01  8.15681592e-02 -3.88465554e-01  1.19171508e-01\n",
      " -1.39439940e-01 -5.28829657e-02  5.44895679e-02  2.29039162e-01\n",
      " -6.98943809e-02 -1.01014234e-01  5.59666604e-02  1.14143446e-01\n",
      " -2.12321505e-02  9.75136533e-02 -1.57954544e-01 -1.34522825e-01\n",
      "  4.88239191e-02  8.14604312e-02 -1.18422881e-01  1.48751931e-02\n",
      "  1.50491878e-01  2.38262732e-02 -1.84578672e-01  3.63801092e-01\n",
      "  1.87334523e-01  3.90830934e-01  2.30484694e-01  7.21839517e-02\n",
      "  1.70834914e-01  5.77181131e-02  8.87801722e-02 -5.96061721e-03\n",
      " -7.67948180e-02 -5.46432734e-02  1.18322559e-01 -5.59270270e-02\n",
      "  2.52183825e-01  8.84858146e-03  1.54043987e-01  2.64691204e-01\n",
      " -1.17293507e-01 -9.05079544e-02  2.73229014e-02 -2.32900172e-01\n",
      "  1.41918128e-02 -1.35468140e-01 -1.22788340e-01  1.78722352e-01\n",
      "  2.25440338e-01 -1.91837609e-01  2.14723095e-01 -1.36207148e-01]\n",
      "L7N0                    -> L8N69 = [-2.84172166e-02 -8.80238973e-03 -4.40115808e-03 -2.29778260e-01\n",
      "  7.25433826e-02  4.65215333e-02 -1.80986375e-01  1.63786575e-01\n",
      " -3.01762402e-01 -6.22089058e-02  1.54430822e-01  3.49597394e-01\n",
      "  3.09491217e-01  5.11218272e-02 -1.74401581e-01 -2.62984902e-01\n",
      "  1.49482325e-01 -1.97040260e-01  4.51036617e-02 -1.11855224e-01\n",
      "  6.80524036e-02 -1.22826539e-01  1.36863381e-01 -1.81452110e-01\n",
      "  5.11938855e-02  2.28967816e-01  7.96547756e-02 -1.44016519e-01\n",
      "  3.21177781e-01  2.27377102e-01  2.39412159e-01  1.93596333e-01\n",
      "  9.21833217e-02 -1.37683619e-02  2.10137188e-01 -5.75419739e-02\n",
      "  4.16390540e-05 -2.93711629e-02  6.85281083e-02 -5.23162708e-02\n",
      " -1.88429177e-01  2.16141175e-02  3.00336272e-01  2.45886996e-01\n",
      " -7.66975433e-02  3.95251602e-01 -5.11757797e-04 -2.94972789e-02\n",
      "  1.12912752e-01  2.79514790e-01  1.68354973e-01  1.59900829e-01\n",
      "  2.54477262e-01  1.19541913e-01 -1.28223285e-01 -6.81857113e-03\n",
      "  7.29292259e-02  5.41616641e-02  8.55732039e-02 -9.95815098e-02\n",
      " -6.07541203e-03  1.54800385e-01  2.41976365e-01  1.37357846e-01\n",
      " -2.03273058e-01  2.96909064e-01  1.47998765e-01  1.53114066e-01\n",
      " -2.65129842e-02  3.45185339e-01 -1.10864984e-02 -1.02411993e-01\n",
      " -1.96593836e-01 -3.83061320e-02 -1.02060132e-01  1.66117190e-03\n",
      " -3.35658528e-02 -1.78988874e-01  9.97358635e-02 -8.07327926e-02\n",
      " -1.84464425e-01 -2.12283134e-01  1.67007357e-01 -1.35967880e-01\n",
      "  5.60267009e-02 -2.02913180e-01 -2.43462816e-01 -1.96795031e-01\n",
      " -3.02999634e-02 -3.45584154e-02 -3.40695083e-01 -4.00500447e-02\n",
      "  3.01911592e-01  7.04409257e-02 -1.15608811e-01  1.77635863e-01\n",
      "  1.53030297e-02  1.61452085e-01  3.18488389e-01 -4.86361943e-02\n",
      "  1.35421529e-01  8.29076022e-02  2.16718733e-01 -1.51934728e-01\n",
      "  7.26758167e-02 -2.22129542e-02  3.18738632e-02  4.10014428e-02\n",
      "  1.38263538e-01  3.61562381e-03 -1.92067578e-01  7.54426196e-02\n",
      "  3.15752357e-01 -5.41214049e-02 -2.01816112e-01 -1.36150345e-01\n",
      "  1.37922719e-01 -8.55671987e-02  1.65150389e-01  7.13108405e-02\n",
      "  1.43533230e-01  4.79226634e-02  1.74148351e-01  5.08545339e-02\n",
      " -3.34279388e-01  1.49869565e-02  3.72573793e-01  3.46454620e-01\n",
      " -7.12083504e-02 -2.13202551e-01  1.54372811e-01  1.14103623e-01\n",
      " -1.71868831e-01  3.37917924e-01 -3.50432917e-02  3.23469073e-01\n",
      "  4.93900701e-02  2.20529675e-01  2.11260214e-01  1.58367917e-01\n",
      "  7.30063915e-02 -1.48965539e-02  1.24569714e-01 -2.46270210e-01\n",
      " -4.71526943e-03 -1.30600631e-01 -3.93816195e-02 -1.96246907e-01\n",
      "  3.68598342e-01  1.20475531e-01  1.53161868e-01  3.92604172e-02\n",
      " -2.09430903e-01  6.27875188e-03  2.06190512e-01  3.42164129e-01\n",
      "  6.41637295e-02 -7.71584883e-02  1.83846295e-01  8.44200850e-02\n",
      " -6.61191791e-02  1.10309288e-01  2.42813140e-01 -3.25828910e-01\n",
      " -1.62492797e-01  9.16608796e-02  1.69549569e-01 -1.98448166e-01\n",
      " -3.64033990e-02  4.61510420e-02 -4.72625084e-02 -1.57972798e-02\n",
      "  2.17809808e-02 -8.84278398e-03  8.57444853e-02  1.95413753e-01\n",
      " -1.29058108e-01 -3.43562931e-01  1.10306814e-01  3.96218449e-02\n",
      " -2.48562098e-02  2.06893951e-01 -3.01991343e-01 -2.59868592e-01\n",
      "  1.72979429e-01  1.96461275e-01  1.65031314e-01  1.21096417e-01\n",
      "  1.10336997e-01 -9.20206755e-02  9.47073102e-02  2.90361702e-01\n",
      " -1.14419885e-01 -4.35447067e-01  1.95029806e-02  3.09329003e-01\n",
      "  7.09460378e-02  2.01599449e-02  1.69618838e-02 -2.43212089e-01]\n",
      "L7N0                    -> L8N70 = [ 0.00313076 -0.16614558  0.13344812  0.26708335  0.00535193 -0.00188479\n",
      " -0.02970476  0.1923791  -0.21222071  0.13658014  0.00081806  0.14394233\n",
      "  0.05148636 -0.14832614 -0.30102715 -0.18896541  0.17246914  0.08981449\n",
      "  0.17934124  0.23796156 -0.05887242  0.01602892 -0.28145885 -0.09869362\n",
      "  0.05535924 -0.01452896 -0.01758361 -0.0118554  -0.07391395 -0.09507658\n",
      " -0.07787068  0.16518398 -0.1386985  -0.27947503 -0.01177851 -0.26071596\n",
      " -0.02545994 -0.14054616  0.12690115 -0.14048404  0.507249    0.00728022\n",
      "  0.10022527 -0.05187899 -0.08780197 -0.03631952 -0.07850517 -0.0480172\n",
      " -0.18470012  0.14542766  0.07471556  0.02914977 -0.06030262  0.07130028\n",
      "  0.07507013  0.00489474 -0.06585331  0.1572411   0.09430265  0.11065681\n",
      " -0.07976214 -0.15538757 -0.02534915 -0.13603419 -0.04940566  0.1365527\n",
      " -0.08586188  0.02981856 -0.10119601  0.05179132  0.09334376  0.1268763\n",
      " -0.10969467 -0.17946115 -0.11700849  0.19041437 -0.3156371   0.27893382\n",
      "  0.01385196  0.05873614 -0.3117582  -0.0715711  -0.11339781  0.3263218\n",
      "  0.13460526  0.00402773 -0.35018685 -0.10516255 -0.06944936 -0.45558235\n",
      "  0.01507465  0.24092768 -0.08832803 -0.17150861 -0.1993097  -0.26775903\n",
      " -0.15548761  0.23982388  0.02690267 -0.3495188  -0.21204445  0.21108253\n",
      " -0.04714344 -0.12882149 -0.05435142 -0.11434606  0.1665166  -0.27467343\n",
      "  0.02015129 -0.10970823  0.13220657  0.12872119 -0.09335913  0.04129839\n",
      "  0.21697015  0.0554954   0.00582851 -0.11464677  0.06897809 -0.31391856\n",
      " -0.33981755  0.15209554  0.04932702 -0.00609253 -0.118236    0.00338936\n",
      " -0.15571614 -0.00525286  0.05947588 -0.16526976 -0.26930723 -0.1696762\n",
      " -0.17722131 -0.08404873  0.22976318 -0.06133074  0.04847091  0.30872998\n",
      " -0.36366752 -0.07908584 -0.09744777 -0.16168687 -0.1829664  -0.11374646\n",
      " -0.12616959  0.18843655 -0.00425085 -0.24465902  0.11087375 -0.13480517\n",
      "  0.12894438  0.09124711 -0.10577752 -0.13885027 -0.10837667 -0.3562431\n",
      "  0.05548909 -0.04029059  0.07134881  0.02452917  0.01885233  0.2482427\n",
      " -0.27975607 -0.04923198 -0.00933423  0.3162171  -0.01334416 -0.07485135\n",
      "  0.09440322  0.09081655 -0.03497541 -0.13112041 -0.03805487 -0.17339993\n",
      "  0.09264019  0.10245788  0.12336878 -0.07402413 -0.17649122  0.0512572\n",
      "  0.20860526 -0.18934557 -0.25854927  0.03879033 -0.23649494 -0.2119464\n",
      "  0.33438805 -0.13082354 -0.09670953 -0.22081922  0.06664304  0.05112036\n",
      " -0.08650719 -0.15857103 -0.17444941 -0.19601877  0.04752921  0.00865104\n",
      "  0.08577016  0.07457048]\n",
      "L7N0                    -> L8N71 = [-7.86539540e-02 -7.41897002e-02  4.38730158e-02  1.28794789e-01\n",
      "  8.52525830e-02 -3.24655503e-01 -3.08311701e-01 -1.55880183e-01\n",
      "  1.78042240e-02 -1.02118336e-01 -3.45163882e-01 -3.82449217e-02\n",
      "  1.60078242e-01 -4.29748595e-01 -2.31542006e-01  1.36312619e-01\n",
      "  8.25822800e-02 -1.10860467e-01  3.85346636e-02 -2.04500988e-01\n",
      " -2.12093607e-01 -3.35440747e-02 -1.23130903e-01 -1.68298990e-01\n",
      " -4.36282188e-01 -7.01105297e-02 -5.73912598e-02 -1.21814944e-01\n",
      " -8.01061317e-02 -1.29208788e-01 -1.63145781e-01 -3.57845932e-01\n",
      "  6.78653410e-03 -3.76503207e-02 -5.94006032e-02 -6.71295524e-02\n",
      " -2.81424522e-01  1.06106721e-01 -1.69946745e-01 -3.60539556e-01\n",
      " -1.43232480e-01  1.02048360e-01 -2.30012000e-01 -4.93286774e-02\n",
      " -1.56427398e-01 -4.89005260e-02  3.36268358e-03 -1.72586545e-01\n",
      " -5.44725358e-02 -4.05510277e-01  5.43655008e-02 -1.09216422e-02\n",
      " -2.13274539e-01  7.01725541e-04 -1.24383762e-01 -4.30411194e-04\n",
      " -2.49881998e-01  7.48640904e-03 -3.06007355e-01 -8.92818719e-02\n",
      " -8.77296329e-02 -8.03779885e-02 -3.37016076e-01  1.58997178e-02\n",
      " -3.12599726e-03 -6.50652349e-02 -5.94080612e-02 -6.43914845e-03\n",
      " -3.53661329e-01 -8.40868205e-02 -3.45205903e-01 -6.81948289e-02\n",
      "  1.54791623e-01 -4.22417641e-01  5.83420284e-02 -1.86864436e-01\n",
      " -2.28594020e-01 -1.76572159e-01 -3.96740288e-01  9.98988003e-02\n",
      " -1.54612169e-01 -3.18902023e-02  1.54317454e-01 -1.85950384e-01\n",
      " -2.96838433e-01 -1.40592456e-01 -9.49449092e-02  2.87383437e-01\n",
      " -1.24757908e-01 -1.08367419e-02 -3.56187336e-02 -7.63390362e-02\n",
      " -3.50586146e-01 -2.41563335e-01 -1.61020935e-01 -1.05756305e-01\n",
      " -2.64127135e-01 -2.68054008e-01  3.31588392e-03 -2.13044822e-01\n",
      " -2.87557334e-01 -1.11776732e-01 -3.03438962e-01  4.72993590e-02\n",
      " -2.06264749e-01 -1.70244962e-01  1.50451735e-01 -1.96234211e-01\n",
      " -1.48996472e-01 -9.86791477e-02  4.31715772e-02 -6.10421300e-02\n",
      "  7.58656710e-02  8.86751264e-02  2.22651690e-01  8.47277716e-02\n",
      " -3.39450032e-01 -1.35335967e-01 -6.95053712e-02 -7.24487826e-02\n",
      " -8.73319209e-02 -1.32702485e-01 -2.21551433e-01 -2.12818623e-01\n",
      "  9.44982190e-03 -1.09167546e-01 -2.43987426e-01  2.87597179e-02\n",
      " -1.30972266e-01 -2.05854297e-01  2.15219380e-03 -1.96258336e-01\n",
      "  9.15658381e-03 -2.42154598e-01 -2.94617191e-02 -1.53652862e-01\n",
      "  3.24506722e-02  1.39001623e-01 -1.34442344e-01 -1.84839994e-01\n",
      " -3.56054485e-01 -1.74450316e-02 -7.97086954e-02  1.20738350e-01\n",
      "  6.36119163e-03  1.69266865e-01 -1.04886524e-01 -1.71146572e-01\n",
      " -2.78535634e-01 -2.80140013e-01  1.32237673e-01 -1.78085059e-01\n",
      "  1.11854151e-02 -6.99789356e-03 -5.30903935e-01  1.37981713e-01\n",
      " -1.59235895e-01  2.47526139e-01 -3.32481325e-01  2.55521655e-01\n",
      " -1.29621163e-01 -2.46892408e-01 -7.32868090e-02 -2.07340851e-01\n",
      " -4.15206468e-03  1.75838377e-02  4.35856637e-05 -2.03967355e-02\n",
      " -1.19055197e-01 -6.68048561e-02  1.00093342e-01  2.04324543e-01\n",
      " -3.27952921e-01  5.77498861e-02  1.09772749e-01 -2.65521437e-01\n",
      " -1.01181246e-01 -1.27432153e-01 -3.04227948e-01  1.68183416e-01\n",
      "  2.75849700e-02 -1.02415502e-01  7.63749033e-02  1.97884198e-02\n",
      "  5.88584132e-02 -2.81839103e-01  1.49222478e-01 -7.07887858e-02\n",
      "  2.04408169e-01 -9.28184763e-02 -4.50309247e-01 -1.94360852e-01\n",
      "  9.13717505e-03 -3.00358742e-01 -2.71240145e-01 -1.80990309e-01\n",
      " -2.68378407e-01  1.51193095e-02 -8.56698379e-02  1.65520441e-02]\n",
      "L7N0                    -> L8N72 = [ 0.07319373 -0.6444608  -0.08762599 -0.03928594 -0.17446846  0.18986319\n",
      "  0.1962016   0.36188513  0.01354884 -0.01668739  0.10131031  0.13035671\n",
      " -0.10237937  0.04832542 -0.02393631  0.03310971  0.03190969 -0.29473054\n",
      "  0.13434273  0.20600577  0.09937812 -0.03519903 -0.09221499 -0.02474173\n",
      " -0.27750516  0.09899251 -0.10863207  0.05920907 -0.16446626  0.06012998\n",
      "  0.01098611  0.01194756  0.17171773  0.03145045  0.01260582  0.08657349\n",
      " -0.00108819 -0.00592014  0.16087991  0.05943535  0.08793656  0.07070309\n",
      " -0.00330832  0.03438377  0.03015592  0.22133476  0.28824055 -0.06542609\n",
      " -0.11361216  0.01782103  0.25468352 -0.23692869  0.14153284 -0.0428867\n",
      "  0.11815351  0.14235023  0.1251109   0.1164223   0.08051889 -0.2388754\n",
      " -0.15661298 -0.01141973  0.1396448   0.1833945   0.24013653  0.7125644\n",
      "  0.26351812 -0.1347682   0.06144021 -0.04548123  0.05879673  0.33987942\n",
      "  0.12421039  0.21438386 -0.03732135 -0.18768193  0.15137887 -0.04932895\n",
      "  0.0516916   0.07029182 -0.17726573  0.15918311  0.08947533  0.08442772\n",
      "  0.3350808   0.1496723  -0.00269166  0.20254843  0.31800738  0.40410405\n",
      " -0.04077904  0.1254177   0.09352138  0.0185855  -0.10815156  0.22117516\n",
      " -0.28937855  0.11329894  0.10865741 -0.11326363 -0.17872162  0.36476117\n",
      "  0.0240225  -0.23868065  0.0702641  -0.29111093  0.02967519 -0.21344444\n",
      "  0.17522988 -0.10491864 -0.03584434 -0.06113393 -0.38261455  0.28876925\n",
      " -0.07103514 -0.27365968 -0.02026734  0.11495224  0.24239288  0.09089818\n",
      "  0.26260248  0.18025817  0.16505714  0.24260333  0.10465775  0.13750887\n",
      "  0.12085387 -0.12301807 -0.16213581 -0.03276979  0.04383461 -0.04175119\n",
      " -0.05935522  0.08278898 -0.00365608  0.04476917  0.46168855  0.01336153\n",
      "  0.06434807  0.06683549  0.26801684  0.02547293 -0.15158282  0.0483951\n",
      "  0.02555924 -0.05556643  0.18275973  0.05497546  0.13080521 -0.07395066\n",
      " -0.1729486   0.10142916 -0.08108686  0.05481568  0.10536988  0.20708989\n",
      "  0.26538768 -0.12677225  0.10972719 -0.15082547  0.17608249  0.04940294\n",
      " -0.14911538 -0.00612229  0.11568505 -0.02996133  0.04666827 -0.00530521\n",
      "  0.2615722   0.19077213  0.38375336  0.35698104  0.08372398  0.33216438\n",
      " -0.10114068  0.12457168  0.16229716  0.1322437  -0.15443695 -0.1012946\n",
      " -0.19695915  0.02499085  0.2309597   0.15062317  0.25543407  0.0081547\n",
      " -0.04669054  0.0703044  -0.25096452 -0.0597999   0.0789986  -0.20909858\n",
      " -0.07238598 -0.02767221  0.14375749  0.12386802 -0.05916171 -0.2512647\n",
      " -0.00544306  0.08608368]\n",
      "L7N0                    -> L8N73 = [ 0.00720114  0.05889726  0.31192198  0.22249474 -0.01257601  0.14125705\n",
      "  0.08918895  0.36397904  0.09391959  0.09150442  0.29168546  0.03189539\n",
      " -0.06096588  0.15752885 -0.0784358  -0.15933126  0.14738615 -0.03658013\n",
      " -0.12332796 -0.05124471  0.31262574  0.07597114  0.11772743 -0.09126901\n",
      "  0.05043164 -0.01161152  0.0542964  -0.05312505  0.10794101  0.04931625\n",
      "  0.5799273   0.14853187  0.22983693  0.15723252 -0.05576923 -0.0466945\n",
      "  0.19257785  0.14967711  0.2966318  -0.11900964  0.18882559 -0.11184472\n",
      "  0.042866    0.252094   -0.01584225  0.16279794 -0.22932516  0.17504631\n",
      "  0.05678966  0.02584204 -0.07636423  0.369836    0.14834467  0.23863283\n",
      "  0.02167278  0.12428245 -0.02608517  0.13468419  0.03823736 -0.05397268\n",
      "  0.00806864  0.13486753  0.04792094  0.2780951  -0.10445084  0.18536107\n",
      "  0.33591947 -0.12256043  0.19031018  0.24778941  0.07351463  0.01716209\n",
      "  0.03896119  0.17291379  0.08899687  0.1827073  -0.17809914  0.18022124\n",
      "  0.04110895  0.12155508  0.17057611 -0.04710151  0.04061184  0.15306354\n",
      "  0.07986171 -0.08419865  0.19471422  0.13840361  0.02246672  0.06344455\n",
      "  0.26678145  0.0056093   0.10154883  0.41472352  0.0417682   0.17210245\n",
      "  0.19086917  0.19059339  0.05988022  0.16161528  0.07777808  0.08859896\n",
      "  0.04861243  0.2468361   0.05802324 -0.15144333 -0.05973927  0.2308644\n",
      " -0.16131781 -0.13940768 -0.16455384  0.30741554 -0.01069944  0.141471\n",
      "  0.04198857 -0.22073129  0.09563343  0.03036211  0.17429273 -0.11510048\n",
      " -0.09210356  0.02693128  0.24582502  0.24791458  0.20700206  0.10329459\n",
      "  0.01957417  0.06924692 -0.0574524  -0.17482874 -0.07899207  0.0300903\n",
      "  0.1678619  -0.01996945 -0.02010112  0.11898807 -0.00823014  0.01636875\n",
      "  0.23196484 -0.0255037   0.08630335  0.09999877 -0.02895678 -0.01635453\n",
      "  0.05363991  0.03789739  0.09145181  0.15505552  0.13264589  0.5363993\n",
      "  0.05969426 -0.10167895 -0.07352751  0.26559314  0.08208709  0.04750294\n",
      " -0.02902002  0.12137325  0.16175956 -0.05638594  0.18355706  0.29419142\n",
      "  0.05225659  0.03005498 -0.10560263  0.12589741 -0.21479593 -0.03149706\n",
      "  0.04820396  0.2217345   0.03868477  0.1952335   0.1325588   0.136455\n",
      "  0.26177615  0.17692325  0.17492324  0.01183273  0.13880765 -0.1642954\n",
      "  0.07963995 -0.04776111 -0.04787624  0.15264736 -0.05850471  0.04062075\n",
      "  0.11300329  0.2104847  -0.03928786 -0.10049696  0.3137553   0.14100187\n",
      "  0.06972425 -0.04616083 -0.03423783  0.18536921  0.17163488 -0.12304514\n",
      "  0.12759732  0.24118166]\n",
      "L7N0                    -> L8N74 = [ 0.1401901  -0.12748133 -0.00527415 -0.0395379   0.1637598  -0.14521557\n",
      " -0.287034   -0.07754799  0.12129756 -0.12216862  0.28487954 -0.10427333\n",
      " -0.24906486 -0.15751345 -0.00455939 -0.28068256 -0.11155655  0.08586922\n",
      " -0.04825049  0.1730065   0.03886583  0.06690495 -0.00228958  0.11810639\n",
      " -0.01541066 -0.21173103 -0.01368212 -0.14036359 -0.10885673 -0.19314846\n",
      " -0.15208611 -0.01617327  0.01251846 -0.03513904 -0.03909958 -0.23602423\n",
      " -0.1417234  -0.1569734   0.00551024  0.09196304 -0.19922544  0.13527289\n",
      " -0.15054767 -0.21527489 -0.15068705 -0.09708428 -0.20719244 -0.1506482\n",
      " -0.2382747  -0.02650855 -0.21723361 -0.0438378  -0.25608632 -0.07643874\n",
      " -0.13499407  0.01416872  0.04123393 -0.16933183 -0.1729022   0.21629547\n",
      " -0.21078475 -0.30402675 -0.07343173  0.02076321 -0.12474734 -0.07998257\n",
      "  0.11761352 -0.1507538  -0.22024094 -0.11596165  0.0076964  -0.10506802\n",
      " -0.10891172  0.04637073 -0.05293527  0.13280772 -0.10796081 -0.02839546\n",
      " -0.30755818 -0.01785232 -0.0703878  -0.19773594 -0.30774918  0.08198991\n",
      "  0.14633916  0.19824184 -0.00788261 -0.00793139 -0.22065037 -0.09361973\n",
      " -0.11214744 -0.26626986 -0.18313365 -0.3059278  -0.09192166 -0.01947308\n",
      "  0.21284021 -0.11757334 -0.12443962 -0.1584166  -0.09222605  0.0126102\n",
      " -0.1989744   0.10796061 -0.11222771  0.12759909 -0.28742698  0.05609655\n",
      " -0.14937472 -0.3131551  -0.29691157 -0.10228124  0.08908898 -0.03485279\n",
      " -0.35918987 -0.15785758 -0.21294262 -0.07887062 -0.0682833  -0.11952828\n",
      " -0.06285244 -0.34447423 -0.2028504   0.06124098  0.02626746 -0.11167125\n",
      " -0.09962852 -0.16031544 -0.15314588  0.05485545 -0.06650747 -0.13776949\n",
      "  0.14546232 -0.05667087 -0.13235037  0.12244705  0.1684591  -0.3468808\n",
      " -0.00701348  0.00875835 -0.17891014 -0.14286    -0.07656948 -0.20750943\n",
      " -0.03257754 -0.05976486 -0.26617417 -0.16583401 -0.0112768  -0.1539913\n",
      " -0.03039906 -0.23437217 -0.23787326 -0.3234784   0.03373155 -0.19662955\n",
      "  0.14204632 -0.24385892  0.17892669 -0.22861898 -0.12240225 -0.09125108\n",
      "  0.1274512  -0.1502557  -0.24204162  0.03779304  0.00734828 -0.10336282\n",
      "  0.15644053 -0.01028823 -0.18090975 -0.02027125  0.14908645 -0.0589348\n",
      "  0.17841358  0.08811959  0.01184364 -0.01805977 -0.05939279 -0.3032573\n",
      " -0.27234235 -0.16769944  0.24833092 -0.07259117 -0.40911478 -0.00648046\n",
      " -0.23373888  0.02559539  0.14660503 -0.06713177  0.4657719   0.14337792\n",
      "  0.15179318  0.09779081  0.01457175 -0.20080279 -0.08408676 -0.2018429\n",
      " -0.2684975   0.03485622]\n",
      "L7N0                    -> L8N75 = [-0.07611792  0.0413209  -0.01810404 -0.4167798   0.17095914  0.18255663\n",
      "  0.04629095 -0.07616986 -0.06714169  0.13145168  0.04305157 -0.06222698\n",
      "  0.20638338  0.29678628 -0.00072463 -0.02138017 -0.24994926 -0.24282832\n",
      "  0.07811607  0.12385374 -0.05446852  0.11935331 -0.04331318  0.34610024\n",
      " -0.15144998  0.01860052 -0.03722046 -0.05275226 -0.03487087 -0.20363835\n",
      " -0.11742581  0.3700057   0.18057284 -0.04729803 -0.0351055   0.22405575\n",
      "  0.17501238  0.2140992   0.00609392  0.02819855  0.31407204 -0.00397028\n",
      "  0.09631918 -0.03894095 -0.09350983  0.02194733  0.28411615 -0.00809991\n",
      "  0.25144583  0.16141762  0.27794582  0.02156162  0.15128917 -0.0609589\n",
      " -0.13697751 -0.04307849  0.07209411  0.16336994  0.1873797   0.07946311\n",
      "  0.04400775  0.00082607 -0.20571592  0.0779941  -0.02679426 -0.01748664\n",
      "  0.04966752  0.0441783   0.19888547  0.0966984   0.03916803  0.1924268\n",
      "  0.14646384 -0.14039424  0.05283235 -0.14863569  0.1325479  -0.4598202\n",
      "  0.10635585 -0.02912831  0.19871782  0.23474325  0.1392637   0.02098154\n",
      " -0.11820526 -0.05091015  0.09576201 -0.04073672  0.05245965  0.20401669\n",
      " -0.2269242  -0.01936546 -0.05228172 -0.0660096   0.2603976  -0.18771395\n",
      "  0.16712043 -0.19491754  0.18001972  0.05393256  0.05396462  0.07603645\n",
      " -0.22584426 -0.0095274  -0.09735417 -0.13180177 -0.3803996   0.01079081\n",
      "  0.00994281  0.1190607  -0.30371898  0.2627167  -0.19476852 -0.26822713\n",
      "  0.10537346 -0.15245387 -0.00885513  0.25770223  0.04788014 -0.1581088\n",
      "  0.15742435  0.18779336 -0.03530081  0.16486831  0.04452264  0.00255506\n",
      "  0.18762876 -0.07853905 -0.12893003  0.19164021  0.06787334  0.09126227\n",
      " -0.10598717  0.19986178  0.13688493  0.14957984  0.22971176  0.1147585\n",
      "  0.04128122 -0.07602859  0.02568781  0.20651871 -0.24924254  0.01518385\n",
      " -0.27508828 -0.04077561 -0.07112238 -0.06408278 -0.12401742  0.04213078\n",
      " -0.24734521 -0.04251275 -0.06531527  0.21595667  0.03838858  0.22762555\n",
      "  0.17335024  0.0716548  -0.00611442  0.21734679  0.10100789 -0.02593156\n",
      " -0.26699322 -0.21066229 -0.18562728 -0.12087793 -0.27141201  0.12627916\n",
      "  0.08676819 -0.05809481  0.13549025  0.07412866  0.2607325   0.07435724\n",
      " -0.15825701 -0.11803311 -0.18909024  0.3567059  -0.01840924 -0.07230017\n",
      " -0.2727813   0.15392129  0.25258207 -0.11479549  0.00838963 -0.04157238\n",
      "  0.05167146 -0.02716918  0.09717891 -0.19563292 -0.22301827 -0.14969563\n",
      " -0.1585043  -0.00306045 -0.04373927  0.27583405  0.02440624 -0.10784833\n",
      "  0.08010179 -0.06240633]\n",
      "L7N0                    -> L8N76 = [ 0.00277729  0.12108815  0.12939242  0.00557169 -0.25116387  0.17434004\n",
      "  0.15840796 -0.02244419  0.16135287  0.08612161  0.09798981 -0.24224359\n",
      " -0.11778577 -0.02346739  0.1720007  -0.27867016  0.03676154 -0.20611402\n",
      " -0.03260449 -0.20151044 -0.0518977   0.00283713  0.22355284  0.03593746\n",
      "  0.0752819  -0.10608272 -0.24889866 -0.19028722 -0.06511842  0.03913266\n",
      " -0.05271887 -0.12062326 -0.14210232 -0.07548568 -0.03276658 -0.2911123\n",
      " -0.22461782  0.08338309  0.003063    0.30702454 -0.08680184 -0.08011503\n",
      " -0.08329682  0.06604763  0.10409489 -0.42004552 -0.24350183 -0.0594341\n",
      " -0.26496485 -0.01310595 -0.24775778 -0.00223852  0.1683865   0.05388562\n",
      " -0.22220628 -0.1320931  -0.01986795  0.17610393 -0.12713191 -0.31673017\n",
      " -0.01873648 -0.11995087  0.05079497 -0.3550468   0.04579364 -0.06107249\n",
      "  0.03713977 -0.04249397 -0.08815204  0.12774424 -0.08986676 -0.30011556\n",
      "  0.09309019 -0.02241016  0.17544046  0.13135155 -0.08899635 -0.37601015\n",
      " -0.07199706 -0.1467071   0.2182318  -0.01556667  0.07936819 -0.15658367\n",
      "  0.08536389  0.02641286  0.00589473  0.2343013  -0.04923391 -0.10219081\n",
      " -0.19792683 -0.11500707  0.07140023 -0.05617867 -0.33811218 -0.07445994\n",
      " -0.01269232  0.00840202  0.00382485 -0.03895479 -0.02840621 -0.21477117\n",
      " -0.24682415  0.14603812 -0.02237656 -0.00451106 -0.40158877 -0.13368642\n",
      "  0.0846307  -0.03457386 -0.32900885  0.00956142 -0.37723956 -0.07668801\n",
      " -0.25394908 -0.14176473 -0.02007915 -0.40173247 -0.19430001  0.06649667\n",
      " -0.23118941 -0.13274293 -0.08674466  0.04496679 -0.00888392  0.09033863\n",
      "  0.11604934 -0.14794646 -0.34763417 -0.14650704  0.07639591  0.07769378\n",
      "  0.22957963 -0.16821213 -0.18111382 -0.26589498  0.00109047 -0.13199687\n",
      "  0.20089865 -0.08332878 -0.06241073 -0.3935751  -0.24544384 -0.3812289\n",
      " -0.02748386 -0.16787393 -0.07670923  0.12225486  0.04959884  0.095635\n",
      " -0.28805983 -0.08094676 -0.24478096 -0.01081333 -0.13418792 -0.00247051\n",
      "  0.05044687 -0.21964855  0.07103547 -0.05212041 -0.03972783 -0.11831597\n",
      "  0.05639441 -0.2691071  -0.07854426  0.04060791 -0.20393227 -0.06923021\n",
      "  0.2737499  -0.07954379 -0.05451936 -0.04020072  0.26960358 -0.11163977\n",
      " -0.32590243 -0.16745472  0.06784855  0.08473937  0.12786505  0.13311087\n",
      " -0.4128006  -0.0698458  -0.19962315 -0.04406025 -0.38854066 -0.1722403\n",
      " -0.3648795   0.0401153  -0.27832913 -0.19376123 -0.01679759 -0.0416059\n",
      "  0.05231399  0.10508184  0.1262725   0.26018545 -0.04298856 -0.45631495\n",
      "  0.10496832 -0.19421217]\n",
      "L7N0                    -> L8N77 = [-0.18229312 -0.11685757 -0.31228185 -0.08273652 -0.05856147  0.03415371\n",
      "  0.04408817 -0.07481788 -0.04842734 -0.0177774  -0.07415573 -0.130808\n",
      " -0.16999446  0.00834251  0.14271355  0.13484326 -0.05887946 -0.00586134\n",
      " -0.02294461  0.10870207 -0.04990742 -0.12175604 -0.26283088 -0.23501192\n",
      " -0.10902952 -0.01666363 -0.0781071   0.06529047  0.1503298  -0.13004246\n",
      " -0.32920793 -0.4448142  -0.08234841 -0.17351429 -0.07804991  0.15667126\n",
      "  0.04704888 -0.024686   -0.0105671   0.04679363  0.03759214  0.02724128\n",
      " -0.21717118 -0.23540294 -0.29984397 -0.09809507 -0.14349025 -0.10704651\n",
      " -0.09577675 -0.14952438  0.15170214 -0.04438866 -0.14762436 -0.13592838\n",
      "  0.06410945 -0.26493877 -0.02764738 -0.23289835 -0.05832601 -0.06282818\n",
      " -0.25560787  0.10789559  0.00509899 -0.0398174  -0.20574489 -0.04503503\n",
      " -0.10011999 -0.08059342 -0.0116839  -0.02657603  0.09941213 -0.08952609\n",
      " -0.06898675 -0.26512825  0.06811218 -0.1945153   0.17549448 -0.18993224\n",
      " -0.17349795 -0.17413868  0.23763531 -0.22139098 -0.19775926  0.11287951\n",
      " -0.51940054  0.04765897 -0.00151505  0.2734427   0.14352985 -0.16903715\n",
      " -0.3777479  -0.15218122  0.06018116  0.05363381  0.08099997 -0.06367923\n",
      " -0.05010371  0.00221106 -0.16582261 -0.19890553  0.13463207 -0.22382385\n",
      " -0.08391938 -0.04725807  0.03624779 -0.07188076 -0.16787517 -0.10769282\n",
      " -0.03117795 -0.2035599  -0.09869859  0.09084423  0.12307271 -0.17363344\n",
      " -0.36729622 -0.1093206  -0.23650347 -0.15772513 -0.02844475 -0.08340625\n",
      " -0.18146846 -0.25277638 -0.0160851  -0.08464598 -0.04002887 -0.11759544\n",
      " -0.12677193 -0.05734508 -0.04710712  0.0361321  -0.10842258 -0.2872811\n",
      " -0.32061234 -0.14401487  0.11760452 -0.13525625 -0.0307449  -0.11236878\n",
      " -0.27074507 -0.1556986  -0.32721078  0.04891882 -0.19081026 -0.07595135\n",
      "  0.33264825  0.08428382 -0.01329074 -0.19839297 -0.32248747 -0.06734487\n",
      " -0.07902896  0.09345479 -0.24644926 -0.06471463 -0.05669062 -0.19017282\n",
      " -0.30968598  0.03655911 -0.27980757 -0.30431107 -0.22656901  0.15850763\n",
      " -0.28012356 -0.2816884   0.10765468 -0.20649274 -0.17026198  0.07603115\n",
      "  0.190807    0.00528395 -0.23203403 -0.28948966 -0.21275778 -0.08283838\n",
      " -0.02333481 -0.08941878 -0.22811364  0.126432    0.04600258 -0.13552596\n",
      " -0.01927133 -0.10170131  0.01587428  0.11957012 -0.20861718  0.03140695\n",
      " -0.2496138  -0.00752981 -0.0867225  -0.38883066 -0.12662797 -0.20293476\n",
      " -0.09201188  0.19589739 -0.094138   -0.2732903  -0.15502582 -0.06636118\n",
      " -0.05878771  0.14709836]\n",
      "L7N0                    -> L8N78 = [-4.25907597e-02  8.11604410e-02  8.78528953e-02 -1.22939289e-01\n",
      " -2.77673453e-01  6.16320074e-02  1.39373617e-04  1.55550148e-03\n",
      "  7.82607943e-02 -3.68820429e-02  8.51978082e-03 -2.89788783e-01\n",
      "  3.72381397e-02  1.92324705e-02  7.95864463e-02 -1.06973507e-01\n",
      " -2.67781857e-02 -1.03736572e-01  1.29223503e-02  1.82234004e-01\n",
      "  1.39949426e-01 -1.83952898e-01 -7.33761862e-02  1.16674140e-01\n",
      "  1.59591600e-01  1.49647519e-01 -2.15829343e-01  3.66288424e-02\n",
      " -1.60967931e-01 -1.36955500e-01 -1.51833296e-02 -1.33972257e-01\n",
      "  1.96904600e-01 -1.56289533e-01 -1.09102562e-01  9.01682898e-02\n",
      " -9.73188654e-02  2.38678213e-02  2.44193058e-02 -3.13192531e-02\n",
      "  5.64948060e-02 -1.67513881e-02 -2.00786199e-02 -1.37235388e-01\n",
      "  1.34028986e-01 -4.97128367e-01 -3.39551158e-02  6.69698119e-02\n",
      " -1.14430852e-01 -1.53451765e-04 -2.92065531e-01  9.12343487e-02\n",
      "  6.94023669e-02 -1.84740871e-01 -3.25283855e-01  2.65020013e-01\n",
      "  8.29577968e-02 -2.49590561e-01 -1.76245064e-01 -3.64230990e-01\n",
      "  1.25955969e-01 -1.63524374e-01  1.14230178e-01 -3.81378755e-02\n",
      " -8.14454537e-03 -4.75553870e-02 -1.36346221e-01 -2.18245745e-01\n",
      " -5.18598370e-02  9.81042534e-02 -2.02215705e-02  5.86367119e-03\n",
      "  2.50251025e-01 -1.53229430e-01 -2.80148327e-01 -9.29252356e-02\n",
      " -1.12340011e-01 -9.51059610e-02  2.52157971e-02  4.80465144e-02\n",
      "  1.33902002e-02  2.05420211e-01  1.48965791e-02 -1.20095156e-01\n",
      "  1.73140913e-01  5.77170812e-02  2.09038500e-02  2.49848608e-02\n",
      " -2.67138898e-01 -2.60408580e-01 -1.52388081e-01 -7.75420070e-02\n",
      " -3.75937857e-02 -5.29256500e-02 -9.62401405e-02  1.14591859e-01\n",
      " -1.64330378e-01  3.38848424e-03  1.25616859e-03  1.32955283e-01\n",
      " -8.47838372e-02 -3.90566997e-02  2.28406802e-01 -2.68988103e-01\n",
      " -1.60622057e-02 -3.89451206e-01 -1.73159465e-01  2.95993567e-01\n",
      " -6.29012063e-02  6.11228272e-02  1.16340660e-01  1.17018200e-01\n",
      " -2.15048820e-01 -4.76830378e-02 -2.17949048e-01 -3.69957060e-01\n",
      " -4.62170169e-02 -4.97405417e-02 -2.00922549e-01 -6.17292374e-02\n",
      " -2.02245377e-02  2.79232375e-02  4.02048826e-02  3.71818170e-02\n",
      " -5.12473620e-02  1.06886579e-02 -9.64284316e-02 -1.90560985e-02\n",
      " -6.47976696e-02 -1.04820430e-01  2.10896432e-01  7.15105087e-02\n",
      "  9.56286117e-02 -1.80850342e-01  5.80599979e-02 -7.68375397e-02\n",
      "  1.14229724e-01 -2.29547158e-01  3.25412899e-01 -2.58119311e-02\n",
      "  6.07071854e-02 -1.29015312e-01  8.93469974e-02  1.36067793e-01\n",
      "  2.29691267e-01 -4.48859185e-01 -1.74295485e-01 -2.48683587e-04\n",
      " -1.08449338e-02  5.48054017e-02  8.24400783e-02 -4.95203696e-02\n",
      "  8.00112635e-02 -2.10580513e-01  2.14138031e-02 -2.21972719e-01\n",
      " -4.51626219e-02 -2.47983530e-01 -2.66813874e-01 -3.00790042e-01\n",
      "  1.24249913e-01 -8.40702951e-02  1.01962119e-01 -9.60161537e-02\n",
      " -1.10659339e-01 -9.93568599e-02 -2.06030905e-02 -5.27669452e-02\n",
      "  4.44668345e-02  1.18458517e-01  1.21645749e-01 -3.61162633e-01\n",
      " -1.90127999e-01  1.07002042e-01 -1.25797182e-01  8.06645378e-02\n",
      "  1.92512289e-01  2.94613279e-02 -1.58555225e-01 -5.81695661e-02\n",
      " -5.00120223e-02  2.76229501e-01 -3.90245505e-02 -1.03421658e-01\n",
      "  2.02161744e-02  1.10818334e-01 -3.42023283e-01  1.96522340e-01\n",
      " -1.50935605e-01  2.62949735e-01 -9.94716212e-02 -2.60115534e-01\n",
      " -1.59037694e-01 -1.05801769e-01  3.52955163e-01  1.09657474e-01\n",
      " -1.38163731e-01 -8.29408467e-02 -2.29949597e-02  6.01168163e-02]\n",
      "L7N0                    -> L8N79 = [-4.15403277e-01  7.84836337e-02 -3.26825827e-01 -1.91969663e-01\n",
      " -1.89419910e-01  9.16378871e-02 -1.08878843e-01 -4.75773998e-02\n",
      "  4.46068235e-02 -7.90188238e-02  5.75017594e-02  1.01197682e-01\n",
      " -2.94430375e-01 -3.70142534e-02  1.98433042e-01 -3.26474383e-02\n",
      " -2.05506191e-01 -3.24374616e-01 -3.00427582e-02  1.83088988e-01\n",
      "  1.12714700e-01 -1.67297333e-01 -1.51760057e-01 -2.11054273e-02\n",
      " -9.94482785e-02 -2.22153187e-01 -2.78389186e-01 -3.87814522e-01\n",
      " -1.35655656e-01 -6.41698018e-02  1.15669100e-02  2.84285583e-02\n",
      " -1.39399633e-01  5.47525510e-02 -2.45435253e-01 -4.68676686e-02\n",
      " -7.57279247e-02  6.42198846e-02 -2.22991794e-01  1.35098398e-01\n",
      "  6.15174510e-02  7.83275440e-02 -5.86358190e-01  1.56937405e-01\n",
      "  1.37104675e-01  1.67428315e-01 -7.42981490e-03 -1.74858555e-01\n",
      " -3.35161127e-02 -2.62269769e-02  2.14840069e-01 -5.10453358e-02\n",
      "  8.16267058e-02 -1.02718450e-01 -1.69503793e-01  1.25166789e-01\n",
      " -2.22685754e-01  1.23449855e-01 -2.24952236e-01 -1.92141786e-01\n",
      "  3.49170342e-02 -3.93826589e-02  1.26272961e-01 -3.35219540e-02\n",
      " -2.08612829e-01 -8.11443254e-02  4.58497293e-02 -1.21340446e-01\n",
      "  9.17379931e-02 -3.06850046e-01 -1.78613052e-01 -5.15345670e-02\n",
      "  2.94410922e-02 -1.10633355e-02 -3.60213108e-02 -7.27302209e-02\n",
      "  8.91130865e-02 -3.55830453e-02 -9.58427340e-02 -2.46955201e-01\n",
      "  2.76763648e-01 -5.92059195e-02 -1.07000545e-01 -5.28550632e-02\n",
      " -8.84679109e-02 -1.28421083e-01 -5.43256812e-02  5.60103729e-02\n",
      " -8.54432434e-02 -8.84569138e-02  1.85819969e-01 -2.54280597e-01\n",
      "  4.52651940e-02  1.19105682e-01 -2.75232255e-01 -1.98496088e-01\n",
      " -2.55219579e-01 -1.72984242e-01  5.86411841e-02  1.05949111e-01\n",
      " -3.11032891e-01 -1.29750699e-01  1.39552742e-01  5.52893765e-02\n",
      " -6.70304298e-02 -2.24792108e-01 -2.23545492e-01 -3.56150627e-01\n",
      " -3.18478644e-02 -1.87518626e-01 -2.33381674e-01 -1.58511579e-01\n",
      " -1.21754028e-01  1.53695747e-01 -8.48664120e-02 -2.36654863e-01\n",
      " -2.39777476e-01 -1.04479611e-01  8.83373711e-03 -9.69090909e-02\n",
      "  3.71678844e-02 -2.05005988e-01  9.03932564e-03 -1.82187743e-02\n",
      " -1.67671889e-02 -1.36538014e-01 -1.14208587e-01 -2.10742518e-01\n",
      " -3.34237255e-02 -5.04087582e-02  9.52867568e-02 -1.45937398e-01\n",
      "  1.36262059e-01  4.51895036e-02 -2.58687865e-02 -3.46835367e-02\n",
      "  1.35175616e-01 -2.17569575e-01  1.21433318e-01 -6.89649805e-02\n",
      "  1.28643885e-01  4.19879444e-02 -8.49037766e-02 -1.88252777e-01\n",
      "  3.75253350e-01 -2.80759424e-01 -1.13441810e-01  2.47309301e-02\n",
      " -3.34549725e-01  2.42410272e-01 -1.25881851e-01  8.45042095e-02\n",
      " -1.15614675e-01  1.17520429e-01  1.95857763e-01  1.18539281e-01\n",
      " -1.49253637e-01 -1.66670799e-01 -4.92090493e-01  3.98186996e-04\n",
      " -2.61074543e-01 -5.47807664e-02 -2.64835298e-01 -1.32214516e-01\n",
      " -2.08649069e-01  4.53269295e-02 -1.12219311e-01  2.03907788e-02\n",
      " -1.99451357e-01 -5.89925656e-03  3.03281210e-02  9.58579108e-02\n",
      " -1.39751568e-01 -6.17458262e-02 -2.24596471e-01 -3.24492157e-01\n",
      " -2.83657521e-01 -7.43910372e-02 -7.11515844e-02  2.19882522e-02\n",
      "  8.61614197e-02 -1.49275884e-01 -3.82536501e-01 -2.88673431e-01\n",
      " -1.52955413e-01 -3.40272523e-02 -1.21951036e-01 -7.45768175e-02\n",
      "  1.15251929e-01  5.79557288e-03 -1.25556752e-01 -3.50249931e-02\n",
      "  1.09224990e-01 -5.45812324e-02  1.11143723e-01  1.38474762e-01\n",
      "  2.61219740e-02 -3.85296106e-01  4.85281460e-02  1.65119469e-01]\n",
      "L7N0                    -> L8N80 = [-0.26692098 -0.189822   -0.10378624 -0.27078283  0.07010709  0.160134\n",
      "  0.09947728  0.04888091  0.25813338  0.0436094   0.15803742 -0.1296432\n",
      "  0.01948159  0.17351021  0.07193637  0.03139606  0.19134372 -0.19954178\n",
      " -0.06875837  0.18460539  0.05603963  0.15558143 -0.07677031  0.25239468\n",
      " -0.06190872  0.2833883   0.01022968 -0.22204511  0.03225304 -0.17377916\n",
      " -0.00866604  0.38004002 -0.06801402  0.28633678  0.21609652  0.10221738\n",
      " -0.10403212 -0.08078757 -0.19474308  0.12062773 -0.06032012 -0.23157482\n",
      " -0.0035123  -0.02660915  0.08665463  0.21108098  0.302096    0.19490194\n",
      "  0.0517289   0.15571414  0.19087954  0.16837093  0.27269483  0.0695949\n",
      "  0.05103635 -0.17904647  0.00315013  0.07576237  0.0410288  -0.16916487\n",
      "  0.18040352 -0.07051965  0.01332519  0.07002511  0.22642107 -0.0389348\n",
      " -0.01322005  0.16443771 -0.07617806  0.15019177  0.19202137  0.21819852\n",
      " -0.01456514  0.18646155  0.03259795  0.00140193  0.1103432  -0.30073017\n",
      "  0.05761223  0.1979131   0.09652746 -0.16072774  0.00586004  0.3075595\n",
      "  0.27913344 -0.03086632  0.08664927  0.01119194  0.1657156  -0.13086063\n",
      " -0.32824773 -0.04748463  0.10094675 -0.14017199  0.1421817   0.03441338\n",
      " -0.23685463  0.01056411  0.05518898  0.00503901  0.08267085  0.20595728\n",
      "  0.12274124 -0.1561246   0.12832779 -0.10800469 -0.15500183 -0.08510106\n",
      " -0.0524581  -0.04342939  0.14529768  0.14509714 -0.07329392  0.11436245\n",
      " -0.23513725 -0.43510807  0.13530453  0.08816014  0.09690245  0.06319588\n",
      "  0.12534687  0.0271736   0.06788965 -0.05081776 -0.28247336 -0.02829545\n",
      "  0.08052218 -0.13334198 -0.07363123  0.08720756 -0.05995002  0.10368189\n",
      " -0.11790497  0.10021529  0.09571679  0.18601057  0.17731525  0.2558194\n",
      "  0.14658111 -0.03296163  0.29902554 -0.00482674 -0.04454762  0.19389546\n",
      " -0.1420511  -0.09046935  0.25643018  0.02624001 -0.04834862  0.26028553\n",
      " -0.10423916 -0.04430396  0.03703607 -0.01050011  0.10068416  0.18148415\n",
      " -0.05522386 -0.04618512  0.2466089  -0.08179052  0.05437647  0.15976082\n",
      " -0.22797112  0.14094707  0.10854869  0.04478463 -0.11227525  0.01298407\n",
      "  0.32151332 -0.11775225 -0.27043682  0.43066174  0.02553332  0.1758446\n",
      " -0.2294628  -0.08220001 -0.05604748  0.04742922  0.06015864  0.0424099\n",
      " -0.14871581  0.10316298  0.5000343  -0.13457717  0.38738573  0.04416105\n",
      " -0.14331265  0.09324437 -0.05191797 -0.12081642 -0.22975057 -0.27027744\n",
      " -0.12478156 -0.12898324 -0.16206418  0.31150278  0.01754399  0.08567547\n",
      "  0.02904802 -0.2676382 ]\n",
      "L7N0                    -> L8N81 = [ 5.50446175e-02 -4.86138128e-02 -1.83143377e-01  5.63755967e-02\n",
      " -5.28175123e-02 -3.67933847e-02 -3.73976342e-02  2.14756243e-02\n",
      " -1.08994329e-02  1.64954290e-01  1.56597510e-01 -1.55347973e-01\n",
      " -2.99609095e-01  7.90868402e-02  1.41008377e-01 -3.43335420e-02\n",
      "  1.14728294e-01 -8.96662176e-02 -1.59667969e-01 -9.50876400e-02\n",
      " -1.42400339e-01 -1.69039201e-02 -4.97561209e-02  1.23144366e-01\n",
      " -2.75291689e-02 -9.75343138e-02 -4.41529714e-02 -2.87386864e-01\n",
      "  1.48362899e-02 -2.38873720e-01 -1.84443384e-01  7.14422315e-02\n",
      " -2.07324520e-01 -5.64085245e-01 -2.12099344e-01 -2.32346639e-01\n",
      "  8.20628274e-03  7.78255314e-02 -7.72036463e-02  9.31039676e-02\n",
      "  3.49460483e-01  1.61431618e-02 -1.99370176e-01 -7.28202313e-02\n",
      " -1.90073684e-01  1.37840256e-01  2.05820113e-01 -1.87246185e-02\n",
      " -5.04117757e-02 -3.87556106e-01  2.57151484e-01 -2.01373756e-01\n",
      " -6.23902865e-02 -1.69267934e-02 -1.09766752e-01 -2.64468729e-01\n",
      " -3.23885888e-01 -1.43937856e-01 -2.28780448e-01  1.67158678e-01\n",
      "  5.10610081e-02 -7.38476962e-02 -1.30668968e-01  9.11062956e-02\n",
      "  2.97958367e-02  3.69721688e-02 -2.58254647e-01  7.54019171e-02\n",
      " -2.94680409e-02  1.39294773e-01  2.65055317e-02  1.36377020e-02\n",
      " -2.19118550e-01 -5.78036197e-02  1.38395011e-01 -1.29548952e-01\n",
      " -1.03771254e-01 -7.16215149e-02 -1.75093159e-01  3.73261683e-02\n",
      " -3.35811198e-01 -9.03382897e-02 -2.35394761e-01 -2.07655616e-02\n",
      " -1.46895545e-02 -3.82250220e-01 -2.90798843e-01 -5.31273603e-01\n",
      "  9.22905877e-02 -3.80482562e-02 -2.12694556e-01  1.79641873e-01\n",
      " -1.94911763e-01 -1.26759320e-01 -2.76676148e-01  4.32571024e-02\n",
      " -2.42004972e-02 -1.18137911e-01  5.34252226e-02 -1.35827541e-01\n",
      "  1.64765000e-01 -1.54265016e-01 -8.44850540e-02 -3.53252888e-01\n",
      " -1.24953184e-02  8.44447911e-02 -4.09571417e-02  3.71656679e-02\n",
      "  1.96212247e-01 -3.28378454e-02  1.44344214e-02  1.36381373e-01\n",
      "  5.85585721e-02 -4.56837146e-03  2.65912861e-01  4.95464318e-02\n",
      "  1.51377648e-01  1.64502650e-01  1.07414924e-01 -9.10440907e-02\n",
      "  2.33632475e-01 -9.98930708e-02  6.47184551e-02 -5.72940037e-02\n",
      " -1.50948986e-01 -8.19723159e-02 -9.88803804e-04  2.82388031e-01\n",
      "  7.17927739e-02 -3.85246515e-01  1.55658811e-01 -2.36886978e-01\n",
      " -2.11996753e-02  3.15161943e-01 -4.67132702e-02 -1.05909906e-01\n",
      " -2.49614134e-01  1.68574944e-01  1.09630987e-01 -9.65840667e-02\n",
      "  1.24679588e-01  9.40872058e-02 -1.36823475e-01  1.18650086e-01\n",
      " -1.07087396e-01  1.58123180e-01  8.13800395e-02 -1.29835689e-02\n",
      " -1.08983189e-01  8.36432353e-02 -1.36765793e-01 -1.22327879e-01\n",
      "  3.02082479e-01  5.07365272e-04  2.89202835e-02  4.61650819e-01\n",
      " -4.90826666e-02 -2.35899165e-01  5.84907830e-02 -2.05538748e-03\n",
      " -2.41550039e-02 -3.43773351e-03 -8.83981064e-02 -2.46956736e-01\n",
      " -4.44340594e-02 -1.82383403e-01 -1.27562648e-03 -1.85715958e-01\n",
      " -4.52128053e-01  4.48568724e-02 -4.34995204e-01  1.75115585e-01\n",
      "  1.89540729e-01 -2.99590435e-02 -1.53202796e-02 -1.33781612e-01\n",
      "  1.25960365e-01 -1.71788633e-01 -6.64078072e-02 -5.96626364e-02\n",
      "  1.42179906e-01 -3.37623917e-02  3.99793297e-01 -4.11231697e-01\n",
      "  2.52331514e-02 -2.93019060e-02  1.99056715e-01 -5.55356592e-02\n",
      "  2.08737329e-01  4.23886394e-03 -4.12603408e-01 -1.18737198e-01\n",
      " -3.95523071e-01 -4.50097322e-02 -3.07534575e-01  1.59643486e-01\n",
      "  1.44090772e-01 -1.47719653e-02 -4.89132553e-02 -1.21348202e-01]\n",
      "L7N0                    -> L8N82 = [ 0.01192343 -0.02855974 -0.08965571  0.20273879  0.08441429  0.00661562\n",
      " -0.28327075  0.016548   -0.2249777  -0.0808562  -0.17939287 -0.16597606\n",
      " -0.15385446 -0.02879387 -0.02007191 -0.02804989  0.09355612  0.08478648\n",
      " -0.05405713 -0.11166453 -0.13292031 -0.03069364 -0.3365997  -0.11181387\n",
      "  0.15270525 -0.08931985  0.1025457  -0.03303871 -0.03192802 -0.0919235\n",
      "  0.11688183 -0.02187531 -0.15136802 -0.2569969   0.07927385  0.11453594\n",
      " -0.04490496 -0.04955047  0.18604207 -0.05887465 -0.13679887 -0.18592343\n",
      " -0.17954284 -0.08263639 -0.18697292  0.2383521  -0.16813104 -0.07325016\n",
      "  0.06415951  0.09829217  0.03041617  0.16499239 -0.12402593 -0.09484553\n",
      "  0.32568026  0.14526334 -0.10009135  0.08511106  0.01690445 -0.06611846\n",
      " -0.08836535 -0.10719444 -0.30848455 -0.10491712 -0.19181329 -0.07660652\n",
      "  0.08027511 -0.09714691  0.06481986 -0.01342492 -0.35197693 -0.14318074\n",
      " -0.1413036   0.08105236 -0.30379918  0.16053373 -0.02173796  0.02787154\n",
      " -0.07941016 -0.01271349 -0.19111472  0.1274234  -0.01715466 -0.08728065\n",
      "  0.06936812 -0.425777    0.05694625 -0.19055705  0.09706201  0.1442845\n",
      " -0.30146748  0.00655229 -0.04640187 -0.16892229  0.19728617  0.17689942\n",
      " -0.01709567  0.1122827  -0.06551091 -0.02418889 -0.23746715 -0.26723388\n",
      " -0.31475028  0.07305045 -0.145696    0.0930746  -0.1584999   0.13941693\n",
      "  0.07440564  0.3347375  -0.23400117 -0.27048066 -0.05521091 -0.20221151\n",
      "  0.21435186  0.03834844  0.01930428 -0.11210541 -0.15498862 -0.1844746\n",
      "  0.03377765  0.03611511  0.02011489 -0.02191019 -0.18742651  0.08237531\n",
      "  0.11377249 -0.24177225 -0.20647666 -0.32948044  0.09124526 -0.08665055\n",
      " -0.31444627 -0.1947459   0.00787454 -0.03376603 -0.16669816 -0.07945572\n",
      "  0.18396397  0.00886034  0.09830142  0.15396494  0.15153079  0.08746293\n",
      " -0.17981113  0.29133207  0.08903424 -0.10652543 -0.18165414  0.04798725\n",
      " -0.06893657  0.1668861   0.03767069  0.12548202  0.18371952 -0.21200879\n",
      "  0.22876719  0.04769836 -0.13702899  0.05543     0.0269495  -0.07217033\n",
      " -0.10415655 -0.09298267 -0.01977412 -0.10973293  0.15252012 -0.13050295\n",
      " -0.08175733  0.07424131 -0.1648116   0.13152486  0.16593534 -0.10298207\n",
      "  0.01183542  0.05706952 -0.08350289 -0.29927775  0.07337953  0.3048595\n",
      " -0.05068794 -0.04585372  0.02481356 -0.23920701 -0.14300224 -0.03039307\n",
      " -0.09919637 -0.04300956  0.11010957  0.2598164   0.0238316   0.31657326\n",
      " -0.19423822  0.2911653  -0.0165856  -0.03349071  0.08883888  0.0509105\n",
      " -0.1195507  -0.1309454 ]\n",
      "L7N0                    -> L8N83 = [-0.2117217  -0.1455273   0.15472317 -0.14287946  0.3591737  -0.06561308\n",
      " -0.01274488 -0.0502487   0.2303318  -0.12698536 -0.08689675  0.18618529\n",
      " -0.00412319  0.2159203   0.02733653 -0.24674699  0.00381495  0.05719352\n",
      " -0.23189037  0.20414451 -0.15313159 -0.16096115  0.10542181  0.06415308\n",
      " -0.11805002 -0.12193584 -0.0250565  -0.23831147 -0.20823593 -0.07520692\n",
      "  0.06909385  0.02318189 -0.19620082  0.04114213 -0.2898859   0.07394034\n",
      " -0.10217329 -0.1408064   0.01761696 -0.260864    0.09378126 -0.10023201\n",
      " -0.07280373  0.20489468 -0.27079672 -0.05683231  0.05063885 -0.24495025\n",
      "  0.20625803 -0.04635556 -0.23436308  0.19634154  0.02005573 -0.19029854\n",
      " -0.04688017  0.06310134  0.08022436  0.02646295 -0.16797225  0.14006682\n",
      " -0.13871188  0.05665722  0.12968583 -0.16459878 -0.1251082   0.18228619\n",
      "  0.3056214   0.01601726 -0.15766527 -0.02536385 -0.05378861 -0.29825544\n",
      "  0.12146518 -0.08737176 -0.10441752  0.06097997 -0.10752797 -0.14319095\n",
      "  0.00067241  0.1458758   0.10439949 -0.23175119 -0.04143267  0.15971744\n",
      " -0.09006304 -0.0107087  -0.06535597  0.05762149  0.11959521 -0.36263597\n",
      "  0.14625904 -0.12985083 -0.15775414  0.2609978   0.12163975 -0.18853301\n",
      " -0.0323691  -0.22473794 -0.26639995 -0.22450617  0.14013055  0.07767972\n",
      " -0.15102701  0.25676328 -0.14370807  0.07076114  0.07158855 -0.1182496\n",
      " -0.213509    0.1824298   0.0275956   0.16711266 -0.01100375  0.1386896\n",
      " -0.06546497  0.30756795 -0.07407167  0.03522213  0.12837824 -0.02978888\n",
      " -0.06308105 -0.01601769 -0.11651397 -0.12232986 -0.01643141 -0.21376763\n",
      "  0.03073214 -0.13931651 -0.2451529   0.11993164  0.06733501 -0.02374415\n",
      "  0.11525054 -0.04588531  0.13224533 -0.00793878 -0.17578459 -0.13434488\n",
      " -0.22398984 -0.14488296  0.15158501  0.11292228  0.07261039 -0.1208784\n",
      " -0.22351092 -0.2310496  -0.41763306  0.00155734 -0.3906041   0.11438981\n",
      " -0.05050439  0.07504264  0.2391716  -0.05859005 -0.12431999 -0.35109994\n",
      " -0.17237495  0.29632902  0.09892228 -0.28062803 -0.02340675 -0.0954409\n",
      " -0.31287017  0.21965995 -0.04507859 -0.20781478  0.35435534 -0.2852906\n",
      " -0.0763241  -0.03868578  0.12958317 -0.08761776 -0.18774694 -0.20531757\n",
      "  0.20283236 -0.08601864 -0.05110497  0.08034187 -0.25833076 -0.28919208\n",
      "  0.14863798 -0.20633057 -0.22961101 -0.10347376 -0.10589268 -0.21035686\n",
      "  0.14790648  0.08101767  0.03649641 -0.07546271  0.22599085  0.1968278\n",
      " -0.03032345 -0.18639171 -0.19924472 -0.10845372 -0.14314343  0.12508166\n",
      "  0.1223888  -0.08705571]\n",
      "L7N0                    -> L8N84 = [-0.08709503 -0.13453546 -0.00953664  0.21728091 -0.03288108  0.19908893\n",
      " -0.10680246 -0.12444707 -0.00587483  0.24338485  0.07942813  0.16868399\n",
      " -0.11991941  0.06662588 -0.21947733  0.09894563 -0.27673697  0.10575837\n",
      " -0.05082085 -0.08255563 -0.12327415 -0.06689413 -0.0605909  -0.11640223\n",
      " -0.15203066  0.07974516 -0.16584255  0.2625125   0.11555678  0.13931704\n",
      "  0.2018979  -0.02487064  0.09277005 -0.32651624  0.07360898 -0.09194279\n",
      " -0.06401218  0.06249594 -0.02674618 -0.06420506  0.23484391 -0.3662378\n",
      "  0.16742116 -0.03430023 -0.22310944 -0.12806778  0.03474497 -0.14033544\n",
      " -0.07170462 -0.07803717  0.15365502 -0.20891725  0.11769915 -0.18869056\n",
      " -0.3973879  -0.04710484  0.02108621 -0.19827761 -0.15524639  0.39497128\n",
      " -0.06996195 -0.02521079 -0.01390857  0.07427168 -0.4132879  -0.17963143\n",
      " -0.31954178  0.00096286 -0.02826936 -0.00749334  0.08522397  0.00384618\n",
      " -0.25202766 -0.06763586 -0.19167036  0.17618707  0.16230465 -0.03278837\n",
      " -0.07990332  0.16322692 -0.52127844  0.02695595 -0.0450516  -0.22518452\n",
      "  0.04486374 -0.36514437 -0.19934808 -0.3518776   0.08704163  0.31952262\n",
      " -0.00802202 -0.07793834  0.05838158 -0.14229354  0.11140852  0.11928182\n",
      "  0.2129346  -0.09350873 -0.01745152  0.11969131  0.09491467 -0.02671078\n",
      "  0.02685878 -0.19591103 -0.00258184  0.09244392  0.06283483  0.05146145\n",
      "  0.03389617 -0.24110502 -0.16490014  0.11610506  0.08772153  0.14414327\n",
      "  0.2113481  -0.11129903 -0.09879716  0.00688316  0.12676889  0.12345532\n",
      " -0.08018769  0.02040244  0.15376684 -0.13855205 -0.1973422  -0.00439858\n",
      " -0.10526797 -0.14648825  0.11656989 -0.3543363  -0.00200862 -0.158571\n",
      "  0.04050886  0.06070694  0.0057195  -0.25174943 -0.3441911   0.20815057\n",
      " -0.09154959  0.08123379 -0.07397786 -0.07689351 -0.02654454 -0.05542206\n",
      " -0.095945    0.03440268  0.40355596  0.10662666  0.0290096   0.3518867\n",
      "  0.2376672  -0.26736113 -0.14493886  0.20503792  0.03958991 -0.12193409\n",
      " -0.00455237  0.16040888  0.1285301  -0.14862779 -0.18339153 -0.02942565\n",
      " -0.22024912 -0.04928098  0.04625002  0.05226314 -0.04789629 -0.21756223\n",
      " -0.23340543  0.0075092   0.05150439  0.0373861  -0.17537917  0.0664815\n",
      "  0.13099799 -0.01067528  0.13939857 -0.15145463 -0.02304348  0.08767732\n",
      " -0.16882119 -0.03832979 -0.19669239 -0.4067719  -0.04369108 -0.13463193\n",
      " -0.01177682 -0.14559333 -0.07312506 -0.30808666 -0.25957698 -0.23008242\n",
      " -0.49906832 -0.1366147  -0.19763601 -0.04927821  0.15742344 -0.25800857\n",
      " -0.13860258 -0.30561873]\n",
      "L7N0                    -> L8N85 = [ 1.66514397e-01 -3.05343419e-01 -2.31652692e-01 -2.60984093e-01\n",
      "  1.08023852e-01  1.65967107e-01 -6.08240664e-02  1.66046456e-01\n",
      " -4.90134418e-01  9.72449481e-02 -2.07629651e-02  2.29074255e-01\n",
      " -1.25126749e-01  1.04767710e-01 -1.41034899e-02  3.17597017e-02\n",
      " -1.14823073e-01 -7.73452297e-02 -1.29484907e-01  7.89082199e-02\n",
      " -1.04238309e-01 -2.06208616e-01 -3.78548712e-01 -1.08853005e-01\n",
      " -2.52799332e-01  8.58858402e-04 -5.35337254e-02 -2.64781535e-01\n",
      "  1.42547950e-01  1.62147582e-01  1.18476644e-01 -1.44469336e-01\n",
      " -5.96977584e-02 -3.60493392e-01 -1.43239975e-01  6.80877194e-02\n",
      " -1.26065910e-01  8.77466798e-02 -2.66275048e-01  1.99866906e-01\n",
      " -4.36541624e-02 -2.50544995e-01 -1.69543192e-01 -1.52057977e-02\n",
      " -4.96988535e-01  3.09561074e-01  2.53163815e-01 -6.13463372e-02\n",
      " -2.17498150e-02  6.85446057e-03 -2.78805923e-02  1.51366904e-01\n",
      "  1.15919791e-01 -1.20675020e-01 -1.79568917e-01 -1.44823700e-01\n",
      " -8.12473297e-02  8.72667506e-02  1.64819822e-01  1.11625560e-01\n",
      " -5.33146486e-02  9.44524780e-02 -1.60977319e-01 -1.55137300e-01\n",
      "  1.56620070e-01  3.46058421e-02 -3.56885314e-01 -1.01226389e-01\n",
      " -5.69601581e-02  1.11745991e-01 -8.25498626e-02 -3.45845461e-01\n",
      " -1.23727486e-01 -3.78158271e-01 -4.17755768e-02 -4.73479867e-01\n",
      " -1.29528955e-01 -6.47597611e-02 -1.78564012e-01 -6.69797733e-02\n",
      " -2.79076844e-01 -1.68993935e-01 -2.81181514e-01  2.72539705e-01\n",
      "  6.04757257e-02  1.99722126e-01 -2.71799535e-01 -4.09636311e-02\n",
      " -4.96357158e-02  3.07065900e-02  6.11948259e-02 -1.67589821e-02\n",
      " -2.97981948e-01 -2.15007648e-01  4.94980440e-02  1.38923945e-02\n",
      "  7.16099069e-02  2.29765385e-01 -2.00501665e-01  2.84120943e-02\n",
      " -1.82416603e-01 -1.97232217e-01 -2.11708337e-01 -1.17337897e-01\n",
      " -5.89322932e-02 -3.32562029e-02  8.93338919e-02 -1.36859268e-01\n",
      " -2.98077762e-01 -9.01905540e-03 -9.53347832e-02  5.74420206e-02\n",
      " -7.85768405e-02  5.53949960e-02 -5.17918095e-02 -5.87222390e-02\n",
      " -1.43205136e-01  1.37929037e-01 -1.07969120e-01 -1.62281131e-03\n",
      " -2.09191859e-01 -8.72346386e-03  1.10514835e-01  3.16265002e-02\n",
      " -2.15686619e-01  8.11425969e-03 -2.03380555e-01  7.42701739e-02\n",
      "  4.23079208e-02  1.84457630e-01  1.46134079e-01  7.33072087e-02\n",
      " -4.70753878e-01 -1.07428335e-01  1.26415566e-01  4.12443615e-02\n",
      "  2.28065982e-01  7.14837015e-02 -1.19761445e-01  5.74306212e-02\n",
      "  2.88997199e-02  3.06361675e-01 -6.81841522e-02 -1.72338095e-02\n",
      " -1.47158951e-02  9.36946645e-02  9.61729418e-03  5.95110841e-02\n",
      " -2.46164322e-01 -2.38898933e-01  8.57107341e-03 -2.45178506e-01\n",
      " -6.04011379e-02 -1.07240987e-04  1.95217833e-01 -1.49415419e-01\n",
      " -1.70404553e-01 -7.91917667e-02 -1.45485438e-02  3.29818390e-02\n",
      " -1.23747639e-01  1.50394619e-01 -2.23087415e-01  7.71935061e-02\n",
      "  1.48414669e-03  1.22368224e-01  9.68780071e-02 -4.41942513e-02\n",
      "  5.52629195e-02 -2.39056200e-01 -1.67158637e-02  2.14432448e-01\n",
      " -1.89801767e-01  2.41684336e-02  1.05136998e-01  1.62782326e-01\n",
      " -1.61407962e-01 -4.56545919e-01  1.24969222e-02  9.37697589e-02\n",
      " -5.15089966e-02 -3.80157471e-01 -2.73712069e-01  1.90610308e-02\n",
      "  3.27381551e-01 -6.85995594e-02  1.99888676e-01 -5.80635108e-02\n",
      "  8.76477212e-02 -5.54184079e-01 -2.53096581e-01  3.30139101e-01\n",
      "  1.61349084e-02 -3.95171970e-01 -1.85515925e-01 -7.55892950e-04\n",
      " -5.39008304e-02  9.56583694e-02 -2.63912827e-01  1.64442006e-02]\n",
      "L7N0                    -> L8N86 = [ 0.1362903   0.0966755   0.19365832  0.11647853 -0.23022288  0.4273267\n",
      " -0.12799862  0.08931789 -0.16683322  0.1278313  -0.15581447 -0.03641073\n",
      "  0.01260961  0.04974331  0.15625577 -0.33844692 -0.03786069 -0.01498963\n",
      " -0.0244015  -0.04527539  0.28746265  0.15069309  0.262299    0.01851568\n",
      "  0.08905271 -0.01337832  0.13146545 -0.18710804 -0.08992541  0.14671738\n",
      "  0.06862099  0.03580371  0.04837672  0.07750794 -0.051385    0.03704353\n",
      "  0.18126553  0.17700352  0.04431624  0.28069237 -0.08240069  0.03267515\n",
      "  0.10562159  0.27246568  0.24104717 -0.14303008 -0.21691073  0.10180731\n",
      " -0.01965444 -0.07339917 -0.24709605  0.06250629  0.1314625   0.01107878\n",
      "  0.14816022 -0.12059285 -0.05670571  0.23998429 -0.05402621  0.17080201\n",
      "  0.07960815 -0.07431084  0.21081516  0.01835681 -0.10798723 -0.12300296\n",
      "  0.43396255 -0.17194074  0.06132526  0.00335785  0.11435135 -0.24237376\n",
      " -0.0237422   0.08226847 -0.13285723  0.16297296  0.09933981  0.23832792\n",
      "  0.22895926 -0.14229222 -0.01096508  0.15111218  0.07729926  0.14222617\n",
      " -0.14019015  0.08732481  0.00886403  0.1838313   0.02280521 -0.3055085\n",
      "  0.12484225 -0.03464809  0.08084789  0.05931355  0.06254175 -0.10575538\n",
      "  0.01482594  0.24307148  0.17199932  0.06419938 -0.12041993  0.12851404\n",
      " -0.14144808 -0.18442786 -0.02375326 -0.14035611 -0.25716248  0.27484939\n",
      "  0.10214814 -0.08815765 -0.12149532  0.19171043 -0.1278233   0.3137898\n",
      "  0.00721243  0.14368297 -0.11755195 -0.37368757 -0.09693914  0.01328637\n",
      "  0.12801886 -0.00621445  0.16323264  0.00579458  0.17393422  0.03291768\n",
      "  0.41790223 -0.16904847  0.0576283  -0.02590596  0.15387848  0.07179387\n",
      " -0.00861624  0.21263808  0.02012271 -0.03518318 -0.27226618 -0.13040319\n",
      "  0.18719785 -0.1214867   0.28113085 -0.22982576  0.07135222 -0.14901838\n",
      "  0.16597876  0.1356712  -0.05776708  0.33573505  0.32924747  0.08602189\n",
      "  0.10628691 -0.0390469  -0.08849984  0.15583678  0.07941283 -0.25962296\n",
      " -0.06996206  0.04786753 -0.01027546 -0.44095498  0.08046688  0.00445282\n",
      " -0.03726351  0.07379469  0.10281146  0.1515291  -0.06214163 -0.12771498\n",
      " -0.01961977  0.01182486 -0.04341486  0.1809088   0.21298683  0.05892956\n",
      "  0.00519091 -0.02811757  0.32649425  0.2225532   0.04624562  0.1935276\n",
      " -0.0146574  -0.10950958 -0.38830516  0.03386223 -0.03009124  0.16911401\n",
      " -0.18738788 -0.23986188  0.02088831  0.0377152   0.11791645  0.14336814\n",
      " -0.2331187   0.35877213  0.37644073  0.03986327  0.0427304   0.07043424\n",
      "  0.06128645  0.05122839]\n",
      "L7N0                    -> L8N87 = [-0.07720857 -0.08255336 -0.14561541 -0.02451027 -0.27332067  0.26006898\n",
      "  0.07447797  0.0865147   0.25674868 -0.01389692  0.14000492 -0.35350078\n",
      " -0.22010294 -0.03306982  0.05897994 -0.24014676  0.13005063 -0.10976258\n",
      " -0.0896401  -0.1877012   0.09388031 -0.01881548  0.26598114 -0.15077633\n",
      " -0.10593182 -0.01408908 -0.25898015 -0.12108397 -0.1718121   0.13900334\n",
      " -0.05452074  0.29410344  0.08476453 -0.27727327 -0.13879092 -0.22768523\n",
      " -0.09048377  0.04153946  0.33815935  0.13650653  0.04094854  0.07283919\n",
      " -0.20454408 -0.10047749  0.18430361 -0.15673149 -0.0724296  -0.03625971\n",
      " -0.23762651  0.10793377 -0.0009911  -0.07499627  0.27133185 -0.06774555\n",
      "  0.2346951  -0.34853718  0.04150983  0.00675974 -0.09794294 -0.07458765\n",
      "  0.0472027  -0.01108801  0.20147829  0.20559217 -0.15996411  0.09197742\n",
      "  0.14992559 -0.22940777  0.28101277 -0.00732938 -0.05152392 -0.2468494\n",
      "  0.02444693  0.04772087  0.14909996 -0.05688333 -0.3027566  -0.23794542\n",
      " -0.1281306  -0.02663563  0.0870923  -0.0565701   0.15113373  0.06166298\n",
      "  0.24608836  0.04330097 -0.07168623 -0.000939   -0.141159   -0.16016705\n",
      "  0.05186326 -0.08545103 -0.14788322 -0.06426765 -0.19672905 -0.04269049\n",
      "  0.03088    -0.18729459 -0.19793634  0.02309489  0.15216999 -0.06856959\n",
      "  0.11074213 -0.08709449  0.05708487 -0.11116959 -0.37517738  0.19901517\n",
      "  0.06574957 -0.27133662 -0.09969633 -0.13655782  0.16136016  0.18012434\n",
      "  0.00637015 -0.12418815  0.23256443 -0.15439585  0.0846462  -0.11395913\n",
      " -0.11387202 -0.02489101  0.00332156 -0.33622634  0.22349429  0.01836012\n",
      "  0.11242968  0.04618385 -0.32298982  0.1311104   0.04288079  0.0617483\n",
      "  0.07465439  0.0166897   0.20687611 -0.09438536 -0.13402572 -0.25810102\n",
      "  0.18114708  0.09001846  0.12226215 -0.04513187 -0.43056768 -0.17998725\n",
      " -0.02892205 -0.0006822  -0.2689374   0.0214807   0.18852068  0.19759531\n",
      " -0.34507734 -0.03945866 -0.21480711 -0.23864208  0.03804881 -0.15793146\n",
      " -0.02280125 -0.31813255  0.00877123 -0.18797533  0.00760357  0.03819047\n",
      "  0.01318722 -0.23621993 -0.10500753 -0.07099633 -0.2187142  -0.10873023\n",
      " -0.17765881  0.05224442 -0.10381696  0.01855662 -0.10761033  0.37098238\n",
      "  0.06993816 -0.04487394 -0.11440275  0.29685014  0.00242184 -0.318144\n",
      "  0.00134431  0.24951425 -0.23495717 -0.09364005 -0.30722654 -0.02759927\n",
      "  0.1372405  -0.01996435  0.00747761  0.06738906  0.05778092 -0.11407921\n",
      "  0.09016815  0.12265756 -0.01394227 -0.01174754 -0.06617666  0.12469977\n",
      "  0.17499879  0.08757413]\n",
      "L7N0                    -> L8N88 = [-0.09177206 -0.42118695  0.14418703 -0.00512116  0.1179641   0.10266217\n",
      " -0.12969781 -0.32065955 -0.16878621  0.13512841  0.07291769  0.08612429\n",
      "  0.0111596  -0.1007368   0.05335397 -0.02975742 -0.06573039  0.02753713\n",
      "  0.02017836  0.07513704 -0.29869327  0.01333346  0.02493984 -0.02926267\n",
      " -0.26827648 -0.03893592  0.07390174  0.03233319  0.10733365  0.05336795\n",
      " -0.24752611  0.00647106 -0.0025431  -0.35139436 -0.24608512  0.17267741\n",
      "  0.01403115  0.021469    0.05863612  0.14573754 -0.13362753 -0.20577466\n",
      " -0.19658758 -0.05565881 -0.07445523  0.14889055  0.26985347  0.10674976\n",
      "  0.03573727 -0.20453647  0.09096285  0.11931781 -0.00690887 -0.01038156\n",
      " -0.21746014 -0.16274513 -0.1549996  -0.06087056  0.12978849  0.06973001\n",
      "  0.0082374   0.04701631 -0.16581276 -0.06861384  0.04184894 -0.09241567\n",
      " -0.04985465  0.0470199  -0.12335777  0.23100908 -0.24961843  0.06863099\n",
      " -0.09276805  0.13887073  0.0754016  -0.17538168 -0.13624184 -0.24372515\n",
      " -0.1535829  -0.17873286 -0.18720229 -0.4934765  -0.04642411 -0.12543505\n",
      " -0.08848659 -0.32258695 -0.12675196  0.22712976 -0.08751761  0.065865\n",
      "  0.00449289 -0.03593447 -0.02053998  0.17552036  0.17819123 -0.12279914\n",
      " -0.11403862  0.00475867  0.09132126 -0.00158886  0.03029823 -0.20103987\n",
      " -0.12128416 -0.24978411 -0.10986328 -0.03910499 -0.03186857  0.11777258\n",
      "  0.06847307  0.14807746  0.14604354 -0.09654163  0.1658777  -0.20429248\n",
      "  0.04481802  0.10640371 -0.12207962  0.07404069 -0.14847566 -0.2171954\n",
      "  0.27036837 -0.12718922 -0.24611834 -0.10172896  0.22924626 -0.05503884\n",
      "  0.10108683 -0.04234019 -0.01712317 -0.07576305 -0.08629382 -0.05964851\n",
      "  0.02471967 -0.09481453  0.03999809 -0.1669053  -0.16559595  0.0484293\n",
      "  0.18874742 -0.00737022 -0.10324056  0.03726868 -0.06559325  0.14010458\n",
      "  0.01747479  0.0536575   0.03392944 -0.0807569   0.12764981  0.15294509\n",
      "  0.24305384 -0.06769468  0.22405276 -0.15504469 -0.08509539 -0.04647063\n",
      " -0.5453575  -0.13597225 -0.19202912  0.246638    0.05738621 -0.05972873\n",
      " -0.00580377  0.10716556 -0.1871311   0.06978688 -0.1278184  -0.28268024\n",
      " -0.07814519  0.00180277  0.03252892 -0.01551006 -0.12259146 -0.30565643\n",
      " -0.14813648 -0.22357646 -0.28847274 -0.28486332 -0.14543584 -0.09348696\n",
      "  0.02364613 -0.16570303 -0.04288851 -0.07229566  0.16082093 -0.18214159\n",
      "  0.28979382 -0.54156554 -0.01369862  0.06607719 -0.18830036  0.10860147\n",
      " -0.06952734  0.35307714 -0.3030294   0.04545507 -0.06031698 -0.0565774\n",
      " -0.19389255 -0.2765812 ]\n",
      "L7N0                    -> L8N89 = [ 0.20680241 -0.23020492 -0.00232088 -0.16544138 -0.13244665  0.06698507\n",
      "  0.20121622 -0.02786999  0.06985977 -0.02167515  0.00281922 -0.24276184\n",
      "  0.19095157  0.01214153 -0.08698162 -0.09305473 -0.15060946 -0.05031839\n",
      " -0.12944247 -0.06519498 -0.01882558 -0.09399518  0.02848003  0.1772137\n",
      "  0.07035533  0.0318079  -0.41007113  0.04771342  0.1210571  -0.22118962\n",
      " -0.14227422  0.05875671  0.11850312 -0.04572875 -0.01988285 -0.37873605\n",
      "  0.0555738  -0.05810821 -0.14847817  0.10377542  0.04818172  0.02190265\n",
      "  0.14145257 -0.00592068 -0.11094591 -0.1082125  -0.11971108  0.03862455\n",
      " -0.25097013 -0.0289714   0.01063605  0.07169777 -0.15457764  0.06480523\n",
      "  0.01369058 -0.03625572  0.02186146  0.13747297 -0.11198352 -0.00630443\n",
      "  0.01230269 -0.1568475  -0.00398714  0.19884697 -0.12879393  0.14395155\n",
      "  0.0540916  -0.03758415  0.01670639  0.16627996  0.10298578 -0.20287943\n",
      "  0.1038326  -0.07167556  0.19786388 -0.05326775  0.11523024 -0.34063146\n",
      "  0.15503311 -0.04137151  0.24110296 -0.16688603  0.10909291  0.18085828\n",
      "  0.3214886   0.28416634 -0.03516894  0.14925718  0.08625233 -0.11655279\n",
      " -0.11617241 -0.21191427  0.20157011 -0.1369181   0.14477134 -0.01565687\n",
      "  0.11286136  0.1232304   0.2266878   0.15707849  0.01846932 -0.00857303\n",
      "  0.17500193  0.13637759  0.1184596  -0.11470898 -0.298903   -0.22479111\n",
      " -0.20032558 -0.25852883 -0.20361188  0.16442817 -0.35813293  0.0709267\n",
      " -0.34770033  0.17256421 -0.2673345  -0.12590706  0.04153438  0.05958495\n",
      " -0.10650421  0.13631651  0.03847981  0.12135204 -0.08950491  0.00775001\n",
      " -0.04132364 -0.10897312 -0.4864429   0.00110716  0.02176517  0.1278706\n",
      " -0.16862883  0.13509135 -0.01050756 -0.13512534  0.2817954  -0.4105099\n",
      " -0.20058861 -0.07012475 -0.32630935 -0.10793561 -0.03007376 -0.04808888\n",
      "  0.00104619 -0.44515526  0.20328656 -0.06485353 -0.05821217 -0.11878604\n",
      " -0.19963734 -0.24438359  0.1445835  -0.08006348  0.09895089  0.01480471\n",
      " -0.23674831 -0.17466609 -0.10523744 -0.0536677   0.16987129  0.10809433\n",
      " -0.20375186  0.13934344  0.03784941  0.07422741 -0.4204976  -0.11494145\n",
      "  0.2690111  -0.18972981 -0.10625178 -0.12628786 -0.04297155 -0.2030052\n",
      " -0.24573316 -0.14720763  0.2550382   0.08840483  0.04854541 -0.07471102\n",
      " -0.1235834  -0.08000702 -0.08267922 -0.12264745 -0.26870954  0.23002537\n",
      " -0.12216107  0.21607323  0.08481273 -0.14711607 -0.01122753  0.03298293\n",
      " -0.09407876 -0.01040065  0.16632883  0.07852876 -0.007101   -0.40745762\n",
      " -0.01759546 -0.0802816 ]\n",
      "L7N0                    -> L8N90 = [-0.18242846  0.12491418 -0.03670133 -0.07746347  0.006893   -0.08402675\n",
      "  0.15338662 -0.24349037  0.07967423 -0.06561117  0.04849346  0.28269857\n",
      " -0.19602975 -0.05101753  0.016548   -0.03321691 -0.05546707 -0.00460996\n",
      "  0.13299458 -0.22058456 -0.04094705 -0.00372705  0.13182312 -0.14843996\n",
      "  0.16523002  0.13693893  0.05685716  0.17835552 -0.09721687  0.0797148\n",
      "  0.06880642 -0.32697704  0.04220277  0.10690244 -0.10101436 -0.23650874\n",
      " -0.1309433   0.02378175  0.02481562 -0.05859534 -0.54285026  0.06651973\n",
      "  0.16857629  0.0984866   0.17710921 -0.24653044 -0.20414007 -0.385055\n",
      "  0.15226795  0.02304068 -0.05821254 -0.09815484 -0.08552922  0.11757414\n",
      " -0.02827549  0.04642864  0.06144078  0.12373549 -0.10823534 -0.23396206\n",
      "  0.10087387  0.01499539  0.13032596  0.01922438 -0.13194063  0.09121069\n",
      "  0.23849231  0.00930382 -0.01485846  0.00703724  0.16686614 -0.02841932\n",
      "  0.00847424 -0.0420616   0.24045584 -0.19888201 -0.26269367 -0.40455547\n",
      "  0.00606191  0.0570572  -0.04840289 -0.03310855 -0.05630421  0.15175979\n",
      "  0.0167566   0.00316183  0.05383362  0.28741315 -0.09463657  0.0234362\n",
      " -0.05249444 -0.18329261  0.1855184   0.08462918 -0.06600977 -0.00657692\n",
      "  0.02299503 -0.23816733  0.19391559 -0.13088259 -0.07402544 -0.07038158\n",
      " -0.1159945   0.17970937  0.1166696  -0.2547827  -0.09280092  0.1443873\n",
      "  0.01042755 -0.12758584 -0.24278031  0.03164154  0.01506419 -0.19110233\n",
      " -0.05368565  0.16838756  0.09384933 -0.03121026  0.03936492  0.0920607\n",
      " -0.19506653 -0.11686409  0.17798781  0.07315144  0.11430805 -0.03474096\n",
      " -0.11378489 -0.05563859 -0.2918931  -0.11912434  0.13715713 -0.20861033\n",
      "  0.12739456 -0.22007191  0.06729082 -0.04324621  0.11720926 -0.18553293\n",
      "  0.00330276 -0.14793977 -0.21727392  0.00163572 -0.20109831 -0.23620713\n",
      "  0.20475966 -0.00241352 -0.31261674  0.06564921 -0.02378462 -0.10497929\n",
      " -0.15257724 -0.06396886  0.04659213 -0.15943149  0.06253809 -0.21593773\n",
      "  0.07053018 -0.29810643 -0.02490078 -0.06286985  0.0241521   0.07037943\n",
      " -0.00748556 -0.30619907 -0.06082701 -0.2486958   0.0792895   0.00494294\n",
      "  0.03995385 -0.10776325  0.11641033 -0.07248245 -0.14523575  0.09789633\n",
      "  0.16126929  0.13485962  0.0296991   0.21525206 -0.29084882 -0.00703513\n",
      " -0.25704244  0.12123913 -0.26043186  0.13006532 -0.06273232  0.10523861\n",
      " -0.31066823  0.01670753  0.14715107 -0.02170972  0.11081737 -0.07536255\n",
      " -0.0612957   0.13628736  0.35155892  0.07796054  0.00220297 -0.10900383\n",
      " -0.15648387  0.13665825]\n",
      "L7N0                    -> L8N91 = [-2.40056589e-01  2.66696904e-02 -5.84827252e-02 -2.27069020e-01\n",
      "  7.67234042e-02 -1.59000337e-01  5.95802553e-02 -9.76933017e-02\n",
      " -2.58106470e-01  2.13117395e-02 -2.56429434e-01 -1.61898553e-01\n",
      " -3.93346071e-01 -2.34533787e-01 -1.63034610e-02 -4.34041828e-01\n",
      " -6.51834160e-02  1.45729631e-01 -4.08381820e-02 -8.40099603e-02\n",
      "  7.29452893e-02  1.02716610e-02  1.28607884e-01 -1.26414955e-01\n",
      " -1.43305555e-01 -1.80187717e-01  7.68005922e-02  2.32021082e-02\n",
      " -5.90110794e-02 -1.26994953e-01  2.67739683e-01 -1.15851834e-01\n",
      " -3.13973762e-02 -2.26145089e-01 -3.70003164e-01 -4.65649143e-02\n",
      " -2.32251182e-01 -5.63842617e-02  1.06934473e-01  1.02608241e-01\n",
      "  2.21422743e-02  5.12005240e-02 -4.13698375e-01 -2.04004124e-01\n",
      " -1.48798339e-02  4.23173467e-03  2.99694273e-03 -2.37084478e-01\n",
      "  1.79999992e-01 -7.94207603e-02 -1.69975888e-02  2.72484776e-02\n",
      " -3.89039099e-01 -1.78695738e-01 -4.57225405e-02 -4.27348278e-02\n",
      " -8.85371193e-02 -5.37765250e-02 -2.46425066e-02  2.14180470e-01\n",
      " -1.43674210e-01 -1.49593592e-01 -7.32847024e-03  5.25869578e-02\n",
      "  2.19285220e-01 -1.04583785e-01 -2.63202518e-01 -1.95021838e-01\n",
      "  2.55043268e-01 -1.62499472e-01 -1.01092540e-01 -2.57703196e-02\n",
      " -2.25029551e-04 -2.24454910e-01 -9.22380909e-02 -2.06938267e-01\n",
      " -1.31449655e-01 -2.37097323e-01 -1.04594752e-01 -1.53297067e-01\n",
      "  1.15645818e-01  2.69659646e-02 -2.00953618e-01 -1.62026823e-01\n",
      " -1.43143520e-01 -2.78028827e-02 -2.25800723e-01 -1.04378313e-01\n",
      "  5.43032587e-02  2.53081620e-02  2.36719266e-01 -1.67608455e-01\n",
      " -4.54368502e-01 -6.16899282e-02 -1.62079558e-01 -8.69652703e-02\n",
      " -5.18451072e-02 -2.48679891e-02 -3.77099901e-01 -1.17622145e-01\n",
      " -2.81362176e-01 -1.56096555e-03  1.46128520e-01 -3.13524008e-01\n",
      "  8.32739919e-02  1.17989287e-01 -1.80059969e-01 -2.59031713e-01\n",
      "  2.10405707e-01 -2.56947547e-01 -1.30657062e-01 -4.86622788e-02\n",
      "  9.57744494e-02  4.02568541e-02 -7.02624619e-02 -1.11913465e-01\n",
      " -2.33779058e-01 -1.85190380e-01 -2.81600833e-01  4.40017283e-02\n",
      " -1.32587954e-01  9.81644634e-03 -1.04136594e-01  2.24683762e-01\n",
      " -1.55722752e-01 -1.28581285e-01 -4.82018888e-02 -5.72139509e-02\n",
      " -1.68139748e-02 -2.07176492e-01  5.17515242e-02 -2.85797510e-02\n",
      " -1.94515407e-01 -6.93237334e-02 -2.61837244e-01  2.11988520e-02\n",
      "  2.47023837e-03 -1.16964728e-01 -2.41815567e-01 -9.59274471e-02\n",
      " -2.31064141e-01 -2.97068894e-01 -4.98467982e-01 -4.43475664e-01\n",
      " -2.50342518e-01  6.91144392e-02  1.41534150e-01  2.26375297e-01\n",
      " -2.99375564e-01 -2.47925252e-01 -2.62959629e-01 -1.73151419e-01\n",
      " -1.83097437e-01  2.10314840e-02 -1.95524886e-01 -5.85563527e-03\n",
      " -5.16335219e-02  2.21057441e-02 -7.61210993e-02 -1.00241482e-01\n",
      "  4.38893028e-02  2.28971057e-02  1.30226910e-01 -3.49104196e-01\n",
      " -2.27718577e-01  6.72266111e-02 -2.80710369e-01 -1.21328654e-02\n",
      " -4.67661843e-02 -2.34887332e-01 -1.42382503e-01 -2.47231111e-01\n",
      " -3.47608298e-01 -2.26734236e-01  1.64828449e-01 -8.70091468e-02\n",
      " -1.14128128e-01 -5.86973168e-02 -1.17072687e-01 -1.65636346e-01\n",
      "  2.24052966e-02 -2.55233824e-01 -1.41499966e-01  7.46938139e-02\n",
      " -1.75552428e-01 -1.93079159e-01 -8.68403390e-02 -3.66051532e-02\n",
      " -2.89545000e-01 -3.20500940e-01 -2.56529599e-01  6.01072051e-02\n",
      "  1.01225071e-01 -2.51861066e-01 -5.77520207e-02 -1.11360587e-01\n",
      " -7.99200386e-02 -9.91093814e-02 -1.71355769e-01  3.64661366e-02]\n",
      "L7N0                    -> L8N92 = [ 2.08575085e-01 -5.99305555e-02 -1.57942101e-01 -2.97728926e-01\n",
      " -6.01827577e-02  4.27632853e-02  1.36052575e-02 -6.32539019e-02\n",
      " -2.30114922e-01 -2.97666639e-01 -4.80387993e-02 -4.37493473e-02\n",
      " -1.39661238e-01 -6.21882565e-02  3.51172425e-02 -1.19693108e-01\n",
      " -1.48158306e-02 -1.99759036e-01  3.24137695e-02 -2.24464908e-02\n",
      " -1.42210737e-01 -1.83959082e-01 -1.18689552e-01  4.80245054e-02\n",
      " -1.19277872e-01  3.20029892e-02 -2.87677981e-02 -6.84045851e-02\n",
      " -7.15005845e-02 -1.30425885e-01  1.93914950e-01 -3.34863067e-02\n",
      " -1.10848971e-01 -2.13473499e-01 -1.03503346e-01  1.82535380e-01\n",
      " -8.85140374e-02  1.52285010e-01 -2.72356533e-02 -1.52110038e-02\n",
      "  8.50370899e-02  4.84470427e-02 -1.82262033e-01 -2.50267476e-01\n",
      "  6.52390271e-02  1.10646412e-01  1.70728371e-01  3.75042781e-02\n",
      "  1.30557984e-01 -1.02676563e-01  1.76982403e-01 -1.65611669e-01\n",
      " -5.68428151e-02 -1.93419680e-01  2.49143988e-01 -3.17962080e-01\n",
      " -2.62571007e-01 -1.43967345e-01  1.44430056e-01  1.98331140e-02\n",
      "  9.80018899e-02 -2.10261509e-01  3.59065756e-02 -1.20302483e-01\n",
      "  1.77043989e-01 -5.18186912e-02 -1.55041024e-01 -9.75365937e-02\n",
      " -8.13178835e-04  2.09577046e-02 -9.78679880e-02  8.70472286e-03\n",
      " -4.65846688e-01 -1.61698967e-01  2.35099290e-02  2.15044454e-01\n",
      "  9.62176919e-02  3.59692276e-02 -9.28665623e-02 -1.57638997e-01\n",
      " -1.41805306e-01 -5.47421947e-02 -2.54919410e-01  1.44516498e-01\n",
      "  2.49773264e-01 -4.25070412e-02 -2.17173845e-01 -3.77786428e-01\n",
      "  2.30702534e-01  8.41114298e-02 -2.37084683e-02 -1.73257113e-01\n",
      "  7.29986653e-02 -2.07924768e-01  1.82460502e-01 -4.77045141e-02\n",
      "  2.15489820e-01 -1.44900493e-02  5.79694659e-02 -7.61968866e-02\n",
      " -1.17454462e-01 -2.09285356e-02 -2.85838507e-02 -4.22776878e-01\n",
      " -1.15270898e-01 -1.05703279e-01 -2.19626293e-01  2.14259718e-02\n",
      " -2.49199852e-01 -3.44250590e-01 -1.37563452e-01 -3.35716486e-01\n",
      " -9.09346715e-02  3.22056472e-01  8.05602968e-02 -1.29163340e-01\n",
      " -5.92503510e-02  5.53987138e-02 -2.31012508e-01  4.45348851e-04\n",
      "  1.50570320e-02 -2.95346864e-02  5.46580292e-02 -1.95461959e-02\n",
      "  1.64838225e-01 -7.35966265e-02  1.35272846e-01  1.66154116e-01\n",
      " -5.87943234e-02  4.83373962e-02 -1.37154281e-01 -9.02475193e-02\n",
      " -1.18073240e-01  2.22961560e-01 -1.94052815e-01  1.93117373e-02\n",
      " -3.56165409e-01  1.23587184e-01  4.81044911e-02  2.05366034e-02\n",
      " -3.76030011e-03  7.62566328e-02  5.56939133e-02  1.70242324e-01\n",
      " -1.01093285e-01  2.27783650e-01  2.33038858e-01  1.24878017e-02\n",
      "  1.09190308e-02 -4.06057946e-02  1.01416811e-01 -8.11259747e-02\n",
      " -2.12142333e-01  6.31291792e-02 -1.80151045e-01  7.80785307e-02\n",
      "  3.05264294e-01 -7.11270869e-02 -7.70717710e-02  6.38375431e-03\n",
      " -1.18012063e-01  9.75880995e-02 -5.11403456e-02  4.08489369e-02\n",
      " -5.25984950e-02 -6.65522441e-02 -1.63601056e-01  1.22466078e-02\n",
      " -4.69135027e-03  1.60956711e-01 -7.59589300e-02  1.61845669e-01\n",
      " -8.61878842e-02  2.37474963e-01  1.65908009e-01  9.43489894e-02\n",
      " -6.66335076e-02 -6.98391795e-02 -2.24117279e-01 -8.13434795e-02\n",
      "  1.16135664e-01 -1.15712732e-01  4.99906167e-02 -4.34937567e-01\n",
      "  2.72136360e-01 -3.64048272e-01  8.69263485e-02 -1.91998020e-01\n",
      "  1.97246354e-02 -1.96892284e-02  4.98724021e-02 -1.21392021e-02\n",
      " -2.62742549e-01  2.07534105e-01 -2.11868063e-01  1.22456893e-01\n",
      " -1.74802169e-01  8.66228044e-02 -4.01547924e-03 -1.25404999e-01]\n",
      "L7N0                    -> L8N93 = [-2.13581696e-01 -8.28989199e-04 -2.24451214e-01 -9.17198882e-02\n",
      " -1.44466069e-02  2.02846289e-01  1.61254704e-02 -8.77347142e-02\n",
      " -1.55904323e-01  2.22140364e-02  1.41654029e-01  1.99907109e-01\n",
      " -6.04289830e-01 -1.71716243e-01 -6.34125769e-02 -3.74209821e-01\n",
      " -3.09103746e-02  4.69723642e-02 -7.58417696e-02 -5.00248551e-01\n",
      " -1.13857783e-01  1.83765069e-01  1.06313691e-01  3.93973663e-02\n",
      "  9.27214790e-03 -9.79154035e-02 -1.30587652e-01 -2.76765972e-01\n",
      " -2.53274113e-01 -1.39231980e-01  7.99553245e-02 -3.11705489e-02\n",
      "  6.20460697e-02  4.42614034e-02 -2.30629053e-02 -3.79241668e-02\n",
      " -1.39178336e-02 -1.54906567e-02  1.03437699e-01  1.19095281e-01\n",
      "  1.29941493e-01 -2.25492790e-02  6.72515109e-02 -1.39393896e-01\n",
      "  9.41131264e-02 -1.55539319e-01 -2.33680516e-01  1.59808531e-01\n",
      "  1.42308529e-02 -9.99509692e-02 -1.23813711e-01 -1.74545109e-01\n",
      "  1.77733690e-01 -8.32562596e-02  8.34984556e-02 -2.76819080e-01\n",
      "  2.25258440e-01  1.64663419e-03 -3.74388159e-03  1.12842172e-01\n",
      "  5.98330498e-02 -2.16106251e-01  1.25602722e-01  6.09473325e-02\n",
      "  4.80336249e-02 -2.32501939e-01 -2.92206742e-02 -3.61814260e-01\n",
      " -1.55789658e-01 -7.17614964e-03  9.63609572e-03 -9.16159451e-02\n",
      " -1.62533671e-01 -3.11306138e-02  5.14841266e-02 -1.26091391e-02\n",
      "  9.28405449e-02 -1.71916664e-01  3.58318798e-02 -3.26474570e-02\n",
      " -1.60165541e-02 -1.09385617e-01  7.38525623e-03 -3.48548591e-01\n",
      "  2.78356612e-01 -1.76831827e-01  1.47762215e-02  1.97454363e-01\n",
      " -3.43590438e-01 -1.32838815e-01  1.56272650e-01 -8.34979340e-02\n",
      "  1.52348652e-01 -8.94065350e-02 -3.52824219e-02 -1.90533057e-01\n",
      " -1.44861639e-01 -3.71793568e-01 -1.46628812e-01 -4.00730968e-03\n",
      "  1.52835310e-01 -2.40274295e-02 -1.97476938e-01 -2.99724843e-02\n",
      " -2.76088893e-01  9.47894081e-02 -1.16187163e-01  4.12255302e-02\n",
      "  3.99308540e-02 -4.91828740e-01 -4.76510189e-02 -1.16935037e-01\n",
      "  2.10819300e-03  1.57204315e-01 -1.15969256e-01 -7.23287910e-02\n",
      " -1.15497559e-01 -4.82620448e-02  8.80999789e-02 -1.05524724e-02\n",
      "  2.28620656e-02  1.59433503e-02 -4.33667563e-02  2.03503311e-01\n",
      " -1.08077370e-01 -4.12442200e-02  1.49333403e-01  2.00911805e-01\n",
      " -3.67826343e-01 -1.89104266e-02 -4.22736071e-02  1.76340118e-01\n",
      " -1.58261359e-02 -5.43309487e-02 -2.44767502e-01 -1.63101017e-01\n",
      " -1.52790904e-01 -2.97256827e-01  3.96847762e-02  4.52531362e-03\n",
      "  1.09689176e-01 -2.31941864e-01 -1.67283360e-02 -5.90826832e-02\n",
      "  2.71328725e-03 -3.10585406e-02  4.19274066e-03  1.34271625e-02\n",
      " -5.27904108e-02  1.50388822e-01 -3.01678985e-01  9.97713953e-02\n",
      " -1.26543999e-01 -1.76394761e-01  5.50949015e-04 -3.70440990e-01\n",
      " -2.00688660e-01 -4.70429547e-02  3.74556124e-01 -6.21294156e-02\n",
      " -3.06198690e-02 -5.21246567e-02  1.67013973e-01 -1.10107429e-01\n",
      " -2.56728202e-01 -2.42141485e-02 -2.61373788e-01 -2.78055351e-02\n",
      " -1.66341066e-02 -1.10714935e-01  3.87313403e-02 -2.06090942e-01\n",
      " -7.52847940e-02 -4.64702062e-02  1.58210143e-01 -2.62122065e-01\n",
      " -1.32890299e-01 -1.55833229e-01 -4.44634259e-02 -4.45653290e-01\n",
      " -1.88868880e-01 -9.24109519e-02 -2.01712236e-01  4.16068286e-02\n",
      " -4.07241076e-01 -6.56867996e-02  1.24458969e-02 -2.72081405e-01\n",
      "  1.73960645e-02 -6.00185543e-02 -2.64768004e-01 -1.16054438e-01\n",
      "  4.42468449e-02 -1.31250486e-01 -1.45626083e-01 -1.29768267e-01\n",
      " -2.03825504e-01  2.50782460e-01 -5.07383049e-02 -2.00605512e-01]\n",
      "L7N0                    -> L8N94 = [-0.3210407   0.01088424 -0.19233152 -0.15139621  0.10103086 -0.03452653\n",
      " -0.12560515  0.21761507 -0.15939876 -0.07712609  0.24463192 -0.0653965\n",
      " -0.14197858  0.03727473 -0.19785509 -0.02809539 -0.2553046  -0.00633102\n",
      "  0.02693925  0.00934352  0.03759847 -0.00133547  0.18038897  0.04967038\n",
      "  0.12971735 -0.09103609  0.04941028 -0.22852713 -0.15845366 -0.02996364\n",
      " -0.03687911  0.15087324 -0.0482783  -0.16599295 -0.14469123 -0.02558763\n",
      " -0.10579897 -0.14169721 -0.11419012 -0.08638545 -0.06439761 -0.14101754\n",
      " -0.1084592  -0.11761459  0.08700357  0.29539758 -0.5513904  -0.27084926\n",
      "  0.13501565 -0.16081676 -0.09497577  0.1457803   0.11978322 -0.09058832\n",
      "  0.01694841  0.4292117  -0.04203983  0.13816448 -0.06355154  0.11974176\n",
      " -0.09239598 -0.09351922 -0.01153731 -0.01266354 -0.11119315  0.07805682\n",
      " -0.18278748 -0.07170137 -0.03030139  0.11051255 -0.11171137  0.00617096\n",
      " -0.00708296 -0.1251587   0.06694381  0.01167994 -0.10402531  0.11185892\n",
      " -0.09743886 -0.13718128  0.14464876  0.20462565  0.06173217  0.17132033\n",
      "  0.00917191  0.1487896   0.14834657 -0.02798386  0.02596355 -0.3715108\n",
      "  0.23882583 -0.19626378 -0.05894253  0.19204433 -0.15811904 -0.01344716\n",
      " -0.03076208 -0.1871349  -0.39023098 -0.19160202 -0.29104647 -0.22672702\n",
      "  0.09883267 -0.03361357 -0.04674866  0.02684249  0.17440867  0.15710796\n",
      " -0.03894293 -0.18100081  0.17614754  0.10913973 -0.1110548   0.04379092\n",
      " -0.03138886 -0.00131567 -0.0831643  -0.16518553  0.03788427  0.03330455\n",
      " -0.15671001 -0.1295199  -0.14341517  0.22031967 -0.04530293 -0.04073643\n",
      " -0.06146073 -0.01807665  0.11815131 -0.27947795 -0.24379231 -0.0480598\n",
      "  0.04079185 -0.1463107   0.0975292  -0.08754035 -0.12094529 -0.00402884\n",
      " -0.00216769 -0.03960165 -0.12667948 -0.3237023  -0.21156552  0.01356609\n",
      " -0.01675087 -0.0698941  -0.18019617 -0.12515931  0.1382796  -0.04989944\n",
      " -0.0365896   0.08140046 -0.32453588 -0.12507424 -0.23913099  0.15538688\n",
      " -0.13941352  0.04374827 -0.05852152 -0.13421229 -0.01241403  0.11031808\n",
      "  0.17529254 -0.02600253 -0.06677423  0.12912408 -0.10272723 -0.11193477\n",
      " -0.24234016 -0.12870592 -0.24429817 -0.12469748 -0.14453948 -0.00962272\n",
      "  0.30970898 -0.07455739  0.12968238 -0.00778115 -0.44423154  0.08032324\n",
      "  0.14768924  0.18473068 -0.18771005 -0.3716803   0.01812155 -0.04242916\n",
      "  0.07342169  0.12266347  0.18411002  0.06906196 -0.12363328  0.38693637\n",
      " -0.19374463  0.04732775 -0.00919076  0.06555182 -0.2728488  -0.14075865\n",
      " -0.02163927 -0.1536646 ]\n",
      "L7N0                    -> L8N95 = [-0.10082711  0.21091102 -0.0654683  -0.19780515 -0.22997606  0.01384869\n",
      " -0.19104128 -0.01775939  0.22495535  0.16120239  0.4545278  -0.22117734\n",
      " -0.3077809  -0.12483136  0.23992927 -0.03752001  0.04787331 -0.02452404\n",
      " -0.29415876 -0.09296431 -0.11132737 -0.07103857 -0.04045876  0.09308488\n",
      "  0.05667247 -0.29884332 -0.11555199 -0.15790379  0.06854884  0.03438764\n",
      " -0.02885525  0.12897553 -0.26048198  0.3486022   0.0721127  -0.10549307\n",
      "  0.00193742 -0.04990257 -0.27028757 -0.05784324  0.13347016 -0.19196784\n",
      " -0.19290462 -0.2447712   0.10485835 -0.21249282 -0.04940156 -0.13400823\n",
      " -0.187357    0.01814818 -0.24258898 -0.02006271  0.04366386 -0.24962199\n",
      " -0.14260007 -0.09333581 -0.18196388  0.00622658  0.0543746  -0.00823483\n",
      "  0.13902703 -0.00188273  0.08480372  0.02442583 -0.22705407  0.02505263\n",
      "  0.06432671 -0.18870772 -0.00504831  0.06517354 -0.13730994 -0.05626395\n",
      " -0.21481247 -0.03305901 -0.02248731 -0.14892748  0.1237037  -0.17624497\n",
      " -0.00936501  0.08887281 -0.0127171   0.10181242 -0.08259249  0.10531947\n",
      " -0.10732058 -0.06599484 -0.13981763  0.04135833 -0.18853678  0.12179374\n",
      " -0.16377273  0.04097033  0.19874033  0.12337029 -0.1522827  -0.17171167\n",
      " -0.10389705  0.35788482  0.04984223  0.19092685 -0.08162437  0.07103154\n",
      " -0.20540817  0.11636732  0.12752117  0.02411366 -0.39300215  0.15813197\n",
      " -0.30763578 -0.11093599 -0.27716398  0.07734922 -0.18500823 -0.21035768\n",
      " -0.31932625 -0.08814556 -0.06754855  0.09173997 -0.08602253  0.02283267\n",
      "  0.22594912  0.09146205 -0.04826496 -0.2424931   0.05386262  0.03635748\n",
      "  0.1408575  -0.22495161 -0.27727968  0.1421248   0.11069389  0.02855466\n",
      " -0.03274979  0.10692882 -0.07648975 -0.08587692  0.05906246 -0.23809884\n",
      "  0.1768019  -0.09755405 -0.16103695 -0.04285399 -0.25206858 -0.27681458\n",
      "  0.14582103 -0.11574864  0.12845163  0.04616468 -0.00759788  0.06498045\n",
      " -0.42830437 -0.19101469 -0.03836006 -0.11361792 -0.00172976  0.06570079\n",
      "  0.05603477 -0.00140184 -0.17842926 -0.21992993 -0.05586085  0.08275697\n",
      "  0.00364204 -0.26807356 -0.00675654 -0.2492768  -0.6947243   0.09426618\n",
      "  0.11579901  0.04962644 -0.14757413 -0.19499004 -0.22702941  0.07163525\n",
      " -0.07470205 -0.11117686  0.01845034 -0.02125474 -0.20353715 -0.19311665\n",
      " -0.36937305 -0.44765252 -0.1180923   0.01425414 -0.32700437 -0.22573084\n",
      " -0.04621898 -0.18659039 -0.20569514  0.00470674  0.08904233 -0.04558101\n",
      "  0.02828637 -0.21883422 -0.0221725   0.1330805   0.10039646 -0.3296306\n",
      " -0.09012607  0.1520009 ]\n",
      "L7N0                    -> L8N96 = [ 0.2932729  -0.00366172 -0.25474405 -0.11493053 -0.13749957  0.1404822\n",
      "  0.05777049 -0.12739883  0.0235207   0.01188085  0.03555529  0.02726167\n",
      " -0.19267865 -0.17102449  0.04449599 -0.16528502 -0.15009815 -0.29402724\n",
      "  0.01720803 -0.16691312  0.02175931 -0.03389762  0.04621824  0.07033178\n",
      " -0.03896552  0.10042987 -0.05064819  0.01698095  0.25168875  0.0373927\n",
      "  0.19368285  0.10748263  0.08058363  0.30435294 -0.00819337 -0.33489087\n",
      " -0.13694164 -0.0223611   0.07662259  0.22982453 -0.01427085 -0.00301378\n",
      " -0.0101779  -0.00797252 -0.20540592 -0.18789816 -0.28562787 -0.09960479\n",
      "  0.26265287  0.18715468 -0.3146414  -0.09853458  0.11285494  0.0042434\n",
      " -0.03340318 -0.33807346 -0.16344157 -0.02528368  0.02423491  0.22134736\n",
      " -0.04493752 -0.21311456 -0.27069348  0.02856182 -0.10153795 -0.02527991\n",
      "  0.50669765 -0.4032933  -0.10809477 -0.16875716  0.11920144 -0.34495205\n",
      " -0.15773025  0.03933993  0.32221344  0.14614198 -0.00180857 -0.24462666\n",
      " -0.05199974  0.3082131   0.0307974   0.07993189  0.19115609  0.17740738\n",
      " -0.00248867  0.05931777 -0.13355987 -0.04953242 -0.04975149 -0.13343698\n",
      "  0.09164528 -0.09519809  0.24128434 -0.00153036 -0.12695204  0.07712648\n",
      "  0.20342179 -0.16342174  0.15589182 -0.04765213  0.00396126 -0.07374843\n",
      "  0.01053034 -0.06427875 -0.03247221 -0.17930746 -0.3824612   0.3511289\n",
      " -0.03610223 -0.12676693 -0.2917644   0.08204801 -0.26452196  0.19854605\n",
      " -0.28449294 -0.1442169  -0.08661676 -0.26490423 -0.0223688  -0.03302899\n",
      " -0.17248848  0.0261238  -0.1440516   0.04616572  0.03008195  0.04333759\n",
      "  0.10536929 -0.03445226 -0.10635575 -0.18025942 -0.07891485 -0.01502112\n",
      "  0.33342785 -0.03594447 -0.17045942 -0.01019698 -0.3649154  -0.18859108\n",
      "  0.08982664  0.08770125  0.16043957 -0.0666259  -0.29286537 -0.02536174\n",
      "  0.29717243  0.08661406 -0.04261942  0.04618468  0.26942647  0.19801362\n",
      "  0.0607951   0.05027891 -0.35809255  0.03667472  0.20145895 -0.23349737\n",
      " -0.10417265 -0.06367812 -0.28178892 -0.03839109  0.1254282  -0.09392092\n",
      "  0.04232188 -0.3267574   0.10842997 -0.13908392 -0.05299459  0.077\n",
      "  0.1777045   0.18887326  0.19749615 -0.36187926  0.02715163  0.2376909\n",
      " -0.04802108 -0.16609971 -0.00557071  0.15109064 -0.17139895 -0.32691863\n",
      " -0.37523293  0.1207764  -0.09313264  0.06394146 -0.22889407  0.0373686\n",
      "  0.28081903 -0.29645467 -0.0525211   0.10918975  0.32651216  0.00473048\n",
      "  0.08868489  0.18523212  0.10548981 -0.05615574 -0.02758538 -0.23004065\n",
      " -0.18996894  0.175058  ]\n",
      "L7N0                    -> L8N97 = [-0.2198249  -0.39165556  0.04532227  0.08323977  0.06650388 -0.16342482\n",
      " -0.13833143 -0.14090738 -0.02481494 -0.13545541 -0.13819943  0.02124406\n",
      "  0.11300044 -0.21362095 -0.18937919  0.00644673 -0.1301025  -0.15574285\n",
      " -0.33653206  0.12430807 -0.02469812 -0.28589025 -0.15146229 -0.25665247\n",
      " -0.42238623 -0.29215464  0.0972149  -0.2657127   0.03684258 -0.16470617\n",
      " -0.28069323 -0.26875576 -0.40112036  0.05696943 -0.01884241  0.29663062\n",
      " -0.35967225 -0.318535   -0.30688506 -0.0777302  -0.33919576 -0.16097166\n",
      " -0.34345034 -0.01606771 -0.32675964 -0.08218139 -0.10115258 -0.24239354\n",
      " -0.22107854 -0.43411863  0.14467844 -0.09502245 -0.20156774 -0.1926653\n",
      " -0.00321959 -0.14820172 -0.13698195 -0.29205248  0.00793834 -0.03779572\n",
      " -0.3907192   0.32333368 -0.39613557 -0.08118143  0.04216549 -0.19267608\n",
      " -0.11539611  0.17507334 -0.00350009 -0.310608    0.10584081 -0.1652928\n",
      " -0.3327681  -0.22963521 -0.10097767 -0.20477308  0.01333857  0.06383796\n",
      " -0.18428065 -0.24585421 -0.5254521  -0.21584147 -0.43930048 -0.24110834\n",
      " -0.35024232  0.03603019 -0.3269312  -0.00976537  0.12725285 -0.11359917\n",
      " -0.1828666  -0.09972074 -0.39264867 -0.07301872 -0.11515827 -0.15879612\n",
      " -0.10742861 -0.03418576 -0.17340048 -0.20672238 -0.17414138 -0.27337512\n",
      " -0.12442579 -0.09610624 -0.27860138 -0.08041995  0.02297457 -0.01489057\n",
      " -0.07586285  0.2231698   0.26151213 -0.32041997 -0.2008112  -0.3000652\n",
      " -0.10600935 -0.06464893 -0.2111111   0.04582867 -0.19202904 -0.14106049\n",
      " -0.16931583 -0.39167956 -0.34599936 -0.23147582  0.01089861 -0.20825781\n",
      " -0.393233   -0.02321718  0.13060154  0.09952435 -0.03940476 -0.19010866\n",
      " -0.35033542 -0.14733866 -0.24396488 -0.02032492  0.04754691  0.03405685\n",
      " -0.40892145 -0.18000795 -0.4469651  -0.10390639  0.16854264  0.07670233\n",
      " -0.01846282  0.06082234 -0.10402313 -0.20072444 -0.1104504  -0.38647878\n",
      "  0.00295525 -0.33702415  0.05597558 -0.14852351 -0.16990626  0.1859728\n",
      " -0.13507505 -0.0840706  -0.30174404 -0.0450585  -0.14785999 -0.11745896\n",
      " -0.24363633  0.21566862 -0.09217131 -0.24964824  0.29273647 -0.02466948\n",
      "  0.1815679  -0.22748038 -0.12480493 -0.21970472 -0.3648067   0.05966404\n",
      "  0.07640629 -0.45192188 -0.30382127 -0.10665365 -0.1947959   0.15262394\n",
      "  0.04832671 -0.14656119  0.09279598 -0.01701961  0.00839246 -0.26562613\n",
      "  0.11074075 -0.0653904  -0.1388656   0.02274445 -0.24491608  0.08437477\n",
      " -0.03045911 -0.00270671 -0.16262895 -0.29215178 -0.27198666  0.0535132\n",
      " -0.15596935 -0.34522077]\n",
      "L7N0                    -> L8N98 = [ 1.94834322e-01 -6.65647313e-02 -1.77968532e-01  3.87302339e-01\n",
      " -3.54617313e-02 -3.65409404e-02 -1.11847920e-02  1.49513409e-01\n",
      " -1.97440982e-01 -6.73636794e-02  1.99726999e-01 -4.61700000e-02\n",
      " -1.86236184e-02 -1.20211050e-01 -1.52699724e-01 -1.41161624e-02\n",
      " -2.22644359e-01 -2.35993154e-02 -1.07778767e-02 -1.40084237e-01\n",
      " -1.03247479e-01 -1.65395409e-01 -9.51881781e-02  2.09869131e-01\n",
      "  2.43154913e-01  2.30013892e-01 -8.15890962e-04 -1.01302661e-01\n",
      "  7.98369721e-02  2.28554696e-01  1.16365515e-01  2.93704510e-01\n",
      " -1.85102541e-02 -2.06004471e-01  2.63449531e-02 -1.68813337e-02\n",
      " -1.32826388e-01  8.42716619e-02 -1.95631236e-01  3.50116968e-01\n",
      " -9.30556506e-02 -8.93817171e-02  1.31956243e-03  1.29704595e-01\n",
      " -2.60127813e-01  2.01015443e-01  8.88331085e-02 -2.94991080e-02\n",
      "  1.72900245e-01  2.33128563e-01  9.79738832e-02  1.70225114e-01\n",
      "  6.27343282e-02  3.06261834e-02  1.04734324e-01  1.13406647e-02\n",
      "  9.94479209e-02  4.75449413e-02 -8.13209042e-02  1.95105761e-01\n",
      "  3.02676875e-02 -1.84252545e-01  2.90632546e-01  5.75429797e-02\n",
      " -1.24443389e-01  1.29449651e-01  7.35851228e-02 -1.58372670e-01\n",
      " -2.28676096e-01  1.05026357e-01 -2.39760995e-01 -1.30242079e-01\n",
      " -1.30996898e-01  1.22366678e-02  1.73212394e-01  2.94197857e-01\n",
      "  2.14267492e-01 -1.41306609e-01  2.76909880e-02 -9.25117210e-02\n",
      " -1.11388721e-01  1.38294443e-01 -1.83046162e-02  1.33349821e-01\n",
      "  2.27619290e-01  1.05652228e-01 -6.93615247e-03  4.05946225e-02\n",
      "  2.46012554e-01  1.90148786e-01 -3.28140855e-01  1.80270582e-01\n",
      "  5.34932204e-02 -2.90570080e-01 -1.23301283e-01  1.02108821e-01\n",
      " -1.49137974e-01  1.66441023e-01 -1.00921452e-01  2.49518886e-01\n",
      "  1.75384611e-01  8.33035931e-02 -4.14971076e-02 -7.03749135e-02\n",
      " -5.74244441e-05  4.05464508e-02 -2.37193003e-01 -6.38387129e-02\n",
      " -8.82628188e-02 -2.04097927e-01  7.37135634e-02 -1.01858355e-01\n",
      " -1.46723583e-01  2.18917221e-01  3.54438350e-02  4.05680761e-03\n",
      " -7.67754018e-02  2.80074894e-01  1.28918365e-02  6.10777326e-02\n",
      "  1.23258345e-01  1.17363278e-02 -6.26229569e-02  4.83479202e-02\n",
      "  5.59579283e-02 -1.36285797e-02 -1.50766866e-02  1.50560528e-01\n",
      " -3.56452316e-02 -6.76083118e-02  5.19324876e-02 -6.65173456e-02\n",
      " -5.00586592e-02  1.54376537e-01  5.14380746e-02  2.94546276e-01\n",
      "  5.38026541e-02  5.26557043e-02  1.48438036e-01  8.04797336e-02\n",
      "  7.90047422e-02 -1.00214733e-03  7.00464472e-02  1.13840871e-01\n",
      "  4.48720306e-02  2.70847580e-04  1.18383020e-01 -3.68650317e-01\n",
      "  1.55548111e-01  1.33705363e-01  2.19335899e-01  7.77869821e-02\n",
      "  2.42805883e-01  1.09542817e-01 -1.98417351e-01  1.85294077e-01\n",
      " -5.14355823e-02  1.74603149e-01  1.07487805e-01 -1.65402547e-01\n",
      " -1.96409941e-01 -1.84967890e-02 -1.17278874e-01  2.19365537e-01\n",
      " -6.27200976e-02  9.23318975e-03  6.64034784e-02 -1.75399035e-01\n",
      " -3.30934495e-01  1.40864607e-02 -3.46222520e-01  3.18575293e-01\n",
      "  1.49691375e-02 -5.98917454e-02 -1.76720787e-03  1.96138233e-01\n",
      "  8.69779736e-02 -2.07029447e-01  1.44727647e-01 -7.24439770e-02\n",
      " -1.42503709e-01  2.75697466e-02  2.39035413e-01 -3.94613706e-02\n",
      "  1.41457602e-01  1.13400212e-02  4.16432172e-01 -3.43417615e-01\n",
      " -1.04679003e-01 -2.35023364e-01 -5.93875255e-03 -2.93569453e-02\n",
      " -1.10309400e-01  3.37145180e-02 -1.60163537e-01 -3.74726020e-02\n",
      " -1.00256585e-01  7.18414262e-02 -1.04200974e-01  4.69286852e-02]\n",
      "L7N0                    -> L8N99 = [-0.21768826  0.202993   -0.14157656 -0.07870879 -0.04949946  0.06018978\n",
      "  0.09302022  0.15451598  0.17153269  0.09103112  0.08683274  0.14996037\n",
      "  0.17251766 -0.07441378  0.05833244 -0.21814643 -0.22887178 -0.11674434\n",
      "  0.00246162  0.06061299  0.10844336 -0.03790036 -0.26861602 -0.05168839\n",
      " -0.19677553  0.08768102 -0.04522228  0.07204088 -0.07078499 -0.13393377\n",
      "  0.08217227  0.01784059 -0.02284781 -0.0245092   0.04660475 -0.08110975\n",
      "  0.06872996 -0.14903364 -0.29763275  0.18821852  0.03296585  0.24804981\n",
      " -0.04525844  0.11520099  0.18678196 -0.03549457  0.28917992  0.03286682\n",
      " -0.11301886  0.20089965 -0.09258508 -0.23807336  0.44800085 -0.15296988\n",
      " -0.09072576 -0.15269884 -0.21924576 -0.03392734  0.05550992 -0.24245912\n",
      " -0.08569537  0.07810628 -0.08869769 -0.2111648  -0.09987705  0.2323856\n",
      " -0.11950449  0.2946106  -0.06377205  0.11451145  0.09386775  0.008793\n",
      "  0.19161907  0.03312865  0.16785425  0.13705252 -0.06684007  0.18079545\n",
      " -0.02952361  0.08257239  0.1803626   0.0499332   0.08923905 -0.07021952\n",
      "  0.21927503  0.17267846  0.13971113  0.23030975  0.05858493  0.04177224\n",
      "  0.18153179 -0.02853848  0.15326071  0.02726362 -0.13006005  0.00372031\n",
      " -0.00622424 -0.00183125 -0.17165935 -0.1741427   0.20681614 -0.23922732\n",
      "  0.01874553  0.05228052  0.18781425  0.05972251 -0.1247206   0.20663461\n",
      " -0.19609708 -0.13343732  0.34083396 -0.13877599 -0.01785074  0.26359925\n",
      "  0.03725301 -0.11300437 -0.12232605  0.19027337 -0.08409441 -0.0383982\n",
      " -0.24956357 -0.04980132 -0.03132513  0.09408899  0.13568635 -0.10164636\n",
      "  0.0388134   0.00193143  0.2297862  -0.0136541  -0.0930673   0.08712205\n",
      " -0.21675232 -0.16381261 -0.00356437 -0.3248677  -0.02259487  0.2980739\n",
      "  0.09478793 -0.08609583  0.14548086  0.12820727  0.25991088 -0.01943266\n",
      " -0.04967127 -0.09801987 -0.04510494 -0.13805045 -0.24437316  0.08940171\n",
      "  0.08889137 -0.04229433  0.0982079   0.06726778 -0.11669387 -0.15327942\n",
      "  0.05120555 -0.44683966  0.05499716 -0.10920581  0.07566955  0.0549209\n",
      " -0.21615641  0.0489263  -0.06377502  0.1813156  -0.2349199   0.01312312\n",
      "  0.35993356 -0.01680527  0.04656216  0.24425402  0.14211397 -0.20409429\n",
      " -0.10192046  0.02138762 -0.10708612  0.19979738  0.05114882 -0.0972397\n",
      " -0.00572929 -0.17494556 -0.11050597  0.08735336  0.14264698 -0.11602813\n",
      "  0.03687821 -0.21193336 -0.12135722 -0.13799986  0.1703128  -0.06641126\n",
      "  0.05434673  0.44540098  0.14277412 -0.04497543 -0.06528144  0.16757779\n",
      " -0.17420845  0.18750104]\n",
      "L7N0                    -> L8N100 = [-0.24037781  0.15402322 -0.02362724 -0.19599587 -0.07332542 -0.02292355\n",
      " -0.1387971   0.1571352   0.03648124 -0.25106412  0.01226791  0.17441253\n",
      " -0.15435202 -0.1057568   0.06780946 -0.06600443 -0.16103408 -0.14203586\n",
      " -0.38431332 -0.08163685  0.07663644 -0.0881146  -0.06534725 -0.13405612\n",
      " -0.2522684  -0.2513546  -0.09040263  0.12796137 -0.04180058 -0.15111065\n",
      " -0.34262007 -0.24272762 -0.16224155  0.0293395  -0.3002827  -0.10974959\n",
      " -0.01664764 -0.3203917  -0.30593905 -0.41110095 -0.1020804  -0.04499108\n",
      "  0.07801613 -0.27428627 -0.02416517 -0.30627865 -0.07761874 -0.15145609\n",
      " -0.18459353 -0.3099781  -0.16225335 -0.3132718  -0.02879378 -0.26320058\n",
      " -0.10643888  0.18262199  0.13035774 -0.46964446 -0.17222202  0.11636557\n",
      " -0.11086724 -0.45641053 -0.20757118 -0.17843825 -0.01136093 -0.05291034\n",
      "  0.08634861 -0.07173937 -0.15224445 -0.15551266 -0.38888317 -0.1693459\n",
      " -0.07002746 -0.10268643  0.00164738 -0.3883864  -0.10002328 -0.1871682\n",
      " -0.20850623  0.01025235 -0.17951971 -0.04673455 -0.17083663 -0.0694093\n",
      "  0.08014373  0.20589904  0.33527604 -0.04442309 -0.07062013  0.0504225\n",
      " -0.40800065  0.02433047 -0.26572558 -0.37514707  0.18178898 -0.21157794\n",
      "  0.04159248  0.12724747 -0.39377633 -0.16957937 -0.412029   -0.18834558\n",
      " -0.18862648  0.10316024 -0.12968905 -0.06562024 -0.00411526 -0.3525888\n",
      " -0.11355689 -0.17894532 -0.04808707 -0.23639433 -0.06407439 -0.15170847\n",
      " -0.0917098  -0.05396268 -0.09236684 -0.01274361 -0.49812338 -0.22088693\n",
      "  0.00704094 -0.34473383 -0.32031825 -0.03346272  0.02741453 -0.11341503\n",
      " -0.20495503 -0.08722518 -0.12571673 -0.13565266 -0.30491787 -0.39931062\n",
      "  0.04169156 -0.28902578 -0.06604611 -0.03138714 -0.01415342 -0.15121056\n",
      " -0.02749806 -0.03740687 -0.27955732 -0.06490916 -0.03668941 -0.20215078\n",
      "  0.20804183 -0.0647713   0.28191727 -0.26624995 -0.08622302  0.04127268\n",
      "  0.00782715 -0.14379044  0.0364777   0.00143308 -0.03571967 -0.25878343\n",
      " -0.1649314   0.05355925 -0.23361012 -0.09021901 -0.1252092  -0.09202609\n",
      " -0.17343871 -0.07974137 -0.20515944 -0.25227532 -0.01441562 -0.14722909\n",
      " -0.00641483 -0.3325976   0.03677943  0.16453776 -0.20505148 -0.12753503\n",
      " -0.35682496  0.02770021 -0.5254609  -0.10917568 -0.06393272 -0.11508704\n",
      " -0.04808773 -0.04889958 -0.10669773 -0.08197816 -0.29445904 -0.30836752\n",
      " -0.0181894   0.18602951 -0.18284279  0.04896787 -0.25126967 -0.10432727\n",
      "  0.03089109 -0.04685166 -0.05824099 -0.05449244 -0.1991417  -0.04262595\n",
      " -0.2944269   0.16567491]\n",
      "L7N0                    -> L8N101 = [-0.18150295 -0.3386871   0.13154028  0.11931482 -0.01249033  0.07063321\n",
      " -0.29251638 -0.18290856 -0.3567719   0.19999808 -0.12694941  0.5087343\n",
      "  0.14781295  0.02185215  0.07530058  0.15604608 -0.07091696 -0.08340448\n",
      " -0.05333853 -0.01205608 -0.39673412 -0.01370735 -0.44307765  0.04163529\n",
      " -0.02831062  0.21641478 -0.05779478 -0.05304649  0.04152006 -0.00683439\n",
      "  0.13521697 -0.23228984 -0.10569412 -0.24498022 -0.23708026 -0.0739635\n",
      "  0.00438024  0.04761093  0.0462456   0.06720053  0.35818267 -0.16454284\n",
      " -0.07394564 -0.06412319 -0.079366   -0.0608306  -0.25367492 -0.08201956\n",
      " -0.03123578 -0.14972493 -0.04449757 -0.15347745  0.04810464 -0.1319269\n",
      " -0.13728221  0.07888938  0.15238683  0.05942873  0.14462118  0.05889828\n",
      "  0.08242339  0.02986829 -0.18907487  0.172166   -0.00706397  0.22200385\n",
      " -0.17372958  0.05088229 -0.09105449  0.01153632  0.24170536 -0.06672964\n",
      " -0.6103372   0.02135232 -0.27912232 -0.08745075 -0.01287179 -0.04590243\n",
      " -0.04995891 -0.256557   -0.12890017 -0.16883475  0.11395694  0.06927884\n",
      "  0.07155076  0.02057046 -0.22903585 -0.26052436 -0.3625822  -0.01040319\n",
      "  0.11617556  0.01567567  0.01377814 -0.20656042  0.14464831  0.01924672\n",
      " -0.12989491 -0.41841894 -0.01705068 -0.20276779  0.0791841  -0.18938573\n",
      " -0.28756315 -0.14216714 -0.03160759  0.0065182  -0.03397761  0.14781018\n",
      "  0.20292637  0.2157264   0.11063614 -0.4123169   0.05560673 -0.18594848\n",
      "  0.21779665  0.07961535  0.13614263  0.04008307  0.02706862 -0.09032283\n",
      " -0.00244505  0.11634818  0.0966318  -0.02000875  0.02281296 -0.10490912\n",
      " -0.15070795 -0.22455688  0.06161331 -0.08973587 -0.01028365  0.24657592\n",
      " -0.14896905 -0.11875249 -0.03283488  0.33327258 -0.11893548  0.27444988\n",
      "  0.1384214   0.10989282 -0.02808674  0.02895419 -0.06903362  0.23918648\n",
      " -0.02647281 -0.07139748 -0.08053166  0.01396897 -0.04129814  0.09722109\n",
      " -0.1774986  -0.11351028  0.01282719  0.10613632  0.05530626 -0.00453447\n",
      " -0.10395654  0.15978132  0.04648012  0.14047456 -0.04301694 -0.17459866\n",
      " -0.07106248  0.0438801   0.13051777 -0.24114971  0.10904876 -0.01416802\n",
      "  0.29066244 -0.01361914 -0.057524    0.12581012 -0.09038809 -0.19899389\n",
      " -0.17970882 -0.34997037 -0.15274487 -0.34696117 -0.00328949  0.18380968\n",
      "  0.10505188  0.03988318 -0.1218317   0.16143598 -0.10780378  0.00131932\n",
      "  0.11864494  0.11198337  0.06253663 -0.3358599  -0.06108264  0.03323847\n",
      " -0.33347604 -0.35342154 -0.17127052 -0.03237048 -0.14218542 -0.01629577\n",
      "  0.0374505  -0.03061805]\n",
      "L7N0                    -> L8N102 = [ 1.94793850e-01 -6.61327783e-03  2.21643284e-01 -1.58363208e-01\n",
      " -2.59764463e-01 -3.34995463e-02  1.75744623e-01  1.61243081e-02\n",
      " -6.62097260e-02  1.32592678e-01  1.94961995e-01 -1.58505902e-01\n",
      " -7.57031813e-02  1.81766246e-02  1.49170645e-02 -2.69331038e-01\n",
      "  2.48374008e-02 -1.62207812e-01 -2.40468234e-01  1.32842995e-02\n",
      " -1.53983489e-01 -4.12786976e-02  2.38525465e-01 -1.37830511e-01\n",
      "  1.84931427e-01 -1.36016563e-01 -3.74067426e-01 -4.85946089e-02\n",
      "  2.55628247e-02  4.09562811e-02 -8.99698585e-02  1.09655313e-01\n",
      "  1.41750034e-02 -1.15103751e-01  3.92322354e-02 -1.48236319e-01\n",
      " -1.24301175e-02 -8.78390893e-02 -3.95997949e-02  1.87894821e-01\n",
      "  1.36429980e-01  2.73915201e-01 -9.99685898e-02  2.45665953e-01\n",
      "  4.32135798e-02 -7.05202445e-02 -2.74756234e-02  2.15932742e-01\n",
      " -1.23691984e-01 -8.44440013e-02 -1.85957089e-01  4.12420630e-02\n",
      "  2.69525796e-02 -1.22102939e-01 -2.26599842e-01  2.40987137e-01\n",
      "  1.95533067e-01  3.45622525e-02  5.95473684e-03 -2.39278063e-01\n",
      "  1.86526224e-01  2.25864619e-01  1.29783258e-01 -3.79535288e-01\n",
      " -7.65842423e-02  1.17067710e-01  1.70624942e-01 -6.10420294e-02\n",
      " -6.72916621e-02 -9.62857455e-02 -1.67493537e-01 -4.09842968e-01\n",
      "  8.75409972e-03  2.85017699e-01  1.89577788e-01  2.72886038e-01\n",
      " -1.34264439e-01  5.49250245e-02  1.50453389e-01  2.49365661e-02\n",
      "  6.90582246e-02  4.77030352e-02  4.66902666e-02  1.39578611e-01\n",
      "  3.25557999e-02 -7.59629980e-02  1.36479288e-01 -4.97033000e-02\n",
      " -2.71293849e-01 -4.53268319e-01  1.75248682e-01 -1.18339837e-01\n",
      "  7.32505322e-02  2.07698315e-01 -7.53843412e-02  1.43678814e-01\n",
      "  3.02166313e-01 -3.13911289e-01 -7.84532577e-02 -1.18124276e-01\n",
      " -3.18121202e-02 -1.29668102e-01  7.03397989e-02  9.21193585e-02\n",
      " -4.39123698e-02 -1.35769695e-01 -2.83877283e-01 -4.54931930e-02\n",
      "  2.49352455e-02  2.00578615e-01 -1.77806497e-01 -2.24359855e-01\n",
      " -4.02423233e-01  2.60530442e-01 -1.33469597e-01  1.22085176e-01\n",
      " -4.70188558e-02 -9.87653881e-02  5.21174669e-02  1.08579718e-01\n",
      " -2.44993985e-01  2.97137648e-02  9.38010067e-02 -1.61858052e-01\n",
      " -7.32535496e-02 -2.48384178e-02  1.60469800e-01 -1.73499003e-01\n",
      " -1.28264368e-01  9.28366557e-02  6.12928197e-02  1.03215724e-01\n",
      "  1.26601674e-03  9.66884494e-02 -1.10131204e-01 -1.36667415e-01\n",
      "  3.62018794e-02 -2.43666843e-01  2.92232960e-01  4.98935254e-03\n",
      "  1.40325621e-01 -1.65602267e-01 -2.05967352e-01 -6.85455650e-02\n",
      "  5.54102473e-02 -3.75264496e-01 -1.81472734e-01  2.39877790e-01\n",
      " -1.04977496e-01  1.42403185e-01 -2.79978216e-01 -9.54136625e-02\n",
      " -1.69036567e-01 -1.11008231e-02  2.09817424e-01  1.54765658e-02\n",
      "  5.91390096e-02 -2.92692840e-01 -2.13553593e-01 -2.47321263e-01\n",
      " -2.17311103e-02 -3.53115313e-02  5.34418561e-02 -1.54526055e-01\n",
      "  4.97077778e-03 -4.89477850e-02 -2.74831295e-01 -5.51303057e-03\n",
      " -2.02190518e-01  2.71740884e-01  4.92522307e-02 -1.03198916e-01\n",
      " -1.53574988e-01  4.56944061e-03 -9.01972279e-02  7.49078616e-02\n",
      " -5.83894327e-02  4.06635441e-02 -5.82972355e-02  1.36278450e-01\n",
      " -3.59238714e-01 -5.03315926e-02 -1.14994764e-01  1.76510260e-01\n",
      " -3.98782715e-02  1.62512243e-01 -6.92382604e-02  3.06995760e-04\n",
      "  6.01439096e-04  1.56947359e-01  1.64648041e-01  2.18208447e-01\n",
      " -8.47836658e-02  5.88212349e-02 -1.49639830e-01 -9.08867046e-02\n",
      " -7.11421818e-02 -4.45492975e-02  2.35701669e-02  2.87008509e-02]\n",
      "L7N0                    -> L8N103 = [-5.16838357e-02 -5.98893361e-03 -1.01960927e-01 -7.11372569e-02\n",
      "  8.47282484e-02  7.65434876e-02  7.48583451e-02 -1.21020623e-01\n",
      "  1.13449246e-01 -1.13175109e-01 -2.22768426e-01  6.83751106e-02\n",
      "  2.14522451e-01 -9.44198966e-02  1.56621173e-01  6.92114010e-02\n",
      "  1.19869277e-01 -6.32335171e-02 -1.34453163e-01 -3.05007964e-01\n",
      " -2.32605889e-01 -6.76838979e-02  1.48241799e-02  3.88179794e-02\n",
      "  4.78812400e-03  5.51219508e-02 -6.32823706e-02 -1.53506204e-01\n",
      " -1.55936852e-01 -1.88413963e-01  1.80638164e-01  3.99998873e-02\n",
      " -1.03542535e-02 -6.60574883e-02  4.56075976e-03  2.22875044e-01\n",
      " -2.16626167e-01 -1.12273492e-01 -2.66843975e-01  3.30896256e-03\n",
      " -2.06566915e-01 -2.44507670e-01  2.49096006e-01 -2.38741800e-01\n",
      "  3.50222439e-02  8.80742818e-02  3.84102881e-01 -1.42434333e-02\n",
      "  3.24891806e-01 -4.56284136e-02  1.08140938e-01  1.53577197e-02\n",
      " -2.46408153e-02 -1.37626290e-01 -1.49156094e-01 -2.07373574e-01\n",
      "  1.26750797e-01 -2.01254450e-02  7.26247504e-02 -1.62400499e-01\n",
      "  1.21593595e-01  3.55151705e-02 -2.88972646e-01  3.94018069e-02\n",
      "  4.25266139e-02 -2.90007633e-03 -7.38452822e-02  1.03540666e-01\n",
      "  1.62294686e-01 -1.51291117e-01  3.26108076e-02  1.58537671e-01\n",
      " -4.15115684e-01  3.02904606e-01 -2.75745660e-01  1.79676786e-01\n",
      " -3.15442115e-01  4.28597704e-02 -2.94863097e-02 -2.37512067e-01\n",
      " -1.67458981e-01 -3.18119854e-01  5.74268633e-03 -1.25261713e-02\n",
      "  6.75173402e-02 -3.72369647e-01 -2.39594489e-01 -1.80072069e-01\n",
      "  2.52830595e-01  3.89367938e-02 -1.15971230e-01  1.35962695e-01\n",
      " -1.80790201e-02 -2.63985302e-02  1.52490899e-01 -6.19977005e-02\n",
      " -7.23227486e-02  1.61352888e-01  1.32308066e-01 -6.91682473e-02\n",
      " -9.81069431e-02 -4.63985950e-02 -1.54245213e-01 -2.46492386e-01\n",
      " -2.97742104e-03 -5.70897982e-02  7.94560835e-02  2.46651977e-01\n",
      " -2.20420986e-01  5.63294627e-02 -5.03140688e-02  8.11247528e-02\n",
      " -6.72330335e-02  1.35589559e-02 -2.92525470e-01  1.55014634e-01\n",
      "  1.34003656e-02  2.12501884e-01  1.81268826e-02 -8.43961835e-02\n",
      " -8.66764933e-02 -1.92168262e-02  5.08086011e-02 -5.36124744e-02\n",
      "  1.18761621e-01 -1.95368260e-01 -2.61104584e-01  8.97183120e-02\n",
      "  5.77229485e-02 -1.36982560e-01  2.63349190e-02 -9.99301970e-02\n",
      " -1.65626302e-01  4.45754938e-02 -6.41379282e-02 -4.33740437e-01\n",
      " -1.18161015e-01  8.24102163e-02  2.10734922e-02 -9.26474482e-02\n",
      "  1.99923933e-01  5.50605357e-02  5.44972979e-02 -1.38743311e-01\n",
      " -1.05342912e-02  4.76231240e-02 -1.57849863e-01  9.78273675e-02\n",
      "  1.29292831e-01 -9.56265852e-02  2.17680469e-01 -3.06138099e-04\n",
      " -1.71834975e-01  9.31518152e-02 -1.44373123e-02 -5.16527742e-02\n",
      "  3.84414494e-02  1.17666729e-01  2.17272729e-01 -4.49248329e-02\n",
      "  5.49880601e-02 -9.89455432e-02 -1.73005015e-01 -1.83138371e-01\n",
      "  2.21118152e-01 -1.69398755e-01  3.11841577e-01 -2.28231102e-01\n",
      "  1.36105329e-01 -1.08569279e-01 -1.53253123e-01 -7.11640939e-02\n",
      " -1.40210018e-01 -2.02430189e-01 -5.85061572e-02 -6.36172593e-02\n",
      "  9.08660889e-02 -1.74049541e-01 -2.80979387e-02  7.35259801e-02\n",
      " -9.98385530e-03  1.19481467e-01  2.34784991e-01 -3.82484525e-01\n",
      "  2.59466618e-01  1.72933519e-01  2.87826862e-02 -2.32515141e-01\n",
      " -1.68944165e-01 -2.62435138e-01 -9.13248882e-02 -1.50221139e-01\n",
      "  6.31493628e-02  1.07748300e-01 -3.34462374e-01  1.18198991e-01\n",
      "  4.54968885e-02 -1.17943577e-01 -3.19686271e-02 -3.41841102e-01]\n",
      "L7N0                    -> L8N104 = [ 0.11852403  0.03233828 -0.38391703 -0.21237811 -0.02717563  0.29707873\n",
      "  0.2697298   0.02341728 -0.09618293  0.35652733  0.1544915   0.16439492\n",
      " -0.02022003  0.06710057 -0.23147297  0.1852596   0.00149158  0.25828624\n",
      "  0.13516295 -0.051564    0.21034415 -0.02280072 -0.11295513  0.27435127\n",
      "  0.2849136   0.02443537 -0.07881059 -0.03534188  0.04885071  0.09855986\n",
      "  0.05933871  0.03324828  0.10962912 -0.16711396  0.24608243 -0.05544982\n",
      "  0.15307765 -0.08792701  0.0027043   0.11818837  0.26037818 -0.10738818\n",
      "  0.05414062 -0.20911868 -0.05888087 -0.02263203 -0.21612446  0.05553852\n",
      "  0.14707725  0.05552033  0.27410227 -0.02778004  0.00972477  0.05057011\n",
      " -0.19845249  0.05062788  0.07369868  0.04283756  0.09477515 -0.04108682\n",
      " -0.06560503  0.11682533  0.12283599  0.0183405  -0.04267164  0.03878964\n",
      "  0.25107265  0.10014457  0.09753297  0.14108318  0.02155056  0.03244483\n",
      " -0.14359899  0.06371805 -0.14411941  0.06480367  0.17497069 -0.34497112\n",
      "  0.17506984 -0.03098504 -0.21934499 -0.16943248 -0.04635172  0.26030988\n",
      "  0.1690562  -0.10475596  0.05966901 -0.0637406   0.11875778  0.11121451\n",
      " -0.03051788 -0.04334534  0.17106427 -0.06783064 -0.01504892  0.12174762\n",
      " -0.02320471  0.07947217  0.30824092 -0.1554664   0.21106593  0.04633412\n",
      "  0.24415165 -0.17403983  0.35947105  0.18854778 -0.02823616  0.08304927\n",
      " -0.029311   -0.03080502 -0.08737551  0.09539708 -0.06550368  0.04462739\n",
      "  0.20184402  0.32288644  0.16018479  0.11632308 -0.01634871  0.11990988\n",
      "  0.22413747  0.20478755 -0.09514888  0.1408565  -0.08726652  0.06940609\n",
      "  0.21835762 -0.03266213 -0.26208502 -0.27187088 -0.18781623  0.11695202\n",
      "  0.16438438  0.21307312  0.10356721  0.04843524 -0.18581904  0.10417928\n",
      "  0.12565784  0.03117258  0.12077487 -0.12238736  0.05261043  0.23098284\n",
      " -0.03449553  0.09856147  0.38032177  0.22909324  0.1343467  -0.06844282\n",
      " -0.14908564  0.09858285  0.184703   -0.17259715  0.08384336 -0.05782029\n",
      " -0.07499338 -0.05812938  0.15822503 -0.04208174 -0.08520789  0.12399957\n",
      " -0.06125064 -0.35467055 -0.18902974  0.04374283 -0.22426349 -0.12474311\n",
      " -0.23130347  0.23275115 -0.08787331  0.21499851  0.05778409 -0.03206359\n",
      "  0.059216    0.01773018  0.39962566 -0.18987039  0.16905887 -0.06766085\n",
      " -0.03312819  0.05824402  0.10757038 -0.13472027  0.21742307  0.02289322\n",
      "  0.21011864 -0.11807186  0.09633147 -0.02329742 -0.11866823  0.08099326\n",
      " -0.21280566 -0.0012055  -0.16082615 -0.05979485  0.01779652  0.09464845\n",
      "  0.02624872 -0.29359573]\n",
      "L7N0                    -> L8N105 = [ 0.34121343  0.06813671  0.08139563  0.17588246  0.10243876  0.01409099\n",
      "  0.01204185  0.07380981 -0.12210094 -0.14835301 -0.08517434 -0.03371369\n",
      "  0.02109305 -0.20853415  0.12595421  0.09732747 -0.09695415 -0.00156207\n",
      " -0.06209642 -0.09574898 -0.03276547 -0.29312548  0.04638203 -0.0715168\n",
      "  0.07290349  0.00496518 -0.07357138 -0.05361546 -0.09105753 -0.4009474\n",
      " -0.1515167   0.01711923 -0.00056751 -0.02583845 -0.05111635  0.09841513\n",
      " -0.0487565  -0.12821162 -0.20995656  0.2171247   0.36291027  0.35737792\n",
      " -0.16439365  0.03653897  0.3111248   0.0370548  -0.2776499  -0.2937653\n",
      "  0.02783429 -0.02160675 -0.09736078  0.09458877 -0.13665338 -0.05606791\n",
      " -0.08528509  0.3125608  -0.0029808   0.03116924 -0.10661627 -0.18442878\n",
      " -0.06993452 -0.39163414 -0.19039406 -0.5191556  -0.01186718  0.07546106\n",
      "  0.13738678 -0.21473864 -0.02672831 -0.00681502 -0.13420177  0.08231761\n",
      " -0.02512383  0.3532236   0.11421684  0.13288173 -0.23812507  0.45489645\n",
      " -0.14820449  0.0057849   0.10118505  0.17114323  0.01284228 -0.2852176\n",
      "  0.19687043 -0.01068976  0.2544362   0.22071518  0.01225512 -0.07293708\n",
      "  0.22453263  0.17180328  0.1815661   0.03010634 -0.13586631 -0.04560389\n",
      "  0.05624554 -0.0067465  -0.12888251  0.04301839 -0.03288422 -0.16192307\n",
      " -0.42978337 -0.03004347 -0.22771022  0.08662582  0.2517733   0.03446006\n",
      " -0.31710035 -0.02032655  0.17374457  0.00310814 -0.04056889 -0.25401807\n",
      " -0.05350098  0.16917902 -0.08352058 -0.13795188 -0.08908564 -0.19591932\n",
      "  0.04379108 -0.00231673  0.14750943 -0.1371184   0.11094601  0.08982822\n",
      " -0.06271803 -0.1930888   0.1059844   0.09922083 -0.13455224 -0.0668843\n",
      "  0.02018585  0.06010053 -0.09723096  0.10915036  0.07815286 -0.03447906\n",
      " -0.13855585  0.03875169 -0.20567049  0.14966838  0.15491816 -0.23187178\n",
      "  0.14953482 -0.08185254  0.04519485 -0.21669029 -0.1990021  -0.15830812\n",
      "  0.00570072 -0.28043178  0.05341543  0.09006698  0.07576642  0.09739057\n",
      "  0.19370589  0.17419568  0.19448483 -0.2288942   0.04398441 -0.29750398\n",
      "  0.15475841  0.17698996  0.02943336 -0.13029811  0.03135125  0.20111181\n",
      " -0.19406421 -0.06949133  0.18546695 -0.1535229  -0.34057927  0.06950973\n",
      " -0.19062409  0.04750098 -0.07131149  0.18476288  0.06715576 -0.14645703\n",
      " -0.01903921 -0.16718554 -0.05930802  0.15639518  0.09255371  0.1189179\n",
      "  0.27321854 -0.24252588 -0.12336485  0.18633126 -0.06026649 -0.05545368\n",
      " -0.03328927 -0.00677009  0.25362745  0.14022754  0.0842847  -0.06788611\n",
      " -0.19567311  0.15676935]\n",
      "L7N0                    -> L8N106 = [-0.25156352 -0.10970423 -0.37225163 -0.02647582 -0.1450737  -0.00358324\n",
      " -0.07582173 -0.00804222 -0.24472208  0.06591561 -0.27335274 -0.09804267\n",
      " -0.46753997 -0.04196371 -0.11745134 -0.0673761  -0.07966135 -0.05525265\n",
      " -0.00897733  0.243917   -0.11813555 -0.05578496 -0.06880792 -0.07244328\n",
      "  0.02883711  0.06994707  0.00174471  0.10110731 -0.18711442  0.03192726\n",
      " -0.15325405 -0.05188123  0.01188925  0.32012355  0.06817561 -0.29349896\n",
      " -0.00483592 -0.16305728  0.36249763 -0.00876827 -0.06457956  0.01202265\n",
      " -0.12153605  0.07621814  0.23526141 -0.17925987 -0.02266185 -0.08436505\n",
      " -0.16104414  0.11174718 -0.19136259 -0.09674294  0.20044398 -0.02124733\n",
      "  0.09146366  0.30552983  0.0079162  -0.04577934 -0.12525879 -0.02676379\n",
      "  0.09714946 -0.11423995 -0.23282827 -0.15221393 -0.21849862  0.01757003\n",
      " -0.11789885 -0.4003765  -0.21428415  0.14975068 -0.04154661 -0.25796878\n",
      "  0.2216985   0.20688652  0.06897828 -0.3173798   0.04632188 -0.14169128\n",
      " -0.11785004  0.28621584  0.00627143 -0.08110045  0.04473063 -0.09270059\n",
      "  0.0439499   0.07081065 -0.1500671  -0.28766072 -0.27033773 -0.10753347\n",
      " -0.14143908 -0.11707895 -0.04382488 -0.20555684 -0.23419546 -0.00404388\n",
      " -0.19224307 -0.15829395  0.23318641  0.04222113  0.00173177 -0.2815766\n",
      "  0.03660281  0.10249408 -0.04530128 -0.26352718 -0.2534893   0.3331168\n",
      " -0.17604436 -0.4651975  -0.1861366   0.01581298 -0.03414698 -0.0557764\n",
      " -0.15993331 -0.11637334  0.06127101 -0.1782767  -0.01331031 -0.05413079\n",
      " -0.19881135  0.21041642 -0.07183979 -0.29522592  0.10255355 -0.15661563\n",
      "  0.27552345 -0.05061127 -0.3132232   0.1302135  -0.11351197  0.01092895\n",
      " -0.47734842  0.14471555  0.04844238 -0.16527398  0.18660657 -0.28163022\n",
      "  0.0323399  -0.17929427  0.04971883 -0.19006093 -0.16372435 -0.02378416\n",
      " -0.0249057   0.04511977  0.00995472 -0.29321787 -0.0051668  -0.09179186\n",
      " -0.38426152 -0.0419522  -0.17090103 -0.19729364  0.01207492 -0.2238713\n",
      " -0.08343159 -0.06242587 -0.13619174 -0.02010785 -0.09142827  0.05801851\n",
      " -0.16030063 -0.20544742  0.03614866  0.01352446 -0.28497827 -0.13375178\n",
      "  0.38357365 -0.07337192  0.04728552  0.08382481  0.27767763 -0.02935218\n",
      "  0.2084039   0.09264944 -0.39776897 -0.34138137  0.13702556 -0.28632626\n",
      " -0.32137406 -0.07140004 -0.20318352 -0.26195872 -0.4840603  -0.01621123\n",
      "  0.26759702  0.04348591  0.12329698  0.17046656  0.07654204 -0.1996546\n",
      "  0.00054683  0.24572745 -0.2237753   0.24845065  0.10793509 -0.1982602\n",
      " -0.05519216  0.33759683]\n",
      "L7N0                    -> L8N107 = [-3.56575387e-04 -1.03472024e-02 -1.89705774e-01 -1.27116114e-01\n",
      " -1.14115685e-01  1.35900438e-01 -1.11265108e-01  1.39045730e-01\n",
      "  2.63065159e-01 -1.73044100e-01  1.18436320e-02  1.23203292e-01\n",
      "  4.00059372e-02  1.38976574e-02  1.01351820e-01 -1.04808256e-01\n",
      " -6.05243519e-02 -1.88071549e-01 -6.40564859e-02 -3.94547917e-02\n",
      "  4.03250270e-02 -2.48099625e-01 -2.09532142e-01  9.07970592e-03\n",
      "  9.56250820e-03 -9.52903032e-02  6.52748346e-02  1.10433608e-01\n",
      " -1.36930600e-01 -9.67679024e-02  4.18617725e-02 -3.66163552e-02\n",
      "  4.88997251e-03  2.20960677e-02 -1.15808293e-01 -1.19125038e-01\n",
      " -2.65870243e-01 -1.34719610e-01 -2.56518781e-01  8.17980692e-02\n",
      " -1.46089450e-01  2.11987391e-01  3.35215154e-04 -1.34830475e-01\n",
      "  6.50351821e-03 -4.27555526e-03  2.63098199e-02 -1.32892013e-01\n",
      " -5.17890081e-02 -1.24430135e-01 -3.72860730e-01 -6.73547536e-02\n",
      "  6.03992306e-02 -7.76104778e-02 -9.51644592e-03 -1.25262752e-01\n",
      "  2.69462001e-02  1.13957247e-03 -3.01950015e-02 -1.48057848e-01\n",
      " -6.71978965e-02 -1.39665395e-01 -1.41278654e-01  2.28696130e-02\n",
      " -1.15985908e-01 -1.57093704e-02 -1.66164815e-01 -1.84563637e-01\n",
      " -4.78764698e-02 -9.55623090e-02 -2.01155692e-01  2.20482759e-02\n",
      "  2.76729111e-02  2.43580937e-01  3.01929079e-02 -6.53117076e-02\n",
      " -4.07481240e-03 -2.34728828e-01  5.44456299e-03  1.25296041e-01\n",
      "  8.68841931e-02 -1.67298004e-01 -1.15328193e-01 -2.19700620e-01\n",
      " -1.73465125e-02 -3.33770141e-02  1.54648200e-01 -5.57833575e-02\n",
      " -1.17743723e-01 -2.94579804e-01 -1.60040438e-01  3.19640748e-02\n",
      " -1.36235446e-01 -9.95676443e-02 -5.32426983e-02 -1.10570617e-01\n",
      "  1.38912186e-01 -1.05560996e-01  1.92735940e-01  3.24046761e-02\n",
      " -1.93550453e-01  3.85452248e-02 -3.60497348e-02  1.47968173e-01\n",
      " -1.79418668e-01 -8.36793408e-02 -2.80943792e-02 -2.64215887e-01\n",
      "  1.02466419e-01 -1.94198817e-01 -1.17750712e-01  5.11286780e-02\n",
      " -1.33075446e-01 -1.93103895e-01 -9.37275738e-02 -1.21105701e-01\n",
      " -2.28324011e-01 -5.32122329e-02 -2.59627074e-01 -8.77331048e-02\n",
      " -3.82877082e-01  1.60190567e-01 -5.54348640e-02 -2.47706681e-01\n",
      " -4.14050259e-02  1.92825720e-02  3.15724872e-02  9.77219269e-02\n",
      " -3.31158191e-01  3.16034913e-01 -1.53947830e-01 -3.94171298e-01\n",
      "  2.70870477e-01 -3.09774019e-02 -5.26823699e-02 -1.62517041e-01\n",
      "  1.39154285e-01 -1.85671136e-01  2.00272441e-01  3.11489385e-02\n",
      "  9.84194577e-02 -2.12999046e-01 -1.20838478e-01 -4.69783276e-01\n",
      "  1.41248181e-01 -3.50931704e-01 -2.09950041e-02  1.53572131e-02\n",
      "  1.26915708e-01  2.34253500e-02 -5.14615932e-03 -3.84192824e-01\n",
      "  7.04681873e-02 -3.35920423e-01 -1.47205785e-01 -2.08501946e-02\n",
      " -1.52845383e-01 -4.28846449e-01 -1.70371443e-01 -1.95681721e-01\n",
      " -9.31389555e-02 -2.70310283e-01 -9.26495939e-02 -2.46955574e-01\n",
      "  1.18861385e-02 -1.86814651e-01 -6.33339211e-02 -5.73787987e-02\n",
      " -4.22312289e-01 -4.71346639e-03  2.32117862e-01 -3.09263706e-01\n",
      " -2.64298737e-01  5.02451696e-03  5.38523272e-02  1.30254388e-01\n",
      "  1.61148503e-01  1.02746166e-01 -3.71881947e-02  1.88779980e-02\n",
      " -2.07265005e-01 -1.85776949e-01 -8.97333920e-02 -2.33351186e-01\n",
      " -1.85704127e-01  1.02625124e-01  2.39634104e-02  2.63681207e-02\n",
      "  2.45674178e-02  8.99720788e-02 -2.98062623e-01 -4.29632217e-02\n",
      "  1.37806728e-01  1.76106557e-01 -3.13652605e-02  1.41960591e-01\n",
      " -1.19748034e-01 -1.56231508e-01 -2.59632498e-01  8.77029449e-02]\n",
      "L7N0                    -> L8N108 = [-0.29993004  0.09660859 -0.11064923 -0.120612   -0.14702545  0.2126518\n",
      " -0.14150058  0.17435136  0.2628114  -0.11225239  0.1695101   0.08426464\n",
      " -0.12627394 -0.09985724 -0.06196421 -0.22120018  0.17729789 -0.17702436\n",
      " -0.05739552  0.2672613   0.18975158 -0.18618558 -0.14598659 -0.11658753\n",
      " -0.07657675  0.17193446 -0.25385478 -0.19945604  0.00427147 -0.1535357\n",
      "  0.10467276  0.01324383 -0.01325348  0.2256968  -0.09871941 -0.25889096\n",
      " -0.08426446  0.22089273 -0.01551002 -0.01925517 -0.259785    0.10497823\n",
      " -0.07350787 -0.09789474 -0.04266773 -0.32471073 -0.19514763 -0.0165076\n",
      " -0.1575964   0.01359431 -0.24194716 -0.16677327  0.06696021 -0.03896867\n",
      " -0.26867476 -0.14207068  0.12170772 -0.14416932 -0.14560021 -0.1664363\n",
      " -0.07075126 -0.08875467 -0.22327785 -0.23837985 -0.16969275 -0.06510906\n",
      "  0.00410658  0.1025143   0.0420346  -0.14426869  0.18446226 -0.07898581\n",
      "  0.3165132   0.09805916 -0.03598829  0.13340363 -0.22819237 -0.05497772\n",
      "  0.19146116 -0.02540577 -0.05925922  0.10161443  0.03730552  0.19608657\n",
      "  0.23449144 -0.25940824 -0.0454606   0.06212363  0.00917856 -0.18561183\n",
      " -0.1627695  -0.01714208 -0.17069371  0.04020715 -0.25973684 -0.00151524\n",
      " -0.26470777 -0.3428975   0.1377966   0.05888109  0.02637631 -0.03979447\n",
      " -0.28214335 -0.14675765  0.02332219 -0.01171056 -0.11119865  0.27895057\n",
      " -0.0546695  -0.12760977  0.17028432  0.19123742 -0.08092577 -0.06305156\n",
      " -0.38987    -0.16203682  0.27457035 -0.06805547 -0.09398615  0.23602062\n",
      "  0.12851793 -0.11020608 -0.12320969  0.01564573  0.09255713 -0.0426241\n",
      " -0.02818372  0.09157068  0.11182582 -0.07115762  0.03178329 -0.04935964\n",
      "  0.14068419  0.02281071  0.12101389  0.00785144 -0.06815027 -0.14804427\n",
      "  0.02366591  0.00838426 -0.04698784 -0.03612297 -0.12549333 -0.11837724\n",
      "  0.13743275 -0.35004294 -0.01346738 -0.1735702  -0.09718575  0.2412346\n",
      "  0.04483624 -0.1007239  -0.41181347 -0.02170185 -0.12757663 -0.11311989\n",
      " -0.00658502 -0.24788813 -0.14679885 -0.17051546 -0.02667204  0.01110005\n",
      "  0.04523581  0.02667906  0.07372936  0.0942291  -0.09206273 -0.11048095\n",
      " -0.29966325  0.06100174 -0.04805789 -0.01246879  0.20384584  0.12313267\n",
      " -0.3049714  -0.1266116  -0.40530962  0.14773774  0.02894361 -0.14718719\n",
      " -0.04656334 -0.09516562 -0.06505015  0.08040144 -0.07595677 -0.02402032\n",
      " -0.07257335  0.22386585 -0.3809544   0.08723679 -0.17161296 -0.03046402\n",
      " -0.08023077  0.08503174  0.04437749 -0.16053498 -0.07531954 -0.08827505\n",
      " -0.10163654 -0.14190423]\n",
      "L7N0                    -> L8N109 = [ 0.31459698  0.2598134   0.06506906 -0.24125805 -0.26871875  0.00906692\n",
      "  0.03324455 -0.06402497 -0.14311185  0.09449995  0.01215629 -0.00395281\n",
      "  0.03921497 -0.2290388   0.04645817 -0.13678643  0.12268803  0.02690052\n",
      "  0.03700784 -0.1167542   0.05257976  0.1089704   0.23286168  0.05399596\n",
      " -0.18457492 -0.01690697  0.12396686 -0.16843155 -0.14005215 -0.10161658\n",
      " -0.2885993  -0.10699845 -0.00989573 -0.06395383 -0.12533468 -0.02320569\n",
      " -0.09799087  0.21803331  0.13421997 -0.07366865  0.35589096  0.20277335\n",
      " -0.22852746  0.04220381 -0.02657786 -0.24420048 -0.00934479 -0.10891639\n",
      " -0.07932127  0.02159431 -0.01668597  0.07189134  0.28842685  0.07516689\n",
      " -0.25376764  0.27116373  0.08402291  0.18888685 -0.05470689 -0.23074543\n",
      " -0.0155345  -0.26392025 -0.18633848 -0.28997028 -0.05448591 -0.16148943\n",
      "  0.07022393  0.01561801  0.00270175  0.0082815  -0.09130565  0.05348859\n",
      "  0.09585285 -0.11985418 -0.2215034  -0.15330553 -0.05691198 -0.49656767\n",
      " -0.0521525  -0.10068426 -0.23456849 -0.02751361  0.01766896  0.09461699\n",
      "  0.24481499  0.2913833  -0.01973538  0.01342594  0.09417339 -0.10842513\n",
      " -0.5108651  -0.1579249  -0.01636712 -0.02984477  0.37014928  0.08033394\n",
      " -0.08838705 -0.18254589 -0.02260974 -0.03536971 -0.02242403 -0.13241586\n",
      "  0.07787401  0.01294703 -0.16178896 -0.37011933 -0.21092735 -0.04653344\n",
      " -0.14618737  0.28468215 -0.4064026  -0.12171952 -0.1435738   0.02353434\n",
      " -0.3196299   0.05027076  0.05817948  0.1382663  -0.09438755 -0.14180012\n",
      "  0.08874334  0.02233935 -0.00207945 -0.08137278  0.10841587 -0.12052492\n",
      "  0.07805366 -0.30457094 -0.16416171 -0.0977442   0.0130109  -0.22191511\n",
      "  0.05591145 -0.03802466  0.13316168  0.11461048  0.0272675  -0.40199444\n",
      "  0.05387773  0.11483845  0.2687715   0.05270734 -0.19240545  0.05093259\n",
      "  0.16554242 -0.39398217  0.10663674 -0.17232561 -0.10075857  0.31481928\n",
      " -0.01614707 -0.00572368  0.30655286  0.00953201  0.2513822   0.06422425\n",
      " -0.03805372 -0.05021323 -0.23069564 -0.24313828 -0.22247402 -0.01188957\n",
      " -0.43409973 -0.0235292   0.17769527 -0.01375605 -0.14423145  0.10894688\n",
      "  0.1068795  -0.15560825  0.0624653  -0.11087444 -0.00938621 -0.11558291\n",
      " -0.06644803 -0.19673656 -0.20543644 -0.06297848  0.05103238  0.06448751\n",
      " -0.13861844 -0.16709602 -0.27859923  0.22705038 -0.03242872 -0.13572668\n",
      " -0.22039922 -0.29555348 -0.13193609 -0.00974265 -0.07057112 -0.27680856\n",
      "  0.04826373  0.01205801  0.08652209  0.16204947  0.20842978 -0.01444466\n",
      " -0.04432102  0.22927576]\n",
      "L7N0                    -> L8N110 = [-2.02737227e-01  9.77464318e-02 -4.10702021e-04  1.06907807e-01\n",
      "  8.46861526e-02  1.62735283e-01 -9.50361192e-02  1.98268313e-02\n",
      " -2.30246894e-02 -1.23311831e-02  1.81980595e-01 -3.60460803e-02\n",
      " -8.40415210e-02  1.98702395e-01 -1.06793001e-01 -3.77556562e-01\n",
      "  1.36743456e-01 -1.50146157e-01  1.90876886e-01  2.66792446e-01\n",
      "  8.33556578e-02  6.00011535e-02 -9.40742567e-02 -1.26580521e-01\n",
      " -4.39768173e-02  3.25866699e-01  8.78987536e-02 -8.37674737e-02\n",
      "  7.60914013e-02  1.78404301e-01  1.76215202e-01  2.70554036e-01\n",
      " -5.77819161e-02 -4.46515977e-02  1.38153052e-02 -4.09548163e-01\n",
      " -2.90622581e-02  1.43062368e-01  1.72821298e-01  6.71403557e-02\n",
      "  4.05042656e-02 -4.74554673e-02  1.68321076e-05 -1.56621009e-01\n",
      "  1.83841556e-01 -2.68437117e-01 -1.83010787e-01 -1.90843955e-01\n",
      " -1.09757178e-01  8.14123973e-02 -3.86306234e-02  2.66976923e-01\n",
      "  3.27562019e-02  4.98252474e-02 -4.87460531e-02 -1.40430063e-01\n",
      " -2.48384830e-02 -5.92575930e-02  2.83590592e-02  3.89313906e-01\n",
      "  1.62693083e-01  2.81698629e-02  1.17256463e-01  1.08023509e-01\n",
      " -7.88566247e-02  1.74137771e-01  4.24939841e-01 -1.30334437e-01\n",
      " -2.57442817e-02  1.50196627e-01  2.47805640e-01 -3.28722209e-01\n",
      " -1.82687640e-01  3.16066481e-02  1.88105494e-01 -1.81240141e-01\n",
      " -3.92802879e-02  2.53359050e-01  1.71971805e-02 -1.29279653e-02\n",
      "  1.69927135e-01  4.60557081e-02 -4.75167856e-02  5.66920005e-02\n",
      "  3.72467674e-02  1.24615334e-01  7.38008618e-02 -7.46058524e-02\n",
      " -3.94166559e-01 -1.26217023e-01  5.46294637e-02 -1.73681781e-01\n",
      "  2.85102129e-01  3.18351060e-01 -6.01991080e-02  1.08834088e-01\n",
      "  1.12291671e-01  1.06918067e-01  6.19685240e-02  2.37979144e-02\n",
      "  4.17839512e-02  8.60138889e-03 -3.30881961e-02 -6.39101118e-02\n",
      "  3.22464854e-02  6.91974089e-02  4.97858077e-02  1.92703691e-03\n",
      "  1.51087731e-01 -4.82554078e-01  1.24253832e-01 -9.16666463e-02\n",
      "  3.00030142e-01  1.32488415e-01 -6.06380813e-02  8.19235072e-02\n",
      "  2.18857720e-01  8.85814577e-02  2.12513074e-01  8.53574648e-02\n",
      " -2.08250925e-01  1.11834243e-01 -1.02746874e-01  4.02956530e-02\n",
      " -2.46370044e-02  1.61807135e-01  9.37446281e-02  1.40922174e-01\n",
      "  1.34353623e-01 -2.71167569e-02  1.11528195e-01  8.71221572e-02\n",
      " -1.82529628e-01  1.23515785e-01 -1.06688659e-03 -1.04997326e-02\n",
      "  1.39322326e-01 -1.32635862e-01  2.40518928e-01  2.02547628e-02\n",
      "  3.63565922e-01 -1.71207651e-01 -2.05614805e-01 -3.78832147e-02\n",
      "  2.29803279e-01  2.56984755e-02 -1.71347007e-01  2.03656912e-01\n",
      " -5.38171902e-02  1.80614784e-01  6.60722628e-02  8.95784423e-03\n",
      " -2.48586461e-01 -2.79377878e-01  2.77893096e-01 -6.93152398e-02\n",
      " -2.63536014e-02  7.32748285e-02  4.38395664e-02 -8.38124976e-02\n",
      "  1.71800241e-01  6.21024035e-02  3.32692832e-01  4.59912181e-01\n",
      " -6.77775070e-02 -8.87515768e-02 -8.87464583e-02  1.38622701e-01\n",
      " -1.15456484e-01 -4.07156385e-02 -5.82379773e-02 -2.18111619e-01\n",
      "  3.26592512e-02  2.89087802e-01  3.04221570e-01  1.92216635e-01\n",
      " -3.61626409e-02  2.68789500e-01 -9.20139179e-02 -2.61691600e-01\n",
      " -8.34276900e-02  9.34199020e-02 -1.95609003e-01  1.42556533e-01\n",
      " -1.79659352e-01  5.84736764e-02  4.68098730e-01  1.67397097e-01\n",
      "  2.05470622e-01  2.15764880e-01  1.43764168e-01  1.60020053e-01\n",
      " -3.71906371e-03 -2.64743119e-02 -4.28897478e-02  5.69323897e-02\n",
      "  1.07680961e-01 -3.31422538e-01 -1.05742961e-01  4.18735947e-03]\n",
      "L7N0                    -> L8N111 = [ 0.0245488   0.12962133 -0.1727801  -0.2363862  -0.14232893 -0.16892141\n",
      " -0.11777366 -0.01719301 -0.10582101 -0.22441553 -0.21477656  0.07734032\n",
      " -0.19002958 -0.16457333  0.22729959 -0.16095088 -0.13942826 -0.23747618\n",
      " -0.17344089  0.11127855 -0.16157801 -0.02536991 -0.25793824 -0.05761804\n",
      " -0.22123706 -0.07356302 -0.11112963 -0.14332166 -0.07087821 -0.011529\n",
      "  0.09592009 -0.36265242 -0.17109762  0.10992593 -0.04872637 -0.44097984\n",
      "  0.08644877 -0.23893715 -0.18789758  0.04536083 -0.23940271 -0.02738227\n",
      "  0.00632923 -0.0046588   0.06051009 -0.1240762  -0.31351098  0.03095205\n",
      " -0.22636658  0.03540099 -0.45220676  0.20283027 -0.11990952 -0.15927857\n",
      " -0.19982278 -0.07554358 -0.10364413 -0.02449432 -0.12366425 -0.3364901\n",
      " -0.08620595  0.12673     0.0459241  -0.00567947 -0.1356002   0.11584184\n",
      " -0.0571125  -0.15486677 -0.10219206  0.01357994 -0.20527413 -0.26372814\n",
      "  0.1392239   0.09297941  0.02134682 -0.42714173 -0.08944594 -0.09231164\n",
      " -0.04079228 -0.0074692  -0.00664712  0.04345803 -0.1345568  -0.20003973\n",
      " -0.04286397  0.15173258  0.11471111 -0.2636423  -0.37945586 -0.34003568\n",
      " -0.16395998 -0.29216403  0.18964623  0.03394684 -0.05324882 -0.1938881\n",
      " -0.18601198 -0.2530925  -0.025977   -0.18315695 -0.28597832 -0.28535336\n",
      "  0.04339563 -0.12133013 -0.13674034 -0.08833277 -0.07894144 -0.0461892\n",
      " -0.18129425 -0.06533335 -0.31938764  0.09936133 -0.19912727 -0.08942349\n",
      "  0.02007975 -0.04497397  0.03067775 -0.2188749  -0.21909428 -0.12370808\n",
      " -0.4320316  -0.17835149 -0.11131231 -0.02121901  0.12027355  0.07505192\n",
      " -0.11432608 -0.21988015  0.055037   -0.12526871 -0.30342776  0.14019127\n",
      "  0.09412906  0.08257848 -0.07312471  0.14617965  0.05115332 -0.16813953\n",
      " -0.30393377 -0.06095882  0.06716553 -0.09938045 -0.18431288 -0.14465655\n",
      "  0.01181584  0.01040639 -0.24917166 -0.08129564 -0.07659363 -0.14037074\n",
      " -0.25508085 -0.16460085  0.09274618 -0.2062184   0.07328273 -0.15520851\n",
      " -0.08388047 -0.3176458  -0.18475541 -0.12753363 -0.43522155 -0.05120369\n",
      " -0.10828461 -0.26614076 -0.15138851 -0.00937829 -0.12109976  0.21850723\n",
      "  0.08743198 -0.13579464  0.05951901 -0.16901754  0.00302433  0.46391964\n",
      " -0.22287925  0.02434927 -0.01013145 -0.03273807 -0.1788038  -0.05580848\n",
      " -0.36738244 -0.00450264 -0.11223556 -0.02145777 -0.2535023  -0.37507877\n",
      " -0.14467339  0.08365879 -0.17428777 -0.06295285 -0.0930711  -0.15774088\n",
      "  0.03978238 -0.0138832   0.02848631  0.0052226  -0.21854462  0.05555067\n",
      " -0.09945893 -0.12830003]\n",
      "L7N0                    -> L8N112 = [ 3.23715396e-02 -2.29460716e-01  7.98113458e-03  2.51059115e-01\n",
      "  1.50495693e-01  6.51207939e-02 -1.99091472e-02 -7.90788755e-02\n",
      "  8.49714428e-02  4.79181223e-02  3.05039287e-01  1.37557477e-01\n",
      "  1.92974210e-02  3.01234752e-01 -1.21335676e-02  7.60727227e-02\n",
      "  1.54556051e-01 -1.88129246e-02  9.22207311e-02 -7.97910243e-02\n",
      " -1.39079556e-01 -4.94567095e-04 -2.36766157e-03 -1.23868227e-01\n",
      "  1.76222190e-01 -5.00461236e-02 -2.07842603e-01 -1.97124615e-01\n",
      "  9.92734507e-02  8.68031681e-02  1.17639350e-02  8.62201601e-02\n",
      "  3.00617497e-02 -1.20846659e-01 -6.45327494e-02 -2.53623515e-01\n",
      "  8.72357376e-03  1.13692597e-01 -5.53360172e-02  3.49284828e-01\n",
      " -6.74618930e-02 -2.40225941e-01  8.79541337e-02  2.09683180e-01\n",
      " -3.49792242e-01 -5.02794981e-01 -1.65749803e-01 -4.38524820e-02\n",
      " -1.79218665e-01 -5.44406064e-02 -7.19680190e-02 -8.25016014e-03\n",
      "  1.91255033e-01  1.34017736e-01  2.29711667e-01 -1.29393652e-01\n",
      " -5.77809028e-02 -5.87093607e-02 -1.60153285e-01  1.07533462e-01\n",
      "  3.37542444e-02 -6.72514364e-02  1.52588084e-01 -4.59439196e-02\n",
      " -4.63965684e-02 -5.36648519e-02  2.30909020e-01 -2.07771212e-01\n",
      "  8.53365734e-02 -6.74188584e-02 -3.07197332e-01 -1.73898458e-01\n",
      " -2.87427306e-01  1.44242674e-01 -5.42341992e-02  1.55318871e-01\n",
      " -3.74023408e-01 -1.42499181e-02  1.20635957e-01 -2.79085021e-02\n",
      " -3.53333354e-01  5.72276898e-02 -2.03492921e-02 -1.83297649e-01\n",
      "  1.99295357e-02 -3.65973830e-01 -5.02335234e-03 -5.52069023e-02\n",
      " -3.03272635e-01  1.84509397e-01 -1.61796927e-01 -2.47987017e-01\n",
      " -5.50983250e-02  1.36749610e-01 -1.46255329e-01 -2.65475549e-02\n",
      "  1.22862518e-01 -2.06366703e-01  1.55480549e-01  2.03834653e-01\n",
      "  1.54147357e-01  2.17056081e-01 -2.59999149e-02 -2.32065290e-01\n",
      "  2.65043937e-02  1.41410843e-01  3.16769145e-02 -1.69171378e-01\n",
      "  1.56783655e-01 -1.46652281e-01  1.48633361e-01  1.04725748e-01\n",
      "  9.84621271e-02  7.63970688e-02  5.75879216e-03  2.49572977e-01\n",
      "  5.17174229e-02 -2.43867412e-01  1.33627430e-01 -1.15534831e-02\n",
      "  5.41743040e-02  6.67206664e-03  1.52269304e-01  2.13775262e-01\n",
      " -2.81098008e-01 -9.20001417e-03  3.53288740e-01 -8.39410275e-02\n",
      " -2.08850913e-02 -8.58564898e-02  2.24656999e-01  3.51278968e-02\n",
      " -1.77765012e-01 -6.03847438e-03  4.95168939e-02 -2.06700310e-01\n",
      " -2.02671051e-01 -3.03226858e-01  1.54857159e-01 -3.65492739e-02\n",
      " -1.01237312e-01 -1.49524510e-01 -1.57964438e-01 -3.16086739e-01\n",
      "  3.50176729e-02 -1.48902819e-01  8.55492521e-03 -2.21092537e-01\n",
      " -1.64614897e-02  6.51920140e-02 -8.68394524e-02  2.05657020e-01\n",
      "  4.40287143e-01 -4.53225747e-02 -8.57857615e-02  1.92757212e-02\n",
      "  3.98360081e-02 -8.58399197e-02  2.06277624e-01 -6.49422631e-02\n",
      "  6.98881745e-02  6.90101832e-02  1.58609197e-01  1.93342328e-01\n",
      "  2.78777629e-02 -8.45037997e-02  1.77761406e-01 -3.43461663e-01\n",
      " -7.16300756e-02  1.49510235e-01 -3.65867354e-02 -1.06431760e-01\n",
      "  1.58599153e-01 -2.54082710e-01 -4.28582102e-01  2.66332567e-01\n",
      "  1.26162469e-01 -2.87205398e-01 -1.00071855e-01 -1.23838179e-01\n",
      "  7.87100866e-02  2.63806228e-02  5.45632327e-03 -2.81684458e-01\n",
      " -2.66029775e-01 -2.93460339e-01  1.20035276e-01 -1.39379531e-01\n",
      "  2.26607993e-01 -1.17133595e-02  1.60680667e-01  9.77237225e-02\n",
      " -2.33493164e-01 -1.01388633e-01 -1.60987198e-01  8.21205601e-02\n",
      "  1.56192109e-01  2.09203109e-01  1.56514660e-01 -1.88927472e-01]\n",
      "L7N0                    -> L8N113 = [-0.19920751 -0.1422658  -0.10243774 -0.13389619 -0.08395359 -0.1141656\n",
      " -0.20155227 -0.04146153  0.11968971 -0.1959526   0.12893587  0.00395268\n",
      "  0.03360743 -0.11151564  0.0394465  -0.03106087 -0.2735909  -0.4251354\n",
      " -0.00308711 -0.23635279  0.05270977 -0.04178851 -0.19632325  0.05391019\n",
      " -0.3768496  -0.23282441  0.05709725 -0.0458294  -0.00297785  0.09625297\n",
      "  0.09114669 -0.04100224 -0.23273544  0.11847731 -0.2611735  -0.23289776\n",
      " -0.18912004 -0.13498099 -0.17833838 -0.01487077 -0.03808274  0.17398168\n",
      "  0.00538823 -0.18628004 -0.01295989 -0.16225243 -0.21577753 -0.16690668\n",
      " -0.05420886 -0.07169899  0.06290407 -0.20815246 -0.09126949 -0.15700942\n",
      " -0.31490618  0.20539732  0.2180896  -0.09389465 -0.0705263  -0.12754062\n",
      " -0.01505425 -0.17225574 -0.22269373 -0.03919958 -0.13816679 -0.02038873\n",
      "  0.10965398 -0.02090958 -0.11068124  0.02048861 -0.25729194  0.1716301\n",
      "  0.30040798 -0.15529087  0.29766548 -0.01960886 -0.20676085 -0.20306098\n",
      "  0.05390628 -0.23502623  0.03192455  0.19505978 -0.07786611 -0.03235683\n",
      " -0.22786228  0.14348856 -0.00283869 -0.0102398  -0.29643053 -0.09206463\n",
      " -0.36234277 -0.2500977  -0.08433533 -0.31418902  0.10127153  0.14160553\n",
      "  0.13920358 -0.17801875  0.00069904  0.03882892 -0.3747046   0.03749536\n",
      " -0.08424954  0.15039957 -0.13838604 -0.17563812 -0.16835673 -0.05071068\n",
      "  0.02425973  0.0372033  -0.1926785   0.00975543 -0.07710761 -0.21684355\n",
      " -0.01611169 -0.2808838   0.07830016  0.141306   -0.20722656 -0.27310795\n",
      " -0.13212201  0.02144746  0.05053342 -0.19738908  0.18313313  0.0553127\n",
      " -0.18352894 -0.23113602 -0.00949355 -0.06056638 -0.05740745 -0.21760784\n",
      "  0.09954998 -0.18619777 -0.1941389   0.03757821 -0.00380807 -0.16142555\n",
      " -0.22534367 -0.15556785 -0.33276448 -0.09019106 -0.2709809  -0.16562149\n",
      " -0.00909083 -0.18167317 -0.16810547 -0.07893484 -0.04979038  0.15251525\n",
      " -0.22252901 -0.09776305 -0.11023635 -0.31050396 -0.07743478 -0.16081572\n",
      "  0.07755667 -0.09243456  0.08492964 -0.02869394 -0.29364944 -0.1806621\n",
      " -0.10570718 -0.0802251  -0.01611814 -0.12493847 -0.21621045  0.174627\n",
      " -0.00569675  0.02479366 -0.18129195 -0.15701756 -0.12845725 -0.26820174\n",
      "  0.21188769  0.12226989  0.13575195 -0.1194797  -0.151766    0.08689756\n",
      " -0.11525353 -0.22172603 -0.0111523  -0.06673542  0.05729625 -0.12359499\n",
      " -0.03168213  0.2067735   0.03688201  0.07452604  0.0809435  -0.25288796\n",
      " -0.14706017 -0.16675518 -0.16165991  0.05634369 -0.31157058 -0.26041612\n",
      " -0.09343954 -0.19675355]\n",
      "L7N0                    -> L8N114 = [-0.02972443 -0.11966417 -0.11622255 -0.0916134  -0.02496724 -0.16717188\n",
      " -0.29459065 -0.12941724  0.06583491 -0.39251897 -0.36248747 -0.17044175\n",
      "  0.04760467 -0.1672281  -0.33220735 -0.09899665 -0.2722201  -0.15640198\n",
      " -0.0723548  -0.25495622 -0.41924506 -0.33340308  0.0269624  -0.22648442\n",
      "  0.00779078 -0.12414185  0.03200144 -0.197504   -0.10066486 -0.30437964\n",
      " -0.21039608 -0.59924114 -0.23991358  0.11464338 -0.28962103  0.00116275\n",
      " -0.08154739 -0.13713987 -0.35682535  0.01694787 -0.28148806 -0.2750006\n",
      " -0.2149843  -0.21274896  0.0722182  -0.04109073 -0.25995895 -0.537593\n",
      "  0.0237578  -0.2124738  -0.46612078 -0.3302855  -0.17432272 -0.34216043\n",
      "  0.02423567 -0.02015349  0.03989255 -0.0582035  -0.08836944 -0.22497427\n",
      " -0.14072013 -0.04235838 -0.14868352 -0.04436875 -0.3229058  -0.12670663\n",
      " -0.24593812 -0.05810655 -0.4337651  -0.12529722 -0.28130937 -0.07309748\n",
      "  0.13242063 -0.19749723  0.09421778 -0.14987594 -0.27214986 -0.3600767\n",
      " -0.2673878  -0.26586205  0.08035687  0.15148632 -0.24791367 -0.20810631\n",
      " -0.02730671 -0.01649925  0.1066343  -0.01208575 -0.14034851 -0.10815638\n",
      " -0.31392822 -0.34089553 -0.42617    -0.23415124  0.1372215  -0.18138896\n",
      "  0.06789378 -0.3465727  -0.4962162  -0.25265148 -0.11137439 -0.20048182\n",
      " -0.46337718  0.00228388  0.0135189  -0.12004337 -0.02616593 -0.20149626\n",
      "  0.06953102  0.05530088 -0.3136499  -0.20980719 -0.22394198 -0.02733581\n",
      " -0.08566675 -0.09824585 -0.24014662 -0.13134354 -0.34335604 -0.20323479\n",
      " -0.30620497 -0.21901825 -0.35900453 -0.2867838  -0.06062846 -0.07984697\n",
      " -0.13011265 -0.17197074 -0.06532459  0.14302348 -0.29170144 -0.23080233\n",
      "  0.05047559 -0.32292873 -0.28854415 -0.2183391   0.07154232 -0.08274917\n",
      " -0.15079322 -0.37482584 -0.15534887  0.0867357   0.05742986 -0.27037743\n",
      "  0.001708    0.01752708 -0.05513993 -0.12929358 -0.2798521  -0.1316786\n",
      " -0.05810617 -0.1720019   0.049627   -0.3192942  -0.0364414  -0.17371161\n",
      " -0.15572336 -0.1183793  -0.01457895 -0.01730416 -0.4644811  -0.2398056\n",
      " -0.11253985 -0.22214736 -0.48310342 -0.04079638 -0.12294682 -0.03929378\n",
      " -0.13225797 -0.3115217  -0.08932182  0.0719106  -0.18834275 -0.04912158\n",
      " -0.07539269 -0.02193592 -0.26021716  0.02118417 -0.00851878 -0.0462238\n",
      " -0.13764703 -0.29936382 -0.30054408  0.2218537   0.09737403 -0.37546632\n",
      " -0.21430738 -0.14154963  0.03064895  0.09229041 -0.24716519 -0.2842166\n",
      " -0.01652286  0.05015732  0.05496091 -0.09987037 -0.3922374   0.0437819\n",
      " -0.2503623   0.04460646]\n",
      "L7N0                    -> L8N115 = [-0.1595676   0.0668791   0.0125979  -0.39948994  0.08979046 -0.10690551\n",
      " -0.13958265 -0.37222525 -0.08147139 -0.11593302 -0.01388359  0.16618645\n",
      "  0.1560595  -0.3208355   0.01761186  0.02741066 -0.11310984 -0.06117871\n",
      " -0.40001863 -0.29468048  0.15544732 -0.07189962 -0.01239699 -0.01003315\n",
      " -0.20642959 -0.38175568  0.23114198  0.00659548 -0.05568359 -0.33648637\n",
      " -0.08155543 -0.1908197  -0.14165722  0.13047707 -0.11192818 -0.172016\n",
      " -0.37169304 -0.07039341 -0.13510719 -0.4034952  -0.20884933  0.06616443\n",
      " -0.05493241  0.01546932  0.08524112 -0.03050448  0.07688802 -0.1493146\n",
      " -0.0589379  -0.327576   -0.1515032  -0.3587473  -0.09501694 -0.17437589\n",
      " -0.18053621 -0.09581562 -0.09253091 -0.13390489 -0.3018886   0.10047643\n",
      "  0.05913699  0.02639863 -0.16009296 -0.05788876 -0.06941745 -0.1802248\n",
      " -0.3905698   0.02919359 -0.07237512 -0.3772789  -0.06311225 -0.3164107\n",
      " -0.0907146  -0.09961695 -0.24709003  0.03279532 -0.11832252 -0.19976725\n",
      " -0.24753363 -0.02037757 -0.07878669 -0.09169367  0.02801487 -0.27730772\n",
      " -0.26557946 -0.3084437  -0.01508895 -0.22601238 -0.12443125 -0.38958207\n",
      " -0.04565303 -0.27308497  0.03141428  0.11067216  0.09357692 -0.3600139\n",
      " -0.10247817 -0.11833593 -0.4059123  -0.1409457  -0.17288408  0.00818857\n",
      " -0.21654773 -0.16191511 -0.01175011  0.09556478  0.02603096 -0.20502292\n",
      " -0.2547036  -0.21847104 -0.06798784 -0.28858644  0.0452034  -0.2799659\n",
      "  0.16788742 -0.16088228  0.00296983  0.08587799 -0.21368857 -0.29527146\n",
      " -0.12944546 -0.25837785 -0.25381     0.07890017  0.07478948 -0.21897246\n",
      " -0.12949088 -0.11361733 -0.09036777 -0.1427134   0.05375727 -0.18193635\n",
      "  0.13016365 -0.2542043  -0.375214   -0.12821288  0.12123728 -0.10636833\n",
      " -0.14832985 -0.367464   -0.21293573 -0.03573237 -0.08030861 -0.2414772\n",
      "  0.13726237  0.05154919 -0.24194048  0.16273513 -0.36848235 -0.04830412\n",
      " -0.09650836 -0.13857882 -0.09257149 -0.38577086 -0.15200824 -0.08206357\n",
      " -0.06598681 -0.20450264 -0.19911075 -0.06766421 -0.2121841  -0.33802092\n",
      " -0.03644111 -0.1201674  -0.02691753 -0.3344229  -0.3258479  -0.11191946\n",
      " -0.11804777 -0.19677392 -0.01005156 -0.19217752 -0.07991725  0.19552739\n",
      "  0.11076739  0.01605177  0.10957514 -0.00566893 -0.25147575  0.15816392\n",
      " -0.20850044 -0.05446589 -0.25687906  0.06340845 -0.10863099 -0.03424742\n",
      " -0.1103323  -0.13914715 -0.12364151  0.19008778 -0.10136195  0.10895728\n",
      " -0.21728064  0.05590847  0.00692276 -0.28986403 -0.23288544  0.2445487\n",
      " -0.23889115 -0.0344845 ]\n",
      "L7N0                    -> L8N116 = [-1.06040336e-01  8.66686851e-02 -1.37185395e-01 -1.52412549e-01\n",
      " -2.83134133e-01 -3.39108594e-02 -1.54107422e-01 -2.34859928e-01\n",
      " -6.88467547e-02 -2.26574112e-02  1.45657584e-01 -1.05806738e-01\n",
      " -6.33090502e-03 -2.80436784e-01  9.01553780e-02 -1.28264219e-01\n",
      " -2.69517064e-01 -1.87161073e-01 -1.93877429e-01  1.71588153e-01\n",
      " -2.06453398e-01 -9.93881896e-02  1.26279090e-04 -3.66028786e-01\n",
      " -6.92109764e-02 -4.03368801e-01 -1.95436090e-01 -2.72356626e-02\n",
      " -1.69300899e-01 -4.60863173e-01 -1.85549125e-01  1.84175540e-02\n",
      " -3.05653751e-01 -2.11822763e-01 -1.57774448e-01 -1.70074314e-01\n",
      " -1.54037178e-01 -2.46596798e-01 -1.84093878e-01 -1.96855083e-01\n",
      " -2.78208673e-01 -2.25936621e-01  1.11542512e-02 -3.81134123e-01\n",
      " -7.45055303e-02 -2.29975224e-01  1.00958578e-01 -1.55027926e-01\n",
      "  4.81104776e-02 -5.19748926e-02 -4.24917489e-01 -3.41250002e-02\n",
      "  2.52700914e-02 -5.03154472e-02 -2.05305800e-01  6.24344759e-02\n",
      " -4.48981486e-03 -1.45654753e-01  1.15984567e-02 -8.78060535e-02\n",
      " -2.76158601e-01 -3.24670166e-01  2.68958714e-02 -1.00350238e-01\n",
      "  3.17223594e-02 -3.65015626e-01  8.71980861e-02 -2.97867298e-01\n",
      " -2.11176679e-01 -3.35885614e-01 -2.36712649e-01 -9.05475244e-02\n",
      " -5.47270663e-02 -6.78901896e-02 -3.05659492e-02 -6.63352534e-02\n",
      " -5.27665690e-02  1.23706006e-01  1.19971335e-02 -1.77256212e-01\n",
      "  1.43299162e-01  1.93632141e-01 -3.78302276e-01 -2.68882141e-02\n",
      " -6.99623972e-02  6.83095008e-02 -1.23968355e-01  3.56551111e-02\n",
      " -4.63845693e-02 -2.43479207e-01 -1.10818952e-01 -2.21696228e-01\n",
      " -2.97439825e-02 -9.60023850e-02 -1.61942646e-01 -2.08145157e-02\n",
      " -9.21224952e-02 -3.10026675e-01 -2.61390470e-02 -2.90595651e-01\n",
      " -8.70913565e-02 -1.12825595e-01 -4.61235382e-02  1.81435511e-01\n",
      " -2.77689427e-01 -1.33566141e-01 -4.53332160e-03 -9.00258422e-02\n",
      "  6.71223998e-02 -1.45008460e-01  2.64229953e-01 -3.56546223e-01\n",
      " -4.47677448e-02 -2.23648939e-02 -2.18417093e-01 -7.53216520e-02\n",
      " -1.83011189e-01 -2.44594991e-01 -2.31120303e-01 -2.75952905e-01\n",
      " -1.80358276e-01 -1.09547488e-01 -2.25987926e-01 -3.09929371e-01\n",
      "  8.58911350e-02 -2.42038235e-01 -9.18321311e-02 -1.98127240e-01\n",
      "  1.45142391e-01 -2.75308006e-02 -1.31130069e-01 -4.15080100e-01\n",
      " -1.61699131e-02 -2.69609600e-01  5.39991297e-02 -1.75895035e-01\n",
      "  2.28144407e-01  8.89611244e-03  7.05215111e-02  5.27103022e-02\n",
      " -7.96194151e-02  5.39273024e-02  1.60229318e-02 -1.40888587e-01\n",
      " -8.04120377e-02  1.81479678e-01 -3.84109080e-01  2.02917844e-01\n",
      " -2.96486050e-01  8.23184848e-03 -1.38234328e-02 -1.66232493e-02\n",
      " -2.47931555e-01  2.63461489e-02  9.44738537e-02  4.57130075e-02\n",
      "  2.29704410e-01 -1.57958135e-01  4.39889804e-02 -2.37029269e-01\n",
      " -1.76325187e-01 -4.10146266e-01 -1.14254095e-01  1.02867149e-02\n",
      " -2.29684263e-01 -1.89321190e-01 -3.07963759e-01  8.90980959e-02\n",
      "  7.46121556e-02 -6.66320398e-02 -5.58003597e-02 -2.03845948e-01\n",
      " -9.74691212e-02 -2.60057777e-01  3.03041190e-02 -9.27449837e-02\n",
      "  2.34661236e-01  1.67417780e-01 -1.65131196e-01 -5.36311686e-01\n",
      "  8.06391388e-02 -3.55766952e-01  9.18893367e-02 -5.97496703e-02\n",
      "  1.30869240e-01 -2.58889854e-01  2.76878718e-02 -4.84607667e-02\n",
      " -1.34915024e-01  1.71387970e-01 -2.59173155e-01 -8.58710036e-02\n",
      "  2.57805943e-01 -8.21521448e-04 -1.18320979e-01 -1.32658049e-01\n",
      " -2.45676294e-01 -3.70987415e-01 -1.64556485e-02  1.20319560e-01]\n",
      "L7N0                    -> L8N117 = [ 0.05199615  0.15265617 -0.2284711  -0.10150928 -0.04620121  0.2614411\n",
      "  0.05923036 -0.18784651 -0.09463606  0.35969773  0.0959226  -0.14045577\n",
      "  0.08645601 -0.04159443  0.00252426 -0.31282416  0.19030602 -0.14802036\n",
      " -0.01207552  0.08438081  0.19983324  0.21062633  0.07264964 -0.02624599\n",
      " -0.05368672  0.17229341 -0.00582503 -0.1461169   0.0998514   0.2779945\n",
      "  0.176098   -0.04801962  0.04315563 -0.08826149 -0.07793202 -0.09799732\n",
      "  0.05610698  0.18661647  0.20288856 -0.08731271 -0.1496106   0.01589395\n",
      "  0.0722836  -0.07375491  0.16659768  0.14817685 -0.19594593 -0.07723716\n",
      " -0.03403039  0.08713313 -0.18761082  0.31787202  0.34078354  0.00959023\n",
      "  0.2697287   0.0461723   0.20753266  0.12981723  0.17467894  0.08138359\n",
      "  0.1146647   0.12856126  0.10956985  0.0523917   0.0081555   0.37984225\n",
      "  0.0048342  -0.26444447  0.10184191  0.10361488  0.13870154 -0.05277182\n",
      " -0.05800798  0.24027076  0.4719718  -0.03437486 -0.04024218  0.0354427\n",
      "  0.16355729  0.01560172 -0.03060096  0.12226541  0.21404707 -0.04150818\n",
      "  0.07011606 -0.13261154  0.0278907  -0.14667052 -0.00688971 -0.01991991\n",
      " -0.07840452  0.17813304 -0.07523201  0.335384   -0.1089      0.06177903\n",
      "  0.32027084 -0.03115445 -0.09881172 -0.00623087  0.11285704 -0.05804299\n",
      " -0.02203826  0.16568977  0.05307009 -0.14587021 -0.14388089  0.04246222\n",
      "  0.13673566  0.00608503  0.03901623  0.12026631 -0.24838069  0.07328119\n",
      " -0.07368784  0.35138065 -0.03752042 -0.24091598  0.01537069  0.00319289\n",
      " -0.08631057  0.05039246  0.04639601  0.21230479  0.13854994 -0.202471\n",
      "  0.1469772  -0.10023242 -0.15397973  0.03641112  0.16878676 -0.0213464\n",
      "  0.02893188  0.10164957 -0.00065305  0.26108012  0.35743183 -0.01503912\n",
      "  0.22530232  0.10650849 -0.00930613 -0.12236956 -0.07464834  0.0604508\n",
      "  0.0680214  -0.14128053  0.28708166  0.2736574   0.09960832  0.03049925\n",
      " -0.07239443 -0.15408222 -0.07511716  0.05759183  0.14256638 -0.23873635\n",
      " -0.3221695  -0.28009346  0.04703313 -0.02119683 -0.06658942  0.13920651\n",
      "  0.07156834 -0.30046242  0.21909678 -0.04298259 -0.02948454  0.12323057\n",
      "  0.28774786  0.13251387  0.34466735 -0.078503    0.19850062  0.03176191\n",
      " -0.08351146 -0.09201085  0.17777394  0.22578494  0.05526695 -0.21209358\n",
      " -0.44014415  0.20409481 -0.07582321  0.08911375 -0.24618998  0.07426099\n",
      " -0.15404665 -0.0512077  -0.12199003  0.15339956  0.24529257  0.20106384\n",
      " -0.03582317  0.10469967  0.3189569   0.25890967  0.26112252  0.15018274\n",
      "  0.15615603  0.1412326 ]\n",
      "L7N0                    -> L8N118 = [-0.13786018  0.2695875  -0.11248015  0.10119405 -0.10039152  0.14521821\n",
      "  0.12326419  0.06587414 -0.05926818  0.14390132  0.2321478   0.12260597\n",
      " -0.4573175   0.03808174  0.2060818  -0.15659314  0.08498359 -0.05211743\n",
      " -0.0087137  -0.11883538  0.05590874 -0.04914453 -0.092591    0.22282398\n",
      " -0.00783693  0.09171865  0.0510322  -0.20233114 -0.02163166  0.15217283\n",
      " -0.15736248  0.06900327  0.00108017  0.16610584  0.15653218 -0.00764187\n",
      "  0.1510507   0.1943466   0.08833198  0.00566236  0.0485993   0.17355196\n",
      "  0.14720936 -0.21666507  0.24742989  0.08443756  0.02929936 -0.08929618\n",
      " -0.0841675  -0.00736787 -0.05456793 -0.00373515  0.22488174 -0.03916699\n",
      " -0.15071853 -0.00049507 -0.1010879  -0.05143231  0.06144608  0.17485476\n",
      "  0.07399982  0.13621542 -0.129108    0.18461779 -0.1329873  -0.00175398\n",
      "  0.04838037 -0.3411777  -0.07752967  0.01905051  0.09113576 -0.09431058\n",
      "  0.38438344  0.11076193 -0.10838789 -0.06095869  0.15320988 -0.06121993\n",
      "  0.23318033  0.16318373  0.04214775  0.07461292  0.04792289  0.29929945\n",
      " -0.09203548 -0.08920655  0.01404841 -0.033952    0.03642434  0.17001578\n",
      " -0.3134125  -0.17774907  0.09760308  0.00389374 -0.07665958  0.16568561\n",
      "  0.04197127 -0.0986446   0.1745261   0.0857685   0.33666727  0.2632094\n",
      "  0.03178117 -0.12202564  0.17967765 -0.17488699 -0.38840243  0.06446099\n",
      " -0.15317515 -0.28047943 -0.3434652   0.13895626  0.1416299   0.1472232\n",
      "  0.10642639 -0.30930826 -0.00662024 -0.05716767  0.01976603  0.04603579\n",
      " -0.02890679  0.03050681  0.06327348 -0.09060511 -0.15500279  0.07792528\n",
      "  0.18137428  0.2622033  -0.38015968  0.09504537  0.05190727  0.19605169\n",
      " -0.21923855  0.26826254  0.18116741  0.10034035  0.00078507  0.01498893\n",
      "  0.09068017  0.0605188   0.3221985  -0.01513367 -0.2651927   0.0736839\n",
      " -0.49029455  0.24100432 -0.20042284 -0.15316223  0.09011788  0.02743806\n",
      " -0.2977785  -0.08706866 -0.2671041  -0.02116876 -0.1856983  -0.00645077\n",
      " -0.18376443 -0.12397392  0.00815082 -0.16698265 -0.14518866  0.04533446\n",
      "  0.07126377 -0.11173403  0.06948298  0.02875794 -0.0559559   0.07277954\n",
      " -0.20356011  0.07381102 -0.0374943   0.02452833  0.10175587  0.04595881\n",
      "  0.09766271  0.09649828 -0.03147321  0.03593568  0.10637035 -0.34873155\n",
      " -0.32759863  0.08598081  0.04168639  0.03255462  0.0873426  -0.06690624\n",
      "  0.14058761  0.05572829 -0.0909498   0.01225176 -0.09114442 -0.3087964\n",
      "  0.03321368 -0.07909811 -0.07901657  0.10065761  0.05724892 -0.12977321\n",
      "  0.10689503  0.05532454]\n",
      "L7N0                    -> L8N119 = [-0.31560624  0.24758454 -0.3859622   0.09413212  0.02520347  0.137658\n",
      " -0.1403482  -0.06182921  0.0594034  -0.15954144 -0.00488145 -0.20304103\n",
      " -0.27786478 -0.3896935   0.02752117 -0.471       0.1860986   0.17816272\n",
      "  0.02773505  0.01974491 -0.03106236 -0.11713063 -0.2616373  -0.21167147\n",
      " -0.48908073  0.11779027  0.00668898  0.1470423  -0.07157879 -0.06022525\n",
      " -0.18178336  0.02004527 -0.3275373   0.11720423 -0.0681843  -0.15164974\n",
      " -0.08310476 -0.2229915  -0.01103666 -0.11745152  0.24777605  0.02049068\n",
      "  0.21410008 -0.24355431  0.05029601 -0.1952698  -0.17104946 -0.07811245\n",
      " -0.16115843 -0.19733912 -0.18003993 -0.24727814 -0.11332423 -0.0972897\n",
      " -0.01540742 -0.23655188 -0.19718866 -0.10398233  0.14461726  0.1761284\n",
      " -0.10514373 -0.01792629 -0.06488754  0.07126842  0.02161944 -0.01806586\n",
      " -0.0446295  -0.46095988 -0.03182914 -0.03255111  0.23437187 -0.14160013\n",
      "  0.09146056 -0.11123075  0.08278242 -0.02848375 -0.03889695 -0.03262894\n",
      " -0.35875446  0.05024448  0.06688387 -0.151632   -0.03445928  0.04025469\n",
      " -0.35258353  0.22009583 -0.16676265 -0.09826095  0.23532464  0.10329415\n",
      " -0.0147458  -0.00414357 -0.08044824 -0.06502292 -0.22353654  0.1095399\n",
      " -0.0274644   0.13516828  0.1087372  -0.03780284  0.04223813  0.08423803\n",
      "  0.01335191 -0.18649891  0.09815677 -0.02623666 -0.02725199 -0.22617063\n",
      " -0.12777223 -0.1343406  -0.00415568 -0.22152978  0.1564665  -0.05273782\n",
      "  0.03108009 -0.44511035  0.00172195 -0.12831654 -0.22736841  0.09653471\n",
      "  0.13349444 -0.09325135  0.02919494  0.04695501 -0.14109986 -0.21656539\n",
      " -0.2733152   0.17072296  0.01919395 -0.02735618 -0.14471756  0.01462879\n",
      " -0.30682677 -0.03796859 -0.08539787 -0.08861706  0.13193214  0.06309041\n",
      " -0.02314808 -0.09789494  0.08779099 -0.253071   -0.33086535  0.05289996\n",
      " -0.10975696  0.02872373 -0.27975258 -0.17377561 -0.2422589  -0.42430767\n",
      " -0.24927466 -0.0300445  -0.17686482  0.03088219  0.01640916 -0.09573026\n",
      " -0.10848134 -0.03257414 -0.12368171  0.12084046 -0.27454948 -0.36852622\n",
      " -0.10921824 -0.04410547  0.04459217 -0.09169389 -0.21255805  0.16928251\n",
      "  0.08546959 -0.24471384  0.05160851 -0.08377008 -0.16675104 -0.035824\n",
      " -0.23876779 -0.45863023  0.07289576  0.02368308 -0.21410298 -0.20933467\n",
      " -0.1347236   0.01056249 -0.13166021  0.07118662 -0.16973425  0.05206537\n",
      "  0.17702295 -0.08988266 -0.30204278 -0.02168634 -0.14963302  0.00567463\n",
      "  0.16111074  0.02989405 -0.26625004 -0.15682644 -0.03905161 -0.28458625\n",
      " -0.22862966  0.02735866]\n",
      "L7N0                    -> L8N120 = [-0.05684217 -0.02479652  0.04051718  0.0009707   0.13335349  0.06943916\n",
      "  0.14359222 -0.02973308 -0.06244136 -0.00981366  0.18701656  0.04618993\n",
      " -0.09722839 -0.20744577  0.07513458 -0.05413366  0.03116773 -0.14422601\n",
      " -0.0353101   0.11060657 -0.03306034 -0.04358723 -0.11152343  0.01372241\n",
      " -0.07107317  0.14486216 -0.02577829 -0.40458378 -0.07121441 -0.20939754\n",
      " -0.22572581  0.0500596  -0.06680878 -0.08141345 -0.08551988 -0.26726243\n",
      " -0.22715518  0.09753514 -0.23012795  0.07610177  0.17315675  0.00242206\n",
      "  0.09813634  0.09682669  0.00144357 -0.08848323 -0.28929493 -0.01089357\n",
      "  0.03430017  0.09032317 -0.15303527 -0.28279394  0.10372829  0.01796341\n",
      " -0.39442924 -0.10988669  0.14631034 -0.03819485  0.1609204   0.0416813\n",
      " -0.05415226 -0.13622431 -0.02643564 -0.11236342 -0.12102377  0.02163226\n",
      "  0.08253175  0.0228149   0.3051276  -0.07296236  0.04633426 -0.04982165\n",
      "  0.08701791  0.22079629 -0.00718558 -0.22456427  0.04385728 -0.1493984\n",
      " -0.15460756 -0.02252753 -0.00092905  0.0529156  -0.00238492  0.10953679\n",
      "  0.22280923 -0.03970391  0.06373805  0.06261024 -0.180943   -0.11642615\n",
      " -0.26766074 -0.25007182  0.10275698  0.01479574 -0.1494853   0.05173163\n",
      " -0.04168019 -0.4804089   0.05682397  0.01511353 -0.00420975  0.30233428\n",
      "  0.0822372   0.00403585  0.13821582 -0.04484687 -0.05980884  0.01433596\n",
      "  0.02754602 -0.52838874 -0.11481036  0.06722316  0.2517547   0.1051999\n",
      " -0.15615477 -0.11901876 -0.00304785 -0.1191548  -0.0599809   0.03844667\n",
      "  0.03110108  0.11176285  0.02972685 -0.09914811  0.02376602 -0.062791\n",
      "  0.00312534 -0.12696944 -0.40621477  0.01024186  0.10425406 -0.13749304\n",
      " -0.08261101 -0.1594609   0.02577745 -0.05911632 -0.05612283 -0.00480117\n",
      " -0.1945949   0.00193327 -0.23808639 -0.11522457 -0.09254281 -0.3805357\n",
      "  0.05684353  0.029257   -0.12667362  0.01060894 -0.03583235  0.04309426\n",
      " -0.11421558  0.14683357 -0.14717174 -0.07894473  0.21074808 -0.17740823\n",
      " -0.12374208  0.09658372  0.10532138 -0.02537328 -0.18133937  0.05268317\n",
      " -0.15837933 -0.17596036 -0.235199    0.02664254 -0.1489776   0.24966633\n",
      " -0.03586297 -0.14620264  0.20531382 -0.30112123 -0.24230611 -0.12766719\n",
      "  0.07416572 -0.03524169 -0.01811082  0.37187985 -0.08090062 -0.03884852\n",
      " -0.404203   -0.21099973 -0.4131437   0.15471949 -0.32829097 -0.01227985\n",
      " -0.14207785  0.04453391  0.23405129  0.30947825 -0.16734427 -0.13830192\n",
      " -0.06101096  0.13111125  0.11466487  0.13269651  0.11834808 -0.05697989\n",
      "  0.1010524   0.12379634]\n",
      "L7N0                    -> L8N121 = [ 5.27201109e-02 -2.25624382e-01  1.38794661e-01  1.05264507e-01\n",
      "  2.11790562e-01 -2.46973395e-01  1.29909053e-01  1.38549760e-01\n",
      " -2.32065395e-01 -2.25609690e-01 -2.43949875e-01  1.66984707e-01\n",
      "  1.45973321e-02 -5.06793521e-02 -1.26772135e-01 -1.14468008e-01\n",
      " -1.24652192e-01  1.58192888e-01  4.57333960e-02  9.99890342e-02\n",
      " -1.17491875e-02 -1.75307304e-01  6.88848868e-02 -1.72781348e-02\n",
      " -3.09718773e-03 -1.83218718e-01 -8.94776732e-02 -1.59104422e-01\n",
      " -5.05913980e-02  1.25121102e-01  1.63857549e-01 -1.72974065e-01\n",
      "  4.89151590e-02 -1.79453835e-01  8.71959925e-02 -1.15639314e-01\n",
      "  1.49558187e-01 -7.91173503e-02 -2.21955612e-01 -3.46521623e-02\n",
      " -3.60247791e-02 -1.49872318e-01 -1.53651116e-02 -2.15018526e-01\n",
      " -2.16497809e-01  2.34416768e-01 -4.18490499e-01 -5.32072689e-03\n",
      " -3.24735910e-01 -1.82978541e-01  7.60820955e-02 -1.92658737e-01\n",
      "  1.11477137e-01 -7.51131028e-02  2.06079900e-01 -1.95360601e-01\n",
      " -1.35748833e-01 -1.23145953e-01 -4.10614051e-02  2.18162730e-01\n",
      "  4.57709655e-02 -1.56873211e-01  1.86154902e-01  7.24122897e-02\n",
      "  2.62856465e-02 -4.22958843e-02 -4.21049111e-02  1.20471470e-01\n",
      " -7.82011896e-02 -5.29076867e-02 -2.32997552e-01 -7.14754760e-02\n",
      " -1.25595674e-01  4.77920137e-02 -1.39070705e-01  1.03760786e-01\n",
      "  9.39734802e-02  1.76029533e-01  2.54428610e-02 -1.81509405e-01\n",
      " -6.27550855e-02 -1.12359866e-03  8.16997811e-02  3.70291293e-01\n",
      " -2.00368688e-02  5.54389507e-02 -1.12480298e-01  7.59114474e-02\n",
      "  4.51923274e-02 -2.50410195e-02  1.83247089e-01  6.05411716e-02\n",
      " -1.08976237e-01 -6.48844317e-02 -4.37710844e-02 -6.26649261e-02\n",
      " -8.87879077e-03  1.84550256e-01 -1.87708177e-02  4.81630936e-02\n",
      " -1.55555695e-01 -1.45670339e-01 -2.27250881e-03 -2.39399493e-01\n",
      " -9.46882740e-02  1.95546821e-01  5.82306571e-02  4.20931578e-01\n",
      "  1.97463995e-03 -3.11251402e-01  8.13740045e-02 -2.05515385e-01\n",
      " -1.63886789e-02 -9.44087431e-02 -1.40290290e-01 -8.99262205e-02\n",
      " -8.75153616e-02 -2.74047345e-01 -3.68376710e-02  1.23988695e-01\n",
      "  1.65644094e-01 -9.51458439e-02  8.35653022e-03  2.06248593e-02\n",
      "  1.19268313e-01 -1.29558861e-01  1.15635969e-01 -1.69549599e-01\n",
      "  1.99183092e-01  2.36022728e-03 -2.62228958e-03  3.31407390e-03\n",
      " -1.45845219e-01  6.26519844e-02 -5.69526702e-02  9.65813249e-02\n",
      " -3.21087509e-01  5.47387861e-02 -1.60358399e-01  2.55397726e-02\n",
      " -5.96383587e-02  4.78541926e-02  1.28417173e-02 -2.40753755e-01\n",
      " -8.21157843e-02  7.75077865e-02  6.96422085e-02  9.55724046e-02\n",
      " -3.86311412e-02  1.71578899e-01 -3.82277668e-02 -1.86033592e-01\n",
      "  2.46021137e-01  2.94648353e-02 -7.03101233e-02 -3.78843844e-01\n",
      "  2.42002085e-01  2.27491856e-01 -1.44205853e-01  3.43032256e-02\n",
      " -1.18765317e-01  3.71831493e-03 -5.49571030e-02  1.22804788e-03\n",
      " -8.52758586e-02 -2.55182758e-02  2.91252971e-01 -1.93189420e-02\n",
      "  3.04701049e-02 -1.39315709e-01 -2.38540873e-01  8.49330500e-02\n",
      " -6.57615662e-02  2.79589832e-01 -2.51486033e-01 -2.34134912e-01\n",
      " -2.02649727e-01 -1.07886396e-01 -4.73299995e-02  2.08618358e-01\n",
      "  1.99329644e-01 -2.01968282e-01 -2.20323037e-02 -1.39561400e-01\n",
      " -3.53925899e-02 -1.12779245e-01 -1.95985407e-01 -6.20834306e-02\n",
      "  7.64150843e-02 -5.17877698e-01  3.97132337e-02 -1.06525712e-01\n",
      " -9.94540006e-02 -1.39321864e-01 -1.78098232e-01 -4.86913323e-02\n",
      "  2.24537011e-02 -1.25638128e-03  1.09530418e-04 -3.88351917e-01]\n",
      "L7N0                    -> L8N122 = [ 4.62870896e-01  2.99570292e-01  4.01969366e-02 -2.89495159e-02\n",
      " -1.94908917e-01  2.93651879e-01  2.49949366e-01 -8.44759196e-02\n",
      "  3.16603072e-02  1.91327900e-01  1.17212400e-01  4.52445149e-02\n",
      " -1.65373072e-01  4.21158075e-02 -9.32563171e-02 -1.98505610e-01\n",
      "  2.23068237e-01  2.16094442e-02  3.95277366e-02  1.18095137e-01\n",
      "  1.62206993e-01  1.38455397e-02 -6.36622012e-02 -3.36940885e-02\n",
      "  1.56216562e-01  2.92026694e-03 -2.26418063e-01 -2.99822271e-01\n",
      "  1.71887338e-01  3.06430697e-01  9.51687098e-02  1.29453585e-01\n",
      "  6.39071763e-02 -8.16753730e-02  1.51670083e-01 -6.69007376e-02\n",
      " -5.37426583e-02  4.95873615e-02  1.72593519e-01 -2.76151318e-02\n",
      " -5.16790807e-01 -1.35279894e-01 -1.24480411e-01 -1.72060393e-02\n",
      "  1.48914419e-02 -3.44517946e-01 -1.72842488e-01 -1.72887985e-02\n",
      " -1.06632397e-01  6.85599595e-02 -7.43363723e-02 -1.02581337e-01\n",
      "  1.30331799e-01  1.83628738e-01 -2.17153311e-01 -4.03232872e-02\n",
      "  9.24341753e-02  7.24284127e-02 -7.59474039e-02 -1.42097927e-03\n",
      "  2.12026417e-01  3.16629887e-01 -9.78431553e-02  2.12238148e-01\n",
      "  1.36902081e-02  1.23170480e-01  2.96595991e-01 -3.14496234e-02\n",
      "  2.24978790e-01  1.40671015e-01  3.93195808e-01  9.24228206e-02\n",
      " -1.74277186e-01 -2.19831262e-02 -1.89562708e-01  2.17203632e-01\n",
      "  9.79637206e-02  1.18461773e-01 -1.73181891e-02  1.25422969e-01\n",
      "  1.56357646e-01  1.42250657e-01  2.36219317e-01  1.08503580e-01\n",
      "  2.60997146e-01 -5.22742458e-02 -1.01875521e-01  9.60858315e-02\n",
      " -7.82958865e-02 -2.12376222e-01 -7.10771009e-02 -3.92175652e-02\n",
      "  2.70884722e-01 -1.18178405e-01 -2.46794477e-01 -2.04077102e-02\n",
      "  2.05799252e-01 -1.01854116e-01  2.17256576e-01  1.72358349e-01\n",
      "  8.13653395e-02 -1.57433629e-01  2.02645734e-01  2.85395473e-01\n",
      " -3.38396318e-02 -2.34268099e-01  2.54198182e-02 -1.20058879e-01\n",
      " -1.69210374e-01 -2.29448825e-02 -4.02578488e-02  3.76178734e-02\n",
      " -1.22078650e-01 -1.11023828e-01 -2.39291221e-01 -1.83021709e-01\n",
      "  1.75492436e-01 -1.08550876e-01  5.10214008e-02  1.68152511e-01\n",
      " -1.70883909e-01  1.10755958e-01 -5.36608994e-02  1.37303025e-01\n",
      "  1.03776611e-01  9.64769349e-02  7.24901706e-02 -3.35473754e-02\n",
      "  1.04853339e-01  6.94718435e-02  8.03366601e-02 -3.04943509e-02\n",
      "  1.21896923e-01  9.88470241e-02  2.36200482e-01 -6.54628128e-02\n",
      "  8.31324160e-02 -2.62396455e-01 -9.05638635e-02  1.38583243e-01\n",
      "  2.35843286e-01 -2.62321651e-01 -1.14302419e-01  4.02509943e-02\n",
      " -9.69808027e-02 -3.60017896e-01 -2.53123254e-01 -1.75432151e-03\n",
      "  5.46364710e-02  2.04931363e-01 -9.85493883e-02  1.59080088e-01\n",
      " -1.33874059e-01  9.56019834e-02 -3.82152162e-02  2.35681742e-01\n",
      "  9.10483748e-02 -3.12083900e-01 -1.90941300e-02 -2.64413953e-01\n",
      "  1.81484237e-01  6.47647604e-02 -6.84604049e-02 -2.29690031e-05\n",
      "  2.92140931e-01 -1.12207018e-01 -2.41342381e-01  1.13054775e-01\n",
      " -4.71641682e-02  2.10152224e-01  1.20963722e-01 -1.19077690e-01\n",
      " -2.02132910e-02  1.92550018e-01 -1.88255817e-01  1.73315868e-01\n",
      "  4.90965247e-02  2.63591316e-02  1.61514953e-01 -1.80586591e-01\n",
      " -7.76679590e-02 -6.56335652e-02  1.28917247e-01  7.22824708e-02\n",
      " -1.95437551e-01  9.13091470e-03 -1.23616777e-01 -5.45712234e-03\n",
      " -4.04377192e-01 -1.01312019e-01 -3.33467349e-02  2.13619754e-01\n",
      "  1.26859367e-01 -7.58952228e-03 -1.73756704e-01  2.37549871e-01\n",
      "  1.14553981e-01 -2.79942989e-01 -4.73324955e-02 -2.84135230e-02]\n",
      "L7N0                    -> L8N123 = [-0.35066593  0.04380986  0.16188252 -0.05259907  0.10573617 -0.3035244\n",
      "  0.1551677  -0.23941179 -0.14334357 -0.20347369 -0.07169364  0.14587392\n",
      " -0.17938158  0.14636788 -0.11025357 -0.00584388 -0.00248157  0.24892183\n",
      "  0.07623168 -0.19950025 -0.09164715 -0.20568134  0.08221386 -0.31468487\n",
      " -0.26157483 -0.27698588  0.21365704 -0.02496677 -0.23017465 -0.12044317\n",
      " -0.09923261 -0.15750676 -0.06575455 -0.16888385 -0.04524762 -0.33038414\n",
      " -0.12523066 -0.00453995 -0.24684112 -0.21216848 -0.09245618 -0.26699382\n",
      " -0.25939503  0.21736364 -0.07740857  0.02335489 -0.03725894 -0.11575466\n",
      "  0.03948602  0.02772489 -0.24851139 -0.22583602 -0.03381151 -0.12345169\n",
      "  0.10644667 -0.05160117 -0.02120779 -0.11938386 -0.1005559  -0.04390833\n",
      "  0.0699749  -0.3641882   0.06517248 -0.07500686 -0.20843543 -0.09888118\n",
      " -0.2771762  -0.27544644 -0.01648834 -0.13536577  0.15111938  0.02794038\n",
      " -0.22675547 -0.18012783  0.00424791 -0.08141484 -0.0193102  -0.01414546\n",
      "  0.06376875  0.04995599 -0.10355546 -0.20030507 -0.10805066  0.17479259\n",
      "  0.1941385  -0.25292605 -0.02128715 -0.19720514  0.05594446 -0.25503498\n",
      "  0.21833813 -0.23305184 -0.3068002   0.02206215  0.05343724  0.05602591\n",
      " -0.17778529  0.11582717 -0.34361097 -0.3062234  -0.15013535  0.06198518\n",
      " -0.1818589  -0.01381671 -0.26174736  0.05167978  0.04630876 -0.18948966\n",
      "  0.22299837  0.25482866  0.18258135  0.12428214  0.14008822  0.15143622\n",
      " -0.24802795 -0.02336128 -0.08924955 -0.14400254  0.01286394 -0.15065145\n",
      " -0.00267745 -0.03885313 -0.2692841  -0.21535107 -0.15985672  0.01909304\n",
      " -0.08668567  0.03660613 -0.07761487 -0.26368472 -0.03012989 -0.1492916\n",
      " -0.12957814 -0.2670372   0.02545246 -0.05752746 -0.03384248  0.19479015\n",
      " -0.01451214 -0.14323848 -0.05206171  0.11753234 -0.32028154 -0.04136533\n",
      " -0.19415686  0.1734045   0.04775761  0.06053399 -0.30728132 -0.01056127\n",
      " -0.07835436 -0.1906478  -0.06607369 -0.05599674 -0.2608709   0.18616806\n",
      " -0.11801296  0.05981161 -0.36411515  0.11217819 -0.20534438 -0.18351282\n",
      "  0.1811195  -0.00500936  0.21453576 -0.17269185 -0.25581962 -0.13366486\n",
      " -0.28530928 -0.220944   -0.09386577 -0.15814978 -0.14462173 -0.02199337\n",
      "  0.211512   -0.362864   -0.09302814 -0.04294207 -0.29835576 -0.01414079\n",
      " -0.1921615  -0.12922817 -0.02237072  0.01544821 -0.10163488 -0.03571146\n",
      " -0.0583431   0.12329997  0.02984726 -0.4050863  -0.01123779  0.02894043\n",
      " -0.18518029 -0.25178543 -0.2528472  -0.11721794 -0.04338256  0.0572595\n",
      " -0.05485412  0.11175148]\n",
      "L7N0                    -> L8N124 = [-5.05479947e-02 -3.74742746e-01 -1.57631263e-01  1.68192819e-01\n",
      "  1.46335244e-01 -1.24898590e-02  1.82298850e-02 -2.44582310e-01\n",
      " -2.46268868e-01 -1.14171207e-01 -3.51901084e-01 -1.98678106e-01\n",
      " -2.18211845e-01 -9.13651288e-02 -7.48183280e-02 -1.96854249e-01\n",
      "  1.39270782e-01  2.50939310e-01 -3.20127517e-01 -3.13946098e-01\n",
      "  3.35520841e-02 -7.53787905e-02  1.67630091e-01 -2.49504656e-01\n",
      " -5.90889491e-02 -2.59193957e-01 -6.35778606e-02 -1.52321920e-01\n",
      "  4.75003719e-02 -3.48935366e-01 -2.66160369e-02  5.68418913e-02\n",
      "  9.01954994e-02 -1.26890436e-01 -1.73216969e-01  6.59165755e-02\n",
      " -1.84361085e-01 -9.52271670e-02 -1.35665923e-01 -2.46381372e-01\n",
      " -7.95971155e-02 -8.24661478e-02 -3.53404194e-01 -8.50472450e-02\n",
      " -5.52653633e-02  1.12710953e-01 -6.38440847e-02 -2.56578058e-01\n",
      "  2.23109916e-01  1.40643299e-01 -1.55749306e-01 -2.30216384e-01\n",
      " -9.80033949e-02  1.52870622e-02  7.14323819e-02 -2.44345248e-01\n",
      " -1.33831993e-01 -5.83900064e-02  6.04589656e-02  2.06659059e-03\n",
      " -1.63531587e-01 -1.39047295e-01 -3.43768075e-02 -3.03317159e-01\n",
      " -3.99454981e-02 -1.75790220e-01 -1.71376199e-01 -3.33754659e-01\n",
      " -8.99557620e-02 -3.11948121e-01  3.55890281e-02 -1.73417822e-01\n",
      " -9.54654589e-02 -4.19582762e-02 -2.73441952e-02 -9.69591811e-02\n",
      " -6.47712313e-03  1.86554156e-02 -1.43050835e-01  6.02529757e-02\n",
      "  3.44976820e-02 -1.91874877e-01 -8.27598050e-02  7.61383325e-02\n",
      " -8.53290111e-02  5.92748523e-02 -2.59223431e-01 -3.10143620e-01\n",
      " -8.41553807e-02 -2.45926917e-01  1.68542221e-01 -3.74552235e-02\n",
      " -5.19181453e-02  2.92780638e-01 -5.69505692e-01 -1.55655801e-01\n",
      " -1.82701647e-01  1.03036471e-01  6.86892048e-02 -6.59219474e-02\n",
      "  4.18842211e-03 -1.97487310e-01  2.37156644e-01 -2.49867514e-01\n",
      " -1.17187515e-01  1.53073132e-01  2.59599090e-02  1.88603252e-02\n",
      " -1.69034854e-01 -1.91990495e-01 -5.44832200e-02 -1.03550635e-01\n",
      "  7.37292925e-03  1.72538251e-01  4.91666235e-02 -1.16100855e-01\n",
      " -6.52361885e-02  1.65900737e-01 -1.21893637e-01 -2.71233439e-01\n",
      " -1.44898504e-01 -2.13824958e-01 -1.46739453e-01  6.19779676e-02\n",
      " -3.72104675e-01  7.32384724e-05 -4.85069826e-02 -6.99102730e-02\n",
      " -2.52143532e-01 -6.74298778e-02  6.77068755e-02 -2.34163329e-01\n",
      " -2.81366944e-01  3.84461470e-02 -2.17633635e-01 -4.71768588e-01\n",
      " -1.99780557e-02 -3.93425286e-01 -1.09840423e-01 -8.82286653e-02\n",
      " -3.81616899e-03 -3.11380953e-01 -2.90973455e-01 -6.95798844e-02\n",
      " -1.38539493e-01  4.35219798e-03 -1.59696773e-01 -1.00786425e-02\n",
      " -2.67842829e-01 -1.48386806e-01 -1.03724867e-01 -2.09823281e-01\n",
      "  1.05570234e-01  1.03170455e-01 -1.40725836e-01 -1.57344222e-01\n",
      " -4.07961160e-01 -1.81334823e-01  1.07842438e-01 -2.45810255e-01\n",
      "  1.39571335e-02  7.44480342e-02 -4.07002605e-02 -8.98044780e-02\n",
      " -2.81902820e-01 -2.55111575e-01 -2.28507876e-01  1.11790776e-01\n",
      "  3.23691182e-02 -3.07060301e-01 -4.91933197e-01 -2.74498016e-01\n",
      " -2.82825887e-01 -1.89551443e-01 -9.77602042e-03  1.23511225e-01\n",
      " -1.45489499e-01 -2.43997216e-01 -1.09525688e-01 -2.81452239e-01\n",
      "  5.60476594e-02 -2.32711986e-01 -3.01030904e-01 -1.75428957e-01\n",
      " -2.36289706e-02  8.92334878e-02  1.06671162e-01 -1.38851047e-01\n",
      "  1.34107787e-02 -4.58446383e-01 -2.64329687e-02 -4.53274436e-02\n",
      "  3.90428118e-02 -3.58160883e-01 -3.23991090e-01 -8.63454130e-04\n",
      " -2.62190908e-01  1.24109231e-01  1.11412443e-01 -1.12693146e-01]\n",
      "L7N0                    -> L8N125 = [-6.78307787e-02 -3.93423170e-01  7.16348663e-02 -3.92738432e-02\n",
      " -1.94758084e-02  2.48738024e-02 -1.52734950e-01 -1.70805782e-01\n",
      " -4.30897504e-01 -9.52394754e-02 -4.31337923e-01  1.59512550e-01\n",
      "  2.60748696e-02 -1.12046920e-01 -1.13987133e-01 -3.09040044e-02\n",
      " -4.48387600e-02  3.75493839e-02  4.83817942e-02 -2.35698428e-02\n",
      " -1.00374013e-01 -2.64051203e-02  1.11822955e-01 -1.80225506e-01\n",
      " -2.37589002e-01 -2.72354215e-01  4.30745482e-02 -3.15274715e-01\n",
      " -5.53657264e-02 -3.67414355e-01  1.03682876e-01 -3.49119484e-01\n",
      "  4.42517251e-02 -9.34351757e-02 -1.65872648e-01  1.44827887e-01\n",
      " -1.38658181e-01 -7.56834149e-02 -2.77097881e-01 -1.70265675e-01\n",
      " -3.34672362e-01 -3.18909049e-01 -3.14336151e-01 -3.10941953e-02\n",
      " -3.82787198e-01 -1.19875176e-02 -1.33710712e-01 -1.43160671e-01\n",
      " -2.21914575e-01 -2.03747243e-01 -1.80002600e-01  1.12940259e-01\n",
      " -8.00831094e-02 -1.89239725e-01 -2.06538200e-01 -3.54811549e-01\n",
      " -2.10681379e-01 -1.20819829e-01 -1.59353033e-01  2.12504193e-02\n",
      " -2.89857015e-02 -8.86929780e-02 -4.11100201e-02 -1.37239411e-01\n",
      " -7.27836415e-02 -4.62185359e-03 -1.70165747e-01 -1.00491764e-02\n",
      " -2.41432548e-01  9.96984318e-02  6.62572682e-02 -1.97785974e-01\n",
      " -6.39648438e-02 -2.55874604e-01 -1.37049913e-01 -1.19312093e-01\n",
      " -2.19273522e-01 -4.41244468e-02  1.59666855e-02 -3.56273592e-01\n",
      " -7.89973512e-02 -9.11795795e-02  1.79108344e-02 -3.33889723e-01\n",
      " -1.43897712e-01 -5.78063913e-02 -2.25112274e-01  9.36723724e-02\n",
      " -7.01549724e-02 -4.18847710e-01 -9.60056707e-02 -2.75306846e-03\n",
      " -1.36518300e-01 -2.41708279e-01  1.45203874e-01 -3.00309122e-01\n",
      " -1.32355332e-01  7.21968710e-02 -4.43422556e-01  1.06081716e-03\n",
      "  5.12411934e-04 -9.09942687e-02 -2.70316482e-01 -3.34790468e-01\n",
      " -6.29726052e-02 -8.83542523e-02 -7.47972131e-02 -1.67183012e-01\n",
      " -1.78424105e-01  2.38455608e-01 -1.16296075e-01 -8.72259866e-03\n",
      "  7.64047503e-02 -1.32495821e-01 -1.36036891e-02  8.04703236e-02\n",
      " -3.17096472e-01 -1.75896585e-01 -1.04023904e-01 -2.51899064e-01\n",
      "  2.74106208e-02 -1.22512363e-01  7.32422844e-02 -1.19934924e-01\n",
      " -3.17535549e-01  3.83691974e-02 -8.92851502e-02 -1.62455216e-01\n",
      " -6.01914302e-02  1.25070244e-01 -1.75848618e-01  2.50017624e-02\n",
      " -3.47757578e-01 -2.88353324e-01 -7.96633661e-02 -8.92110690e-02\n",
      "  1.23667836e-01 -6.46713600e-02 -8.39253291e-02  8.30067471e-02\n",
      " -3.17802519e-01  1.11551329e-01  2.75615108e-04  6.18078895e-02\n",
      "  8.19235221e-02 -2.54934784e-02 -2.09880307e-01 -3.21818113e-01\n",
      " -2.28101134e-01 -3.00637722e-01  1.16025172e-01 -2.95409322e-01\n",
      "  8.95805433e-02 -2.13330723e-02 -6.42067119e-02 -1.90216109e-01\n",
      " -4.95220050e-02  4.24902551e-02 -4.43569832e-02  1.00685634e-01\n",
      " -4.59027328e-02 -6.22213930e-02  1.22132339e-02 -3.09124384e-02\n",
      " -1.83472753e-01 -1.84054017e-01  1.39640039e-02  2.20606670e-01\n",
      "  1.90187812e-01 -4.70745951e-01 -4.83404607e-01 -2.94625163e-01\n",
      " -1.72479257e-01 -4.07096520e-02 -1.70357842e-02 -2.13793829e-01\n",
      " -3.31429839e-01 -7.12349713e-02  2.58439090e-02 -1.38803229e-01\n",
      "  1.21108703e-01 -3.91151965e-01 -3.26612562e-01 -1.21460505e-01\n",
      "  1.06093965e-01  4.35480997e-02 -3.08728248e-01  1.48048073e-01\n",
      " -7.20460862e-02 -2.24238500e-01 -7.70552531e-02  1.16825260e-01\n",
      " -2.84008145e-01 -9.26594883e-02 -1.73984617e-01 -2.38593638e-01\n",
      " -1.03119239e-01 -1.85054943e-01 -1.01952456e-01 -3.00459683e-01]\n",
      "L7N0                    -> L8N126 = [-0.3411004  -0.2992449   0.04230692  0.19495802 -0.1663651  -0.00690944\n",
      "  0.02744505 -0.10490867 -0.13270253 -0.03902234 -0.05666647  0.04278233\n",
      " -0.18664949 -0.22119245  0.06304605 -0.24377865 -0.05762627 -0.10444467\n",
      " -0.1680306  -0.10618115 -0.01640512 -0.24262524 -0.07169011  0.01998392\n",
      " -0.04370994 -0.02922979 -0.15796688 -0.08219901 -0.22275586 -0.09886909\n",
      " -0.13715333 -0.28139576 -0.11194906 -0.01111469 -0.02160215 -0.33317348\n",
      " -0.07956813  0.15153609 -0.11188062  0.1841673   0.05545096  0.09686876\n",
      " -0.11675567 -0.27791867 -0.07614946 -0.3374313   0.12063538 -0.10187253\n",
      "  0.05746033 -0.05475122 -0.07070714  0.02635743  0.02264072 -0.10940841\n",
      " -0.261879    0.07555202  0.00609751 -0.09111377  0.09169012  0.18839025\n",
      " -0.12534764 -0.11952964 -0.07126028  0.17503846 -0.09973188 -0.07184174\n",
      " -0.29489323 -0.22858989 -0.20456432 -0.20646167 -0.15092728 -0.25368285\n",
      "  0.0386817  -0.03699262 -0.20721634 -0.07987044  0.10583677  0.29320523\n",
      " -0.04421306  0.02797591 -0.06586924  0.0175897  -0.19779731  0.19934185\n",
      " -0.195682    0.02290144  0.0829554  -0.0295078   0.01771548 -0.20069851\n",
      "  0.08196831 -0.13774142  0.21377854 -0.29216668 -0.2696297   0.02169735\n",
      " -0.10811062 -0.02940932  0.04777421 -0.09927185 -0.12166466 -0.06413122\n",
      " -0.15619095  0.1506455  -0.09278813  0.12176267  0.0507164  -0.16339676\n",
      " -0.27072972 -0.48900107 -0.00653561 -0.05170759 -0.0881888  -0.22918852\n",
      " -0.11086432  0.10186871 -0.38867912 -0.2818438  -0.224736    0.05410429\n",
      " -0.13374053 -0.02490656 -0.0518489   0.18505874  0.10089889 -0.04203517\n",
      " -0.15875584 -0.28224662 -0.01229903 -0.0992033  -0.04407862 -0.23055397\n",
      " -0.5414095   0.0187066  -0.20827983 -0.05698618  0.15679201 -0.27749887\n",
      " -0.25131914 -0.14031635  0.2798487  -0.39858428  0.05182938 -0.18036865\n",
      " -0.02170487  0.09969698 -0.1895846  -0.42739153 -0.17418312 -0.04657836\n",
      " -0.0631582  -0.07827473 -0.23876774 -0.23768501  0.04758484 -0.22228798\n",
      " -0.24971694 -0.10704717 -0.35808742  0.0416666  -0.14626393 -0.21611461\n",
      " -0.0376297  -0.02902117 -0.0243333   0.03644888 -0.22174588  0.16189314\n",
      "  0.08053732 -0.09306187 -0.2890753   0.09335922  0.14004555 -0.29495287\n",
      "  0.06155021 -0.22912137  0.01171305  0.10121106  0.04285399 -0.3431002\n",
      "  0.054092   -0.04213502 -0.10878627  0.09988151 -0.2731642   0.01266129\n",
      " -0.20995991  0.02140206  0.11420663 -0.22653691  0.09411559 -0.10540002\n",
      "  0.0429775  -0.22976308 -0.18111534  0.27906537 -0.24462192 -0.2915073\n",
      " -0.1335247  -0.06507113]\n",
      "L7N0                    -> L8N127 = [ 0.33990306 -0.19537565  0.03593355 -0.06479299 -0.17110813  0.13053378\n",
      "  0.17026627  0.01356597 -0.13271533 -0.11281299 -0.17392892 -0.2165744\n",
      "  0.08255865  0.05062237 -0.09577343  0.07589446 -0.07250775 -0.21623589\n",
      " -0.08989521 -0.03617609 -0.02866481 -0.09621244 -0.17912796  0.22742888\n",
      "  0.13751201 -0.05916785 -0.25201192 -0.39709377 -0.09734298  0.24356987\n",
      "  0.03343255  0.00231498 -0.19090079 -0.01658127  0.11777639 -0.10543736\n",
      "  0.01844839 -0.21282817 -0.11453114  0.17581679 -0.04060509 -0.39180648\n",
      " -0.0872976   0.16041377  0.12692928  0.15595582  0.14166376 -0.06831856\n",
      "  0.32549015  0.15889986  0.21582806 -0.08119278  0.2232766  -0.03238033\n",
      " -0.01398584  0.07014963  0.07834504 -0.06739572  0.10205834 -0.01025112\n",
      "  0.0640754  -0.05452401 -0.08687337  0.10401818 -0.21703681 -0.09881464\n",
      "  0.08014092  0.03828014  0.0170673  -0.02857832 -0.19958404  0.03744362\n",
      " -0.28015745  0.31634516  0.11500699 -0.02503533 -0.05101816  0.04834783\n",
      "  0.08786568 -0.10472518 -0.24271019 -0.16789326  0.13831447  0.0380518\n",
      "  0.17591174 -0.19306605 -0.12573007 -0.29839107  0.01801582 -0.12909666\n",
      " -0.04054749 -0.05213798  0.21744856 -0.06216799  0.05986795 -0.21681285\n",
      " -0.3582477   0.30922383 -0.03211131  0.08575794  0.04126077 -0.07276388\n",
      "  0.0706019  -0.42702243 -0.00261071  0.23748708  0.22899613  0.13742967\n",
      " -0.04461521  0.17658564  0.01339189 -0.08051293  0.05515083 -0.0914657\n",
      "  0.27974224  0.06605588  0.13371043  0.25610337 -0.18612668  0.02322608\n",
      " -0.07066614  0.05647542  0.00978187  0.08434349 -0.05035833  0.04848649\n",
      " -0.05319914 -0.1848838   0.03345271 -0.23386085 -0.20627093  0.0573859\n",
      " -0.24096008 -0.22392507 -0.06490168  0.12011451 -0.26017624 -0.00077205\n",
      " -0.11030464  0.09932895 -0.00527785  0.01830324 -0.08498831 -0.14515992\n",
      "  0.05189523  0.09353951  0.15246986 -0.08009089  0.11633579  0.06446913\n",
      "  0.02675526  0.03914874  0.00762935  0.03759821  0.027819    0.05567217\n",
      " -0.1454196   0.1446567   0.04112933 -0.13454328 -0.02361593 -0.08619649\n",
      " -0.302494    0.09995021  0.18587953 -0.03183964 -0.06866687 -0.07998308\n",
      " -0.14115968 -0.09774791 -0.2707715  -0.21219851  0.04249134 -0.31145746\n",
      " -0.04958802  0.0452708   0.31600145 -0.04482258 -0.04382727 -0.2029537\n",
      "  0.07971675 -0.08297735  0.14972812 -0.2858171  -0.04637069  0.32795414\n",
      " -0.10868774 -0.33155134  0.17385517 -0.00059436  0.2309174  -0.12961452\n",
      " -0.35184005  0.04956626 -0.21054384 -0.0273357  -0.02832111 -0.0306093\n",
      " -0.17465281 -0.2605702 ]\n",
      "L7N0                    -> L8N128 = [-2.45171875e-01 -1.14348128e-01 -1.27266690e-01  6.75898045e-02\n",
      " -1.98525973e-02  9.14245844e-02  4.87920344e-02  1.87758714e-01\n",
      "  1.54481068e-01  7.26980045e-02 -2.24216189e-02  1.96194667e-02\n",
      " -2.67638415e-01 -5.08302264e-02  2.35712364e-01 -1.00711383e-01\n",
      " -4.39595282e-02 -1.84300914e-01  2.09127963e-02  8.80163610e-02\n",
      " -8.63666832e-02  1.06983341e-01 -1.94871843e-01  7.41110370e-02\n",
      "  8.79595708e-03  2.88648438e-02 -1.66931406e-01 -3.37204784e-01\n",
      "  1.29175652e-02  1.53033528e-03 -6.68199658e-02  1.85205732e-02\n",
      " -1.84568241e-01 -8.46204566e-05 -1.19363375e-01 -4.03856277e-01\n",
      "  2.09742822e-02 -5.67421876e-02 -3.84662896e-01  1.46309495e-01\n",
      " -5.08037657e-02  2.52796263e-01 -1.90295160e-01  2.77357604e-02\n",
      "  9.09595266e-02 -7.84512684e-02 -2.19085991e-01 -9.69741419e-02\n",
      " -2.72185922e-01 -2.58773025e-02 -1.79097533e-01 -1.43421322e-01\n",
      " -8.95600095e-02 -3.75312306e-02  5.80509454e-02 -5.17834388e-02\n",
      "  4.90332991e-02  1.09548278e-01 -6.94551840e-02 -1.99025661e-01\n",
      " -1.60123542e-01 -2.03667637e-02 -3.82742733e-02  1.29882708e-01\n",
      " -3.27348262e-01 -7.61220902e-02  1.98578641e-01 -2.27475628e-01\n",
      " -1.16081148e-01 -2.43543424e-02 -1.23235740e-01 -1.60101458e-01\n",
      " -1.68972522e-01  1.40853912e-01  8.13106820e-02  9.34812501e-02\n",
      "  5.03338221e-03 -1.25753745e-01 -1.13550924e-01  6.39953092e-03\n",
      " -2.10999981e-01 -1.18124396e-01 -7.33129084e-02  5.48163243e-02\n",
      "  1.13713726e-01 -1.21720597e-01 -2.22796984e-02  3.36795561e-02\n",
      "  8.83416831e-03 -1.10149741e-01 -1.33543506e-01 -2.73711979e-01\n",
      "  1.47695556e-01 -1.86435029e-01 -2.05230474e-01 -2.17741445e-01\n",
      "  1.54643998e-01 -2.48152316e-01  8.24611783e-02  1.25092268e-01\n",
      "  1.63542964e-02 -1.64773539e-01  1.17749967e-01 -6.03582412e-02\n",
      " -1.67246103e-01 -4.03897837e-02 -2.23175481e-01  1.85817093e-01\n",
      "  3.22079174e-02 -3.70129496e-01 -1.73701376e-01  7.38144666e-02\n",
      " -3.63042057e-02  6.21600822e-03 -4.16370779e-02 -1.58897474e-01\n",
      " -4.10193056e-02 -1.88155517e-01 -1.04381219e-01  5.02625713e-03\n",
      " -1.89331815e-01  1.63038522e-01  1.44048944e-01 -1.56707525e-01\n",
      "  8.22827816e-02  1.07662670e-01  1.06949821e-01 -9.48051512e-02\n",
      " -2.42017195e-01  4.73110452e-02 -4.22693305e-02  2.95246597e-02\n",
      "  1.99629799e-01 -5.88064753e-02  3.76020521e-02 -7.40866587e-02\n",
      " -2.74969731e-02 -2.53713101e-01 -1.33762091e-01 -5.28165177e-02\n",
      "  1.61132887e-01 -4.35847156e-02 -2.61390507e-01 -1.33496121e-01\n",
      "  9.40253437e-02 -8.51975530e-02 -2.51658916e-01  3.47811356e-02\n",
      " -5.69449402e-02  1.40935883e-01  3.49303447e-02  5.49615659e-02\n",
      " -2.14609697e-01 -7.04065561e-02  9.61675495e-02 -2.63776034e-01\n",
      " -2.11529359e-01 -4.09702033e-01 -3.08677405e-01 -1.87565401e-01\n",
      "  1.15135044e-01 -8.96452665e-02 -1.45638958e-01 -1.69686913e-01\n",
      " -3.18575241e-02 -1.36407912e-01 -2.60749638e-01  1.33956239e-01\n",
      " -2.34473884e-01 -7.06121698e-02 -1.02216929e-01 -9.45159644e-02\n",
      " -2.70732552e-01  2.64597218e-02 -5.21402434e-02  4.51337695e-02\n",
      " -4.59801964e-02  2.99587339e-01 -3.46901678e-02 -3.46809834e-01\n",
      " -1.83238700e-01  7.02474192e-02 -7.17455447e-02 -8.95489082e-02\n",
      " -1.83013722e-01  3.33259627e-03 -3.08510631e-01 -1.05938474e-02\n",
      " -9.39199179e-02 -1.32612390e-02 -1.69681817e-01 -1.40307948e-01\n",
      "  1.46373957e-01  3.23712118e-02  1.06020749e-01 -1.82434022e-02\n",
      " -7.99699426e-02 -2.05097646e-01 -1.75769571e-02  3.86293381e-02]\n",
      "L7N0                    -> L8N129 = [ 0.0372118  -0.11321653 -0.0725295   0.30564055  0.1316672   0.0549657\n",
      "  0.16097772 -0.02206151 -0.11582661 -0.06436743  0.11912158 -0.15512034\n",
      " -0.18700452 -0.04162474 -0.02201362  0.06538577 -0.03084378 -0.18001506\n",
      " -0.15700147  0.05845477 -0.07370338  0.19733171  0.04351841  0.1314925\n",
      "  0.35525683 -0.02091703 -0.27941117 -0.28739178  0.01349142  0.13404217\n",
      " -0.01713954  0.15597886  0.01137814 -0.3475023   0.0460719   0.03461251\n",
      "  0.08744775  0.18361787 -0.10979454  0.08405196 -0.20387064 -0.07787114\n",
      " -0.01061312  0.08851998 -0.04685419  0.07116639 -0.08031801  0.24418262\n",
      " -0.276694    0.01418242  0.06700347  0.19072483  0.15630713  0.05074461\n",
      " -0.02067197 -0.23337649 -0.00290923 -0.11495209 -0.18814921  0.03909574\n",
      " -0.06400144 -0.10945106  0.00697292  0.09465814  0.14857961  0.1764428\n",
      " -0.0006533   0.26742247 -0.15829435  0.25992548 -0.13528377 -0.42866823\n",
      " -0.279285    0.07176947 -0.08851565  0.09511458  0.1876333   0.14206429\n",
      "  0.14122796  0.21901567 -0.07871234  0.04141865 -0.02630699 -0.07248416\n",
      "  0.03230561 -0.29210493 -0.34663433  0.20436059  0.00142684 -0.11751433\n",
      "  0.01092152 -0.0796154   0.18122546 -0.11867692  0.11000361  0.13350353\n",
      "  0.07990577 -0.08074656 -0.00760352  0.07135282 -0.1064732   0.02753894\n",
      "  0.16408642 -0.42867914  0.02919502  0.12473177 -0.10274597 -0.01889904\n",
      "  0.00727029  0.26818606 -0.04852708 -0.14472388  0.11156903  0.15150586\n",
      "  0.07848134  0.18713239  0.03400576  0.03282146 -0.073416    0.12508737\n",
      " -0.12654899  0.21216369  0.1660367   0.0262516  -0.08746232  0.09347168\n",
      " -0.07471201  0.05719813  0.01708629  0.00111507  0.09953022  0.04690788\n",
      " -0.07308383  0.20263976  0.03204324  0.0079582   0.1359764  -0.04395632\n",
      "  0.14220116  0.09807572  0.04524302  0.03431668  0.19703332  0.00459561\n",
      "  0.08824975  0.04880661  0.26135936 -0.0059294   0.34926718  0.14504774\n",
      " -0.16157806  0.0369285   0.08569013  0.18464242  0.1580247   0.01843954\n",
      " -0.11644866  0.02713741 -0.03609269 -0.18386917  0.157906   -0.09743723\n",
      "  0.08638272  0.22286168  0.01902023 -0.06635118 -0.0144559   0.01308898\n",
      "  0.03502959  0.26199403  0.09456334  0.06636547  0.0471092  -0.1676943\n",
      " -0.4011203   0.15622307  0.05936499 -0.18753943 -0.07931668  0.07794355\n",
      " -0.14870684  0.0271865   0.0761521  -0.08813092  0.2246446   0.20379926\n",
      " -0.05863559 -0.15626875 -0.06954332 -0.00941167  0.1184083  -0.11598346\n",
      "  0.00075045 -0.11826225 -0.18865596  0.20939465  0.00686718 -0.20072716\n",
      " -0.0559289  -0.21207225]\n",
      "L7N0                    -> L8N130 = [-0.05370928 -0.08332633 -0.27089998 -0.20130235 -0.0625246   0.08952796\n",
      "  0.40465444  0.2928332  -0.18046604 -0.02223232  0.12967506 -0.13726237\n",
      " -0.21788497 -0.0669999   0.19753088 -0.16070223  0.08801349  0.02542302\n",
      " -0.03882584  0.03741151 -0.02198198  0.08609443  0.14848956 -0.11472299\n",
      "  0.20811854 -0.01365338 -0.2955923   0.2028156  -0.00249706  0.2784805\n",
      "  0.07356975 -0.08330221  0.03993201  0.06238641  0.10379255 -0.14416382\n",
      "  0.1916717   0.21941328  0.16246256  0.14279754 -0.06144362  0.2716583\n",
      " -0.25212607 -0.02223609 -0.18584338 -0.19502108 -0.18858954  0.02816627\n",
      " -0.38456497  0.31465724 -0.18706724 -0.00832344  0.2345716   0.11852163\n",
      " -0.01546237  0.25572723  0.06286487 -0.01929941  0.08167627 -0.25283083\n",
      "  0.1105318  -0.06469014 -0.11322047 -0.2301379  -0.18145518  0.1283259\n",
      " -0.24267398 -0.15644307  0.15736614  0.01544479  0.21273485 -0.17535958\n",
      "  0.21216671  0.02388479  0.17084002  0.09867859  0.01930343 -0.18000822\n",
      "  0.0006919   0.14469807 -0.17368616  0.02680646  0.25353494 -0.00421191\n",
      " -0.00566681  0.02174575  0.05778217  0.10293391 -0.09466695 -0.1471196\n",
      "  0.01747735  0.1394354   0.10752461  0.31425026  0.15505953 -0.11477427\n",
      "  0.06798633 -0.1145651  -0.17771423  0.09963533  0.1211693   0.13347228\n",
      "  0.17967992  0.10989522  0.02358829 -0.4948096  -0.1830945  -0.17281348\n",
      "  0.08440354 -0.18054038 -0.41980746 -0.12762007 -0.23414944  0.0934749\n",
      " -0.16421005 -0.22327569 -0.08110259  0.02218671  0.05198029  0.09685622\n",
      "  0.05075777  0.17472734 -0.01364895 -0.0220198   0.22327222  0.08375926\n",
      "  0.11674583 -0.25788334 -0.36159128  0.28978872  0.01916063 -0.10419217\n",
      "  0.25719067  0.0853844   0.03486465 -0.03776217 -0.00218061 -0.13846083\n",
      "  0.12213953  0.07269871 -0.02886144 -0.15258232 -0.17816475 -0.11388359\n",
      " -0.03763669 -0.24211426 -0.08418779  0.11109591  0.18063219  0.08958901\n",
      " -0.17268857 -0.11193828 -0.10095946 -0.10243487 -0.20143494 -0.07636854\n",
      "  0.3025247  -0.17599407 -0.13681224 -0.25318494  0.1669363  -0.08819661\n",
      " -0.15884046 -0.18981113  0.23697354  0.17564307 -0.17468429  0.14824489\n",
      "  0.25578156  0.12465119  0.02803329  0.00706604  0.06960505  0.16548465\n",
      " -0.15026593 -0.14734936 -0.0804577  -0.05939388  0.17180748 -0.18467979\n",
      " -0.2563447   0.06364101  0.10749733 -0.14518617 -0.23935847 -0.06447276\n",
      "  0.06015304  0.27528778 -0.32745707  0.19279854  0.10489199 -0.20760062\n",
      "  0.0549476  -0.1719763   0.00266655  0.14360102  0.07022059 -0.17626755\n",
      " -0.01436342 -0.1336378 ]\n",
      "L7N0                    -> L8N131 = [ 0.13668121 -0.01999821  0.02023895 -0.03616908 -0.07754568 -0.29506874\n",
      " -0.11073373 -0.3493929   0.00611468 -0.19371974  0.3249265  -0.22414456\n",
      "  0.0422601  -0.15821181  0.04493317 -0.07139943 -0.20249172  0.13944276\n",
      " -0.02236529 -0.13036937  0.24968685 -0.1672583  -0.22226024 -0.22673918\n",
      " -0.10782371 -0.1091267  -0.07307467  0.05269774 -0.12290659 -0.24687956\n",
      " -0.13126384  0.07313246 -0.0101352  -0.05686042 -0.21758212 -0.13610159\n",
      " -0.07526875 -0.0763844  -0.02322773 -0.10514152 -0.16071099  0.20647672\n",
      " -0.08884861 -0.02787705  0.16719806 -0.00425728  0.14217345 -0.17923813\n",
      " -0.06067551 -0.09103293 -0.18255351 -0.08705921 -0.06601284 -0.11698559\n",
      " -0.24762693 -0.1148095  -0.10420836 -0.17964558 -0.23259799 -0.2337541\n",
      " -0.13146009 -0.35369056 -0.10223174 -0.14155892 -0.07194287  0.08686405\n",
      "  0.01385336 -0.17255595 -0.03771561 -0.05998356 -0.35472724 -0.0362592\n",
      " -0.01526755 -0.06709944 -0.01637922 -0.2698664  -0.04789348 -0.06812242\n",
      " -0.08256699 -0.33055136 -0.07061509  0.0485637  -0.48832127 -0.2550118\n",
      "  0.09696457  0.15861873  0.1201463   0.13651371 -0.13838093  0.20015079\n",
      " -0.3119756  -0.1016169   0.05110985 -0.11097777 -0.22476429 -0.06311332\n",
      " -0.31659037 -0.31031692 -0.06809165 -0.24114965 -0.13707508 -0.05139787\n",
      "  0.08696804 -0.10711392 -0.20250005  0.10729454 -0.0775428   0.11681582\n",
      "  0.08270139 -0.13411266 -0.293178   -0.3524796  -0.16487798 -0.31074664\n",
      "  0.06269667  0.09075982 -0.26028267  0.07489213 -0.4497816  -0.25002086\n",
      " -0.0834034  -0.40012494 -0.06885192 -0.12795669  0.05751586 -0.1456862\n",
      " -0.43891516 -0.18269397 -0.12510657 -0.11922827 -0.18149799 -0.11429068\n",
      "  0.062069   -0.423351   -0.22436617 -0.05141501 -0.23245999  0.06240095\n",
      "  0.14698142 -0.2606472  -0.16856177 -0.23667896 -0.11799007 -0.09433051\n",
      "  0.1487212  -0.1915289  -0.03951427 -0.06466387 -0.32456863 -0.06014452\n",
      " -0.42164958 -0.20220947 -0.08894175  0.00274868 -0.21548791 -0.2137817\n",
      "  0.21837392 -0.00079773 -0.12014206  0.02023538 -0.11086666 -0.07848584\n",
      " -0.08264339 -0.19532473 -0.34806708 -0.30127716 -0.11600576  0.07346552\n",
      " -0.16724777 -0.2947141   0.15373677 -0.12714992 -0.17949222  0.05144602\n",
      "  0.07734122  0.01730958 -0.01025994  0.04507379 -0.09059928 -0.05340995\n",
      "  0.07890784 -0.14141412 -0.12819684  0.14795493 -0.04213275 -0.22161095\n",
      "  0.01930173 -0.10045262 -0.2467902   0.15283579 -0.22786464 -0.3043112\n",
      "  0.09406865  0.2365698   0.13180329  0.00485989 -0.2174206   0.137952\n",
      " -0.20164368 -0.00359306]\n",
      "L7N0                    -> L8N132 = [ 0.03421359 -0.08327427  0.07509664 -0.42766637 -0.11872784  0.09594871\n",
      "  0.00675972 -0.15124176  0.09726286  0.03514447  0.16326481 -0.4087132\n",
      "  0.05484198  0.02664465  0.07860763 -0.1190798  -0.0939331  -0.25176546\n",
      " -0.07288887 -0.00827777 -0.02786956 -0.25660402 -0.10139468 -0.06712416\n",
      " -0.21590902 -0.03784473 -0.34116355 -0.02655943 -0.04145317  0.10740793\n",
      " -0.02821853 -0.05580986 -0.11693449 -0.0850515   0.00184386 -0.29726323\n",
      "  0.06004251 -0.04848468  0.05735614  0.07919122 -0.0267234   0.25228047\n",
      " -0.25049743  0.09551319  0.10214491  0.06788951 -0.06548364  0.15134114\n",
      "  0.10401202  0.0055     -0.20115817 -0.1222797  -0.24642451 -0.2146885\n",
      "  0.0422973  -0.05573276 -0.09708583 -0.07601138 -0.19208856 -0.22851753\n",
      " -0.1111917  -0.02551596  0.08459041 -0.1745494  -0.04830037 -0.00055863\n",
      "  0.12282925 -0.05862757  0.12352771 -0.16272508 -0.24021141 -0.08369217\n",
      "  0.23434404 -0.0172375   0.20035166  0.06026878 -0.20365414  0.01905433\n",
      " -0.00842066 -0.11974529 -0.0617104  -0.1085057   0.03616857 -0.23744033\n",
      " -0.0066469  -0.02911336  0.18726695 -0.03283107 -0.02178152 -0.09934526\n",
      "  0.0610889   0.00839445 -0.16354     0.20273086 -0.2891491   0.03416268\n",
      "  0.160562   -0.02584805 -0.0232705   0.08764601 -0.17428876  0.09674896\n",
      "  0.15097947  0.22607362 -0.10125101 -0.12871405 -0.25696015 -0.23758085\n",
      "  0.09721646  0.00212153 -0.03427325  0.27530733  0.04590371  0.2452701\n",
      " -0.1670841  -0.10526575  0.08220715 -0.4300918  -0.14947495 -0.2567358\n",
      " -0.01105397  0.02743173 -0.26277006  0.13646346  0.20175192 -0.0021215\n",
      " -0.02131167 -0.17102106 -0.16300862  0.04802601 -0.02341478 -0.01802959\n",
      " -0.16222005  0.1003382   0.24920934 -0.21894197 -0.04147153 -0.22364631\n",
      " -0.10535216 -0.13934574  0.23762572 -0.22237985 -0.14381213 -0.32768598\n",
      " -0.12678604 -0.15748605 -0.16172628 -0.11264586  0.2713207  -0.14547049\n",
      "  0.1139568   0.02734742 -0.19979389 -0.0442275  -0.05667466 -0.19051017\n",
      "  0.0609869  -0.25902173 -0.1069214  -0.08410742  0.1296184   0.05212986\n",
      " -0.04080684  0.00674226 -0.04065958  0.03851116 -0.16153088 -0.26308236\n",
      " -0.15323134 -0.06586777 -0.09965758 -0.1729647  -0.00492185  0.18338546\n",
      "  0.05520719 -0.26127702 -0.03368159  0.0585545  -0.12617068  0.15225896\n",
      " -0.2806358   0.05244958 -0.01414888  0.24425937 -0.21948737  0.08282474\n",
      " -0.06053364  0.23241131 -0.18835902  0.2575126   0.01685405 -0.13722222\n",
      "  0.16829984  0.17988165  0.11512274  0.07171327  0.15188928 -0.4758049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04843094  0.01262809]\n",
      "L7N0                    -> L8N133 = [-1.93273723e-01 -1.68177173e-01 -9.58325714e-02  3.16089094e-02\n",
      " -5.61170466e-02  4.65489663e-02 -1.34200022e-01 -1.05850667e-01\n",
      "  1.85711771e-01  1.40504530e-02  3.83628123e-02 -1.38887599e-01\n",
      " -4.80512559e-01  3.37158233e-01  2.00456515e-01 -1.52770579e-01\n",
      " -1.04661532e-01 -1.39309436e-01  2.35479679e-02 -7.98109695e-02\n",
      " -7.82628283e-02  1.36741214e-02  3.94480452e-02  1.72252610e-01\n",
      " -1.03074186e-01  1.38734534e-01 -4.14637588e-02 -1.63544137e-02\n",
      "  9.25791487e-02  5.63686788e-02 -5.66792078e-02 -1.71011358e-01\n",
      "  4.66978326e-02 -1.56802416e-01 -8.24335441e-02 -2.87001014e-01\n",
      "  9.18872952e-02  2.66451798e-02  4.31281142e-02  2.01950982e-01\n",
      " -1.18775778e-01 -2.46307682e-02  1.64773017e-01  7.59901330e-02\n",
      " -8.80616065e-03 -5.22444546e-01 -2.10604504e-01  2.64396608e-01\n",
      " -2.86985338e-01 -2.18217205e-02 -2.70708859e-01  1.80169597e-01\n",
      " -2.33576372e-02  9.54234675e-02 -1.12490449e-03  3.28557342e-01\n",
      "  8.77534002e-02 -1.33621320e-01 -5.67919239e-02 -2.47189146e-03\n",
      "  7.54872411e-02 -2.06488147e-02  4.75475244e-04  7.41560236e-02\n",
      " -2.99553990e-01  3.03184390e-02 -5.84887564e-02 -3.65777165e-01\n",
      "  1.24597691e-01 -4.22130190e-02  9.19906721e-02 -2.45545313e-01\n",
      " -1.52823180e-02  1.83822978e-02  2.61401117e-01  5.15902787e-02\n",
      " -1.75308511e-01 -1.50505662e-01 -4.55891415e-02  7.65134096e-02\n",
      "  2.19524562e-01 -1.11154988e-01  1.61575168e-01  2.00330690e-01\n",
      " -1.66728944e-01  3.77267972e-02  9.79129896e-02  1.26458719e-01\n",
      " -9.04897228e-02 -3.21770966e-01 -1.07304759e-01 -1.96617067e-01\n",
      " -1.47095412e-01  2.26340562e-01 -2.01887235e-01 -2.14116395e-01\n",
      " -3.20600607e-02 -2.15677038e-01  1.13595590e-01  7.27979839e-02\n",
      " -1.82054237e-01  2.19431281e-01  1.52099365e-02  1.64275557e-01\n",
      " -6.98864534e-02 -1.00441985e-01 -4.99967992e-01  1.35693371e-01\n",
      " -1.28845841e-01 -3.60776007e-01 -2.31044233e-01  2.33232044e-02\n",
      "  9.19643044e-02  1.28727823e-01 -8.24544802e-02 -1.88301094e-02\n",
      " -1.14510491e-01 -8.34326595e-02  9.44279134e-02 -1.03028201e-01\n",
      " -3.65454912e-01  5.42180948e-02 -2.62439489e-01 -1.82504416e-01\n",
      "  1.03044435e-01 -1.26347825e-01  4.65807430e-02  1.98582843e-01\n",
      " -3.66795838e-01  2.53264066e-02  7.02807605e-02 -2.57480115e-01\n",
      " -1.96851164e-01  1.75579917e-02  1.60758108e-01 -1.53173089e-01\n",
      "  3.78945731e-02 -1.91882327e-01 -2.41304170e-02  7.60495812e-02\n",
      "  1.96228430e-01 -1.15747929e-01 -1.33816421e-01 -1.46209374e-01\n",
      " -9.56092104e-02 -6.15398400e-02 -3.87345999e-02 -1.49030089e-01\n",
      " -6.57354817e-02  2.65507903e-02 -1.14424415e-02 -2.42838431e-02\n",
      " -3.26022744e-01  6.41693920e-02 -2.96791340e-03 -1.20107107e-01\n",
      " -2.78521061e-01 -6.79914504e-02  3.88407893e-02 -1.74786493e-01\n",
      "  3.68343317e-03 -1.02776453e-01  9.00385827e-02  3.78053300e-02\n",
      " -2.43562430e-01 -8.83742198e-02 -3.77920538e-01  1.63280070e-02\n",
      "  1.63688749e-01  1.31215394e-01 -4.83064316e-02 -1.79748431e-01\n",
      " -1.25510231e-01 -1.11579679e-01 -9.64936763e-02 -1.70922652e-01\n",
      "  6.42108470e-02  8.72837752e-02  3.38581055e-02 -3.45667809e-01\n",
      " -3.61895233e-01  8.05348456e-02 -1.27209082e-01 -9.26858708e-02\n",
      " -3.82481307e-01 -2.07501024e-01 -2.18529254e-02 -1.86620608e-01\n",
      "  2.12713048e-01  1.33467749e-01  4.70570009e-03  7.39502311e-02\n",
      " -1.08541213e-01  6.68387413e-02 -3.75129506e-02 -6.96308464e-02\n",
      "  1.96225107e-01 -1.57735407e-01  5.53418584e-02 -3.88048217e-02]\n",
      "L7N0                    -> L8N134 = [ 4.51443613e-01  4.18518364e-01  6.21873476e-02 -1.12764202e-01\n",
      " -2.30855033e-01  2.56366163e-01  1.37705132e-01 -1.72121286e-01\n",
      " -1.97673932e-01  1.89204440e-01 -2.16907859e-01 -2.09675848e-01\n",
      " -1.98944584e-01  1.54881984e-01 -1.09923109e-01 -6.72179833e-02\n",
      "  1.25731423e-01 -2.51305968e-01  2.35815942e-02  3.77432019e-01\n",
      "  1.27878055e-01  6.24019280e-02  2.08619490e-01  1.79017425e-01\n",
      "  1.73460364e-01 -6.25464544e-02 -2.75432378e-01  7.77985305e-02\n",
      " -9.30072516e-02  8.96505713e-02 -2.94517772e-03  2.25029290e-01\n",
      " -6.73834682e-02  4.61842492e-02  8.07713717e-03  6.83533698e-02\n",
      "  1.11427583e-01  2.44322047e-01 -9.25939903e-02  2.98734665e-01\n",
      " -1.17797211e-01 -1.93747446e-01 -7.50899538e-02  7.43720382e-02\n",
      "  1.21248387e-01 -1.43632010e-01 -9.40225720e-02 -2.18320996e-01\n",
      " -1.52986392e-01  1.16621100e-04 -1.29966557e-01 -1.12186752e-01\n",
      "  2.14975163e-01  1.93335235e-01  1.44896090e-01  2.28492841e-01\n",
      "  9.76894051e-03 -1.72070652e-01 -1.50799961e-03 -3.98871988e-01\n",
      "  4.30289730e-02 -1.17775276e-01 -7.44399056e-02 -1.84772953e-01\n",
      "  1.80188809e-02 -1.93231747e-01  8.75029489e-02 -9.19153616e-02\n",
      " -3.15921344e-02  1.64417595e-01  1.00697331e-01 -2.52990751e-03\n",
      " -1.41050771e-01  4.82047610e-02 -5.37057687e-03  2.06593215e-01\n",
      "  2.16717273e-01 -3.28118384e-01  7.24025518e-02  2.17509136e-01\n",
      "  1.51171654e-01  4.05050740e-02  1.50043055e-01 -5.83121888e-02\n",
      "  1.53554201e-01  1.08291067e-01  4.74773496e-02 -1.93157196e-01\n",
      " -7.04590604e-02 -1.44286171e-01  1.48854852e-01 -8.89474005e-02\n",
      "  2.61070490e-01  2.60062367e-02 -1.97927028e-01  1.49516732e-01\n",
      "  2.21562669e-01 -1.04520246e-01  1.46152452e-01  6.84035122e-02\n",
      "  9.43138674e-02 -1.88711450e-01  4.52645682e-02  2.42863178e-01\n",
      "  2.13503852e-01 -2.37149000e-01 -1.88611418e-01  3.25685561e-01\n",
      "  1.01471089e-01  1.12326629e-02 -1.49136722e-01  1.18304074e-01\n",
      " -2.28460819e-01  9.90592018e-02 -2.70035833e-01 -3.29071134e-01\n",
      " -4.16410491e-02 -8.18896815e-02  3.87971997e-02 -3.82596962e-02\n",
      " -4.42117676e-02  3.48228738e-02  2.85361242e-02  1.36562288e-01\n",
      " -1.44804837e-02  2.95421276e-02  7.25540668e-02 -6.17826916e-02\n",
      " -1.48307696e-01 -4.83351760e-02  9.32357535e-02  7.06673786e-02\n",
      "  1.07577920e-01  3.70688409e-01 -1.84523612e-02  1.21904820e-01\n",
      " -2.41392255e-01 -1.54000074e-01 -4.06374931e-02  2.02689499e-01\n",
      "  1.91204488e-01 -1.76522374e-01 -2.61823177e-01 -2.64280289e-01\n",
      " -1.28487751e-01 -2.89670080e-01 -6.52376190e-02  1.98412277e-02\n",
      "  2.22859129e-01  2.15846434e-01 -1.49050593e-01  4.95863073e-02\n",
      "  1.99391134e-02 -2.42799893e-01  1.89882547e-01  6.74784407e-02\n",
      "  3.97748739e-01 -2.84888774e-01  1.22290865e-01 -2.19030932e-01\n",
      "  5.68258613e-02 -1.46932423e-01  2.01345861e-01 -3.08661342e-01\n",
      " -1.18279997e-02  3.68240336e-03 -1.53514177e-01  1.78528979e-01\n",
      " -1.90061554e-01  8.65226462e-02 -7.79669136e-02  8.21258407e-03\n",
      " -4.98489477e-02  1.44827515e-01 -2.55085796e-01  3.19486201e-01\n",
      "  4.85866219e-02 -2.29125485e-01  1.20603174e-01 -5.99780604e-02\n",
      " -3.56056452e-01  2.17185527e-01  3.41187492e-02 -6.43129572e-02\n",
      " -7.88985193e-02  1.07098907e-01 -1.26406640e-01  1.00999363e-01\n",
      " -1.48960978e-01  1.54114636e-02  2.01825351e-01 -1.32982358e-01\n",
      " -2.37338990e-01  5.90998260e-03 -6.67826086e-02 -3.32350284e-02\n",
      "  5.79072982e-02 -3.09084833e-01  5.66369034e-02 -6.18545152e-02]\n",
      "L7N0                    -> L8N135 = [-1.17289871e-02 -1.38596997e-01 -4.02247645e-02 -1.92882232e-02\n",
      "  1.66612342e-01  9.15278792e-02 -1.06434966e-03  1.57472700e-01\n",
      " -1.11876428e-01 -1.34666547e-01 -1.02046639e-01  1.23698436e-01\n",
      " -9.24967751e-02 -7.05356970e-02  2.25125715e-01 -5.62959611e-02\n",
      " -4.56469059e-01 -1.69848427e-01 -9.20309648e-02 -5.19799553e-02\n",
      "  1.00969918e-01 -1.74568191e-01 -9.61995348e-02 -2.36865699e-01\n",
      " -1.40162304e-01 -6.73607290e-02 -7.52344355e-03  7.36868083e-02\n",
      " -1.62531659e-01 -7.30983540e-02 -1.26469225e-01  2.03960761e-01\n",
      " -1.97254106e-01 -8.77311751e-02 -1.92598790e-01 -1.64882720e-01\n",
      " -2.44116789e-04 -1.30729424e-02 -5.52058481e-02 -6.89577237e-02\n",
      "  2.22161219e-01  7.98825175e-02 -2.66759992e-01  5.40319495e-02\n",
      "  1.80924580e-01 -7.62647465e-02 -2.57146329e-01 -2.87004322e-01\n",
      " -3.00371856e-03  4.54304777e-02 -1.48529097e-01 -1.07248567e-01\n",
      " -4.69990857e-02 -2.22551554e-01 -1.24158457e-01  1.78364798e-01\n",
      " -3.94813716e-02 -6.23222180e-02 -2.79629882e-02 -2.71651559e-02\n",
      " -1.11810751e-01 -8.61078724e-02  1.17418632e-01  2.42774785e-01\n",
      " -1.22454911e-01  1.36355758e-01  1.70409620e-01 -2.33640932e-02\n",
      " -2.67231297e-02 -2.16459230e-01 -3.90358828e-02  1.33517189e-02\n",
      "  2.18500063e-01 -2.18718592e-02 -3.61690223e-01  5.13193831e-02\n",
      " -8.16718787e-02 -4.70325612e-02 -1.82929076e-02 -1.68286875e-01\n",
      "  2.67554641e-01  8.86225104e-02 -2.17216238e-02 -2.06254981e-03\n",
      "  1.49613678e-01  9.96739864e-02  1.04464322e-01  2.06125323e-02\n",
      " -3.01075220e-01 -9.39851552e-02  4.19051796e-02 -2.47354463e-01\n",
      "  7.99786821e-02 -2.46958718e-01 -2.54902661e-01 -1.52204707e-01\n",
      " -4.48683323e-03 -2.17737362e-01  2.10350692e-01  4.54160608e-02\n",
      " -1.97656125e-01 -2.62425184e-01 -3.51886638e-02 -2.31949210e-01\n",
      " -1.17491677e-01 -7.81784654e-02  2.63673402e-02  3.77557129e-02\n",
      "  1.04026429e-01 -2.91746110e-01 -2.75916010e-01  1.53121606e-01\n",
      " -4.51796763e-02 -2.34623834e-01 -7.60241449e-02 -1.14833198e-01\n",
      "  9.88198146e-02 -1.41208529e-01 -1.92087322e-01  1.81984773e-03\n",
      "  9.56843719e-02 -2.22312599e-01 -1.88176259e-02 -2.06042528e-02\n",
      " -2.21475482e-01 -4.30181213e-02  2.65500601e-02 -1.44114122e-01\n",
      " -2.37451598e-01  2.80685350e-02 -2.01178476e-01 -1.55558974e-01\n",
      " -3.89531016e-01  1.15724251e-01 -3.94655645e-01 -5.39319590e-02\n",
      " -2.62986630e-01 -2.20085457e-02 -1.61848694e-01 -9.74404067e-02\n",
      "  1.64563060e-01 -7.59552568e-02  2.09537451e-03 -2.01071382e-01\n",
      " -1.02445640e-01  2.64835179e-01 -5.39056845e-02 -2.12181225e-01\n",
      " -1.99173823e-01  1.23839974e-01 -2.45843530e-01 -2.53813528e-02\n",
      " -4.82871607e-02 -2.61274166e-02 -1.52312875e-01  2.72671655e-02\n",
      " -1.29702821e-01 -2.34742999e-01 -9.10554007e-02  1.04348011e-01\n",
      " -3.59445542e-01 -1.88096672e-01  3.27233896e-02 -2.74067253e-01\n",
      " -3.16719472e-01 -1.67359456e-01 -2.10097864e-01  3.00540384e-02\n",
      " -1.83346320e-03 -3.56094092e-01  1.82517156e-01 -2.06392445e-02\n",
      " -1.50048390e-01  2.14743838e-01 -4.15800251e-02 -3.45016003e-01\n",
      "  2.46939480e-01  3.50298658e-02 -4.23356332e-02  1.73818290e-01\n",
      " -1.75738141e-01 -1.28963754e-01 -1.81010947e-01  4.90888692e-02\n",
      " -5.06712258e-01 -1.36498109e-01 -2.76425809e-01  3.04326534e-01\n",
      " -1.68811399e-02 -2.60954171e-01 -1.96990311e-01 -2.98877209e-01\n",
      "  1.13028415e-01 -7.69845694e-02  1.00716576e-01 -5.05565144e-02\n",
      " -1.53488502e-01 -1.17168456e-01 -1.65766284e-01  2.83757839e-02]\n",
      "L7N0                    -> L8N136 = [-0.19055806  0.04783274 -0.0651928   0.17275155 -0.12139781 -0.13068168\n",
      " -0.01629945 -0.00503076 -0.05316943 -0.12631322 -0.00412132 -0.00929618\n",
      " -0.2810017  -0.21206081 -0.0613191  -0.10054233 -0.21038038 -0.19912708\n",
      " -0.24508731  0.07870343  0.01375314 -0.17624255 -0.2750932  -0.13600145\n",
      "  0.05829793 -0.21326967  0.05335131  0.25175822 -0.12733567  0.04126972\n",
      " -0.19082585 -0.20766366 -0.26107085  0.18968278 -0.11050257 -0.30723444\n",
      " -0.12873694  0.10300291 -0.12186763  0.1035077  -0.18128811  0.03169682\n",
      "  0.05155722 -0.42367604  0.00873138 -0.10509708 -0.09507032 -0.1788559\n",
      " -0.2145548  -0.09965073 -0.31881052 -0.14300804 -0.19295655 -0.11394221\n",
      " -0.03552675 -0.08934595  0.02993718 -0.14548208  0.03759227  0.06750113\n",
      "  0.00549539 -0.30824625 -0.3911049  -0.04544521 -0.19011363 -0.22702658\n",
      " -0.027356   -0.1361151  -0.09058385 -0.23706783 -0.32192    -0.13324052\n",
      " -0.17181914 -0.15669356  0.22514203 -0.17587294 -0.10431927 -0.14741708\n",
      " -0.24509802 -0.14646406 -0.10741528 -0.2738386  -0.24695641 -0.09159762\n",
      "  0.22858898  0.18531564  0.05110471 -0.00193516 -0.2774063  -0.00444923\n",
      " -0.2673474  -0.28367406 -0.06376228 -0.14705093 -0.36922398 -0.24292561\n",
      " -0.14668909 -0.18581325  0.0175257  -0.13822557  0.01606344  0.04647209\n",
      " -0.20845532 -0.05167031 -0.24287221 -0.23448513 -0.19489044  0.06233494\n",
      " -0.07511967 -0.18051146 -0.1295929  -0.33676383 -0.08788736  0.00382415\n",
      " -0.05592173 -0.22303893 -0.16814132 -0.15508752 -0.14327492 -0.08620591\n",
      "  0.02838497 -0.01708645 -0.15655658 -0.1202678   0.12606077 -0.13379978\n",
      " -0.23844013 -0.09229543 -0.07925895  0.03160691 -0.04963435 -0.03930719\n",
      "  0.15077084 -0.21067582 -0.15937454 -0.17176245  0.04374627 -0.12843396\n",
      "  0.06406716 -0.0922189   0.11945113 -0.10383112 -0.25621122 -0.29546964\n",
      "  0.2203929   0.0080663  -0.20400836 -0.00771894 -0.2018729   0.07158531\n",
      " -0.25148344 -0.29314786 -0.13220996 -0.24184555  0.09090098 -0.07227673\n",
      "  0.15014726 -0.10734791  0.03189112 -0.2575182  -0.21316381 -0.08327002\n",
      " -0.19928391 -0.17281556 -0.15478443 -0.13425694 -0.05753408  0.09764531\n",
      "  0.11923835 -0.31612894 -0.01003157 -0.14664206 -0.0124484  -0.04167858\n",
      " -0.12221522  0.21308894 -0.33959562 -0.14793064  0.02412661 -0.2117618\n",
      "  0.11379432 -0.19379972 -0.01172197  0.08163615 -0.19714801 -0.1558459\n",
      " -0.00642895 -0.01992769 -0.13718463  0.09589975 -0.35484987 -0.35843316\n",
      "  0.12422157  0.06318765 -0.04374125  0.18459886 -0.16457091 -0.14293072\n",
      " -0.11210099  0.09554337]\n",
      "L7N0                    -> L8N137 = [ 0.2472411   0.14078242 -0.00093101  0.12023292 -0.03551417  0.13617443\n",
      "  0.11395928 -0.24655688 -0.23878278 -0.02900228  0.05373299 -0.04944029\n",
      "  0.00203311  0.04735641 -0.12096019  0.0318909  -0.00939371  0.03990899\n",
      "  0.03336474  0.03311374 -0.02594546 -0.08806193 -0.10284576 -0.02280683\n",
      " -0.00855191  0.14740643  0.369578   -0.05474192  0.0541302   0.18718958\n",
      " -0.14362295  0.10977039 -0.19623113 -0.41690314 -0.04945073 -0.0284102\n",
      "  0.17216353 -0.00266011  0.23052047 -0.11665224  0.29627302  0.08374378\n",
      "  0.12031753 -0.01870096 -0.17907561  0.11537372  0.12254741 -0.3062859\n",
      "  0.14363138  0.00529162  0.015194   -0.03050126 -0.1032336  -0.14652422\n",
      " -0.1631176  -0.22615425 -0.14346452 -0.03089308  0.1748263  -0.17002057\n",
      " -0.1733214  -0.07868174 -0.28014177 -0.09822904  0.07477539  0.09215739\n",
      " -0.31380832  0.02438681  0.16715446 -0.14374132 -0.20862079  0.16664982\n",
      " -0.17182384 -0.37030178  0.30664065 -0.17568386  0.00477865  0.17477836\n",
      "  0.03435037  0.32710615 -0.20858608 -0.06042782  0.03217742 -0.08992596\n",
      "  0.12905464 -0.3058272  -0.45568714 -0.46181253  0.05085327  0.19963226\n",
      " -0.08471991 -0.22099401 -0.1133273  -0.03420673 -0.08715092  0.02668935\n",
      " -0.04343552  0.05525727  0.22706239  0.03810344  0.1189821   0.10956078\n",
      "  0.14452595 -0.30158156 -0.15196088  0.05759524  0.15693583 -0.03032634\n",
      "  0.09550018 -0.17749268 -0.16057724  0.1364346   0.02156717  0.07616359\n",
      "  0.21296091 -0.12969784 -0.21559186 -0.00078069  0.03455748  0.09037998\n",
      " -0.11483227 -0.05690847 -0.00807323 -0.25269264 -0.24001685 -0.06735863\n",
      "  0.22535779 -0.2857155  -0.05558737 -0.27360728 -0.09940354  0.1392015\n",
      " -0.5535734  -0.04479283  0.02608084 -0.2861171  -0.28160873  0.11414775\n",
      "  0.18581323 -0.06101628  0.11403596  0.07694388 -0.24107723  0.1108439\n",
      " -0.39950964  0.08687389  0.18714535 -0.12329339 -0.07076899  0.02925012\n",
      " -0.01836487 -0.3365937  -0.2302926   0.22341175  0.11585431 -0.1511251\n",
      "  0.15638828  0.20754634 -0.19286825  0.10464799  0.11862408  0.2247783\n",
      " -0.08744386 -0.10864513 -0.01126517  0.12886293 -0.11653093 -0.142421\n",
      " -0.336661    0.12941343 -0.04178771  0.21239798  0.08377789 -0.25179675\n",
      " -0.08985005  0.2803734   0.1806906  -0.00196039  0.06314482 -0.02299278\n",
      "  0.11219948 -0.10148057 -0.09171332 -0.43120813  0.27016702  0.00210706\n",
      "  0.3902131  -0.36936173 -0.39733213 -0.09335733 -0.42991108  0.04257184\n",
      " -0.29400426 -0.06919684 -0.24645154  0.10300072 -0.00807682  0.06914521\n",
      " -0.10118983  0.03213186]\n",
      "L7N0                    -> L8N138 = [-1.31258503e-01  3.86155725e-01 -2.79562056e-01 -2.09069774e-01\n",
      " -2.41701186e-01  4.66868319e-02  2.19991580e-01  1.64322853e-01\n",
      "  9.73318815e-02  8.76249298e-02  1.12684265e-01 -3.31876904e-01\n",
      "  2.81060040e-01 -8.43954310e-02 -1.73827652e-02  2.77830195e-02\n",
      "  1.67730629e-01 -2.58446813e-01  6.08198866e-02  6.04676045e-02\n",
      "  2.74284989e-01  7.45014697e-02  7.86942095e-02 -7.73074664e-03\n",
      "  8.31025187e-03 -9.29298997e-02 -2.35706583e-01 -1.92815214e-01\n",
      "  8.20959583e-02 -5.97129576e-02 -6.95482343e-02 -9.79340523e-02\n",
      "  2.79917926e-01  1.69385210e-01 -5.48164826e-03  1.67068437e-01\n",
      "  1.33678705e-01  4.54792529e-02  1.02296777e-01 -5.00040241e-02\n",
      " -4.48805869e-01  4.57837991e-02  4.61177863e-02 -2.20676407e-01\n",
      "  1.19218670e-01  2.59366035e-02  2.12610632e-01  3.28851305e-02\n",
      " -1.84875712e-01 -6.03747033e-02 -1.05944522e-01 -1.12155713e-01\n",
      "  2.36171298e-02  2.05024242e-01  1.39339818e-02  2.63470531e-01\n",
      "  4.38144460e-04  2.05081910e-01 -1.29950605e-02 -1.82493076e-01\n",
      "  2.49001399e-01  6.19123504e-03  6.05661757e-02  2.19149455e-01\n",
      "  1.16832696e-01 -2.13855132e-01  2.07040235e-01 -9.31724980e-02\n",
      "  7.40355328e-02 -8.35431553e-03  1.46239147e-01 -1.32936791e-01\n",
      "  5.96175939e-02  2.80557096e-01 -1.82206184e-01 -1.66753829e-01\n",
      "  1.19210660e-01 -1.50869727e-01 -1.50754765e-01 -1.26315549e-01\n",
      " -3.09374243e-01  3.12612116e-01  1.53689846e-01 -2.28854436e-02\n",
      "  3.13742459e-01 -6.81371987e-02  1.04589470e-01  9.11698267e-02\n",
      "  1.54780626e-01 -1.37330696e-01 -2.17624485e-01  2.23800287e-01\n",
      "  9.60411206e-02  2.21900091e-01  1.14330515e-01  7.78239500e-03\n",
      "  2.30748355e-01 -1.96267933e-01 -2.01825574e-01  3.43805403e-02\n",
      "  7.62543231e-02  2.81292759e-02 -1.31663024e-01  1.91407464e-02\n",
      "  1.06651150e-01 -1.92150578e-01 -1.31950527e-02  1.76729396e-01\n",
      "  7.80936554e-02 -1.54909596e-01  9.11021382e-02  1.19542673e-01\n",
      "  3.98140103e-02  1.00499943e-01 -1.95608199e-01 -2.68888205e-01\n",
      "  1.08893983e-01  1.42509863e-01  1.19398169e-01 -2.71231961e-02\n",
      " -1.02152899e-01 -9.86784026e-02  6.93313926e-02 -9.10946280e-02\n",
      " -2.31621414e-01 -6.32509142e-02  1.09672330e-01 -2.26433709e-01\n",
      "  2.24292632e-02 -1.12685934e-01  5.37151285e-02  1.18209556e-01\n",
      "  4.51228879e-02  1.57061443e-01  7.87176937e-02 -3.03868875e-02\n",
      " -2.34772582e-02 -3.89587507e-02  5.55792190e-02  2.11704642e-01\n",
      "  2.49820903e-01  1.56698823e-01  5.94159625e-02  4.03537564e-02\n",
      " -2.27223951e-02 -1.83299854e-01  7.26342127e-02  1.27984047e-01\n",
      " -5.70984893e-02 -1.98661819e-01 -9.71732065e-02 -1.83808476e-01\n",
      "  1.29993185e-01  8.19000602e-02  3.53506841e-02  4.11697686e-01\n",
      " -4.28410657e-02  3.13112289e-02 -1.06088109e-01 -4.62790072e-01\n",
      " -5.51324524e-02 -2.98922360e-02 -3.69160250e-02 -1.61542341e-01\n",
      " -4.66893204e-02 -1.59152653e-02 -4.66217071e-01  1.31120712e-01\n",
      " -3.23576108e-02  4.70838696e-02  2.06587315e-02  1.86500281e-01\n",
      " -4.62309346e-02  5.61727025e-02  1.73730738e-02  2.88308412e-01\n",
      " -3.31836231e-02 -4.08214554e-02  1.35627780e-02  4.76698689e-02\n",
      " -1.15835190e-01  2.09520981e-01  1.26054049e-01  2.16709301e-02\n",
      "  9.73091274e-02  7.62497336e-02 -1.89355895e-01  2.73600250e-01\n",
      " -1.54217184e-01  4.89327945e-02  3.34088574e-03 -5.09051196e-02\n",
      " -3.68431881e-02  4.69118766e-02  2.83552647e-01  2.79793292e-01\n",
      " -2.90683210e-02 -3.64220649e-01 -3.99776734e-02 -7.61724412e-02]\n",
      "L7N0                    -> L8N139 = [-0.27997866 -0.10891495 -0.16461033  0.1286278   0.05189541 -0.03236046\n",
      " -0.23032604 -0.3964646   0.01361754 -0.1820427  -0.04259921  0.0160932\n",
      "  0.06130623  0.01306641  0.05030572 -0.01264101 -0.23099577 -0.04966473\n",
      " -0.07046432  0.06667307 -0.02341439 -0.30107194 -0.12276935 -0.15207349\n",
      " -0.30543956 -0.21582305  0.10530914 -0.208573   -0.1695066  -0.11624605\n",
      " -0.0710438  -0.14165056  0.00405187 -0.13057154 -0.34408614 -0.04278158\n",
      " -0.02694377 -0.1252897  -0.09662595  0.17622387  0.05399777 -0.0568427\n",
      " -0.2628887  -0.10458653 -0.26145568  0.22046769  0.18914175 -0.16602644\n",
      " -0.04596549 -0.04374497  0.07222269 -0.16043088 -0.3179894   0.1106521\n",
      " -0.10230033 -0.15810701 -0.11910883 -0.2907777  -0.05709928  0.0904465\n",
      " -0.04949925  0.0937372  -0.06672691 -0.26506487  0.10930535  0.03231304\n",
      " -0.01789181  0.10832036 -0.11676072 -0.2644087   0.01067267  0.11494055\n",
      " -0.11546085  0.10487185 -0.01705665 -0.04289087 -0.3483572   0.04719801\n",
      "  0.13093407 -0.17981926 -0.19444893 -0.1608919  -0.20260286  0.07487038\n",
      " -0.24765661 -0.2154022  -0.18152893  0.21835127 -0.07813958 -0.16027655\n",
      " -0.02946903 -0.07081024 -0.15664665 -0.04479387 -0.07231635 -0.34654856\n",
      "  0.20923054  0.35565415 -0.06349105 -0.00781634 -0.2834708  -0.17318277\n",
      " -0.08340866 -0.15071006 -0.11373148  0.269375    0.15665257 -0.03568679\n",
      " -0.24082117 -0.34270236  0.06975246 -0.15561822 -0.06434083 -0.30326486\n",
      "  0.04702053 -0.03099048 -0.04722705  0.00911992  0.01817211 -0.0626397\n",
      " -0.08872309 -0.00588028 -0.01910752  0.15302348 -0.0853732   0.08522538\n",
      " -0.12600508 -0.07530054  0.20984763 -0.02907752 -0.26642114 -0.27820495\n",
      " -0.21905282  0.071058   -0.23958278 -0.3816247   0.031       0.1361435\n",
      " -0.01261625  0.01231756 -0.21661621 -0.14718747  0.07304847  0.06234488\n",
      "  0.29123524  0.13359217  0.1370798  -0.05682272 -0.15979542 -0.1689821\n",
      "  0.00500987 -0.17645635 -0.0229456  -0.02454915 -0.1528397  -0.33997315\n",
      " -0.26051378  0.29671055 -0.2996475   0.05658966 -0.03935834 -0.00758439\n",
      " -0.12157743  0.19209021  0.06191236 -0.16251369 -0.19134587  0.12398543\n",
      "  0.11010877 -0.07790107  0.10709158 -0.02226843 -0.33334798  0.01000725\n",
      "  0.01321156 -0.22453022 -0.16941921 -0.12352485 -0.07265329 -0.05969629\n",
      "  0.03548829 -0.21933419  0.13466391  0.08190112  0.30593386 -0.21702039\n",
      " -0.03446065  0.0497059   0.19789034 -0.21831107 -0.0373733   0.18280551\n",
      "  0.19187042 -0.28182223 -0.34099796 -0.35171443  0.06674109  0.13114668\n",
      " -0.04726085 -0.22390628]\n",
      "L7N0                    -> L8N140 = [-0.3134009  -0.03035068 -0.02652756  0.2634667  -0.01877487  0.08255393\n",
      " -0.29081535 -0.1772318  -0.30267707  0.10560613  0.05300746  0.04579728\n",
      " -0.20342594  0.02951859 -0.3264109  -0.11216477  0.14176668  0.0785732\n",
      " -0.05827088 -0.03975147 -0.00462498 -0.0077299  -0.4898429  -0.13682526\n",
      "  0.10249675  0.13666023  0.18153255 -0.22955331  0.07196077 -0.08335184\n",
      " -0.24992259 -0.4096818  -0.11060249 -0.2833351  -0.0016679  -0.0976112\n",
      " -0.15301189 -0.15955232  0.13658401 -0.19443546 -0.20953621 -0.08155701\n",
      " -0.15336905  0.03296265 -0.01748166 -0.07417514 -0.4392737  -0.2433152\n",
      " -0.03012242 -0.1339041  -0.2433129  -0.14923103 -0.00198429  0.16997445\n",
      "  0.05101844  0.3044159  -0.21114518  0.05419536 -0.11801035  0.0109367\n",
      " -0.02362361  0.04270959 -0.03168107 -0.16600509 -0.17747284 -0.3586773\n",
      " -0.18861344  0.02842285 -0.05747685 -0.02510159 -0.11582737 -0.06743001\n",
      " -0.12429725  0.07553364 -0.2515887   0.09788532 -0.08324628  0.11520296\n",
      " -0.14967698 -0.07886829 -0.0994771  -0.02499709 -0.06524447 -0.0674238\n",
      " -0.09802976 -0.04183649 -0.12087495  0.08300832 -0.08309175 -0.3191473\n",
      "  0.01475681 -0.0129736  -0.21573444  0.02221404 -0.09712434 -0.09445463\n",
      " -0.04532816 -0.1864854   0.23888978 -0.30493882 -0.19324525  0.26858118\n",
      "  0.06100795 -0.4269322  -0.08035843  0.06160459  0.26056722 -0.07208361\n",
      " -0.25756365  0.11950408 -0.05837224 -0.31509376  0.08327786 -0.2782873\n",
      "  0.1578545   0.16493447  0.12931727  0.1204729  -0.10486353 -0.00766982\n",
      " -0.32484296 -0.02754822  0.08239314  0.03025266 -0.06961203  0.06930054\n",
      "  0.20109627  0.03653311 -0.02534013 -0.2080667  -0.29670572 -0.05281679\n",
      "  0.03353481  0.16206162 -0.05830304 -0.3161424  -0.1440323   0.04884902\n",
      " -0.104183   -0.2705665   0.0304844   0.06787997 -0.08077933 -0.05316479\n",
      "  0.02530733  0.09645244 -0.3230558   0.09487014  0.20906034 -0.1765678\n",
      " -0.28666314 -0.01742563 -0.07209553 -0.10515243  0.12133391  0.08789955\n",
      " -0.28280616 -0.04747235 -0.08220264 -0.11567735 -0.08648425 -0.05231419\n",
      "  0.07561222  0.0996377  -0.13142389 -0.06596357  0.09224791 -0.05899174\n",
      " -0.01584225 -0.03908407 -0.31784952 -0.10146277 -0.01562881  0.14423211\n",
      " -0.21195644 -0.07748991 -0.13126525 -0.01117232 -0.16951947  0.00662201\n",
      "  0.27714378 -0.30302674  0.16188623 -0.2681783  -0.1749181   0.18785474\n",
      "  0.05819343  0.03277295 -0.04195796 -0.12355434 -0.03985241 -0.05807371\n",
      " -0.2971816  -0.13609526  0.07115299 -0.14498755 -0.0609268   0.04684632\n",
      " -0.0337228  -0.02848566]\n",
      "L7N0                    -> L8N141 = [-0.02575451 -0.1616178  -0.24738684  0.11417153  0.17824093 -0.07296582\n",
      " -0.08905108 -0.02874268 -0.04281981 -0.18270767  0.00836032 -0.22626488\n",
      " -0.35882133 -0.07947567  0.09872651 -0.27134883  0.04146294  0.02829807\n",
      " -0.1912564   0.04285644 -0.08499445  0.17797987 -0.21141803 -0.2154746\n",
      "  0.0069788  -0.03359231  0.10208312 -0.31511423 -0.22066332 -0.0507683\n",
      "  0.0447729  -0.02791934 -0.14731404 -0.08068814 -0.27503893 -0.08585612\n",
      " -0.01427385 -0.17670748  0.05107816 -0.0063675   0.30888936  0.04176761\n",
      " -0.05351954 -0.14470813  0.09127615 -0.3808976   0.18398328 -0.07936797\n",
      " -0.08741187 -0.10857138 -0.0837634  -0.23449813  0.03461546 -0.12378512\n",
      " -0.06637295 -0.24730904 -0.01715078 -0.07120319 -0.00967463  0.03127027\n",
      "  0.08941817 -0.09967621 -0.04758708  0.02373387 -0.16826378 -0.29433313\n",
      "  0.04959884 -0.06753542 -0.23827569 -0.2053727  -0.1659188  -0.22159263\n",
      " -0.02620634 -0.07060679  0.0640781  -0.2417167  -0.08079597  0.18098255\n",
      " -0.00819339 -0.32072696  0.09432165 -0.34699395 -0.19755657 -0.06908027\n",
      " -0.17893246 -0.2332836  -0.16648732  0.05372706  0.03161092 -0.04935852\n",
      " -0.05565221 -0.04748744 -0.26340035 -0.27101654 -0.3438156  -0.15248814\n",
      " -0.16569498  0.314631   -0.16926205 -0.09051479  0.04571632  0.22629826\n",
      " -0.327871   -0.21521434 -0.13448569  0.11580458  0.04452109 -0.11459289\n",
      " -0.28232867 -0.19504479 -0.13326469 -0.264824    0.15583073 -0.42780617\n",
      " -0.22385207 -0.5914859  -0.06961276 -0.10967339 -0.08499381  0.05400463\n",
      " -0.01173583 -0.25591975  0.07178579 -0.15369278 -0.16875102  0.11325227\n",
      " -0.10394547 -0.06890766 -0.32302374  0.02214849 -0.08920579 -0.17983422\n",
      " -0.18590742  0.0116617   0.02543852 -0.29035422 -0.26727834 -0.1425262\n",
      " -0.11754531 -0.07826773  0.16374546 -0.23274274 -0.03664707 -0.05345302\n",
      "  0.02337518 -0.02657728 -0.09571688 -0.1678662   0.11158437 -0.2663225\n",
      " -0.09289096  0.10062347 -0.2611995  -0.2614833   0.06727952 -0.26529774\n",
      " -0.16814405 -0.03720188  0.10401604  0.03528208 -0.1867945  -0.19371961\n",
      " -0.35186294 -0.01803397 -0.02482974 -0.06010631 -0.22073878 -0.27311864\n",
      " -0.12036806 -0.0792865  -0.23971945 -0.01909994 -0.16413799 -0.25610226\n",
      " -0.1027251  -0.16228712 -0.14961945 -0.23874016 -0.18215026 -0.20948517\n",
      "  0.11533175  0.16343287  0.05931105  0.12251464  0.00679384  0.10669918\n",
      " -0.0318202  -0.01950146 -0.31916073 -0.17933957 -0.1044989  -0.3941951\n",
      " -0.08040158  0.03764661  0.15822572 -0.02247044  0.04608692 -0.06048373\n",
      " -0.19876105  0.07910307]\n",
      "L7N0                    -> L8N142 = [-1.25466049e-01 -2.51590580e-01  5.32438755e-02 -1.25844151e-01\n",
      "  1.61914200e-01 -2.86412269e-01 -6.28977120e-02 -2.42901012e-01\n",
      " -2.18421444e-01 -2.01178700e-01 -1.37622640e-01 -7.41422772e-02\n",
      "  6.47828430e-02 -2.46370226e-01 -3.39866690e-02  4.00241986e-02\n",
      "  2.68294010e-02  4.03171033e-02 -5.46850860e-02 -2.19824776e-01\n",
      " -2.79917538e-01 -1.21859573e-01  2.55634785e-01 -1.52783319e-01\n",
      " -5.24810851e-01 -3.47469956e-01  8.74883458e-02 -3.53216082e-01\n",
      "  1.64531320e-02 -2.42943987e-01 -1.07270792e-01 -5.15543558e-02\n",
      " -9.44184214e-02 -1.94888830e-01 -1.68091148e-01 -4.48054522e-01\n",
      " -3.66279781e-02 -2.37616077e-01 -4.13216054e-02 -2.85674155e-01\n",
      " -1.67525098e-01 -1.08960629e-01 -2.80436695e-01 -3.24901417e-02\n",
      "  2.91445851e-02 -2.30015352e-01 -1.78397909e-01 -3.49524349e-01\n",
      "  1.11305505e-01 -3.21808830e-02 -2.01755837e-01  6.77296100e-03\n",
      " -2.42132694e-01 -1.94455665e-02  1.76373318e-01 -3.83441180e-01\n",
      " -6.99652210e-02 -2.54335135e-01 -2.61932760e-01  1.44277975e-01\n",
      " -1.11124970e-01 -3.59608263e-01 -1.60813816e-02 -2.01586887e-01\n",
      "  1.30160496e-01 -1.78134575e-01 -2.22036645e-01  6.04235865e-02\n",
      "  4.26413305e-02 -4.05585438e-01 -2.50359457e-02 -4.84549701e-01\n",
      " -1.83179796e-01 -2.34496653e-01 -4.56646413e-01 -9.67860892e-02\n",
      " -4.55083311e-01 -1.37733340e-01 -1.23226061e-01  6.61772564e-02\n",
      " -1.11655325e-01 -2.49058843e-01  3.25844809e-02 -2.15109482e-01\n",
      " -1.60402954e-01 -3.24780732e-01 -1.32194132e-01 -1.21156305e-01\n",
      " -1.18882237e-02 -2.20747530e-01 -1.47990435e-01 -2.40227848e-01\n",
      " -3.67002130e-01  6.21875338e-02 -1.07724264e-01 -3.35112572e-01\n",
      " -2.89248079e-01 -2.56180819e-02 -4.16221559e-01  3.97874566e-04\n",
      " -1.24532118e-01 -1.48622185e-01 -4.64058131e-01 -8.91394615e-02\n",
      "  3.19771767e-02  1.02738272e-02  3.42681333e-02 -1.76068485e-01\n",
      " -3.40967715e-01 -1.50255635e-01 -9.00392141e-03  7.03361630e-02\n",
      " -5.46370521e-02 -2.24772304e-01  1.12857118e-01  4.63346876e-02\n",
      " -2.64880180e-01 -1.34905040e-01 -5.95151559e-02 -1.85074672e-01\n",
      " -1.27281584e-02 -4.50127423e-02 -3.31972182e-01 -2.12932512e-01\n",
      " -1.79819345e-01 -3.10843787e-03  4.15006606e-03  1.03813194e-01\n",
      " -3.01891148e-01 -9.35591012e-02 -4.02988702e-01 -1.71753600e-01\n",
      "  2.41420381e-02 -1.66153371e-01  3.27151082e-02 -2.53613830e-01\n",
      "  7.33575374e-02  1.34114251e-01 -3.31839532e-01 -7.33286981e-03\n",
      " -1.57050237e-01 -2.03595966e-01 -6.39644265e-02 -2.94388115e-01\n",
      " -1.42403752e-01  1.48121305e-02 -4.02772635e-01  1.26700133e-01\n",
      " -1.02981083e-01 -2.75054187e-01  3.81292007e-03 -2.50016987e-01\n",
      " -1.21255800e-01 -7.81944171e-02 -3.34472239e-01  6.74018338e-02\n",
      " -1.23607889e-01 -5.48538677e-02 -3.96152765e-01  4.82032001e-02\n",
      " -4.87290978e-01 -1.72813669e-01  1.66476831e-01 -2.20468324e-02\n",
      " -5.51763624e-02 -4.27647054e-01 -9.50210616e-02 -1.86597377e-01\n",
      " -2.57187456e-01 -5.62144756e-01 -2.18005866e-01 -1.67271763e-01\n",
      " -1.19333312e-01 -6.67556524e-02  6.08547479e-02 -2.20306605e-01\n",
      " -3.82741988e-01 -7.41964504e-02 -2.08527654e-01 -9.61928349e-03\n",
      "  5.79103939e-02 -2.72216231e-01 -3.33265476e-02 -1.53670728e-01\n",
      " -1.00038841e-01 -9.98070464e-04  2.49077287e-02 -1.69797108e-01\n",
      "  2.24915314e-02 -1.99354619e-01  4.95271757e-02  8.32521692e-02\n",
      " -2.61380672e-01 -7.83036128e-02 -1.20887011e-01 -2.37463370e-01\n",
      " -5.10340817e-02  6.84451014e-02  3.75357382e-02 -2.15341195e-01]\n",
      "L7N0                    -> L8N143 = [ 2.24263608e-01  3.22094299e-02 -4.82346229e-02 -1.69880360e-01\n",
      " -4.64383923e-02  1.89971641e-01  5.34968004e-02  2.84881964e-02\n",
      "  1.76855698e-01 -4.00514416e-02  6.33911416e-02  1.57906905e-01\n",
      "  1.24764005e-02  8.04651752e-02 -1.25893101e-01  4.29136604e-02\n",
      " -1.08744502e-02  1.01324491e-01  1.18826199e-02  2.90675461e-01\n",
      "  2.84696907e-01  1.80986524e-02 -7.43794441e-02  8.26840028e-02\n",
      "  5.20307422e-02 -1.64632514e-01  4.07233573e-02 -7.76704401e-02\n",
      "  1.02376223e-01 -2.49567181e-01 -1.67071652e-02 -9.53503475e-02\n",
      "  3.27676185e-03  9.96284932e-02 -2.38103539e-01 -2.41898522e-02\n",
      " -1.17356852e-01 -3.57504711e-02 -2.46200129e-01 -2.21679702e-01\n",
      " -1.37776688e-01  6.05325326e-02  2.86379129e-01 -2.61151850e-01\n",
      "  1.52215511e-01  1.43808916e-01 -1.10062435e-01 -4.11083810e-02\n",
      "  3.47666293e-01 -2.10635308e-02 -1.95353404e-01  5.23502147e-03\n",
      "  6.76724017e-02 -5.06863222e-02  2.58309901e-01  5.30932784e-01\n",
      "  1.52027309e-01 -6.46530697e-03 -4.06809412e-02 -1.71852544e-01\n",
      "  1.02215871e-01 -1.07582428e-01 -1.01310618e-01 -2.58931845e-01\n",
      " -4.95438799e-02 -2.78244205e-02  1.14246801e-01  9.05542672e-02\n",
      " -8.46901983e-02  1.15030549e-01  6.93937764e-02 -2.14252084e-01\n",
      " -1.76870391e-01  2.80062079e-01  1.10528611e-01 -2.27236599e-01\n",
      " -2.23268002e-01  2.09590588e-02  1.27437472e-01 -2.13495716e-01\n",
      " -1.23929409e-02  1.23318821e-01 -2.25394615e-04  1.07095368e-01\n",
      "  1.17792681e-01 -2.00616300e-01  6.77686930e-02  1.28855467e-01\n",
      " -1.18965343e-01 -3.05121154e-01  2.36546949e-01 -3.07824109e-02\n",
      "  7.63551071e-02  2.96809375e-01 -2.20649570e-01  1.73391271e-02\n",
      "  2.17055127e-01 -2.18350321e-01 -9.73519385e-02 -1.83260098e-01\n",
      "  1.18459158e-01 -1.77852973e-01 -6.76387250e-02  9.05064121e-02\n",
      " -1.52163878e-02 -8.61217752e-02 -6.08112626e-02 -1.66409388e-01\n",
      " -3.36779431e-02  5.98696247e-02  5.92922159e-02 -1.48708314e-01\n",
      "  2.04714432e-01 -1.44073777e-02  1.83402952e-02 -1.34859324e-01\n",
      "  1.72152534e-01  6.31405860e-02 -5.37450835e-02  1.89245809e-02\n",
      " -1.15888014e-01  9.58669856e-02 -4.60003726e-02  5.16940877e-02\n",
      " -1.07515015e-01 -1.56669971e-02 -1.40689969e-01 -2.11280301e-01\n",
      "  1.71314090e-01 -1.70048952e-01  6.60074428e-02  1.26879677e-01\n",
      "  3.14599633e-01 -1.07036896e-01 -2.80013457e-02 -1.37642026e-01\n",
      " -2.61693329e-01  4.10648026e-02  3.51240456e-01 -1.65494666e-01\n",
      "  1.16316482e-01 -2.38931015e-01  6.81467652e-02 -2.36826926e-01\n",
      "  1.14749670e-01  6.56943321e-02 -3.14751297e-01  3.95719633e-02\n",
      " -1.56182691e-01  5.13955653e-01 -2.49675184e-01  1.05962120e-01\n",
      " -6.41486347e-02 -6.49233907e-02  2.84956187e-01 -1.34482190e-01\n",
      "  6.19457290e-02  5.95640875e-02  2.95467287e-01  2.33062893e-01\n",
      "  6.31465614e-02  2.17730656e-01  1.98026821e-01 -9.33943689e-02\n",
      " -2.82156646e-01 -4.61890958e-02 -1.14397451e-01  2.32593656e-01\n",
      " -1.69999644e-01  3.35763514e-01  7.78103843e-02  7.70830885e-02\n",
      "  2.88578153e-01  1.46907926e-01  2.05567889e-02  2.80880947e-02\n",
      " -5.73298223e-02  2.34073073e-01  7.33977333e-02 -5.28050140e-02\n",
      " -4.13232334e-02  1.74445048e-01  3.88120208e-03  5.31419180e-03\n",
      " -2.15339169e-01  1.36973009e-01 -8.69067311e-02  2.50968069e-01\n",
      "  5.48084266e-02  6.35395348e-02 -6.52804691e-03  1.75181285e-01\n",
      " -3.12558264e-01  1.05634563e-01  2.51197696e-01  1.03840739e-01\n",
      "  8.41426197e-03  1.38822347e-01  9.07740146e-02  6.25073388e-02]\n",
      "L7N0                    -> L8N144 = [ 0.02412197  0.09286191  0.19331734 -0.27957597 -0.01394045  0.24285139\n",
      "  0.2429373   0.2795152   0.23010369  0.24647842  0.18524942 -0.2144391\n",
      " -0.15372738  0.01413795  0.21297893 -0.18333343  0.13073808 -0.14405246\n",
      "  0.1785772   0.12736516 -0.15443048  0.16758992  0.3306219  -0.01801399\n",
      "  0.06351087 -0.03821985 -0.14053671 -0.04853387  0.04192651  0.18510365\n",
      "  0.1488408  -0.06866113  0.0395465   0.09001157  0.01182532 -0.1746327\n",
      "  0.01111377  0.10686235 -0.02307234  0.29363388 -0.2611307  -0.08630971\n",
      "  0.28136078  0.07412183  0.01782279 -0.02623949 -0.22068699 -0.1221147\n",
      " -0.26329046  0.16272363 -0.15717456  0.14199789  0.26849106  0.03502978\n",
      " -0.19511956  0.27366412  0.10862101  0.1162496  -0.02101736 -0.18200165\n",
      "  0.06461852  0.13631786  0.10339091 -0.19481765  0.04725278  0.22979942\n",
      "  0.19540425  0.04982444  0.22857986  0.08975352 -0.11182484 -0.15365621\n",
      "  0.09334626 -0.08253247  0.05590631 -0.08188136 -0.23313269 -0.18934645\n",
      "  0.12337387 -0.03160502  0.06675215 -0.23842813  0.07206729  0.13717622\n",
      "  0.24431328 -0.09380361  0.17132318 -0.02085529 -0.26074693 -0.09386986\n",
      "  0.24227922  0.17477356  0.10791951  0.24272844 -0.157734   -0.053248\n",
      "  0.11458923 -0.19365774 -0.05769876 -0.02879101  0.1306103   0.30687928\n",
      "  0.03902897  0.075614    0.08984509 -0.22083384 -0.20935878  0.15897132\n",
      "  0.03662814 -0.11581698 -0.07927992 -0.17370184 -0.08452298  0.24817167\n",
      " -0.2899302  -0.0857502  -0.07456835 -0.1707535  -0.01917978  0.15160775\n",
      "  0.0547036   0.03101451  0.17954367  0.17225227  0.03935095  0.10363456\n",
      "  0.501075   -0.1484779   0.00652124  0.10809421  0.1401009  -0.10161167\n",
      "  0.00425766 -0.02119755 -0.14862853  0.08911734  0.02697643 -0.2951422\n",
      "  0.07365162  0.07795221 -0.05691925 -0.2031175  -0.19098984  0.02455468\n",
      " -0.01303837 -0.13851246  0.03056249  0.19099975  0.12428613  0.13325414\n",
      "  0.00778568  0.02114044 -0.14244613  0.07297004  0.11471139  0.04973045\n",
      "  0.24192673 -0.32049635  0.15644564 -0.24216357  0.0723509  -0.07064186\n",
      "  0.05934703 -0.05382766  0.1285345   0.13397634 -0.00333648  0.05911796\n",
      " -0.00256965 -0.1529497   0.3155353  -0.01856778 -0.07955384  0.06019982\n",
      " -0.25335142  0.3707247   0.0362925  -0.08019695 -0.14710744 -0.19164222\n",
      " -0.25372168  0.12310959 -0.0644288  -0.31064412 -0.05622011 -0.00129906\n",
      " -0.2662912   0.0540094  -0.33345523  0.06526521  0.05831345  0.07900326\n",
      "  0.2146484   0.0638332   0.25734687 -0.05276294  0.0881111  -0.12372606\n",
      " -0.01259021  0.30724278]\n",
      "L7N0                    -> L8N145 = [ 0.19692759 -0.31273788  0.05117659  0.01480991  0.04105947 -0.11841699\n",
      " -0.19389066 -0.00357288 -0.18578249 -0.05345307  0.3499281   0.11891347\n",
      " -0.01700072  0.0475946  -0.10865302  0.1456676  -0.14134689  0.19508803\n",
      "  0.13216063 -0.1577354   0.00730267  0.10028009 -0.05799592 -0.02003206\n",
      "  0.19470838  0.11415485  0.31149682  0.03495013 -0.09044953 -0.26544538\n",
      " -0.26385266  0.03420376 -0.18962823 -0.17167775 -0.01598623  0.12786762\n",
      "  0.02060697 -0.03807909  0.13723953  0.04363121  0.19527245 -0.2775408\n",
      "  0.12600541 -0.03823156 -0.35097188 -0.07405142 -0.05029955 -0.00379588\n",
      "  0.05610366 -0.02500335 -0.02062068 -0.21158607 -0.10678501  0.07685078\n",
      "  0.20825616 -0.02022399 -0.04142225  0.02718405 -0.09626728  0.07905897\n",
      " -0.02244013 -0.3126747   0.04130697 -0.16260801  0.06917389  0.17782481\n",
      " -0.08661808  0.15631711 -0.14218216  0.0250384  -0.06632018  0.295352\n",
      " -0.1180295  -0.23888588 -0.07870108 -0.31856832  0.10319613 -0.04779661\n",
      "  0.07877645  0.15421565 -0.29376748 -0.00950051  0.07839121 -0.22867784\n",
      "  0.04532591 -0.18114462 -0.06130816 -0.2628331  -0.18918107  0.25603265\n",
      "  0.04331244  0.12423635  0.0666578   0.19558772  0.19356172  0.01827425\n",
      " -0.04186023 -0.13525748  0.22680274  0.18844755  0.18514183  0.05543897\n",
      "  0.01566533 -0.11186903 -0.17198226  0.0982139  -0.29223785 -0.10017217\n",
      " -0.04116721  0.00069801  0.00832265  0.07442129 -0.01946226 -0.15063858\n",
      "  0.18045074  0.02112158  0.16558181  0.15839656  0.1801091   0.04889184\n",
      "  0.03746451  0.09778538  0.10415789  0.00915742 -0.22208807 -0.0058062\n",
      "  0.11658682 -0.12081221 -0.11693591 -0.28135043 -0.10941382  0.01627935\n",
      "  0.05463124  0.06227239 -0.06208038  0.14865826  0.0051241   0.21783572\n",
      "  0.10321479 -0.04244474 -0.14188716 -0.02612474  0.01225741 -0.3816446\n",
      " -0.04345063  0.008148   -0.14412588 -0.25729033  0.06267277  0.10825688\n",
      " -0.01761354 -0.02251835  0.1694573   0.05051697  0.00049115  0.12262676\n",
      " -0.09646717  0.29302603 -0.04374818  0.10924149 -0.1852655   0.11759121\n",
      " -0.02232729 -0.03677933 -0.3416787   0.21723089  0.25652936 -0.34939846\n",
      " -0.10087512  0.27527612  0.2018775   0.16187814 -0.16451335 -0.14069745\n",
      "  0.07706976  0.20548156 -0.16348134 -0.23945393  0.0407812   0.03918908\n",
      "  0.02136543  0.0589768  -0.18125263 -0.27478108 -0.14108475  0.0406953\n",
      " -0.09580288 -0.12689108 -0.09899227  0.11688343 -0.11568515 -0.17719269\n",
      " -0.16225374 -0.23275529 -0.18489191  0.10920561 -0.02240013  0.06959885\n",
      " -0.16857733 -0.13638057]\n",
      "L7N0                    -> L8N146 = [-4.75237332e-02 -2.89862044e-02  3.68102565e-02  4.65557911e-02\n",
      "  1.90357342e-01 -4.77718711e-02  6.25039712e-02  7.95788094e-02\n",
      " -5.98506629e-02 -3.61353941e-02 -9.55358148e-03  4.29917902e-01\n",
      "  1.62753224e-01  4.69536744e-02 -1.46329552e-01  3.61373350e-02\n",
      "  6.71762833e-03 -2.26715393e-02 -9.48671028e-02 -2.79641002e-01\n",
      " -1.10593192e-01 -3.67931165e-02  2.84163296e-01  3.38427663e-01\n",
      " -6.20618127e-02  2.18604524e-02 -3.77744436e-02 -1.98361158e-01\n",
      "  2.47279443e-02 -4.75672679e-03 -3.44486356e-01  2.14100316e-01\n",
      "  8.12467635e-02 -1.60180181e-01  1.62925795e-01  1.32083178e-01\n",
      " -1.16382547e-01  1.31185547e-01  2.77512282e-01  1.36351973e-01\n",
      "  2.22014070e-01 -1.26714364e-01  5.60137630e-02 -9.73663628e-02\n",
      " -2.40833580e-01 -2.04119772e-01  1.77718461e-01  9.76089202e-03\n",
      "  2.56888688e-01  2.09131092e-01 -1.94044083e-01 -2.11243197e-01\n",
      "  9.42678973e-02 -6.59018755e-02 -7.53362700e-02 -1.82878539e-01\n",
      "  1.88987806e-01  2.80128680e-02  9.62970331e-02  6.33561164e-02\n",
      "  3.87874991e-02 -4.22011949e-02 -2.02812195e-01 -6.56006113e-02\n",
      " -3.57530825e-02  2.09963098e-02 -8.38298723e-02  2.90702134e-01\n",
      "  6.53823912e-02 -1.60886839e-01  3.13710421e-02  1.10248371e-03\n",
      " -1.85297921e-01 -2.88211647e-02 -1.47997305e-01  9.01243649e-03\n",
      " -2.38231406e-01  5.32394946e-02 -8.18880051e-02  2.28142232e-01\n",
      " -1.38333365e-01 -2.63031930e-01 -9.91810262e-02  3.97586003e-02\n",
      "  6.03367910e-02 -2.16998160e-01 -2.90076524e-01 -1.57023922e-01\n",
      " -1.54398322e-01  1.80827484e-01  3.42375785e-01 -5.28027490e-02\n",
      "  1.21350579e-01  1.10951588e-01  1.18668839e-01  2.06541076e-01\n",
      "  1.13681883e-01 -4.05849831e-04  1.58402771e-01 -5.83472028e-02\n",
      "  3.57803609e-03  7.24947751e-02  2.29975685e-01 -1.75721005e-01\n",
      " -6.63347542e-02 -3.24066123e-03 -1.04194149e-01  7.24979341e-02\n",
      " -2.20606282e-01  1.79869547e-01  2.79032737e-01  7.61805475e-02\n",
      "  2.56272405e-01 -3.89562212e-02  1.63787410e-01  4.47539762e-02\n",
      " -8.31351522e-03 -1.82749778e-01 -2.03598917e-01 -6.39058203e-02\n",
      " -2.69234926e-01  7.27315173e-02 -2.30221629e-01 -4.78767827e-02\n",
      " -1.70022234e-01 -1.09088905e-02  2.94494271e-01  2.97912359e-01\n",
      "  7.03121051e-02 -2.01537475e-01  9.14615169e-02 -4.82318886e-02\n",
      " -2.25314811e-01 -2.35701017e-02  2.67185450e-01 -4.24058223e-03\n",
      " -2.61466712e-01  1.37410805e-01  1.58946350e-01  2.07826495e-02\n",
      "  4.60406393e-02  6.30463883e-02 -1.12412967e-01 -1.74381688e-01\n",
      " -1.90616220e-01 -1.65381998e-01 -7.75916502e-02  1.62197292e-01\n",
      "  8.28711390e-02  1.43578332e-02  2.92934366e-02  1.11351669e-01\n",
      "  6.38308153e-02  1.18517643e-02 -7.67510533e-02 -7.32328147e-02\n",
      " -6.64595068e-02 -5.38680963e-02  2.47024804e-01  1.49228647e-02\n",
      " -1.68203302e-02  1.43980846e-01 -4.38713208e-02  1.18131831e-01\n",
      "  5.37855551e-02  7.31237233e-02 -3.87730412e-02 -2.21260250e-01\n",
      " -4.65922728e-02  3.83429900e-02 -1.37968868e-01 -2.19305962e-01\n",
      " -6.96308985e-02 -1.83578625e-01  1.72639489e-01 -1.59491867e-01\n",
      " -7.09729418e-02 -3.39379668e-01 -3.38939659e-04 -1.30533144e-01\n",
      " -3.66349071e-02 -7.43086636e-02 -3.48292470e-01 -9.63386968e-02\n",
      " -6.60027042e-02  2.21988738e-01 -3.45901489e-01 -4.77356464e-01\n",
      " -3.39450315e-02 -2.38499567e-01 -8.90943184e-02 -4.87724245e-02\n",
      " -1.54833302e-01 -1.36058375e-01 -2.70655572e-01  7.14954315e-03\n",
      "  5.71730323e-02 -1.02717623e-01 -6.53415024e-02 -1.59084007e-01]\n",
      "L7N0                    -> L8N147 = [ 1.77020311e-01  5.24523444e-02  8.66117105e-02 -8.64777118e-02\n",
      " -2.01110706e-01  6.21137442e-04 -6.99911863e-02 -1.03782624e-01\n",
      "  8.38875622e-02 -3.24852735e-01 -1.91737682e-01 -1.04670718e-01\n",
      " -9.03121158e-02  4.15489897e-02  1.01592340e-01 -1.26266599e-01\n",
      "  5.19171618e-02 -3.78090777e-02 -2.65169293e-01 -3.57561439e-01\n",
      "  2.62049824e-01  4.83790636e-02 -2.37052932e-01 -1.44626290e-01\n",
      "  1.54546857e-01 -1.87753245e-01 -2.12008804e-01 -7.97884464e-02\n",
      " -1.35609135e-01 -4.25749958e-01 -6.99176043e-02 -1.80695802e-01\n",
      " -1.48384079e-01  3.82843822e-01 -1.82770953e-01 -9.56409797e-02\n",
      " -2.79922277e-01 -2.56050915e-01  9.42505226e-02  2.17172623e-01\n",
      " -1.20634034e-01 -1.23669431e-01 -1.06353164e-01 -1.93858147e-01\n",
      "  2.06422657e-01 -1.78674549e-01 -2.97858477e-01 -3.37413102e-01\n",
      " -1.68855954e-02  3.16359513e-02 -1.62281826e-01 -1.52538866e-01\n",
      " -1.97263092e-01  4.21762030e-04 -2.71252781e-01 -6.18295521e-02\n",
      " -1.81477144e-01 -1.13241181e-01 -5.39552458e-02 -5.13379797e-02\n",
      " -1.41422451e-01 -1.14548758e-01 -1.12028047e-01 -5.58100417e-02\n",
      " -1.39030337e-01 -2.04841480e-01  1.07712172e-01 -2.14775458e-01\n",
      " -9.62191299e-02 -2.86266152e-02 -1.95563301e-01 -3.05657629e-02\n",
      " -1.29296273e-01  1.86604336e-01 -1.58061385e-01 -2.54590183e-01\n",
      "  8.60704333e-02 -1.07795872e-01 -2.09731027e-01 -2.57745594e-01\n",
      "  1.86972376e-02  1.18155770e-01 -4.23663072e-02 -8.30998346e-02\n",
      "  5.07773012e-02 -3.89884822e-02  1.69761851e-01  1.73864827e-01\n",
      " -1.04596905e-01  8.51172805e-02  1.79790668e-02 -7.98753202e-02\n",
      "  6.94578094e-03 -2.47518122e-01  4.17834036e-02 -1.01980709e-01\n",
      "  1.44712090e-01 -1.66269511e-01 -1.35189164e-02 -3.54242444e-01\n",
      " -1.71225760e-02 -2.30864614e-01 -1.39164478e-01  5.31856529e-02\n",
      " -1.75550118e-01 -3.01244929e-02  9.18265730e-02 -7.78625859e-03\n",
      " -6.20041825e-02  7.03163305e-03 -2.95442045e-01 -1.48109779e-01\n",
      " -1.50737897e-01 -2.89382696e-01 -2.24077553e-01 -3.81197661e-01\n",
      " -3.35001722e-02 -1.44879952e-01 -1.08961299e-01 -1.44414604e-01\n",
      "  4.54862788e-02 -6.02306277e-02 -1.58931196e-01 -1.68468118e-01\n",
      "  3.72880697e-02 -1.96256593e-01 -1.32998481e-01 -5.44232316e-02\n",
      " -1.27238393e-01  2.34592900e-01 -2.93822497e-01 -1.85649276e-01\n",
      "  1.03645464e-02 -1.39991522e-01 -3.29287559e-01  1.34309568e-02\n",
      " -8.76569375e-02 -1.08116128e-01 -1.41691417e-01 -1.46482468e-01\n",
      " -2.13207856e-01 -2.37746596e-01 -1.23764016e-02 -1.59072459e-01\n",
      "  6.47298759e-03 -1.75048158e-01 -9.39875692e-02 -1.25060268e-02\n",
      "  1.24471579e-02 -1.27898321e-01 -2.56134719e-01 -2.14675769e-01\n",
      " -9.55850631e-02 -3.48007381e-02 -3.27384263e-01 -7.38570606e-03\n",
      " -1.87757373e-01  3.33542819e-03 -1.14637487e-01 -1.44465178e-01\n",
      "  1.67744700e-02 -1.50301173e-01 -6.42390326e-02 -2.17271060e-01\n",
      " -2.12991372e-01 -2.95360852e-02 -1.31700262e-01 -9.58447680e-02\n",
      "  1.15897767e-01 -7.12956265e-02  8.45159069e-02  2.41510049e-02\n",
      " -2.94313252e-01  6.31505325e-02 -2.56396711e-01 -3.62706408e-02\n",
      " -3.67990792e-01 -2.21494138e-02 -3.02596480e-01  3.36310826e-03\n",
      " -4.73142564e-02 -1.37538359e-01  5.75877316e-02 -8.16989504e-03\n",
      " -2.12473646e-01  5.79080544e-03 -1.54536933e-01  4.77316789e-02\n",
      " -1.21586978e-01  1.08791590e-02 -3.00846040e-01 -1.06322601e-01\n",
      "  1.27366483e-01  2.07570001e-01 -2.91001081e-01 -4.65847626e-02\n",
      " -1.51152611e-01 -2.44524390e-01 -1.42995752e-02  1.75515532e-01]\n",
      "L7N0                    -> L8N148 = [-0.07229923  0.15396327 -0.10139744  0.0744356  -0.11749543  0.2829136\n",
      " -0.09962118  0.25999448  0.18235844  0.06975836  0.11847807 -0.23244992\n",
      " -0.2615113   0.03619001 -0.08337164 -0.09411965  0.12328123 -0.40783527\n",
      " -0.03190475  0.18677807  0.15094544 -0.00690721 -0.1987452  -0.07259607\n",
      " -0.00092477 -0.20506096 -0.11137533 -0.21501741 -0.11640435  0.04768594\n",
      "  0.17576137 -0.31981122  0.13822615  0.20157145  0.01749655 -0.32992053\n",
      " -0.02162511  0.14629756 -0.12744977 -0.06053449  0.00105824 -0.18380344\n",
      "  0.09803428 -0.07977889  0.14234528  0.04222993 -0.01635339 -0.08851469\n",
      " -0.23591885 -0.07224388 -0.11170863  0.1899775   0.18545781  0.02659782\n",
      " -0.14182135  0.07269234  0.10196298  0.05296592 -0.11467938  0.01945754\n",
      "  0.14220195 -0.10454289 -0.11268776  0.25122005 -0.2492753   0.0801359\n",
      " -0.00933636 -0.07596691  0.06909274  0.27784076 -0.23795682 -0.08708379\n",
      " -0.07891408 -0.04381967 -0.08119601  0.17996852  0.1865965  -0.19435695\n",
      "  0.07375661 -0.01493786  0.04338381  0.0025227  -0.01121762 -0.19598694\n",
      "  0.13413966  0.12549332 -0.02454996  0.03905395  0.05787316  0.21248482\n",
      " -0.16471116  0.14967541  0.12122846 -0.20985867 -0.2728938  -0.0790194\n",
      "  0.09257457 -0.18707293  0.28266245  0.09567986  0.15250379 -0.05408207\n",
      "  0.00400583 -0.16886953 -0.02543337 -0.14484826 -0.09094984  0.00485341\n",
      " -0.02528049 -0.2487336  -0.1168042  -0.11473867 -0.04205237 -0.05237821\n",
      " -0.16105601 -0.07489909  0.01643651 -0.18234235  0.06023073 -0.07395015\n",
      " -0.01094316  0.08729243  0.08076065  0.11225012 -0.04964405 -0.02277535\n",
      " -0.06764713 -0.19259852 -0.3190689   0.17149983  0.15587315  0.03115149\n",
      " -0.01382075  0.09534516 -0.02047133  0.11489338  0.13969736 -0.2225196\n",
      " -0.00658479  0.04199972  0.01144455 -0.0067372  -0.3104171  -0.12774953\n",
      "  0.03217762 -0.12848613  0.13152522  0.00985178  0.09958936  0.29993394\n",
      " -0.13049397 -0.04516717 -0.23684496  0.00744849 -0.14677943 -0.07950903\n",
      "  0.00585285  0.00469069 -0.19548741 -0.23437479  0.2951201   0.09303703\n",
      " -0.15160292 -0.12807119  0.20178647 -0.11671308 -0.11833779 -0.00700366\n",
      "  0.10514145 -0.01205326  0.1717111   0.02590143  0.35953012  0.3050856\n",
      " -0.11757073  0.1482666   0.12933318 -0.07264541  0.09616556 -0.38211837\n",
      " -0.04709123 -0.01692939 -0.15247472  0.15682341  0.05998139 -0.00416201\n",
      " -0.05656275  0.31682026 -0.15369062 -0.2224244  -0.04231091 -0.2480175\n",
      "  0.16145498 -0.01911048  0.04163994  0.23535535  0.05951916 -0.18743896\n",
      " -0.2168213   0.07806006]\n",
      "L7N0                    -> L8N149 = [ 0.16473396 -0.12236207 -0.15559442 -0.24802102  0.20088226  0.19824633\n",
      "  0.13735625  0.34138083 -0.02969252 -0.19825105 -0.17952067  0.21221572\n",
      "  0.21721844  0.02904509 -0.24401319  0.07400178  0.06173581 -0.20726593\n",
      " -0.05283142  0.23123957 -0.11648708  0.1183747   0.23185186  0.01930252\n",
      "  0.32978085  0.24311781  0.0377637  -0.05627842  0.11518142  0.09578583\n",
      " -0.10852113  0.289992    0.10864373 -0.17927481  0.06140664  0.21428859\n",
      "  0.17533366  0.07106143 -0.02638493  0.14663889  0.07893445 -0.24405318\n",
      "  0.11206196 -0.07071412 -0.04119712  0.22518301  0.1706606   0.4197988\n",
      "  0.2831783   0.2186799   0.10059115 -0.11094202  0.32187     0.1470488\n",
      " -0.12211496  0.1286699   0.09025918  0.14680603  0.0557147   0.12127116\n",
      "  0.3334306   0.01595774  0.16412912 -0.03976837 -0.16587032  0.12368496\n",
      "  0.27032644  0.02454948  0.14804031  0.2983347   0.25206324  0.2971616\n",
      " -0.24696909  0.13780552  0.13390353  0.29975355 -0.00271633 -0.18706058\n",
      "  0.26715845 -0.04902604 -0.0675253  -0.09698217  0.09352044  0.01781913\n",
      "  0.15910788 -0.21833983 -0.13169995 -0.17201868  0.12708269  0.04206186\n",
      "  0.095713    0.13351758  0.21563917  0.0811389   0.18629918  0.1652284\n",
      " -0.06645496 -0.23040348  0.39081678 -0.16303167  0.09203253  0.16830327\n",
      " -0.02407465 -0.08398689  0.22585079 -0.01710052 -0.14666896  0.22381136\n",
      "  0.06419037 -0.16263731  0.0485958   0.13577677 -0.13668752  0.11844224\n",
      " -0.15358783 -0.06527305  0.03911979  0.0136993   0.18491681  0.04230355\n",
      " -0.05919347  0.10325202  0.1594802   0.17444448 -0.19805004  0.0014167\n",
      "  0.18818238  0.08362994 -0.01175826 -0.03791372  0.10093422 -0.08915662\n",
      "  0.06834884  0.07181194 -0.12023244 -0.01270612  0.02207345  0.01332664\n",
      "  0.27043414  0.07444254  0.23915939  0.19693322 -0.11300708  0.16572425\n",
      "  0.21315086  0.06376876  0.08582246  0.1998327   0.22763053  0.16727935\n",
      "  0.02522716  0.19217326  0.2216501   0.06468262  0.2691247   0.05210945\n",
      " -0.0272256   0.06824604  0.2517455  -0.06074039  0.00752656  0.20273831\n",
      " -0.1694671   0.00145152 -0.00405438 -0.04953086  0.10454307 -0.2975126\n",
      "  0.00998965  0.01378745 -0.25020033  0.0338116   0.13718323  0.03324241\n",
      "  0.1989782  -0.04845694  0.18104702 -0.08961305  0.00825443  0.05278322\n",
      "  0.14799617  0.08687679  0.24140786 -0.08186246  0.02806851  0.19419216\n",
      " -0.2005667  -0.13844821 -0.04201742  0.03381406 -0.06287586  0.03848987\n",
      " -0.16029668 -0.01035867 -0.21926102 -0.04107531  0.10944108 -0.07008204\n",
      "  0.12100771 -0.29928628]\n",
      "L7N1                    -> L8N0 = -0.25137507915496826\n",
      "L7N1                    -> L8N1 = -0.17765706777572632\n",
      "L7N1                    -> L8N2 = -0.15730945765972137\n",
      "L7N1                    -> L8N3 = -0.13486050069332123\n",
      "L7N1                    -> L8N4 = 0.011880667880177498\n",
      "L7N1                    -> L8N5 = -0.5964014530181885\n",
      "L7N1                    -> L8N6 = -0.3187336027622223\n",
      "L7N1                    -> L8N7 = -0.2649994492530823\n",
      "L7N1                    -> L8N8 = -0.1912161111831665\n",
      "L7N1                    -> L8N9 = -0.2972963750362396\n",
      "L7N1                    -> L8N10 = -0.27489060163497925\n",
      "L7N1                    -> L8N11 = -0.1087714284658432\n",
      "L7N1                    -> L8N12 = -0.06087620556354523\n",
      "L7N1                    -> L8N13 = -0.2967987656593323\n",
      "L7N1                    -> L8N14 = -0.1417265683412552\n",
      "L7N1                    -> L8N15 = -0.07963529229164124\n",
      "L7N1                    -> L8N16 = -0.31566405296325684\n",
      "L7N1                    -> L8N17 = -0.0003825739258900285\n",
      "L7N1                    -> L8N18 = -0.2615317702293396\n",
      "L7N1                    -> L8N19 = -0.30093997716903687\n",
      "L7N1                    -> L8N20 = -0.2717857360839844\n",
      "L7N1                    -> L8N21 = -0.3225083649158478\n",
      "L7N1                    -> L8N22 = -0.2919448912143707\n",
      "L7N1                    -> L8N23 = -0.46179142594337463\n",
      "L7N1                    -> L8N24 = -0.45613500475883484\n",
      "L7N1                    -> L8N25 = -0.2869100272655487\n",
      "L7N1                    -> L8N26 = 0.008379271253943443\n",
      "L7N1                    -> L8N27 = -0.12177767604589462\n",
      "L7N1                    -> L8N28 = -0.28606608510017395\n",
      "L7N1                    -> L8N29 = -0.4237751364707947\n",
      "L7N1                    -> L8N30 = -0.29169726371765137\n",
      "L7N1                    -> L8N31 = -0.3014269173145294\n",
      "L7N1                    -> L8N32 = -0.35228732228279114\n",
      "L7N1                    -> L8N33 = -0.06297874450683594\n",
      "L7N1                    -> L8N34 = -0.3648965358734131\n",
      "L7N1                    -> L8N35 = -0.04938613995909691\n",
      "L7N1                    -> L8N36 = -0.34194090962409973\n",
      "L7N1                    -> L8N37 = -0.3644898533821106\n",
      "L7N1                    -> L8N38 = -0.31378188729286194\n",
      "L7N1                    -> L8N39 = -0.26402711868286133\n",
      "L7N1                    -> L8N40 = -0.16612276434898376\n",
      "L7N1                    -> L8N41 = -0.07683917135000229\n",
      "L7N1                    -> L8N42 = -0.3715917766094208\n",
      "L7N1                    -> L8N43 = -0.24854625761508942\n",
      "L7N1                    -> L8N44 = -0.08782413601875305\n",
      "L7N1                    -> L8N45 = -0.11728440225124359\n",
      "L7N1                    -> L8N46 = -0.1679544746875763\n",
      "L7N1                    -> L8N47 = -0.28002676367759705\n",
      "L7N1                    -> L8N48 = -0.06360713392496109\n",
      "L7N1                    -> L8N49 = -0.40288156270980835\n",
      "L7N1                    -> L8N50 = -0.09833619743585587\n",
      "L7N1                    -> L8N51 = -0.2041744887828827\n",
      "L7N1                    -> L8N52 = -0.5026439428329468\n",
      "L7N1                    -> L8N53 = -0.24643316864967346\n",
      "L7N1                    -> L8N54 = -0.15928809344768524\n",
      "L7N1                    -> L8N55 = -0.26442620158195496\n",
      "L7N1                    -> L8N56 = -0.21637655794620514\n",
      "L7N1                    -> L8N57 = -0.3826116621494293\n",
      "L7N1                    -> L8N58 = -0.3008567988872528\n",
      "L7N1                    -> L8N59 = -0.11744000017642975\n",
      "L7N1                    -> L8N60 = -0.4448104202747345\n",
      "L7N1                    -> L8N61 = -0.3479706346988678\n",
      "L7N1                    -> L8N62 = -0.2650819420814514\n",
      "L7N1                    -> L8N63 = -0.3409043550491333\n",
      "L7N1                    -> L8N64 = -0.2904420495033264\n",
      "L7N1                    -> L8N65 = -0.29133251309394836\n",
      "L7N1                    -> L8N66 = -0.41735830903053284\n",
      "L7N1                    -> L8N67 = -0.04288264736533165\n",
      "L7N1                    -> L8N68 = -0.3453666865825653\n",
      "L7N1                    -> L8N69 = -0.4498235881328583\n",
      "L7N1                    -> L8N70 = -0.34203821420669556\n",
      "L7N1                    -> L8N71 = -0.11630921065807343\n",
      "L7N1                    -> L8N72 = -0.03275148943066597\n",
      "L7N1                    -> L8N73 = -0.20640796422958374\n",
      "L7N1                    -> L8N74 = -0.2062264084815979\n",
      "L7N1                    -> L8N75 = -0.24897770583629608\n",
      "L7N1                    -> L8N76 = -0.2566879689693451\n",
      "L7N1                    -> L8N77 = -0.22564949095249176\n",
      "L7N1                    -> L8N78 = -0.3246729075908661\n",
      "L7N1                    -> L8N79 = -0.2766486704349518\n",
      "L7N1                    -> L8N80 = -0.027477167546749115\n",
      "L7N1                    -> L8N81 = -0.20519788563251495\n",
      "L7N1                    -> L8N82 = -0.4132416248321533\n",
      "L7N1                    -> L8N83 = -0.330426961183548\n",
      "L7N1                    -> L8N84 = -0.3938785195350647\n",
      "L7N1                    -> L8N85 = -0.002053379314020276\n",
      "L7N1                    -> L8N86 = -0.11884777247905731\n",
      "L7N1                    -> L8N87 = -0.053242024034261703\n",
      "L7N1                    -> L8N88 = -0.20351925492286682\n",
      "L7N1                    -> L8N89 = -0.1598132997751236\n",
      "L7N1                    -> L8N90 = -0.176725834608078\n",
      "L7N1                    -> L8N91 = -0.3306832015514374\n",
      "L7N1                    -> L8N92 = -0.4426443576812744\n",
      "L7N1                    -> L8N93 = -0.32442617416381836\n",
      "L7N1                    -> L8N94 = -0.12607921659946442\n",
      "L7N1                    -> L8N95 = -0.29069575667381287\n",
      "L7N1                    -> L8N96 = -0.2350732684135437\n",
      "L7N1                    -> L8N97 = -0.08706348389387131\n",
      "L7N1                    -> L8N98 = -0.4637070298194885\n",
      "L7N1                    -> L8N99 = -0.36398178339004517\n",
      "L7N1                    -> L8N100 = -0.30397865176200867\n",
      "L7N1                    -> L8N101 = -0.3422377109527588\n",
      "L7N1                    -> L8N102 = -0.33858200907707214\n",
      "L7N1                    -> L8N103 = -0.0929407998919487\n",
      "L7N1                    -> L8N104 = -0.3513880968093872\n",
      "L7N1                    -> L8N105 = 0.02807575836777687\n",
      "L7N1                    -> L8N106 = 0.0518513098359108\n",
      "L7N1                    -> L8N107 = -0.35765063762664795\n",
      "L7N1                    -> L8N108 = -0.22300194203853607\n",
      "L7N1                    -> L8N109 = 0.013240889646112919\n",
      "L7N1                    -> L8N110 = 0.0032869181595742702\n",
      "L7N1                    -> L8N111 = -0.3695383369922638\n",
      "L7N1                    -> L8N112 = -0.04034951701760292\n",
      "L7N1                    -> L8N113 = -0.24297213554382324\n",
      "L7N1                    -> L8N114 = -0.07575514912605286\n",
      "L7N1                    -> L8N115 = -0.05098402127623558\n",
      "L7N1                    -> L8N116 = -0.3322916030883789\n",
      "L7N1                    -> L8N117 = -0.1915334314107895\n",
      "L7N1                    -> L8N118 = -0.39149239659309387\n",
      "L7N1                    -> L8N119 = -0.2914133071899414\n",
      "L7N1                    -> L8N120 = -0.12806428968906403\n",
      "L7N1                    -> L8N121 = -0.38517481088638306\n",
      "L7N1                    -> L8N122 = -0.3578249514102936\n",
      "L7N1                    -> L8N123 = -0.20494312047958374\n",
      "L7N1                    -> L8N124 = -0.07980512082576752\n",
      "L7N1                    -> L8N125 = -0.3348694145679474\n",
      "L7N1                    -> L8N126 = -0.5011005401611328\n",
      "L7N1                    -> L8N127 = -0.21855762600898743\n",
      "L7N1                    -> L8N128 = -0.03893966227769852\n",
      "L7N1                    -> L8N129 = -0.03423035889863968\n",
      "L7N1                    -> L8N130 = -0.3746982514858246\n",
      "L7N1                    -> L8N131 = -0.35802119970321655\n",
      "L7N1                    -> L8N132 = -0.17388388514518738\n",
      "L7N1                    -> L8N133 = -0.39207813143730164\n",
      "L7N1                    -> L8N134 = -0.31230661273002625\n",
      "L7N1                    -> L8N135 = -0.2751092314720154\n",
      "L7N1                    -> L8N136 = -0.15961067378520966\n",
      "L7N1                    -> L8N137 = -0.08222871273756027\n",
      "L7N1                    -> L8N138 = -0.4894430935382843\n",
      "L7N1                    -> L8N139 = -0.436412513256073\n",
      "L7N1                    -> L8N140 = -0.4727688133716583\n",
      "L7N1                    -> L8N141 = -0.1224244087934494\n",
      "L7N1                    -> L8N142 = -0.01385581400245428\n",
      "L7N1                    -> L8N143 = -0.18286769092082977\n",
      "L7N1                    -> L8N144 = -0.08656544238328934\n",
      "L7N1                    -> L8N145 = -0.04589959233999252\n",
      "L7N1                    -> L8N146 = -0.11402028053998947\n",
      "L7N1                    -> L8N147 = -0.17892172932624817\n",
      "L7N1                    -> L8N148 = -0.5535358786582947\n",
      "L7N1                    -> L8N149 = -0.5391568541526794\n",
      "L7N1                    -> L8N150 = -0.1561880260705948\n",
      "L7N1                    -> L8N151 = -0.26644712686538696\n",
      "L7N1                    -> L8N152 = -0.07250392436981201\n",
      "L7N1                    -> L8N153 = -0.2103622853755951\n",
      "L7N1                    -> L8N154 = -0.3632403612136841\n",
      "L7N1                    -> L8N155 = -0.15565256774425507\n",
      "L7N1                    -> L8N156 = -0.26866841316223145\n",
      "L7N1                    -> L8N157 = -0.06084541976451874\n",
      "L7N1                    -> L8N158 = -0.3850536346435547\n",
      "L7N1                    -> L8N159 = 0.007935091853141785\n",
      "L7N1                    -> L8N160 = -0.30514228343963623\n",
      "L7N1                    -> L8N161 = -0.3451860547065735\n",
      "L7N1                    -> L8N162 = -0.24502156674861908\n",
      "L7N1                    -> L8N163 = -0.08621294796466827\n",
      "L7N1                    -> L8N164 = -0.2924976348876953\n",
      "L7N1                    -> L8N165 = -0.23513451218605042\n",
      "L7N1                    -> L8N166 = -0.09802307188510895\n",
      "L7N1                    -> L8N167 = -0.06912761181592941\n",
      "L7N1                    -> L8N168 = -0.10364314913749695\n",
      "L7N1                    -> L8N169 = -0.4595016539096832\n",
      "L7N1                    -> L8N170 = -0.2165033370256424\n",
      "L7N1                    -> L8N171 = -0.18315564095973969\n",
      "L7N1                    -> L8N172 = -0.31457260251045227\n",
      "L7N1                    -> L8N173 = -0.13963113725185394\n",
      "L7N1                    -> L8N174 = -0.05576040968298912\n",
      "L7N1                    -> L8N175 = -0.2893117666244507\n",
      "L7N1                    -> L8N176 = -0.23769129812717438\n",
      "L7N1                    -> L8N177 = -0.08879262208938599\n",
      "L7N1                    -> L8N178 = -0.33695268630981445\n",
      "L7N1                    -> L8N179 = 0.0746452659368515\n",
      "L7N1                    -> L8N180 = -0.07194069772958755\n",
      "L7N1                    -> L8N181 = -0.363216370344162\n",
      "L7N1                    -> L8N182 = -0.26898321509361267\n",
      "L7N1                    -> L8N183 = -0.06551249325275421\n",
      "L7N1                    -> L8N184 = -0.09027352929115295\n",
      "L7N1                    -> L8N185 = -0.34134146571159363\n",
      "L7N1                    -> L8N186 = -0.12379439920186996\n",
      "L7N1                    -> L8N187 = -0.11975909769535065\n",
      "L7N1                    -> L8N188 = -0.0324488990008831\n",
      "L7N1                    -> L8N189 = -0.17014220356941223\n",
      "L7N1                    -> L8N190 = -0.200306236743927\n",
      "L7N1                    -> L8N191 = -0.13131096959114075\n",
      "L7N1                    -> L8N192 = -0.011240866966545582\n",
      "L7N1                    -> L8N193 = -0.06626808643341064\n",
      "L7N1                    -> L8N194 = -0.13251811265945435\n",
      "L7N1                    -> L8N195 = -0.418952614068985\n",
      "L7N1                    -> L8N196 = -0.3608582019805908\n",
      "L7N1                    -> L8N197 = -0.0017205759650096297\n",
      "L7N1                    -> L8N198 = -0.3425199091434479\n",
      "L7N1                    -> L8N199 = -0.028192216530442238\n",
      "L9N0                    -> L10N0 = [-0.08986937]\n",
      "L9N0                    -> L10N1 = [-0.02864641]\n",
      "L9N0                    -> L10N2 = [0.02987262]\n",
      "L9N0                    -> L10N3 = [0.03107759]\n",
      "L9N0                    -> L10N4 = [0.01601925]\n",
      "L9N0                    -> L10N5 = [0.01028104]\n",
      "L9N0                    -> L10N6 = [0.03167761]\n",
      "L9N0                    -> L10N7 = [-0.02473183]\n",
      "L9N0                    -> L10N8 = [-0.03622937]\n",
      "L9N0                    -> L10N9 = [-0.0078416]\n",
      "L9N0                    -> L10N10 = [-0.02309064]\n",
      "L9N0                    -> L10N11 = [0.01955561]\n",
      "L9N0                    -> L10N12 = [0.02762954]\n",
      "L9N0                    -> L10N13 = [0.04034556]\n",
      "L9N0                    -> L10N14 = [-0.0192114]\n",
      "L9N0                    -> L10N15 = [0.02015968]\n",
      "L9N0                    -> L10N16 = [-0.01538425]\n",
      "L9N0                    -> L10N17 = [0.01565122]\n",
      "L9N0                    -> L10N18 = [0.00170156]\n",
      "L9N0                    -> L10N19 = [-0.01881123]\n",
      "L9N0                    -> L10N20 = [-0.02082674]\n",
      "L9N0                    -> L10N21 = [-0.01293137]\n",
      "L9N0                    -> L10N22 = [0.09021988]\n",
      "L9N0                    -> L10N23 = [0.03439843]\n",
      "L9N0                    -> L10N24 = [0.0313017]\n",
      "L9N0                    -> L10N25 = [-0.01119829]\n",
      "L9N0                    -> L10N26 = [0.01202885]\n",
      "L9N0                    -> L10N27 = [0.00026651]\n",
      "L9N0                    -> L10N28 = [-0.0124132]\n",
      "L9N0                    -> L10N29 = [-0.04729929]\n",
      "L9N0                    -> L10N30 = [0.03294888]\n",
      "L9N0                    -> L10N31 = [-0.03854056]\n",
      "L9N0                    -> L10N32 = [-0.01378798]\n",
      "L9N0                    -> L10N33 = [-0.01676692]\n",
      "L9N0                    -> L10N34 = [-0.02680594]\n",
      "L9N0                    -> L10N35 = [0.03203604]\n",
      "L9N0                    -> L10N36 = [-0.01500421]\n",
      "L9N0                    -> L10N37 = [0.00106284]\n",
      "L9N0                    -> L10N38 = [0.03888559]\n",
      "L9N0                    -> L10N39 = [-0.03033159]\n",
      "L9N0                    -> L10N40 = [0.0058624]\n",
      "L9N0                    -> L10N41 = [-0.0173122]\n",
      "L9N0                    -> L10N42 = [0.03120478]\n",
      "L9N0                    -> L10N43 = [0.10202273]\n",
      "L9N0                    -> L10N44 = [-0.01999153]\n",
      "L9N0                    -> L10N45 = [0.02823049]\n",
      "L9N0                    -> L10N46 = [0.03206142]\n",
      "L9N0                    -> L10N47 = [0.03705015]\n",
      "L9N0                    -> L10N48 = [0.01934115]\n",
      "L9N0                    -> L10N49 = [0.0070718]\n",
      "L9N0                    -> L10N50 = [0.03449836]\n",
      "L9N0                    -> L10N51 = [0.05597175]\n",
      "L9N0                    -> L10N52 = [-0.07655821]\n",
      "L9N0                    -> L10N53 = [-0.01537976]\n",
      "L9N0                    -> L10N54 = [0.02275984]\n",
      "L9N0                    -> L10N55 = [-0.05318803]\n",
      "L9N0                    -> L10N56 = [-0.03059914]\n",
      "L9N0                    -> L10N57 = [0.04485763]\n",
      "L9N0                    -> L10N58 = [0.06805738]\n",
      "L9N0                    -> L10N59 = [0.0195341]\n",
      "L9N0                    -> L10N60 = [-0.00119023]\n",
      "L9N0                    -> L10N61 = [0.00042154]\n",
      "L9N0                    -> L10N62 = [0.03124695]\n",
      "L9N0                    -> L10N63 = [0.00085871]\n",
      "L9N0                    -> L10N64 = [0.0603343]\n",
      "L9N0                    -> L10N65 = [-0.04383573]\n",
      "L9N0                    -> L10N66 = [-0.01481745]\n",
      "L9N0                    -> L10N67 = [0.02329347]\n",
      "L9N0                    -> L10N68 = [-0.02439044]\n",
      "L9N0                    -> L10N69 = [-0.06228171]\n",
      "L9N0                    -> L10N70 = [0.0102554]\n",
      "L9N0                    -> L10N71 = [0.06357045]\n",
      "L9N0                    -> L10N72 = [-0.0195866]\n",
      "L9N0                    -> L10N73 = [-0.01461954]\n",
      "L9N0                    -> L10N74 = [-0.02897194]\n",
      "L9N0                    -> L10N75 = [0.04069722]\n",
      "L9N0                    -> L10N76 = [-0.00485408]\n",
      "L9N0                    -> L10N77 = [0.0708928]\n",
      "L9N0                    -> L10N78 = [-0.01705655]\n",
      "L9N0                    -> L10N79 = [0.06525905]\n",
      "L9N0                    -> L10N80 = [-0.02007888]\n",
      "L9N0                    -> L10N81 = [-0.01966667]\n",
      "L9N0                    -> L10N82 = [-0.00620118]\n",
      "L9N0                    -> L10N83 = [0.03832872]\n",
      "L9N0                    -> L10N84 = [-0.0108969]\n",
      "L9N0                    -> L10N85 = [-0.02512928]\n",
      "L9N0                    -> L10N86 = [-0.01964692]\n",
      "L9N0                    -> L10N87 = [-0.0168666]\n",
      "L9N0                    -> L10N88 = [0.05656636]\n",
      "L9N0                    -> L10N89 = [0.05073066]\n",
      "L9N0                    -> L10N90 = [0.04426233]\n",
      "L9N0                    -> L10N91 = [0.00316654]\n",
      "L9N0                    -> L10N92 = [-0.06629691]\n",
      "L9N0                    -> L10N93 = [0.03449732]\n",
      "L9N0                    -> L10N94 = [0.01545712]\n",
      "L9N0                    -> L10N95 = [-0.00866084]\n",
      "L9N0                    -> L10N96 = [-0.05985299]\n",
      "L9N0                    -> L10N97 = [0.03682916]\n",
      "L9N0                    -> L10N98 = [-0.01893491]\n",
      "L9N0                    -> L10N99 = [-0.00795263]\n",
      "L9N0                    -> L10N100 = [-0.00957404]\n",
      "L9N0                    -> L10N101 = [0.0042116]\n",
      "L9N0                    -> L10N102 = [-0.05746616]\n",
      "L9N0                    -> L10N103 = [-0.03020927]\n",
      "L9N0                    -> L10N104 = [-0.02167324]\n",
      "L9N0                    -> L10N105 = [0.01481954]\n",
      "L9N0                    -> L10N106 = [0.01713927]\n",
      "L9N0                    -> L10N107 = [-0.03982173]\n",
      "L9N0                    -> L10N108 = [0.06538324]\n",
      "L9N0                    -> L10N109 = [0.03025817]\n",
      "L9N0                    -> L10N110 = [0.02355472]\n",
      "L9N0                    -> L10N111 = [-0.08611756]\n",
      "L9N0                    -> L10N112 = [0.01619243]\n",
      "L9N0                    -> L10N113 = [0.01902076]\n",
      "L9N0                    -> L10N114 = [0.02203435]\n",
      "L9N0                    -> L10N115 = [0.01869454]\n",
      "L9N0                    -> L10N116 = [0.01304981]\n",
      "L9N0                    -> L10N117 = [0.04819703]\n",
      "L9N0                    -> L10N118 = [0.00653043]\n",
      "L9N0                    -> L10N119 = [0.07514623]\n",
      "L9N0                    -> L10N120 = [0.06501378]\n",
      "L9N0                    -> L10N121 = [0.0068723]\n",
      "L9N0                    -> L10N122 = [0.01216432]\n",
      "L9N0                    -> L10N123 = [0.05488209]\n",
      "L9N0                    -> L10N124 = [-0.01775238]\n",
      "L9N0                    -> L10N125 = [0.00231316]\n",
      "L9N0                    -> L10N126 = [0.06490336]\n",
      "L9N0                    -> L10N127 = [0.02477456]\n",
      "L9N0                    -> L10N128 = [0.03618792]\n",
      "L9N0                    -> L10N129 = [-0.01961364]\n",
      "L9N0                    -> L10N130 = [-0.00312849]\n",
      "L9N0                    -> L10N131 = [0.00131982]\n",
      "L9N0                    -> L10N132 = [-0.02726563]\n",
      "L9N0                    -> L10N133 = [-0.01545885]\n",
      "L9N0                    -> L10N134 = [0.00235901]\n",
      "L9N0                    -> L10N135 = [-0.11160649]\n",
      "L9N0                    -> L10N136 = [-0.01580354]\n",
      "L9N0                    -> L10N137 = [0.02130466]\n",
      "L9N0                    -> L10N138 = [-0.0226449]\n",
      "L9N0                    -> L10N139 = [0.02160327]\n",
      "L9N0                    -> L10N140 = [-0.00055342]\n",
      "L9N0                    -> L10N141 = [0.01380365]\n",
      "L9N0                    -> L10N142 = [0.01539541]\n",
      "L9N0                    -> L10N143 = [0.0333542]\n",
      "L9N0                    -> L10N144 = [-0.01539457]\n",
      "L9N0                    -> L10N145 = [0.02399177]\n",
      "L9N0                    -> L10N146 = [0.02433161]\n",
      "L9N0                    -> L10N147 = [0.05289801]\n",
      "L9N0                    -> L10N148 = [-0.00039138]\n",
      "L9N0                    -> L10N149 = [-0.05131436]\n",
      "L9N0                    -> L10N150 = [0.02386025]\n",
      "L9N0                    -> L10N151 = [0.01764839]\n",
      "L9N0                    -> L10N152 = [0.01008529]\n",
      "L9N0                    -> L10N153 = [0.00289242]\n",
      "L9N0                    -> L10N154 = [-0.02877486]\n",
      "L9N0                    -> L10N155 = [0.01986545]\n",
      "L9N0                    -> L10N156 = [-0.01472467]\n",
      "L9N0                    -> L10N157 = [0.0207974]\n",
      "L9N0                    -> L10N158 = [0.04362475]\n",
      "L9N0                    -> L10N159 = [0.01759663]\n",
      "L9N0                    -> L10N160 = [-0.00224679]\n",
      "L9N0                    -> L10N161 = [0.02223873]\n",
      "L9N0                    -> L10N162 = [0.0249678]\n",
      "L9N0                    -> L10N163 = [0.04452528]\n",
      "L9N0                    -> L10N164 = [-0.00426685]\n",
      "L9N0                    -> L10N165 = [-0.02761367]\n",
      "L9N0                    -> L10N166 = [0.04399759]\n",
      "L9N0                    -> L10N167 = [-0.01241297]\n",
      "L9N0                    -> L10N168 = [-0.01606634]\n",
      "L9N0                    -> L10N169 = [-0.00035221]\n",
      "L9N0                    -> L10N170 = [-0.01823903]\n",
      "L9N0                    -> L10N171 = [0.02811595]\n",
      "L9N0                    -> L10N172 = [0.01626048]\n",
      "L9N0                    -> L10N173 = [-0.02220559]\n",
      "L9N0                    -> L10N174 = [0.01975738]\n",
      "L9N0                    -> L10N175 = [-0.06668968]\n",
      "L9N0                    -> L10N176 = [-0.04184246]\n",
      "L9N0                    -> L10N177 = [-0.02338508]\n",
      "L9N0                    -> L10N178 = [0.01553108]\n",
      "L9N0                    -> L10N179 = [0.01909357]\n",
      "L9N0                    -> L10N180 = [0.01892895]\n",
      "L9N0                    -> L10N181 = [0.03269062]\n",
      "L9N0                    -> L10N182 = [0.06858771]\n",
      "L9N0                    -> L10N183 = [-0.01952728]\n",
      "L9N0                    -> L10N184 = [0.03414237]\n",
      "L9N0                    -> L10N185 = [0.00315331]\n",
      "L9N0                    -> L10N186 = [0.02119444]\n",
      "L9N0                    -> L10N187 = [-0.02597203]\n",
      "L9N0                    -> L10N188 = [0.02576302]\n",
      "L9N0                    -> L10N189 = [-0.03235881]\n",
      "L9N0                    -> L10N190 = [0.03634986]\n",
      "L9N0                    -> L10N191 = [0.01723361]\n",
      "L9N0                    -> L10N192 = [-0.0233425]\n",
      "L9N0                    -> L10N193 = [-0.02042398]\n",
      "L9N0                    -> L10N194 = [-0.01732292]\n",
      "L9N0                    -> L10N195 = [-0.05428082]\n",
      "L9N0                    -> L10N196 = [-0.00824254]\n",
      "L9N0                    -> L10N197 = [0.02080644]\n",
      "L9N0                    -> L10N198 = [0.02052682]\n",
      "L9N0                    -> L10N199 = [-0.01600039]\n",
      "L9N1                    -> L10N0 = -0.045716844499111176\n"
     ]
    }
   ],
   "source": [
    "for layerNum, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()\n",
    "#     biases = layer.get_weights()[1]\n",
    "    \n",
    "#     for toNeuronNum, bias in enumerate(biases):\n",
    "#         print(f'{layerNum}B -> L{layerNum+1}N{toNeuronNum}: {bias}')\n",
    "    \n",
    "    for fromNeuronNum, wgt in enumerate(weights):\n",
    "        for toNeuronNum, wgt2 in enumerate(wgt):\n",
    "             print(f'L{layerNum}N{fromNeuronNum} \\\n",
    "                   -> L{layerNum+1}N{toNeuronNum} = {wgt2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Cross Val 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_11\\\\'\n",
    "num = '11'\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 12:18 - loss: 1.0155 - accuracy: 0.5078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.7164s). Check your callbacks.\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9971 - accuracy: 0.5050\n",
      "Epoch 00001: val_loss improved from inf to 0.98025, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9971 - accuracy: 0.5049 - val_loss: 0.9803 - val_accuracy: 0.5368\n",
      "Epoch 2/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9886 - accuracy: 0.5194\n",
      "Epoch 00002: val_loss improved from 0.98025 to 0.96107, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9884 - accuracy: 0.5196 - val_loss: 0.9611 - val_accuracy: 0.5469\n",
      "Epoch 3/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.5354\n",
      "Epoch 00003: val_loss improved from 0.96107 to 0.94803, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9732 - accuracy: 0.5354 - val_loss: 0.9480 - val_accuracy: 0.5548\n",
      "Epoch 4/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9587 - accuracy: 0.5458\n",
      "Epoch 00004: val_loss improved from 0.94803 to 0.94423, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9587 - accuracy: 0.5458 - val_loss: 0.9442 - val_accuracy: 0.5562\n",
      "Epoch 5/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9506 - accuracy: 0.5518\n",
      "Epoch 00005: val_loss improved from 0.94423 to 0.94149, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 13s 6ms/step - loss: 0.9506 - accuracy: 0.5518 - val_loss: 0.9415 - val_accuracy: 0.5591\n",
      "Epoch 6/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9481 - accuracy: 0.5525\n",
      "Epoch 00006: val_loss improved from 0.94149 to 0.94103, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9482 - accuracy: 0.5525 - val_loss: 0.9410 - val_accuracy: 0.5595\n",
      "Epoch 7/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9433 - accuracy: 0.5575\n",
      "Epoch 00007: val_loss improved from 0.94103 to 0.93896, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9433 - accuracy: 0.5575 - val_loss: 0.9390 - val_accuracy: 0.5614\n",
      "Epoch 8/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9409 - accuracy: 0.5599\n",
      "Epoch 00008: val_loss did not improve from 0.93896\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9406 - accuracy: 0.5601 - val_loss: 0.9391 - val_accuracy: 0.5611\n",
      "Epoch 9/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9403 - accuracy: 0.5604\n",
      "Epoch 00009: val_loss improved from 0.93896 to 0.93464, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9403 - accuracy: 0.5604 - val_loss: 0.9346 - val_accuracy: 0.5655\n",
      "Epoch 10/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9380 - accuracy: 0.5625\n",
      "Epoch 00010: val_loss did not improve from 0.93464\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9380 - accuracy: 0.5625 - val_loss: 0.9353 - val_accuracy: 0.5653\n",
      "Epoch 11/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9383 - accuracy: 0.5620\n",
      "Epoch 00011: val_loss did not improve from 0.93464\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9382 - accuracy: 0.5620 - val_loss: 0.9354 - val_accuracy: 0.5650\n",
      "Epoch 12/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.5633\n",
      "Epoch 00012: val_loss improved from 0.93464 to 0.93350, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9368 - accuracy: 0.5633 - val_loss: 0.9335 - val_accuracy: 0.5668\n",
      "Epoch 13/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9366 - accuracy: 0.5638\n",
      "Epoch 00013: val_loss did not improve from 0.93350\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9366 - accuracy: 0.5638 - val_loss: 0.9367 - val_accuracy: 0.5636\n",
      "Epoch 14/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5631\n",
      "Epoch 00014: val_loss improved from 0.93350 to 0.93319, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9368 - accuracy: 0.5631 - val_loss: 0.9332 - val_accuracy: 0.5674\n",
      "Epoch 15/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9359 - accuracy: 0.5641\n",
      "Epoch 00015: val_loss did not improve from 0.93319\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9360 - accuracy: 0.5640 - val_loss: 0.9336 - val_accuracy: 0.5666\n",
      "Epoch 16/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9373 - accuracy: 0.5629\n",
      "Epoch 00016: val_loss did not improve from 0.93319\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9373 - accuracy: 0.5628 - val_loss: 0.9356 - val_accuracy: 0.5646\n",
      "Epoch 17/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9344 - accuracy: 0.5656\n",
      "Epoch 00017: val_loss improved from 0.93319 to 0.93224, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9344 - accuracy: 0.5656 - val_loss: 0.9322 - val_accuracy: 0.5679\n",
      "Epoch 18/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9352 - accuracy: 0.5649\n",
      "Epoch 00018: val_loss did not improve from 0.93224\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9351 - accuracy: 0.5649 - val_loss: 0.9323 - val_accuracy: 0.5680\n",
      "Epoch 19/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9358 - accuracy: 0.5642\n",
      "Epoch 00019: val_loss improved from 0.93224 to 0.93151, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9358 - accuracy: 0.5642 - val_loss: 0.9315 - val_accuracy: 0.5689\n",
      "Epoch 20/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9366 - accuracy: 0.5634\n",
      "Epoch 00020: val_loss did not improve from 0.93151\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9366 - accuracy: 0.5634 - val_loss: 0.9351 - val_accuracy: 0.5650\n",
      "Epoch 21/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.5641\n",
      "Epoch 00021: val_loss improved from 0.93151 to 0.93112, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9362 - accuracy: 0.5641 - val_loss: 0.9311 - val_accuracy: 0.5690\n",
      "Epoch 22/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9375 - accuracy: 0.5625\n",
      "Epoch 00022: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9375 - accuracy: 0.5625 - val_loss: 0.9311 - val_accuracy: 0.5693\n",
      "Epoch 23/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9350 - accuracy: 0.5652\n",
      "Epoch 00023: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9349 - accuracy: 0.5652 - val_loss: 0.9406 - val_accuracy: 0.5599\n",
      "Epoch 24/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9357 - accuracy: 0.5644\n",
      "Epoch 00024: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9357 - accuracy: 0.5644 - val_loss: 0.9328 - val_accuracy: 0.5678\n",
      "Epoch 25/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5631\n",
      "Epoch 00025: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9367 - accuracy: 0.5632 - val_loss: 0.9320 - val_accuracy: 0.5681\n",
      "Epoch 26/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5648\n",
      "Epoch 00026: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9350 - accuracy: 0.5649 - val_loss: 0.9335 - val_accuracy: 0.5668\n",
      "Epoch 27/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9358 - accuracy: 0.5643\n",
      "Epoch 00027: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9357 - accuracy: 0.5643 - val_loss: 0.9338 - val_accuracy: 0.5664\n",
      "Epoch 28/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.5667\n",
      "Epoch 00028: val_loss did not improve from 0.93112\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9331 - accuracy: 0.5667 - val_loss: 0.9315 - val_accuracy: 0.5688\n",
      "Epoch 29/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9340 - accuracy: 0.5660\n",
      "Epoch 00029: val_loss improved from 0.93112 to 0.92951, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9340 - accuracy: 0.5660 - val_loss: 0.9295 - val_accuracy: 0.5707\n",
      "Epoch 30/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.5677\n",
      "Epoch 00030: val_loss did not improve from 0.92951\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9325 - accuracy: 0.5676 - val_loss: 0.9357 - val_accuracy: 0.5647\n",
      "Epoch 31/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9340 - accuracy: 0.5659\n",
      "Epoch 00031: val_loss improved from 0.92951 to 0.92812, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9340 - accuracy: 0.5659 - val_loss: 0.9281 - val_accuracy: 0.5721\n",
      "Epoch 32/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.5670\n",
      "Epoch 00032: val_loss improved from 0.92812 to 0.92626, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.1_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9329 - accuracy: 0.5670 - val_loss: 0.9263 - val_accuracy: 0.5739\n",
      "Epoch 33/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9327 - accuracy: 0.5674 ETA: 0s - loss: 0\n",
      "Epoch 00033: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9326 - accuracy: 0.5675 - val_loss: 0.9268 - val_accuracy: 0.5737\n",
      "Epoch 34/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9310 - accuracy: 0.5690 ETA: 0s - loss: 0.9313 \n",
      "Epoch 00034: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9310 - accuracy: 0.5690 - val_loss: 0.9282 - val_accuracy: 0.5720\n",
      "Epoch 35/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9316 - accuracy: 0.5684\n",
      "Epoch 00035: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9315 - accuracy: 0.5684 - val_loss: 0.9316 - val_accuracy: 0.5688\n",
      "Epoch 36/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9320 - accuracy: 0.5680 ETA: 0s - loss: 0.9320 \n",
      "Epoch 00036: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9319 - accuracy: 0.5680 - val_loss: 0.9289 - val_accuracy: 0.5715\n",
      "Epoch 37/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.5693\n",
      "Epoch 00037: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9307 - accuracy: 0.5692 - val_loss: 0.9288 - val_accuracy: 0.5716\n",
      "Epoch 38/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.5699\n",
      "Epoch 00038: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9301 - accuracy: 0.5699 - val_loss: 0.9298 - val_accuracy: 0.5705\n",
      "Epoch 39/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9296 - accuracy: 0.5704\n",
      "Epoch 00039: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9296 - accuracy: 0.5704 - val_loss: 0.9271 - val_accuracy: 0.5734\n",
      "Epoch 40/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9304 - accuracy: 0.5696\n",
      "Epoch 00040: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9304 - accuracy: 0.5696 - val_loss: 0.9288 - val_accuracy: 0.5716\n",
      "Epoch 41/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9298 - accuracy: 0.5701\n",
      "Epoch 00041: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9298 - accuracy: 0.5702 - val_loss: 0.9287 - val_accuracy: 0.5717\n",
      "Epoch 42/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9285 - accuracy: 0.5716\n",
      "Epoch 00042: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9284 - accuracy: 0.5716 - val_loss: 0.9285 - val_accuracy: 0.5719\n",
      "Epoch 43/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9300 - accuracy: 0.5702\n",
      "Epoch 00043: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9300 - accuracy: 0.5702 - val_loss: 0.9310 - val_accuracy: 0.5691\n",
      "Epoch 44/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9294 - accuracy: 0.5705\n",
      "Epoch 00044: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9293 - accuracy: 0.5706 - val_loss: 0.9304 - val_accuracy: 0.5696\n",
      "Epoch 45/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9292 - accuracy: 0.5708\n",
      "Epoch 00045: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9292 - accuracy: 0.5708 - val_loss: 0.9293 - val_accuracy: 0.5712\n",
      "Epoch 46/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9288 - accuracy: 0.5712\n",
      "Epoch 00046: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9288 - accuracy: 0.5712 - val_loss: 0.9294 - val_accuracy: 0.5709\n",
      "Epoch 47/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.5717\n",
      "Epoch 00047: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9282 - accuracy: 0.5717 - val_loss: 0.9279 - val_accuracy: 0.5721\n",
      "Epoch 48/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9281 - accuracy: 0.5717\n",
      "Epoch 00048: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9282 - accuracy: 0.5716 - val_loss: 0.9278 - val_accuracy: 0.5724\n",
      "Epoch 49/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9273 - accuracy: 0.5726\n",
      "Epoch 00049: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9271 - accuracy: 0.5727 - val_loss: 0.9284 - val_accuracy: 0.5718\n",
      "Epoch 50/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9283 - accuracy: 0.5715\n",
      "Epoch 00050: val_loss did not improve from 0.92626\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9283 - accuracy: 0.5715 - val_loss: 0.9282 - val_accuracy: 0.5720\n",
      "accuracy: 57.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 31:04 - loss: 1.0288 - accuracy: 0.4570WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0109s vs `on_train_batch_end` time: 1.8339s). Check your callbacks.\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9980 - accuracy: 0.5044\n",
      "Epoch 00001: val_loss improved from inf to 0.98176, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9979 - accuracy: 0.5045 - val_loss: 0.9818 - val_accuracy: 0.5426\n",
      "Epoch 2/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9867 - accuracy: 0.5245\n",
      "Epoch 00002: val_loss improved from 0.98176 to 0.95903, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9867 - accuracy: 0.5245 - val_loss: 0.9590 - val_accuracy: 0.5479\n",
      "Epoch 3/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9716 - accuracy: 0.5359\n",
      "Epoch 00003: val_loss improved from 0.95903 to 0.94873, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 12s 6ms/step - loss: 0.9716 - accuracy: 0.5359 - val_loss: 0.9487 - val_accuracy: 0.5533\n",
      "Epoch 4/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9595 - accuracy: 0.5446\n",
      "Epoch 00004: val_loss improved from 0.94873 to 0.94448, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9596 - accuracy: 0.5445 - val_loss: 0.9445 - val_accuracy: 0.5565\n",
      "Epoch 5/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9530 - accuracy: 0.5490\n",
      "Epoch 00005: val_loss did not improve from 0.94448\n",
      "2013/2013 [==============================] - 15s 7ms/step - loss: 0.9531 - accuracy: 0.5490 - val_loss: 0.9445 - val_accuracy: 0.5554\n",
      "Epoch 6/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9490 - accuracy: 0.5523\n",
      "Epoch 00006: val_loss improved from 0.94448 to 0.93986, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 13s 7ms/step - loss: 0.9490 - accuracy: 0.5523 - val_loss: 0.9399 - val_accuracy: 0.5607\n",
      "Epoch 7/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9475 - accuracy: 0.5532\n",
      "Epoch 00007: val_loss improved from 0.93986 to 0.93732, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9475 - accuracy: 0.5533 - val_loss: 0.9373 - val_accuracy: 0.5634\n",
      "Epoch 8/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9439 - accuracy: 0.5569\n",
      "Epoch 00008: val_loss improved from 0.93732 to 0.93632, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9437 - accuracy: 0.5570 - val_loss: 0.9363 - val_accuracy: 0.5643\n",
      "Epoch 9/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9417 - accuracy: 0.5586\n",
      "Epoch 00009: val_loss improved from 0.93632 to 0.93493, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9418 - accuracy: 0.5586 - val_loss: 0.9349 - val_accuracy: 0.5657\n",
      "Epoch 10/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9400 - accuracy: 0.5604\n",
      "Epoch 00010: val_loss improved from 0.93493 to 0.93416, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9400 - accuracy: 0.5604 - val_loss: 0.9342 - val_accuracy: 0.5661\n",
      "Epoch 11/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9399 - accuracy: 0.5603\n",
      "Epoch 00011: val_loss improved from 0.93416 to 0.93155, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9399 - accuracy: 0.5604 - val_loss: 0.9315 - val_accuracy: 0.5691\n",
      "Epoch 12/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9373 - accuracy: 0.5630\n",
      "Epoch 00012: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9373 - accuracy: 0.5630 - val_loss: 0.9334 - val_accuracy: 0.5667\n",
      "Epoch 13/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9370 - accuracy: 0.5630\n",
      "Epoch 00013: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9370 - accuracy: 0.5630 - val_loss: 0.9352 - val_accuracy: 0.5650\n",
      "Epoch 14/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9356 - accuracy: 0.5645\n",
      "Epoch 00014: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 11s 5ms/step - loss: 0.9356 - accuracy: 0.5645 - val_loss: 0.9363 - val_accuracy: 0.5642\n",
      "Epoch 15/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9375 - accuracy: 0.5627\n",
      "Epoch 00015: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9376 - accuracy: 0.5626 - val_loss: 0.9357 - val_accuracy: 0.5645\n",
      "Epoch 16/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9364 - accuracy: 0.5639\n",
      "Epoch 00016: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9363 - accuracy: 0.5639 - val_loss: 0.9319 - val_accuracy: 0.5681\n",
      "Epoch 17/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9357 - accuracy: 0.5645\n",
      "Epoch 00017: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9357 - accuracy: 0.5645 - val_loss: 0.9340 - val_accuracy: 0.5665\n",
      "Epoch 18/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9367 - accuracy: 0.5632\n",
      "Epoch 00018: val_loss did not improve from 0.93155\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9367 - accuracy: 0.5632 - val_loss: 0.9319 - val_accuracy: 0.5685\n",
      "Epoch 19/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.5647\n",
      "Epoch 00019: val_loss improved from 0.93155 to 0.93056, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9354 - accuracy: 0.5647 - val_loss: 0.9306 - val_accuracy: 0.5697\n",
      "Epoch 20/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9349 - accuracy: 0.5652\n",
      "Epoch 00020: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9350 - accuracy: 0.5652 - val_loss: 0.9335 - val_accuracy: 0.5668\n",
      "Epoch 21/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5650\n",
      "Epoch 00021: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9350 - accuracy: 0.5650 - val_loss: 0.9332 - val_accuracy: 0.5672\n",
      "Epoch 22/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9356 - accuracy: 0.5644\n",
      "Epoch 00022: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9356 - accuracy: 0.5644 - val_loss: 0.9351 - val_accuracy: 0.5654\n",
      "Epoch 23/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9366 - accuracy: 0.5636\n",
      "Epoch 00023: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9366 - accuracy: 0.5637 - val_loss: 0.9369 - val_accuracy: 0.5636\n",
      "Epoch 24/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9366 - accuracy: 0.5634\n",
      "Epoch 00024: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9367 - accuracy: 0.5635 - val_loss: 0.9334 - val_accuracy: 0.5670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9367 - accuracy: 0.5636\n",
      "Epoch 00025: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9366 - accuracy: 0.5636 - val_loss: 0.9386 - val_accuracy: 0.5620\n",
      "Epoch 26/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9360 - accuracy: 0.5639\n",
      "Epoch 00026: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9359 - accuracy: 0.5641 - val_loss: 0.9335 - val_accuracy: 0.5671\n",
      "Epoch 27/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.5660\n",
      "Epoch 00027: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9339 - accuracy: 0.5660 - val_loss: 0.9327 - val_accuracy: 0.5679\n",
      "Epoch 28/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9335 - accuracy: 0.5666\n",
      "Epoch 00028: val_loss did not improve from 0.93056\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9335 - accuracy: 0.5666 - val_loss: 0.9350 - val_accuracy: 0.5655\n",
      "Epoch 29/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9347 - accuracy: 0.5656\n",
      "Epoch 00029: val_loss improved from 0.93056 to 0.93046, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9346 - accuracy: 0.5656 - val_loss: 0.9305 - val_accuracy: 0.5702\n",
      "Epoch 30/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.5662\n",
      "Epoch 00030: val_loss did not improve from 0.93046\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9339 - accuracy: 0.5662 - val_loss: 0.9350 - val_accuracy: 0.5655\n",
      "Epoch 31/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.5672\n",
      "Epoch 00031: val_loss did not improve from 0.93046\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9330 - accuracy: 0.5672 - val_loss: 0.9322 - val_accuracy: 0.5681\n",
      "Epoch 32/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.5659\n",
      "Epoch 00032: val_loss did not improve from 0.93046\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9339 - accuracy: 0.5660 - val_loss: 0.9333 - val_accuracy: 0.5671\n",
      "Epoch 33/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9335 - accuracy: 0.5664\n",
      "Epoch 00033: val_loss did not improve from 0.93046\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9335 - accuracy: 0.5665 - val_loss: 0.9328 - val_accuracy: 0.5677\n",
      "Epoch 34/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.5669\n",
      "Epoch 00034: val_loss did not improve from 0.93046\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9331 - accuracy: 0.5668 - val_loss: 0.9306 - val_accuracy: 0.5697\n",
      "Epoch 35/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9321 - accuracy: 0.5680\n",
      "Epoch 00035: val_loss did not improve from 0.93046\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9319 - accuracy: 0.5680 - val_loss: 0.9324 - val_accuracy: 0.5681\n",
      "Epoch 36/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9314 - accuracy: 0.5687\n",
      "Epoch 00036: val_loss improved from 0.93046 to 0.93040, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9313 - accuracy: 0.5688 - val_loss: 0.9304 - val_accuracy: 0.5699\n",
      "Epoch 37/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5700\n",
      "Epoch 00037: val_loss did not improve from 0.93040\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9301 - accuracy: 0.5700 - val_loss: 0.9305 - val_accuracy: 0.5695\n",
      "Epoch 38/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.5681\n",
      "Epoch 00038: val_loss improved from 0.93040 to 0.92883, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9318 - accuracy: 0.5681 - val_loss: 0.9288 - val_accuracy: 0.5716\n",
      "Epoch 39/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9313 - accuracy: 0.5685\n",
      "Epoch 00039: val_loss did not improve from 0.92883\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9313 - accuracy: 0.5686 - val_loss: 0.9323 - val_accuracy: 0.5677\n",
      "Epoch 40/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9314 - accuracy: 0.5686\n",
      "Epoch 00040: val_loss did not improve from 0.92883\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9314 - accuracy: 0.5687 - val_loss: 0.9308 - val_accuracy: 0.5696\n",
      "Epoch 41/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9298 - accuracy: 0.5701\n",
      "Epoch 00041: val_loss did not improve from 0.92883\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9297 - accuracy: 0.5702 - val_loss: 0.9296 - val_accuracy: 0.5707\n",
      "Epoch 42/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9303 - accuracy: 0.5696\n",
      "Epoch 00042: val_loss did not improve from 0.92883\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9303 - accuracy: 0.5696 - val_loss: 0.9312 - val_accuracy: 0.5690\n",
      "Epoch 43/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9299 - accuracy: 0.5700\n",
      "Epoch 00043: val_loss did not improve from 0.92883\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9299 - accuracy: 0.5700 - val_loss: 0.9289 - val_accuracy: 0.5714\n",
      "Epoch 44/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9283 - accuracy: 0.5717\n",
      "Epoch 00044: val_loss improved from 0.92883 to 0.92827, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9283 - accuracy: 0.5718 - val_loss: 0.9283 - val_accuracy: 0.5720\n",
      "Epoch 45/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9295 - accuracy: 0.5704\n",
      "Epoch 00045: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9295 - accuracy: 0.5704 - val_loss: 0.9289 - val_accuracy: 0.5714\n",
      "Epoch 46/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9292 - accuracy: 0.5709\n",
      "Epoch 00046: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9292 - accuracy: 0.5709 - val_loss: 0.9285 - val_accuracy: 0.5718\n",
      "Epoch 47/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.5718\n",
      "Epoch 00047: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9283 - accuracy: 0.5717 - val_loss: 0.9290 - val_accuracy: 0.5713\n",
      "Epoch 48/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.5710\n",
      "Epoch 00048: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9289 - accuracy: 0.5711 - val_loss: 0.9290 - val_accuracy: 0.5714\n",
      "Epoch 49/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9286 - accuracy: 0.5714\n",
      "Epoch 00049: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9284 - accuracy: 0.5715 - val_loss: 0.9289 - val_accuracy: 0.5715\n",
      "Epoch 50/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9284 - accuracy: 0.5713\n",
      "Epoch 00050: val_loss did not improve from 0.92827\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9284 - accuracy: 0.5713 - val_loss: 0.9288 - val_accuracy: 0.5715\n",
      "accuracy: 57.15%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 29:38 - loss: 1.0155 - accuracy: 0.5117WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0068s vs `on_train_batch_end` time: 1.7618s). Check your callbacks.\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9978 - accuracy: 0.5033\n",
      "Epoch 00001: val_loss improved from inf to 0.98294, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 11s 6ms/step - loss: 0.9978 - accuracy: 0.5033 - val_loss: 0.9829 - val_accuracy: 0.5212\n",
      "Epoch 2/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9857 - accuracy: 0.5221\n",
      "Epoch 00002: val_loss improved from 0.98294 to 0.95866, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9856 - accuracy: 0.5221 - val_loss: 0.9587 - val_accuracy: 0.5460\n",
      "Epoch 3/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9708 - accuracy: 0.5359\n",
      "Epoch 00003: val_loss improved from 0.95866 to 0.94734, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9708 - accuracy: 0.5359 - val_loss: 0.9473 - val_accuracy: 0.5544\n",
      "Epoch 4/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9593 - accuracy: 0.5446\n",
      "Epoch 00004: val_loss improved from 0.94734 to 0.94467, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9593 - accuracy: 0.5445 - val_loss: 0.9447 - val_accuracy: 0.5559\n",
      "Epoch 5/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9531 - accuracy: 0.5494\n",
      "Epoch 00005: val_loss improved from 0.94467 to 0.94242, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9531 - accuracy: 0.5494 - val_loss: 0.9424 - val_accuracy: 0.5584\n",
      "Epoch 6/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9491 - accuracy: 0.5518\n",
      "Epoch 00006: val_loss improved from 0.94242 to 0.93905, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9491 - accuracy: 0.5518 - val_loss: 0.9390 - val_accuracy: 0.5620\n",
      "Epoch 7/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9453 - accuracy: 0.5555\n",
      "Epoch 00007: val_loss improved from 0.93905 to 0.93816, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9453 - accuracy: 0.5556 - val_loss: 0.9382 - val_accuracy: 0.5620\n",
      "Epoch 8/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9425 - accuracy: 0.5582\n",
      "Epoch 00008: val_loss improved from 0.93816 to 0.93653, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9425 - accuracy: 0.5582 - val_loss: 0.9365 - val_accuracy: 0.5639\n",
      "Epoch 9/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9419 - accuracy: 0.5586\n",
      "Epoch 00009: val_loss did not improve from 0.93653\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9419 - accuracy: 0.5586 - val_loss: 0.9382 - val_accuracy: 0.5620\n",
      "Epoch 10/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9402 - accuracy: 0.5606\n",
      "Epoch 00010: val_loss improved from 0.93653 to 0.93536, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9401 - accuracy: 0.5606 - val_loss: 0.9354 - val_accuracy: 0.5651\n",
      "Epoch 11/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9382 - accuracy: 0.5622 ETA: 0s - los\n",
      "Epoch 00011: val_loss improved from 0.93536 to 0.93499, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9382 - accuracy: 0.5622 - val_loss: 0.9350 - val_accuracy: 0.5655\n",
      "Epoch 12/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9386 - accuracy: 0.5615\n",
      "Epoch 00012: val_loss did not improve from 0.93499\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9386 - accuracy: 0.5615 - val_loss: 0.9376 - val_accuracy: 0.5626\n",
      "Epoch 13/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9376 - accuracy: 0.5628\n",
      "Epoch 00013: val_loss did not improve from 0.93499\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9376 - accuracy: 0.5628 - val_loss: 0.9386 - val_accuracy: 0.5618\n",
      "Epoch 14/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9375 - accuracy: 0.5628\n",
      "Epoch 00014: val_loss did not improve from 0.93499\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9375 - accuracy: 0.5628 - val_loss: 0.9385 - val_accuracy: 0.5621\n",
      "Epoch 15/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9383 - accuracy: 0.5618\n",
      "Epoch 00015: val_loss did not improve from 0.93499\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9383 - accuracy: 0.5617 - val_loss: 0.9377 - val_accuracy: 0.5624\n",
      "Epoch 16/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9370 - accuracy: 0.5635\n",
      "Epoch 00016: val_loss did not improve from 0.93499\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9370 - accuracy: 0.5634 - val_loss: 0.9350 - val_accuracy: 0.5653\n",
      "Epoch 17/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9379 - accuracy: 0.5623\n",
      "Epoch 00017: val_loss improved from 0.93499 to 0.93433, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9379 - accuracy: 0.5623 - val_loss: 0.9343 - val_accuracy: 0.5661\n",
      "Epoch 18/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9366 - accuracy: 0.5638\n",
      "Epoch 00018: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9366 - accuracy: 0.5638 - val_loss: 0.9384 - val_accuracy: 0.5619\n",
      "Epoch 19/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9371 - accuracy: 0.5632\n",
      "Epoch 00019: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9371 - accuracy: 0.5632 - val_loss: 0.9388 - val_accuracy: 0.5617\n",
      "Epoch 20/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9381 - accuracy: 0.5618\n",
      "Epoch 00020: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9382 - accuracy: 0.5618 - val_loss: 0.9369 - val_accuracy: 0.5635\n",
      "Epoch 21/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9379 - accuracy: 0.5624\n",
      "Epoch 00021: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9377 - accuracy: 0.5625 - val_loss: 0.9353 - val_accuracy: 0.5652\n",
      "Epoch 22/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9357 - accuracy: 0.5645\n",
      "Epoch 00022: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9357 - accuracy: 0.5645 - val_loss: 0.9352 - val_accuracy: 0.5652\n",
      "Epoch 23/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9353 - accuracy: 0.5649\n",
      "Epoch 00023: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9352 - accuracy: 0.5650 - val_loss: 0.9351 - val_accuracy: 0.5654\n",
      "Epoch 24/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9355 - accuracy: 0.5648\n",
      "Epoch 00024: val_loss did not improve from 0.93433\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9355 - accuracy: 0.5648 - val_loss: 0.9374 - val_accuracy: 0.5631\n",
      "Epoch 25/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9350 - accuracy: 0.5650\n",
      "Epoch 00025: val_loss improved from 0.93433 to 0.93321, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9349 - accuracy: 0.5650 - val_loss: 0.9332 - val_accuracy: 0.5675\n",
      "Epoch 26/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9365 - accuracy: 0.5636\n",
      "Epoch 00026: val_loss improved from 0.93321 to 0.93283, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9364 - accuracy: 0.5637 - val_loss: 0.9328 - val_accuracy: 0.5676\n",
      "Epoch 27/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9344 - accuracy: 0.5657\n",
      "Epoch 00027: val_loss did not improve from 0.93283\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9344 - accuracy: 0.5656 - val_loss: 0.9360 - val_accuracy: 0.5646\n",
      "Epoch 28/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5656\n",
      "Epoch 00028: val_loss did not improve from 0.93283\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9346 - accuracy: 0.5655 - val_loss: 0.9369 - val_accuracy: 0.5635\n",
      "Epoch 29/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9356 - accuracy: 0.5645\n",
      "Epoch 00029: val_loss did not improve from 0.93283\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9356 - accuracy: 0.5645 - val_loss: 0.9343 - val_accuracy: 0.5661\n",
      "Epoch 30/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9364 - accuracy: 0.5637\n",
      "Epoch 00030: val_loss did not improve from 0.93283\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9364 - accuracy: 0.5637 - val_loss: 0.9354 - val_accuracy: 0.5649\n",
      "Epoch 31/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9370 - accuracy: 0.5629\n",
      "Epoch 00031: val_loss did not improve from 0.93283\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9370 - accuracy: 0.5629 - val_loss: 0.9344 - val_accuracy: 0.5661\n",
      "Epoch 32/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.5638\n",
      "Epoch 00032: val_loss did not improve from 0.93283\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9363 - accuracy: 0.5639 - val_loss: 0.9331 - val_accuracy: 0.5672\n",
      "Epoch 33/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9344 - accuracy: 0.5656\n",
      "Epoch 00033: val_loss improved from 0.93283 to 0.93224, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9345 - accuracy: 0.5656 - val_loss: 0.9322 - val_accuracy: 0.5680\n",
      "Epoch 34/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9345 - accuracy: 0.5655\n",
      "Epoch 00034: val_loss did not improve from 0.93224\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9345 - accuracy: 0.5655 - val_loss: 0.9328 - val_accuracy: 0.5675\n",
      "Epoch 35/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.5677\n",
      "Epoch 00035: val_loss improved from 0.93224 to 0.93085, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9324 - accuracy: 0.5676 - val_loss: 0.9308 - val_accuracy: 0.5695\n",
      "Epoch 36/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9327 - accuracy: 0.5672\n",
      "Epoch 00036: val_loss improved from 0.93085 to 0.92999, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9327 - accuracy: 0.5673 - val_loss: 0.9300 - val_accuracy: 0.5705\n",
      "Epoch 37/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9315 - accuracy: 0.5685\n",
      "Epoch 00037: val_loss did not improve from 0.92999\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9315 - accuracy: 0.5685 - val_loss: 0.9307 - val_accuracy: 0.5696\n",
      "Epoch 38/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9307 - accuracy: 0.5690\n",
      "Epoch 00038: val_loss improved from 0.92999 to 0.92977, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9308 - accuracy: 0.5691 - val_loss: 0.9298 - val_accuracy: 0.5709\n",
      "Epoch 39/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9311 - accuracy: 0.5689\n",
      "Epoch 00039: val_loss improved from 0.92977 to 0.92919, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9312 - accuracy: 0.5688 - val_loss: 0.9292 - val_accuracy: 0.5711\n",
      "Epoch 40/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.5681\n",
      "Epoch 00040: val_loss did not improve from 0.92919\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9317 - accuracy: 0.5681 - val_loss: 0.9301 - val_accuracy: 0.5703\n",
      "Epoch 41/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.5682\n",
      "Epoch 00041: val_loss did not improve from 0.92919\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9317 - accuracy: 0.5683 - val_loss: 0.9301 - val_accuracy: 0.5702\n",
      "Epoch 42/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9317 - accuracy: 0.5684\n",
      "Epoch 00042: val_loss improved from 0.92919 to 0.92842, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9318 - accuracy: 0.5683 - val_loss: 0.9284 - val_accuracy: 0.5722\n",
      "Epoch 43/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9311 - accuracy: 0.5688\n",
      "Epoch 00043: val_loss improved from 0.92842 to 0.92821, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9311 - accuracy: 0.5688 - val_loss: 0.9282 - val_accuracy: 0.5720\n",
      "Epoch 44/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9295 - accuracy: 0.5705\n",
      "Epoch 00044: val_loss improved from 0.92821 to 0.92809, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9294 - accuracy: 0.5706 - val_loss: 0.9281 - val_accuracy: 0.5721\n",
      "Epoch 45/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9293 - accuracy: 0.5706\n",
      "Epoch 00045: val_loss did not improve from 0.92809\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9293 - accuracy: 0.5706 - val_loss: 0.9291 - val_accuracy: 0.5715\n",
      "Epoch 46/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9294 - accuracy: 0.5705\n",
      "Epoch 00046: val_loss improved from 0.92809 to 0.92767, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9295 - accuracy: 0.5704 - val_loss: 0.9277 - val_accuracy: 0.5727\n",
      "Epoch 47/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.5709\n",
      "Epoch 00047: val_loss improved from 0.92767 to 0.92757, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_11\\best_try_11.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9291 - accuracy: 0.5709 - val_loss: 0.9276 - val_accuracy: 0.5726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9292 - accuracy: 0.5709\n",
      "Epoch 00048: val_loss did not improve from 0.92757\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9292 - accuracy: 0.5709 - val_loss: 0.9278 - val_accuracy: 0.5725\n",
      "Epoch 49/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.5713\n",
      "Epoch 00049: val_loss did not improve from 0.92757\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9286 - accuracy: 0.5714 - val_loss: 0.9284 - val_accuracy: 0.5717\n",
      "Epoch 50/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9285 - accuracy: 0.5716\n",
      "Epoch 00050: val_loss did not improve from 0.92757\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9285 - accuracy: 0.5716 - val_loss: 0.9282 - val_accuracy: 0.5721\n",
      "accuracy: 57.21%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "57.19% (+/- 0.03%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_train, y_train_0):\n",
    "    # create model\n",
    "    num = float(num)\n",
    "    num = num + 0.1\n",
    "    num = str(num)\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[19]),\n",
    "        keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.experimental.RandomFourierFeatures(output_dim=20, kernel_initializer='gaussian'),\n",
    "        keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='hinge', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    # Callbacks\n",
    "    NAME = \"Survivability-200-150-100-D-BN-He-{0}-{1}\".format(time.time(), num)\n",
    "    tensorboard = TensorBoard(log_dir=\"{0}\\\\logs\\\\{1}\".format(path, NAME))\n",
    "    \n",
    "    onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(path+folder+'best_try_'+num+'_1.h5', monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "    callbacks = [checkpoint, onecycle, tensorboard]\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train_0, epochs=epochs, batch_size=batch_size, \n",
    "                        validation_data=(X_test, y_test_0), callbacks = callbacks)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_test, y_test_0, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    savepickle(path, folder, 'history_'+num+'_1', history)\n",
    "    plotdata(path, folder, 'plot_'+num+'_1', history)\n",
    "    model.save_weights(path+folder+'try_'+num+'_1.h5')\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Cross Val 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_9\\\\'\n",
    "num = '9'\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 29:08 - loss: 1.0451 - accuracy: 0.4453WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 1.7271s). Check your callbacks.\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9950 - accuracy: 0.5079\n",
      "Epoch 00001: val_loss improved from inf to 0.96526, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9949 - accuracy: 0.5079 - val_loss: 0.9653 - val_accuracy: 0.5470\n",
      "Epoch 2/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9786 - accuracy: 0.5308\n",
      "Epoch 00002: val_loss improved from 0.96526 to 0.95159, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9785 - accuracy: 0.5308 - val_loss: 0.9516 - val_accuracy: 0.5535\n",
      "Epoch 3/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9655 - accuracy: 0.5424\n",
      "Epoch 00003: val_loss improved from 0.95159 to 0.94514, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9654 - accuracy: 0.5424 - val_loss: 0.9451 - val_accuracy: 0.5573\n",
      "Epoch 4/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9558 - accuracy: 0.5494\n",
      "Epoch 00004: val_loss improved from 0.94514 to 0.93945, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9559 - accuracy: 0.5494 - val_loss: 0.9394 - val_accuracy: 0.5618\n",
      "Epoch 5/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9471 - accuracy: 0.5563\n",
      "Epoch 00005: val_loss improved from 0.93945 to 0.93868, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9471 - accuracy: 0.5564 - val_loss: 0.9387 - val_accuracy: 0.5622\n",
      "Epoch 6/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9421 - accuracy: 0.5603\n",
      "Epoch 00006: val_loss improved from 0.93868 to 0.93560, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9421 - accuracy: 0.5603 - val_loss: 0.9356 - val_accuracy: 0.5645\n",
      "Epoch 7/50\n",
      "2000/2013 [============================>.] - ETA: 0s - loss: 0.9390 - accuracy: 0.5623\n",
      "Epoch 00007: val_loss improved from 0.93560 to 0.93441, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9391 - accuracy: 0.5623 - val_loss: 0.9344 - val_accuracy: 0.5663\n",
      "Epoch 8/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9379 - accuracy: 0.5633\n",
      "Epoch 00008: val_loss did not improve from 0.93441\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9377 - accuracy: 0.5633 - val_loss: 0.9345 - val_accuracy: 0.5660\n",
      "Epoch 9/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9359 - accuracy: 0.5646\n",
      "Epoch 00009: val_loss improved from 0.93441 to 0.93138, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9359 - accuracy: 0.5646 - val_loss: 0.9314 - val_accuracy: 0.5689\n",
      "Epoch 10/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9349 - accuracy: 0.5653\n",
      "Epoch 00010: val_loss improved from 0.93138 to 0.93122, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9348 - accuracy: 0.5654 - val_loss: 0.9312 - val_accuracy: 0.5693\n",
      "Epoch 11/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9347 - accuracy: 0.5655\n",
      "Epoch 00011: val_loss improved from 0.93122 to 0.93043, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 7s 4ms/step - loss: 0.9348 - accuracy: 0.5655 - val_loss: 0.9304 - val_accuracy: 0.5698\n",
      "Epoch 12/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9343 - accuracy: 0.5659\n",
      "Epoch 00012: val_loss did not improve from 0.93043\n",
      "2013/2013 [==============================] - 7s 4ms/step - loss: 0.9343 - accuracy: 0.5658 - val_loss: 0.9306 - val_accuracy: 0.5699\n",
      "Epoch 13/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5670\n",
      "Epoch 00013: val_loss did not improve from 0.93043\n",
      "2013/2013 [==============================] - 7s 4ms/step - loss: 0.9334 - accuracy: 0.5670 - val_loss: 0.9327 - val_accuracy: 0.5681\n",
      "Epoch 14/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5673\n",
      "Epoch 00014: val_loss did not improve from 0.93043\n",
      "2013/2013 [==============================] - 7s 4ms/step - loss: 0.9333 - accuracy: 0.5673 - val_loss: 0.9309 - val_accuracy: 0.5693\n",
      "Epoch 15/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9327 - accuracy: 0.5676\n",
      "Epoch 00015: val_loss did not improve from 0.93043\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9328 - accuracy: 0.5675 - val_loss: 0.9308 - val_accuracy: 0.5698\n",
      "Epoch 16/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9329 - accuracy: 0.5675\n",
      "Epoch 00016: val_loss improved from 0.93043 to 0.92982, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9328 - accuracy: 0.5674 - val_loss: 0.9298 - val_accuracy: 0.5707\n",
      "Epoch 17/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.5688\n",
      "Epoch 00017: val_loss did not improve from 0.92982\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9317 - accuracy: 0.5688 - val_loss: 0.9305 - val_accuracy: 0.5700\n",
      "Epoch 18/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5669\n",
      "Epoch 00018: val_loss improved from 0.92982 to 0.92955, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9332 - accuracy: 0.5669 - val_loss: 0.9296 - val_accuracy: 0.5710\n",
      "Epoch 19/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.5671 ETA: 0s - los\n",
      "Epoch 00019: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9330 - accuracy: 0.5671 - val_loss: 0.9339 - val_accuracy: 0.5668\n",
      "Epoch 20/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9337 - accuracy: 0.5663\n",
      "Epoch 00020: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9337 - accuracy: 0.5663 - val_loss: 0.9328 - val_accuracy: 0.5674\n",
      "Epoch 21/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9344 - accuracy: 0.5656\n",
      "Epoch 00021: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9343 - accuracy: 0.5656 - val_loss: 0.9336 - val_accuracy: 0.5665\n",
      "Epoch 22/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5667\n",
      "Epoch 00022: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9334 - accuracy: 0.5667 - val_loss: 0.9356 - val_accuracy: 0.5644\n",
      "Epoch 23/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9337 - accuracy: 0.5665\n",
      "Epoch 00023: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9336 - accuracy: 0.5666 - val_loss: 0.9314 - val_accuracy: 0.5690\n",
      "Epoch 24/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9324 - accuracy: 0.5676\n",
      "Epoch 00024: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9325 - accuracy: 0.5675 - val_loss: 0.9306 - val_accuracy: 0.5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9327 - accuracy: 0.5674\n",
      "Epoch 00025: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9326 - accuracy: 0.5675 - val_loss: 0.9310 - val_accuracy: 0.5693\n",
      "Epoch 26/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.5683\n",
      "Epoch 00026: val_loss did not improve from 0.92955\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9317 - accuracy: 0.5684 - val_loss: 0.9307 - val_accuracy: 0.5695\n",
      "Epoch 27/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.5671\n",
      "Epoch 00027: val_loss improved from 0.92955 to 0.92772, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9329 - accuracy: 0.5671 - val_loss: 0.9277 - val_accuracy: 0.5729\n",
      "Epoch 28/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9312 - accuracy: 0.5687\n",
      "Epoch 00028: val_loss did not improve from 0.92772\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9313 - accuracy: 0.5687 - val_loss: 0.9295 - val_accuracy: 0.5709\n",
      "Epoch 29/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9319 - accuracy: 0.5683\n",
      "Epoch 00029: val_loss did not improve from 0.92772\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9319 - accuracy: 0.5682 - val_loss: 0.9290 - val_accuracy: 0.5720\n",
      "Epoch 30/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9326 - accuracy: 0.5676\n",
      "Epoch 00030: val_loss did not improve from 0.92772\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9325 - accuracy: 0.5675 - val_loss: 0.9280 - val_accuracy: 0.5725\n",
      "Epoch 31/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9311 - accuracy: 0.5689\n",
      "Epoch 00031: val_loss did not improve from 0.92772\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9310 - accuracy: 0.5689 - val_loss: 0.9291 - val_accuracy: 0.5710\n",
      "Epoch 32/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.5696\n",
      "Epoch 00032: val_loss improved from 0.92772 to 0.92685, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9306 - accuracy: 0.5696 - val_loss: 0.9268 - val_accuracy: 0.5735\n",
      "Epoch 33/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9294 - accuracy: 0.5705\n",
      "Epoch 00033: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9294 - accuracy: 0.5706 - val_loss: 0.9281 - val_accuracy: 0.5723\n",
      "Epoch 34/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9295 - accuracy: 0.5706\n",
      "Epoch 00034: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9294 - accuracy: 0.5706 - val_loss: 0.9310 - val_accuracy: 0.5693\n",
      "Epoch 35/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9292 - accuracy: 0.5708\n",
      "Epoch 00035: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9292 - accuracy: 0.5708 - val_loss: 0.9283 - val_accuracy: 0.5719\n",
      "Epoch 36/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.5714\n",
      "Epoch 00036: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9287 - accuracy: 0.5714 - val_loss: 0.9278 - val_accuracy: 0.5724\n",
      "Epoch 37/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.5712\n",
      "Epoch 00037: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9290 - accuracy: 0.5711 - val_loss: 0.9281 - val_accuracy: 0.5722\n",
      "Epoch 38/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9296 - accuracy: 0.5704\n",
      "Epoch 00038: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9296 - accuracy: 0.5704 - val_loss: 0.9286 - val_accuracy: 0.5720\n",
      "Epoch 39/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.5711\n",
      "Epoch 00039: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9290 - accuracy: 0.5710 - val_loss: 0.9292 - val_accuracy: 0.5711\n",
      "Epoch 40/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.5719\n",
      "Epoch 00040: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9282 - accuracy: 0.5719 - val_loss: 0.9301 - val_accuracy: 0.5701\n",
      "Epoch 41/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9278 - accuracy: 0.5723\n",
      "Epoch 00041: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9277 - accuracy: 0.5724 - val_loss: 0.9281 - val_accuracy: 0.5723\n",
      "Epoch 42/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9262 - accuracy: 0.5738\n",
      "Epoch 00042: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9263 - accuracy: 0.5736 - val_loss: 0.9272 - val_accuracy: 0.5733\n",
      "Epoch 43/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9275 - accuracy: 0.5725\n",
      "Epoch 00043: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9275 - accuracy: 0.5725 - val_loss: 0.9270 - val_accuracy: 0.5734\n",
      "Epoch 44/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.5726\n",
      "Epoch 00044: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9272 - accuracy: 0.5728 - val_loss: 0.9271 - val_accuracy: 0.5733\n",
      "Epoch 45/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9269 - accuracy: 0.5730\n",
      "Epoch 00045: val_loss did not improve from 0.92685\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9269 - accuracy: 0.5731 - val_loss: 0.9277 - val_accuracy: 0.5727\n",
      "Epoch 46/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9266 - accuracy: 0.5733\n",
      "Epoch 00046: val_loss improved from 0.92685 to 0.92671, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9267 - accuracy: 0.5733 - val_loss: 0.9267 - val_accuracy: 0.5735\n",
      "Epoch 47/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9260 - accuracy: 0.5741\n",
      "Epoch 00047: val_loss improved from 0.92671 to 0.92656, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9261 - accuracy: 0.5740 - val_loss: 0.9266 - val_accuracy: 0.5738\n",
      "Epoch 48/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9264 - accuracy: 0.5734\n",
      "Epoch 00048: val_loss did not improve from 0.92656\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9264 - accuracy: 0.5735 - val_loss: 0.9267 - val_accuracy: 0.5736\n",
      "Epoch 49/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9263 - accuracy: 0.5738\n",
      "Epoch 00049: val_loss improved from 0.92656 to 0.92651, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.1_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9262 - accuracy: 0.5738 - val_loss: 0.9265 - val_accuracy: 0.5738\n",
      "Epoch 50/50\n",
      "1999/2013 [============================>.] - ETA: 0s - loss: 0.9261 - accuracy: 0.5739\n",
      "Epoch 00050: val_loss did not improve from 0.92651\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9261 - accuracy: 0.5738 - val_loss: 0.9266 - val_accuracy: 0.5738\n",
      "accuracy: 57.38%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 27:42 - loss: 1.0208 - accuracy: 0.5430WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0059s vs `on_train_batch_end` time: 1.6474s). Check your callbacks.\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9963 - accuracy: 0.5088\n",
      "Epoch 00001: val_loss improved from inf to 0.97948, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9962 - accuracy: 0.5089 - val_loss: 0.9795 - val_accuracy: 0.5339\n",
      "Epoch 2/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9872 - accuracy: 0.5233\n",
      "Epoch 00002: val_loss improved from 0.97948 to 0.96294, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9870 - accuracy: 0.5234 - val_loss: 0.9629 - val_accuracy: 0.5438\n",
      "Epoch 3/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9738 - accuracy: 0.5368\n",
      "Epoch 00003: val_loss improved from 0.96294 to 0.95187, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9735 - accuracy: 0.5369 - val_loss: 0.9519 - val_accuracy: 0.5520\n",
      "Epoch 4/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9619 - accuracy: 0.5460\n",
      "Epoch 00004: val_loss improved from 0.95187 to 0.94526, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9620 - accuracy: 0.5458 - val_loss: 0.9453 - val_accuracy: 0.5563\n",
      "Epoch 5/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9514 - accuracy: 0.5532\n",
      "Epoch 00005: val_loss improved from 0.94526 to 0.94043, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9514 - accuracy: 0.5533 - val_loss: 0.9404 - val_accuracy: 0.5615\n",
      "Epoch 6/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9461 - accuracy: 0.5574\n",
      "Epoch 00006: val_loss did not improve from 0.94043\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9461 - accuracy: 0.5574 - val_loss: 0.9407 - val_accuracy: 0.5590\n",
      "Epoch 7/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9418 - accuracy: 0.5601\n",
      "Epoch 00007: val_loss improved from 0.94043 to 0.93584, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9418 - accuracy: 0.5602 - val_loss: 0.9358 - val_accuracy: 0.5645\n",
      "Epoch 8/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9411 - accuracy: 0.5604\n",
      "Epoch 00008: val_loss improved from 0.93584 to 0.93537, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9409 - accuracy: 0.5606 - val_loss: 0.9354 - val_accuracy: 0.5649\n",
      "Epoch 9/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9378 - accuracy: 0.5629\n",
      "Epoch 00009: val_loss did not improve from 0.93537\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9379 - accuracy: 0.5629 - val_loss: 0.9361 - val_accuracy: 0.5639\n",
      "Epoch 10/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5636\n",
      "Epoch 00010: val_loss did not improve from 0.93537\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9368 - accuracy: 0.5636 - val_loss: 0.9361 - val_accuracy: 0.5641\n",
      "Epoch 11/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9361 - accuracy: 0.5644\n",
      "Epoch 00011: val_loss improved from 0.93537 to 0.93488, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9361 - accuracy: 0.5644 - val_loss: 0.9349 - val_accuracy: 0.5656\n",
      "Epoch 12/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5655\n",
      "Epoch 00012: val_loss did not improve from 0.93488\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9351 - accuracy: 0.5654 - val_loss: 0.9361 - val_accuracy: 0.5640\n",
      "Epoch 13/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9343 - accuracy: 0.5660\n",
      "Epoch 00013: val_loss improved from 0.93488 to 0.93229, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9343 - accuracy: 0.5660 - val_loss: 0.9323 - val_accuracy: 0.5682\n",
      "Epoch 14/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9342 - accuracy: 0.5662\n",
      "Epoch 00014: val_loss did not improve from 0.93229\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9342 - accuracy: 0.5662 - val_loss: 0.9350 - val_accuracy: 0.5657\n",
      "Epoch 15/50\n",
      "2000/2013 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5658\n",
      "Epoch 00015: val_loss improved from 0.93229 to 0.93169, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9345 - accuracy: 0.5660 - val_loss: 0.9317 - val_accuracy: 0.5686\n",
      "Epoch 16/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9323 - accuracy: 0.5677\n",
      "Epoch 00016: val_loss did not improve from 0.93169\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9323 - accuracy: 0.5677 - val_loss: 0.9329 - val_accuracy: 0.5679\n",
      "Epoch 17/50\n",
      "2000/2013 [============================>.] - ETA: 0s - loss: 0.9333 - accuracy: 0.5671\n",
      "Epoch 00017: val_loss did not improve from 0.93169\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9331 - accuracy: 0.5672 - val_loss: 0.9338 - val_accuracy: 0.5667\n",
      "Epoch 18/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9338 - accuracy: 0.5665\n",
      "Epoch 00018: val_loss did not improve from 0.93169\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9338 - accuracy: 0.5664 - val_loss: 0.9334 - val_accuracy: 0.5669\n",
      "Epoch 19/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9352 - accuracy: 0.5650\n",
      "Epoch 00019: val_loss did not improve from 0.93169\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9352 - accuracy: 0.5650 - val_loss: 0.9340 - val_accuracy: 0.5662\n",
      "Epoch 20/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9344 - accuracy: 0.5657\n",
      "Epoch 00020: val_loss did not improve from 0.93169\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9344 - accuracy: 0.5657 - val_loss: 0.9355 - val_accuracy: 0.5649\n",
      "Epoch 21/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9336 - accuracy: 0.5665\n",
      "Epoch 00021: val_loss did not improve from 0.93169\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9336 - accuracy: 0.5666 - val_loss: 0.9324 - val_accuracy: 0.5680\n",
      "Epoch 22/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9328 - accuracy: 0.5672\n",
      "Epoch 00022: val_loss improved from 0.93169 to 0.92954, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9327 - accuracy: 0.5673 - val_loss: 0.9295 - val_accuracy: 0.5712\n",
      "Epoch 23/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9326 - accuracy: 0.5676\n",
      "Epoch 00023: val_loss did not improve from 0.92954\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9326 - accuracy: 0.5676 - val_loss: 0.9328 - val_accuracy: 0.5675\n",
      "Epoch 24/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.5669\n",
      "Epoch 00024: val_loss did not improve from 0.92954\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9331 - accuracy: 0.5669 - val_loss: 0.9354 - val_accuracy: 0.5648\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5669\n",
      "Epoch 00025: val_loss did not improve from 0.92954\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9332 - accuracy: 0.5669 - val_loss: 0.9318 - val_accuracy: 0.5687\n",
      "Epoch 26/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.5671\n",
      "Epoch 00026: val_loss did not improve from 0.92954\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9330 - accuracy: 0.5671 - val_loss: 0.9321 - val_accuracy: 0.5682\n",
      "Epoch 27/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9317 - accuracy: 0.5685\n",
      "Epoch 00027: val_loss improved from 0.92954 to 0.92944, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9317 - accuracy: 0.5685 - val_loss: 0.9294 - val_accuracy: 0.5710\n",
      "Epoch 28/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9308 - accuracy: 0.5694 ETA: 0s - loss: 0.9308 - accuracy: 0.\n",
      "Epoch 00028: val_loss did not improve from 0.92944\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9308 - accuracy: 0.5694 - val_loss: 0.9304 - val_accuracy: 0.5702\n",
      "Epoch 29/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9320 - accuracy: 0.5682\n",
      "Epoch 00029: val_loss improved from 0.92944 to 0.92923, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9320 - accuracy: 0.5682 - val_loss: 0.9292 - val_accuracy: 0.5713\n",
      "Epoch 30/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9316 - accuracy: 0.5684\n",
      "Epoch 00030: val_loss did not improve from 0.92923\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9316 - accuracy: 0.5684 - val_loss: 0.9320 - val_accuracy: 0.5683\n",
      "Epoch 31/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9313 - accuracy: 0.5688\n",
      "Epoch 00031: val_loss did not improve from 0.92923\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9313 - accuracy: 0.5688 - val_loss: 0.9305 - val_accuracy: 0.5700\n",
      "Epoch 32/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9312 - accuracy: 0.5691\n",
      "Epoch 00032: val_loss improved from 0.92923 to 0.92873, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 9s 5ms/step - loss: 0.9311 - accuracy: 0.5692 - val_loss: 0.9287 - val_accuracy: 0.5720\n",
      "Epoch 33/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9310 - accuracy: 0.5689\n",
      "Epoch 00033: val_loss did not improve from 0.92873\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9310 - accuracy: 0.5691 - val_loss: 0.9291 - val_accuracy: 0.5714\n",
      "Epoch 34/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9291 - accuracy: 0.5708\n",
      "Epoch 00034: val_loss did not improve from 0.92873\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9291 - accuracy: 0.5708 - val_loss: 0.9303 - val_accuracy: 0.5704\n",
      "Epoch 35/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5698\n",
      "Epoch 00035: val_loss did not improve from 0.92873\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9301 - accuracy: 0.5698 - val_loss: 0.9299 - val_accuracy: 0.5702\n",
      "Epoch 36/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9288 - accuracy: 0.5714\n",
      "Epoch 00036: val_loss did not improve from 0.92873\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9287 - accuracy: 0.5714 - val_loss: 0.9325 - val_accuracy: 0.5681\n",
      "Epoch 37/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9293 - accuracy: 0.5709\n",
      "Epoch 00037: val_loss did not improve from 0.92873\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9293 - accuracy: 0.5708 - val_loss: 0.9309 - val_accuracy: 0.5698\n",
      "Epoch 38/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9281 - accuracy: 0.5718\n",
      "Epoch 00038: val_loss did not improve from 0.92873\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9281 - accuracy: 0.5717 - val_loss: 0.9299 - val_accuracy: 0.5702\n",
      "Epoch 39/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.5713\n",
      "Epoch 00039: val_loss improved from 0.92873 to 0.92770, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9287 - accuracy: 0.5712 - val_loss: 0.9277 - val_accuracy: 0.5726\n",
      "Epoch 40/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9271 - accuracy: 0.5728\n",
      "Epoch 00040: val_loss did not improve from 0.92770\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9271 - accuracy: 0.5728 - val_loss: 0.9285 - val_accuracy: 0.5718\n",
      "Epoch 41/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9273 - accuracy: 0.5726\n",
      "Epoch 00041: val_loss did not improve from 0.92770\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9272 - accuracy: 0.5728 - val_loss: 0.9290 - val_accuracy: 0.5717\n",
      "Epoch 42/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9268 - accuracy: 0.5732 E\n",
      "Epoch 00042: val_loss improved from 0.92770 to 0.92757, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9268 - accuracy: 0.5732 - val_loss: 0.9276 - val_accuracy: 0.5731\n",
      "Epoch 43/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9272 - accuracy: 0.5730\n",
      "Epoch 00043: val_loss did not improve from 0.92757\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9272 - accuracy: 0.5730 - val_loss: 0.9278 - val_accuracy: 0.5725\n",
      "Epoch 44/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9270 - accuracy: 0.5730\n",
      "Epoch 00044: val_loss improved from 0.92757 to 0.92754, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9269 - accuracy: 0.5731 - val_loss: 0.9275 - val_accuracy: 0.5729\n",
      "Epoch 45/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9262 - accuracy: 0.5737\n",
      "Epoch 00045: val_loss did not improve from 0.92754\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9263 - accuracy: 0.5735 - val_loss: 0.9287 - val_accuracy: 0.5717\n",
      "Epoch 46/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9260 - accuracy: 0.5740\n",
      "Epoch 00046: val_loss did not improve from 0.92754\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9260 - accuracy: 0.5740 - val_loss: 0.9281 - val_accuracy: 0.5721\n",
      "Epoch 47/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9253 - accuracy: 0.5746\n",
      "Epoch 00047: val_loss improved from 0.92754 to 0.92744, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.2_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9253 - accuracy: 0.5746 - val_loss: 0.9274 - val_accuracy: 0.5729\n",
      "Epoch 48/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9258 - accuracy: 0.5743\n",
      "Epoch 00048: val_loss did not improve from 0.92744\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9258 - accuracy: 0.5743 - val_loss: 0.9276 - val_accuracy: 0.5727\n",
      "Epoch 49/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9261 - accuracy: 0.5739\n",
      "Epoch 00049: val_loss did not improve from 0.92744\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9261 - accuracy: 0.5740 - val_loss: 0.9278 - val_accuracy: 0.5727\n",
      "Epoch 50/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9261 - accuracy: 0.5740\n",
      "Epoch 00050: val_loss did not improve from 0.92744\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9260 - accuracy: 0.5740 - val_loss: 0.9275 - val_accuracy: 0.5730\n",
      "accuracy: 57.30%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "Epoch 1/50\n",
      "   2/2013 [..............................] - ETA: 29:17 - loss: 0.9880 - accuracy: 0.5391WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0087s vs `on_train_batch_end` time: 1.7400s). Check your callbacks.\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9950 - accuracy: 0.5081\n",
      "Epoch 00001: val_loss improved from inf to 0.98287, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9949 - accuracy: 0.5081 - val_loss: 0.9829 - val_accuracy: 0.5172\n",
      "Epoch 2/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9827 - accuracy: 0.5249\n",
      "Epoch 00002: val_loss improved from 0.98287 to 0.95854, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9827 - accuracy: 0.5249 - val_loss: 0.9585 - val_accuracy: 0.5463\n",
      "Epoch 3/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.5388 ETA: \n",
      "Epoch 00003: val_loss improved from 0.95854 to 0.94874, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9687 - accuracy: 0.5388 - val_loss: 0.9487 - val_accuracy: 0.5545\n",
      "Epoch 4/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9584 - accuracy: 0.5469\n",
      "Epoch 00004: val_loss improved from 0.94874 to 0.94304, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9585 - accuracy: 0.5469 - val_loss: 0.9430 - val_accuracy: 0.5590\n",
      "Epoch 5/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9515 - accuracy: 0.5524\n",
      "Epoch 00005: val_loss improved from 0.94304 to 0.94087, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9515 - accuracy: 0.5524 - val_loss: 0.9409 - val_accuracy: 0.5603\n",
      "Epoch 6/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9467 - accuracy: 0.5559\n",
      "Epoch 00006: val_loss improved from 0.94087 to 0.93913, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9466 - accuracy: 0.5559 - val_loss: 0.9391 - val_accuracy: 0.5614\n",
      "Epoch 7/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9432 - accuracy: 0.5583\n",
      "Epoch 00007: val_loss improved from 0.93913 to 0.93621, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9432 - accuracy: 0.5583 - val_loss: 0.9362 - val_accuracy: 0.5646\n",
      "Epoch 8/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9403 - accuracy: 0.5613\n",
      "Epoch 00008: val_loss did not improve from 0.93621\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9401 - accuracy: 0.5615 - val_loss: 0.9380 - val_accuracy: 0.5622\n",
      "Epoch 9/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9391 - accuracy: 0.5621\n",
      "Epoch 00009: val_loss did not improve from 0.93621\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9390 - accuracy: 0.5621 - val_loss: 0.9366 - val_accuracy: 0.5639\n",
      "Epoch 10/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9375 - accuracy: 0.5633\n",
      "Epoch 00010: val_loss improved from 0.93621 to 0.93388, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9375 - accuracy: 0.5633 - val_loss: 0.9339 - val_accuracy: 0.5672\n",
      "Epoch 11/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9369 - accuracy: 0.5638\n",
      "Epoch 00011: val_loss did not improve from 0.93388\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9369 - accuracy: 0.5639 - val_loss: 0.9349 - val_accuracy: 0.5661\n",
      "Epoch 12/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9372 - accuracy: 0.5631\n",
      "Epoch 00012: val_loss did not improve from 0.93388\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9371 - accuracy: 0.5632 - val_loss: 0.9349 - val_accuracy: 0.5658\n",
      "Epoch 13/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9360 - accuracy: 0.5646\n",
      "Epoch 00013: val_loss did not improve from 0.93388\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9359 - accuracy: 0.5646 - val_loss: 0.9369 - val_accuracy: 0.5632\n",
      "Epoch 14/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9359 - accuracy: 0.5646\n",
      "Epoch 00014: val_loss did not improve from 0.93388\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9358 - accuracy: 0.5647 - val_loss: 0.9367 - val_accuracy: 0.5637\n",
      "Epoch 15/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.5657\n",
      "Epoch 00015: val_loss did not improve from 0.93388\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9347 - accuracy: 0.5657 - val_loss: 0.9342 - val_accuracy: 0.5659\n",
      "Epoch 16/50\n",
      "2004/2013 [============================>.] - ETA: 0s - loss: 0.9353 - accuracy: 0.5643\n",
      "Epoch 00016: val_loss improved from 0.93388 to 0.93373, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9353 - accuracy: 0.5643 - val_loss: 0.9337 - val_accuracy: 0.5663\n",
      "Epoch 17/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9346 - accuracy: 0.5659\n",
      "Epoch 00017: val_loss did not improve from 0.93373\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9345 - accuracy: 0.5660 - val_loss: 0.9347 - val_accuracy: 0.5660\n",
      "Epoch 18/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9350 - accuracy: 0.5651\n",
      "Epoch 00018: val_loss did not improve from 0.93373\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9350 - accuracy: 0.5651 - val_loss: 0.9366 - val_accuracy: 0.5634\n",
      "Epoch 19/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9362 - accuracy: 0.5638\n",
      "Epoch 00019: val_loss did not improve from 0.93373\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9363 - accuracy: 0.5638 - val_loss: 0.9348 - val_accuracy: 0.5650\n",
      "Epoch 20/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9343 - accuracy: 0.5659\n",
      "Epoch 00020: val_loss did not improve from 0.93373\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9344 - accuracy: 0.5659 - val_loss: 0.9359 - val_accuracy: 0.5643\n",
      "Epoch 21/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9348 - accuracy: 0.5656\n",
      "Epoch 00021: val_loss improved from 0.93373 to 0.93306, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9348 - accuracy: 0.5657 - val_loss: 0.9331 - val_accuracy: 0.5676\n",
      "Epoch 22/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.5651\n",
      "Epoch 00022: val_loss improved from 0.93306 to 0.93280, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9354 - accuracy: 0.5651 - val_loss: 0.9328 - val_accuracy: 0.5677\n",
      "Epoch 23/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9358 - accuracy: 0.5646\n",
      "Epoch 00023: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 10s 5ms/step - loss: 0.9358 - accuracy: 0.5646 - val_loss: 0.9371 - val_accuracy: 0.5632\n",
      "Epoch 24/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9355 - accuracy: 0.5649\n",
      "Epoch 00024: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9355 - accuracy: 0.5648 - val_loss: 0.9345 - val_accuracy: 0.5657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9347 - accuracy: 0.5654\n",
      "Epoch 00025: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9347 - accuracy: 0.5654 - val_loss: 0.9371 - val_accuracy: 0.5635\n",
      "Epoch 26/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9347 - accuracy: 0.5653\n",
      "Epoch 00026: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9347 - accuracy: 0.5653 - val_loss: 0.9376 - val_accuracy: 0.5626\n",
      "Epoch 27/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9340 - accuracy: 0.5660\n",
      "Epoch 00027: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9340 - accuracy: 0.5660 - val_loss: 0.9341 - val_accuracy: 0.5662\n",
      "Epoch 28/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9328 - accuracy: 0.5678\n",
      "Epoch 00028: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 9s 4ms/step - loss: 0.9328 - accuracy: 0.5678 - val_loss: 0.9346 - val_accuracy: 0.5658\n",
      "Epoch 29/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.5663\n",
      "Epoch 00029: val_loss did not improve from 0.93280\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9339 - accuracy: 0.5663 - val_loss: 0.9336 - val_accuracy: 0.5667\n",
      "Epoch 30/50\n",
      "2013/2013 [==============================] - ETA: 0s - loss: 0.9340 - accuracy: 0.5662\n",
      "Epoch 00030: val_loss improved from 0.93280 to 0.93165, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9340 - accuracy: 0.5662 - val_loss: 0.9316 - val_accuracy: 0.5688\n",
      "Epoch 31/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9334 - accuracy: 0.5668\n",
      "Epoch 00031: val_loss improved from 0.93165 to 0.93089, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9334 - accuracy: 0.5668 - val_loss: 0.9309 - val_accuracy: 0.5691\n",
      "Epoch 32/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.5670\n",
      "Epoch 00032: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9331 - accuracy: 0.5670 - val_loss: 0.9330 - val_accuracy: 0.5669\n",
      "Epoch 33/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9352 - accuracy: 0.5647\n",
      "Epoch 00033: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9353 - accuracy: 0.5648 - val_loss: 0.9334 - val_accuracy: 0.5667\n",
      "Epoch 34/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9328 - accuracy: 0.5674\n",
      "Epoch 00034: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9328 - accuracy: 0.5674 - val_loss: 0.9332 - val_accuracy: 0.5668\n",
      "Epoch 35/50\n",
      "2012/2013 [============================>.] - ETA: 0s - loss: 0.9322 - accuracy: 0.5677\n",
      "Epoch 00035: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9323 - accuracy: 0.5677 - val_loss: 0.9309 - val_accuracy: 0.5692\n",
      "Epoch 36/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9325 - accuracy: 0.5677 ETA: 0s - loss: 0.9326 - accuracy: 0.\n",
      "Epoch 00036: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9324 - accuracy: 0.5677 - val_loss: 0.9312 - val_accuracy: 0.5693\n",
      "Epoch 37/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9311 - accuracy: 0.5690\n",
      "Epoch 00037: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9313 - accuracy: 0.5688 - val_loss: 0.9336 - val_accuracy: 0.5668\n",
      "Epoch 38/50\n",
      "2010/2013 [============================>.] - ETA: 0s - loss: 0.9309 - accuracy: 0.5690\n",
      "Epoch 00038: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9309 - accuracy: 0.5689 - val_loss: 0.9343 - val_accuracy: 0.5660\n",
      "Epoch 39/50\n",
      "2007/2013 [============================>.] - ETA: 0s - loss: 0.9307 - accuracy: 0.5692\n",
      "Epoch 00039: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9307 - accuracy: 0.5692 - val_loss: 0.9310 - val_accuracy: 0.5695\n",
      "Epoch 40/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.5696\n",
      "Epoch 00040: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9302 - accuracy: 0.5696 - val_loss: 0.9314 - val_accuracy: 0.5691\n",
      "Epoch 41/50\n",
      "2005/2013 [============================>.] - ETA: 0s - loss: 0.9292 - accuracy: 0.5708\n",
      "Epoch 00041: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9292 - accuracy: 0.5709 - val_loss: 0.9325 - val_accuracy: 0.5676\n",
      "Epoch 42/50\n",
      "2003/2013 [============================>.] - ETA: 0s - loss: 0.9295 - accuracy: 0.5703\n",
      "Epoch 00042: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9295 - accuracy: 0.5703 - val_loss: 0.9313 - val_accuracy: 0.5689\n",
      "Epoch 43/50\n",
      "2008/2013 [============================>.] - ETA: 0s - loss: 0.9295 - accuracy: 0.5705\n",
      "Epoch 00043: val_loss did not improve from 0.93089\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9295 - accuracy: 0.5705 - val_loss: 0.9322 - val_accuracy: 0.5679\n",
      "Epoch 44/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9296 - accuracy: 0.5706\n",
      "Epoch 00044: val_loss improved from 0.93089 to 0.93051, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9294 - accuracy: 0.5706 - val_loss: 0.9305 - val_accuracy: 0.5702\n",
      "Epoch 45/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9299 - accuracy: 0.5700\n",
      "Epoch 00045: val_loss did not improve from 0.93051\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9301 - accuracy: 0.5699 - val_loss: 0.9311 - val_accuracy: 0.5692\n",
      "Epoch 46/50\n",
      "2002/2013 [============================>.] - ETA: 0s - loss: 0.9293 - accuracy: 0.5704\n",
      "Epoch 00046: val_loss did not improve from 0.93051\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9294 - accuracy: 0.5704 - val_loss: 0.9311 - val_accuracy: 0.5689\n",
      "Epoch 47/50\n",
      "2009/2013 [============================>.] - ETA: 0s - loss: 0.9292 - accuracy: 0.5708\n",
      "Epoch 00047: val_loss improved from 0.93051 to 0.93047, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9292 - accuracy: 0.5708 - val_loss: 0.9305 - val_accuracy: 0.5698\n",
      "Epoch 48/50\n",
      "2011/2013 [============================>.] - ETA: 0s - loss: 0.9290 - accuracy: 0.5709\n",
      "Epoch 00048: val_loss improved from 0.93047 to 0.93024, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9290 - accuracy: 0.5710 - val_loss: 0.9302 - val_accuracy: 0.5700\n",
      "Epoch 49/50\n",
      "2001/2013 [============================>.] - ETA: 0s - loss: 0.9287 - accuracy: 0.5715\n",
      "Epoch 00049: val_loss did not improve from 0.93024\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9285 - accuracy: 0.5716 - val_loss: 0.9304 - val_accuracy: 0.5700\n",
      "Epoch 50/50\n",
      "2006/2013 [============================>.] - ETA: 0s - loss: 0.9289 - accuracy: 0.5711\n",
      "Epoch 00050: val_loss improved from 0.93024 to 0.93018, saving model to C:\\Users\\mqian\\Documents\\senior schoolwork\\syslab\\model\\model_9\\best_try_9.299999999999999_1.h5\n",
      "2013/2013 [==============================] - 8s 4ms/step - loss: 0.9289 - accuracy: 0.5711 - val_loss: 0.9302 - val_accuracy: 0.5702\n",
      "accuracy: 57.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with plot\n",
      "57.24% (+/- 0.15%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_train, y_train_0):\n",
    "    # create model\n",
    "    num = float(num)\n",
    "    num = num + 0.1\n",
    "    num = str(num)\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[19]),\n",
    "        keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        keras.layers.Dropout(.3),\n",
    "        keras.layers.experimental.RandomFourierFeatures(output_dim=20, kernel_initializer='gaussian'),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='hinge', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    # Callbacks\n",
    "    NAME = \"Survivability-200-150-100-D-BN-He-{0}-{1}\".format(time.time(), num)\n",
    "    tensorboard = TensorBoard(log_dir=\"{0}\\\\logs\\\\{1}\".format(path, NAME))\n",
    "    \n",
    "    onecycle = OneCycleScheduler(len(X_train) // batch_size * epochs, max_rate=0.001)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(path+folder+'best_try_'+num+'_1.h5', monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "    callbacks = [checkpoint, onecycle, tensorboard]\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train_0, epochs=epochs, batch_size=batch_size, \n",
    "                        validation_data=(X_test, y_test_0), callbacks = callbacks)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_test, y_test_0, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    savepickle(path, folder, 'history_'+num+'_1', history)\n",
    "    plotdata(path, folder, 'plot_'+num+'_1', history)\n",
    "    model.save_weights(path+folder+'try_'+num+'_1.h5')\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[19]),\n",
    "    keras.layers.Dense(200, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(.3),\n",
    " keras.layers.experimental.RandomFourierFeatures(output_dim=20, kernel_initializer='gaussian'),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "\n",
    "plot_model(model, to_file='model_plot_rbf_svm.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
